{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DznW7BNex-hd",
        "outputId": "709ce6e2-fea2-4f1e-f3e3-c6f70c110522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.12\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.26)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.37.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.43.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.11.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.12.0 numpy-1.23.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "91435e076bf6413aa982fa64ce2f4404",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tensorflow==2.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvh1CAmlSd82"
      },
      "source": [
        "## Prerequisite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yJLUUThyFDa"
      },
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b74l0wAtgWzn",
        "outputId": "63b75f30-c83b-470e-a7a8-0144846ae224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sklearn-evaluation\n",
            "  Downloading sklearn_evaluation-0.12.1-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.2/111.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ploomber-core>=0.2.6 (from sklearn-evaluation)\n",
            "  Downloading ploomber_core-0.2.25-py3-none-any.whl (22 kB)\n",
            "Collecting ploomber-extension (from sklearn-evaluation)\n",
            "  Downloading ploomber_extension-0.1.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (3.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (4.4.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (0.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (3.1.4)\n",
            "Requirement already satisfied: mistune in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (0.8.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (2.0.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (5.10.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (7.34.0)\n",
            "Collecting black (from sklearn-evaluation)\n",
            "  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (0.8.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ploomber-core>=0.2.6->sklearn-evaluation) (6.0.1)\n",
            "Collecting posthog (from ploomber-core>=0.2.6->sklearn-evaluation)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->sklearn-evaluation)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (24.1)\n",
            "Collecting pathspec>=0.9.0 (from black->sklearn-evaluation)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (4.12.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->sklearn-evaluation)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->sklearn-evaluation) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (1.23.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->sklearn-evaluation) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->sklearn-evaluation) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->sklearn-evaluation) (5.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sklearn-evaluation) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sklearn-evaluation) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-evaluation) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-evaluation) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-evaluation) (3.5.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (0.18.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->sklearn-evaluation) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->sklearn-evaluation) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->sklearn-evaluation) (1.16.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from posthog->ploomber-core>=0.2.6->sklearn-evaluation) (2.31.0)\n",
            "Collecting monotonic>=1.5 (from posthog->ploomber-core>=0.2.6->sklearn-evaluation)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->ploomber-core>=0.2.6->sklearn-evaluation)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (2024.6.2)\n",
            "Installing collected packages: monotonic, pathspec, mypy-extensions, jedi, backoff, posthog, black, ploomber-core, ploomber-extension, sklearn-evaluation\n",
            "Successfully installed backoff-2.2.1 black-24.4.2 jedi-0.19.1 monotonic-1.6 mypy-extensions-1.0.0 pathspec-0.12.1 ploomber-core-0.2.25 ploomber-extension-0.1.1 posthog-3.5.0 sklearn-evaluation-0.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn-evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaL2ks-meLOL",
        "outputId": "d6a1adcb-d635-4167-ebd5-844bf1dbc2b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/159.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m122.9/159.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZswIb7QaVmC",
        "outputId": "9283e7bb-89cb-4f4d-9282-e4ea4f624acd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting plotly.express\n",
            "  Downloading plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from plotly.express) (2.0.3)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from plotly.express) (5.15.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from plotly.express) (0.14.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from plotly.express) (1.11.4)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.10/dist-packages (from plotly.express) (0.5.6)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.10/dist-packages (from plotly.express) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->plotly.express) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->plotly.express) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->plotly.express) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5->plotly.express) (1.16.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.1.0->plotly.express) (8.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.1.0->plotly.express) (24.1)\n",
            "Installing collected packages: plotly.express\n",
            "Successfully installed plotly.express-0.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install plotly.express"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoTuyH3VsxAI",
        "outputId": "2cc8a3e8-8878-4f37-b378-f8d148888c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deploy Flask apps for free on Ploomber Cloud! Learn more: https://ploomber.io/s/signup\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "\n",
        "# Data utilities\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "# Data visualization\n",
        "import plotly.express as px\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, make_scorer, f1_score, recall_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn_evaluation import plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdo1PbAg2dWN",
        "outputId": "1a5412a0-864e-42a4-be6e-84b97021413e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydyh-KnUWTNV"
      },
      "source": [
        "## Utility Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MIcQL7TV7AE"
      },
      "outputs": [],
      "source": [
        "# Utility function: plot model's accuracy and loss\n",
        "\n",
        "# https://realpython.com/python-keras-text-classification/\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  x = range(1, len(acc) + 1)\n",
        "\n",
        "  plt.figure(figsize=(12, 5))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(x, acc, 'b', label='Training acc')\n",
        "  plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(x, loss, 'b', label='Training loss')\n",
        "  plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1miZbCjfWcl3"
      },
      "outputs": [],
      "source": [
        "# Utility function: Display model score(Loss & Accuracy) across all sets.\n",
        "\n",
        "def display_model_score(model, train, val, test, batch_size):\n",
        "\n",
        "  train_score = model.evaluate(train[0], train[1], batch_size=batch_size, verbose=1)\n",
        "  print('Train loss: ', train_score[0])\n",
        "  print('Train accuracy: ', train_score[1])\n",
        "  print('-'*70)\n",
        "\n",
        "  val_score = model.evaluate(val[0], val[1], batch_size=batch_size, verbose=1)\n",
        "  print('Val loss: ', val_score[0])\n",
        "  print('Val accuracy: ', val_score[1])\n",
        "  print('-'*70)\n",
        "\n",
        "  test_score = model.evaluate(test[0], test[1], batch_size=batch_size, verbose=1)\n",
        "  print('Test loss: ', test_score[0])\n",
        "  print('Test accuracy: ', test_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpxhCHwhne2g"
      },
      "outputs": [],
      "source": [
        "def equal_error_rate(y_true, y_pred):\n",
        "    n_imp = tf.count_nonzero(tf.equal(y_true, 0), dtype=tf.float32) + tf.constant(K.epsilon())\n",
        "    n_gen = tf.count_nonzero(tf.equal(y_true, 1), dtype=tf.float32) + tf.constant(K.epsilon())\n",
        "\n",
        "    scores_imp = tf.boolean_mask(y_pred, tf.equal(y_true, 0))\n",
        "    scores_gen = tf.boolean_mask(y_pred, tf.equal(y_true, 1))\n",
        "\n",
        "    loop_vars = (tf.constant(0.0), tf.constant(1.0), tf.constant(0.0))\n",
        "    cond = lambda t, fpr, fnr: tf.greater_equal(fpr, fnr)\n",
        "    body = lambda t, fpr, fnr: (\n",
        "        t + 0.001,\n",
        "        tf.divide(tf.count_nonzero(tf.greater_equal(scores_imp, t), dtype=tf.float32), n_imp),\n",
        "        tf.divide(tf.count_nonzero(tf.less(scores_gen, t), dtype=tf.float32), n_gen)\n",
        "    )\n",
        "    t, fpr, fnr = tf.while_loop(cond, body, loop_vars, back_prop=False)\n",
        "    eer = (fpr + fnr) / 2\n",
        "\n",
        "    return eer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIt5zirSvOsV"
      },
      "outputs": [],
      "source": [
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTZaj-RZHjTn"
      },
      "outputs": [],
      "source": [
        "def error_rate(testing_labels, predicted_testing_labels):\n",
        "    from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score, classification_report, recall_score, confusion_matrix\n",
        "    import numpy as np\n",
        "\n",
        "    bootstrap_performances = list()\n",
        "    performances = list()\n",
        "    f1_performances = list()\n",
        "    sn = list()\n",
        "    sp = list()\n",
        "    Y = np.array(testing_labels)  # convert list of groundtruths to numpy\n",
        "    Yhat = np.array(predicted_testing_labels)  # same same for predictions\n",
        "    n_samples = len(Y)  # get number of samples\n",
        "    n_bootstrap = 1000  # number of bootstrap iterations\n",
        "\n",
        "    for i in range(n_bootstrap):  # for each bootstrap draw\n",
        "        subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        # create a random subset of your predictions/targets with replacement\n",
        "        Y_subset = Y[subset]\n",
        "        Yhat_subset = Yhat[subset]\n",
        "\n",
        "        bootstrap_performances.append(matthews_corrcoef(Y_subset, Yhat_subset))\n",
        "        performances.append(accuracy_score(Y_subset, Yhat_subset))\n",
        "        f1_performances.append(f1_score(Y_subset, Yhat_subset))\n",
        "        sn.append(recall_score(Y_subset, Yhat_subset))\n",
        "\n",
        "        tn, fp, fn, tp = confusion_matrix(Y_subset, Yhat_subset).ravel()\n",
        "        sp.append(tn / (tn + fp))\n",
        "\n",
        "    sd_mcc = np.std(bootstrap_performances)  # compute std deviation over the bootstrapped performances\n",
        "    sd_acc = np.std(performances)\n",
        "    sd_f1 = np.std(f1_performances)\n",
        "    sd_sn = np.std(sn)\n",
        "    sd_sp = np.std(sp)\n",
        "\n",
        "    print('acc:', accuracy_score(testing_labels, predicted_testing_labels))\n",
        "    print('f1:', f1_score(testing_labels, predicted_testing_labels))\n",
        "    print('mcc:', matthews_corrcoef(testing_labels, predicted_testing_labels))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(testing_labels, predicted_testing_labels).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    print('sn:', recall_score(testing_labels, predicted_testing_labels))\n",
        "    print('sp:', specificity)\n",
        "    print('sd_acc:', sd_acc)\n",
        "    print('sd_f1:', sd_f1)\n",
        "    print('sd_mcc:', sd_mcc)\n",
        "    print('sd_sn:', sd_sn)\n",
        "    print('sd_sp:', sd_sp)\n",
        "    print(classification_report(testing_labels, predicted_testing_labels))\n",
        "\n",
        "    return (sd_acc, sd_mcc, sd_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQ0RjSyMHkAJ"
      },
      "outputs": [],
      "source": [
        "def conf_matrix(confusion_matrix_data):\n",
        "  from mlxtend.plotting import plot_confusion_matrix\n",
        "  fig, ax = plot_confusion_matrix(conf_mat =confusion_matrix_data,\n",
        "                                show_absolute=True,\n",
        "                                show_normed=True,\n",
        "                                #display_labels=class_dict.values(),\n",
        "                                colorbar=True)\n",
        "  labels = ['Non-halophilic', 'Halophilic']\n",
        "  ax.set_xticklabels([''] + labels)\n",
        "  ax.set_yticklabels([''] + labels)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkglNc-EcVv_"
      },
      "outputs": [],
      "source": [
        "def mcc(clf,X,y):\n",
        "  y_pred = clf.predict(X)\n",
        "  mcc = matthews_corrcoef(y, y_pred)\n",
        "  return mcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wwFOnySchG-"
      },
      "outputs": [],
      "source": [
        "def std_acc(clf,X,y):\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  import numpy as np\n",
        "\n",
        "  bootstrap_performances = list()\n",
        "  performances = list()\n",
        "  y_pred = clf.predict(X)\n",
        "  Y = np.array(y) # convert list of groundtruths to numpy\n",
        "  Yhat = np.array(y_pred) # same same for predictions\n",
        "  n_samples = len(Y) # get number of samples\n",
        "  n_bootstrap = 1000 # number of bootstrap iterations\n",
        "  for i in range(n_bootstrap): # for each bootstrap draw\n",
        "    subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    # create a random subset of your predictions/targets with replacement (this line will only generate the indices for list elements and the line below will grab the random subset with replacement\n",
        "    bootstrap_performances.append( accuracy_score(y[subset], y_pred[subset]) )\n",
        "  sd_acc = np.std(bootstrap_performances)*1.96\n",
        "  return sd_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQm6_4VUcjlN"
      },
      "outputs": [],
      "source": [
        "def std_f1(clf,X,y):\n",
        "  from sklearn.metrics import f1_score\n",
        "  import numpy as np\n",
        "\n",
        "  bootstrap_performances = list()\n",
        "  performances = list()\n",
        "  y_pred = clf.predict(X)\n",
        "  Y = np.array(y) # convert list of groundtruths to numpy\n",
        "  Yhat = np.array(y_pred) # same same for predictions\n",
        "  n_samples = len(Y) # get number of samples\n",
        "  n_bootstrap = 1000 # number of bootstrap iterations\n",
        "  for i in range(n_bootstrap): # for each bootstrap draw\n",
        "    subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    # create a random subset of your predictions/targets with replacement (this line will only generate the indices for list elements and the line below will grab the random subset with replacement\n",
        "    bootstrap_performances.append(f1_score(y[subset], y_pred[subset]) )\n",
        "  sd_f1 = np.std(bootstrap_performances)*1.96\n",
        "  return sd_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GecjuMJLclwq"
      },
      "outputs": [],
      "source": [
        "def std_mcc(clf,X,y):\n",
        "  from sklearn.metrics import matthews_corrcoef\n",
        "  import numpy as np\n",
        "\n",
        "  bootstrap_performances = list()\n",
        "  performances = list()\n",
        "  y_pred = clf.predict(X)\n",
        "  Y = np.array(y) # convert list of groundtruths to numpy\n",
        "  Yhat = np.array(y_pred) # same same for predictions\n",
        "  n_samples = len(Y) # get number of samples\n",
        "  n_bootstrap = 1000 # number of bootstrap iterations\n",
        "  for i in range(n_bootstrap): # for each bootstrap draw\n",
        "    subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    # create a random subset of your predictions/targets with replacement (this line will only generate the indices for list elements and the line below will grab the random subset with replacement\n",
        "    bootstrap_performances.append(matthews_corrcoef(y[subset], y_pred[subset]) )\n",
        "  sd_mcc = np.std(bootstrap_performances)*1.96\n",
        "  return sd_mcc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrEQOWRAufE"
      },
      "source": [
        "## Open embedding file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8A4aZOotEMQ",
        "outputId": "2d5ba04a-f80e-44cd-fd96-9ba096d6663d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-19 15:28:30--  https://raw.githubusercontent.com/33220311/halophilic/main/dataset/haloAdd.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1362849 (1.3M) [text/plain]\n",
            "Saving to: ‘haloAdd.csv’\n",
            "\n",
            "haloAdd.csv         100%[===================>]   1.30M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-06-19 15:28:31 (19.9 MB/s) - ‘haloAdd.csv’ saved [1362849/1362849]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "proteins = []\n",
        "!wget https://raw.githubusercontent.com/33220311/halophilic/main/dataset/haloAdd.csv\n",
        "#!wget https://raw.githubusercontent.com/33220311/halophilic/main/dataset/haloNath.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT3TeC09C_8Z",
        "outputId": "f52826c1-4412-4cf1-c9d6-b9b23f3c3fdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-19 15:28:31--  https://github.com/33220311/Extremophilic/raw/main/Embeddings/haloAdd.h5\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/33220311/Extremophilic/main/Embeddings/haloAdd.h5 [following]\n",
            "--2024-06-19 15:28:31--  https://raw.githubusercontent.com/33220311/Extremophilic/main/Embeddings/haloAdd.h5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18247096 (17M) [application/octet-stream]\n",
            "Saving to: ‘haloAdd.h5’\n",
            "\n",
            "haloAdd.h5          100%[===================>]  17.40M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-06-19 15:28:32 (138 MB/s) - ‘haloAdd.h5’ saved [18247096/18247096]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/33220311/Extremophilic/raw/main/Embeddings/haloAdd.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eScyOlMFtGjH"
      },
      "outputs": [],
      "source": [
        "with h5py.File('haloAdd.h5', 'r') as f:\n",
        "    for new_identifier in f.keys():\n",
        "        proteins.append((new_identifier, np.array(f[new_identifier])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l68btnmGrtF7"
      },
      "outputs": [],
      "source": [
        "#with h5py.File('haloRed2.h5', 'r') as f:\n",
        "#    for new_identifier in f.keys():\n",
        "#        proteins.append((new_identifier, np.array(f[new_identifier])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L84gHo7frtvZ"
      },
      "outputs": [],
      "source": [
        "#with h5py.File('halo_embds.h5', 'r') as f:\n",
        "#    for new_identifier in f.keys():\n",
        "#        proteins.append((new_identifier, np.array(f[new_identifier])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ4bWHvtsLbG"
      },
      "outputs": [],
      "source": [
        "#with h5py.File('thermophilic_embeddings.h5', 'r') as f:\n",
        "#    for new_identifier in f.keys():\n",
        "#        proteins.append((new_identifier, np.array(f[new_identifier])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMRGRSLItYc3"
      },
      "outputs": [],
      "source": [
        "#with h5py.File('halophilic_embeddings.h5', 'r') as f:\n",
        "#    for new_identifier in f.keys():\n",
        "#        proteins.append((new_identifier, np.array(f[new_identifier])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abJp6wZvtUb2",
        "outputId": "6cb5d6f0-1ba6-45b7-b2f9-44b0b8036211"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('17KD_RICPR',\n",
              "  array([[ 0.0507  ,  0.04422 ,  0.04874 , ..., -0.01797 ,  0.012634,\n",
              "          -0.0263  ]], dtype=float16)),\n",
              " ('3HAO_PSEFL',\n",
              "  array([[ 0.03503 ,  0.009346,  0.03093 , ..., -0.03087 ,  0.02304 ,\n",
              "           0.03967 ]], dtype=float16)),\n",
              " ('3MDO_PSEAE',\n",
              "  array([[ 0.01591,  0.01863, -0.0296 , ..., -0.0056 , -0.01912,  0.0237 ]],\n",
              "        dtype=float16)),\n",
              " ('5C1CA',\n",
              "  array([[-0.0231  , -0.00796 ,  0.0429  , ...,  0.006405,  0.00494 ,\n",
              "          -0.002222]], dtype=float16)),\n",
              " ('6H82D',\n",
              "  array([[ 0.0531 ,  0.06793,  0.02309, ...,  0.0322 ,  0.0666 , -0.00908]],\n",
              "        dtype=float16)),\n",
              " ('6OJ0_Z',\n",
              "  array([[ 0.04663,  0.03262,  0.02162, ..., -0.03275,  0.07367,  0.03656]],\n",
              "        dtype=float16)),\n",
              " ('6OJ0_f',\n",
              "  array([[0.0439  , 0.011536, 0.0853  , ..., 0.0461  , 0.0455  , 0.02231 ]],\n",
              "        dtype=float16)),\n",
              " ('6PGL_THEMA',\n",
              "  array([[ 7.538e-02,  1.711e-05,  7.983e-02, ..., -1.578e-04,  6.598e-02,\n",
              "           2.870e-02]], dtype=float16)),\n",
              " ('AAC82870',\n",
              "  array([[ 0.037   , -0.1256  , -0.003265, ...,  0.003574, -0.00943 ,\n",
              "           0.0628  ]], dtype=float16)),\n",
              " ('AAC82872',\n",
              "  array([[ 0.0569 ,  0.06586, -0.02461, ..., -0.01209,  0.00182,  0.02016]],\n",
              "        dtype=float16)),\n",
              " ('AACC1_PSEAI',\n",
              "  array([[ 0.01677 , -0.03885 , -0.0383  , ...,  0.02365 ,  0.003164,\n",
              "           0.03488 ]], dtype=float16)),\n",
              " ('AACP_AGRFC',\n",
              "  array([[ 0.02637 , -0.04584 ,  0.0348  , ..., -0.04602 ,  0.005352,\n",
              "           0.02922 ]], dtype=float16)),\n",
              " ('AADR_RHOPA',\n",
              "  array([[-0.0134  ,  0.004147,  0.01767 , ..., -0.04196 ,  0.03668 ,\n",
              "           0.01445 ]], dtype=float16)),\n",
              " ('AAEB_SHIFL',\n",
              "  array([[ 0.05728 ,  0.04462 ,  0.02658 , ..., -0.01101 , -0.0596  ,\n",
              "          -0.002272]], dtype=float16)),\n",
              " ('AAK14975',\n",
              "  array([[0.02417, 0.1004 , 0.04095, ..., 0.01539, 0.01898, 0.0638 ]],\n",
              "        dtype=float16)),\n",
              " ('AAP41498',\n",
              "  array([[ 0.03123, -0.09265, -0.03973, ..., -0.04172, -0.02873,  0.0121 ]],\n",
              "        dtype=float16)),\n",
              " ('AAS13419',\n",
              "  array([[ 0.004295,  0.02722 , -0.01003 , ...,  0.02258 ,  0.02068 ,\n",
              "          -0.03072 ]], dtype=float16)),\n",
              " ('AAS13421',\n",
              "  array([[ 0.0188  , -0.08844 , -0.01689 , ..., -0.00365 ,  0.02582 ,\n",
              "           0.004944]], dtype=float16)),\n",
              " ('AAV44265',\n",
              "  array([[ 0.0368 , -0.11475, -0.01344, ...,  0.02068,  0.0461 , -0.02815]],\n",
              "        dtype=float16)),\n",
              " ('AAV44354',\n",
              "  array([[ 0.01947 , -0.0355  , -0.03323 , ..., -0.01179 ,  0.003832,\n",
              "           0.00878 ]], dtype=float16)),\n",
              " ('AAV44368',\n",
              "  array([[ 0.05856, -0.04333,  0.04407, ..., -0.03925, -0.04257,  0.0935 ]],\n",
              "        dtype=float16)),\n",
              " ('AAV44371',\n",
              "  array([[-0.02507 ,  0.0686  ,  0.008354, ...,  0.03543 ,  0.02655 ,\n",
              "           0.02737 ]], dtype=float16)),\n",
              " ('AAV44449',\n",
              "  array([[-0.01633,  0.0822 ,  0.02318, ...,  0.04364,  0.0849 , -0.02121]],\n",
              "        dtype=float16)),\n",
              " ('AAV44493',\n",
              "  array([[ 0.02159, -0.07794, -0.01918, ..., -0.01079,  0.06137, -0.0667 ]],\n",
              "        dtype=float16)),\n",
              " ('AAV44566',\n",
              "  array([[ 0.03262, -0.0426 , -0.02261, ...,  0.06018,  0.0451 , -0.02362]],\n",
              "        dtype=float16)),\n",
              " ('AAV44731',\n",
              "  array([[-0.02014  , -0.0003817,  0.073    , ...,  0.05997  ,  0.0499   ,\n",
              "          -0.0786   ]], dtype=float16)),\n",
              " ('AAV45349',\n",
              "  array([[-0.03488 , -0.0342  ,  0.0418  , ...,  0.002365, -0.03857 ,\n",
              "           0.0815  ]], dtype=float16)),\n",
              " ('AAV45378',\n",
              "  array([[ 0.07544 , -0.1829  ,  0.000817, ...,  0.01662 ,  0.0804  ,\n",
              "           0.02736 ]], dtype=float16)),\n",
              " ('AAV45540',\n",
              "  array([[ 0.001936, -0.04236 ,  0.00879 , ...,  0.05515 ,  0.04327 ,\n",
              "           0.00545 ]], dtype=float16)),\n",
              " ('AAV45606',\n",
              "  array([[-0.02596,  0.02205,  0.01921, ...,  0.0878 , -0.03076,  0.01273]],\n",
              "        dtype=float16)),\n",
              " ('AAV45915',\n",
              "  array([[ 0.01682 , -0.0904  ,  0.0598  , ...,  0.00698 ,  0.02484 ,\n",
              "          -0.009254]], dtype=float16)),\n",
              " ('AAV46261',\n",
              "  array([[ 0.0399  , -0.03293 , -0.03087 , ...,  0.0327  ,  0.03262 ,\n",
              "           0.001626]], dtype=float16)),\n",
              " ('AAV46365',\n",
              "  array([[-0.00237 , -0.00576 , -0.04626 , ...,  0.02364 ,  0.004684,\n",
              "           0.01505 ]], dtype=float16)),\n",
              " ('AAV46711',\n",
              "  array([[0.0738 , 0.0335 , 0.01405, ..., 0.0591 , 0.04977, 0.0526 ]],\n",
              "        dtype=float16)),\n",
              " ('AAV46844',\n",
              "  array([[ 0.0225  , -0.09845 , -0.02176 , ..., -0.002508,  0.007526,\n",
              "          -0.01674 ]], dtype=float16)),\n",
              " ('AAV47010',\n",
              "  array([[-0.01046 ,  0.0398  ,  0.01131 , ...,  0.014145, -0.01941 ,\n",
              "          -0.02081 ]], dtype=float16)),\n",
              " ('AAV47111',\n",
              "  array([[ 0.03293, -0.03293, -0.02274, ..., -0.02783,  0.05655,  0.01505]],\n",
              "        dtype=float16)),\n",
              " ('AAV47281',\n",
              "  array([[ 0.08014 , -0.01098 , -0.005222, ...,  0.02094 ,  0.016   ,\n",
              "           0.01288 ]], dtype=float16)),\n",
              " ('AAV47499',\n",
              "  array([[ 0.0465 , -0.047  , -0.02678, ...,  0.0673 ,  0.0378 ,  0.0711 ]],\n",
              "        dtype=float16)),\n",
              " ('AAY24960',\n",
              "  array([[ 0.00846 , -0.0716  ,  0.01458 , ...,  0.03354 ,  0.02069 ,\n",
              "          -0.004726]], dtype=float16)),\n",
              " ('ABE57473',\n",
              "  array([[ 0.04074, -0.04196, -0.04718, ...,  0.1469 ,  0.01846,  0.05508]],\n",
              "        dtype=float16)),\n",
              " ('ABE57481',\n",
              "  array([[-0.06287, -0.0387 , -0.02835, ...,  0.04123,  0.0242 ,  0.04898]],\n",
              "        dtype=float16)),\n",
              " ('ABE57489',\n",
              "  array([[-0.002464, -0.01877 ,  0.006496, ...,  0.004704,  0.01107 ,\n",
              "           0.04153 ]], dtype=float16)),\n",
              " ('ABE57494',\n",
              "  array([[ 0.02481  ,  0.01591  , -0.02534  , ..., -0.01099  , -0.005943 ,\n",
              "           0.0005755]], dtype=float16)),\n",
              " ('ABE57495',\n",
              "  array([[-0.0683 , -0.0647 ,  0.00931, ..., -0.08246,  0.1054 ,  0.00607]],\n",
              "        dtype=float16)),\n",
              " ('ABE57564',\n",
              "  array([[-0.01851 ,  0.009094,  0.04745 , ...,  0.0806  ,  0.002064,\n",
              "          -0.02164 ]], dtype=float16)),\n",
              " ('ABE57667',\n",
              "  array([[-0.006916, -0.03293 ,  0.01613 , ...,  0.0503  ,  0.0083  ,\n",
              "           0.01293 ]], dtype=float16)),\n",
              " ('ABE57687',\n",
              "  array([[0.03748 , 0.0143  , 0.02309 , ..., 0.01012 , 0.006813, 0.0315  ]],\n",
              "        dtype=float16)),\n",
              " ('ABE57960',\n",
              "  array([[-0.00414,  0.03653,  0.02295, ..., -0.01102, -0.04132,  0.03403]],\n",
              "        dtype=float16)),\n",
              " ('ABE58224',\n",
              "  array([[ 0.005436, -0.0375  , -0.00961 , ..., -0.004116, -0.00714 ,\n",
              "           0.04092 ]], dtype=float16)),\n",
              " ('ABE58278',\n",
              "  array([[ 0.001168, -0.005077,  0.01852 , ..., -0.01298 ,  0.02666 ,\n",
              "           0.04413 ]], dtype=float16)),\n",
              " ('ABE58472',\n",
              "  array([[-0.00998 , -0.03952 ,  0.002522, ...,  0.00936 , -0.04272 ,\n",
              "           0.05225 ]], dtype=float16)),\n",
              " ('ABE58488',\n",
              "  array([[ 0.004246, -0.09753 ,  0.003029, ...,  0.03253 ,  0.03986 ,\n",
              "           0.0252  ]], dtype=float16)),\n",
              " ('ABE58558',\n",
              "  array([[ 0.0399  ,  0.0766  ,  0.001381, ...,  0.05756 ,  0.002092,\n",
              "          -0.01003 ]], dtype=float16)),\n",
              " ('ABE58621',\n",
              "  array([[ 0.01685,  0.01156,  0.04913, ..., -0.04727,  0.02025,  0.03354]],\n",
              "        dtype=float16)),\n",
              " ('ABE58729',\n",
              "  array([[ 0.01154 , -0.02086 ,  0.03613 , ..., -0.001119, -0.01862 ,\n",
              "          -0.04163 ]], dtype=float16)),\n",
              " ('ABE58758',\n",
              "  array([[ 0.04904,  0.10187,  0.00815, ...,  0.07495,  0.03165, -0.0663 ]],\n",
              "        dtype=float16)),\n",
              " ('ABE58760',\n",
              "  array([[ 0.04578 , -0.03537 , -0.04385 , ..., -0.02036 ,  0.02896 ,\n",
              "           0.002064]], dtype=float16)),\n",
              " ('ABE58779',\n",
              "  array([[ 0.03168, -0.1382 , -0.0485 , ..., -0.0742 ,  0.1156 ,  0.0668 ]],\n",
              "        dtype=float16)),\n",
              " ('ABE58781',\n",
              "  array([[-0.02039, -0.1232 , -0.05524, ..., -0.04102, -0.00518,  0.0742 ]],\n",
              "        dtype=float16)),\n",
              " ('ABE58849',\n",
              "  array([[ 0.02197 , -0.03506 ,  0.03033 , ...,  0.01373 , -0.001074,\n",
              "          -0.0196  ]], dtype=float16)),\n",
              " ('ABE58926',\n",
              "  array([[ 0.0314  ,  0.1112  ,  0.04178 , ...,  0.015305, -0.006874,\n",
              "           0.03986 ]], dtype=float16)),\n",
              " ('ABE59016',\n",
              "  array([[-0.00587, -0.0894 ,  0.0579 , ...,  0.04633,  0.0762 ,  0.05862]],\n",
              "        dtype=float16)),\n",
              " ('ABE59157',\n",
              "  array([[ 0.007008,  0.00838 , -0.05264 , ...,  0.006687,  0.0226  ,\n",
              "           0.02586 ]], dtype=float16)),\n",
              " ('ABE59170',\n",
              "  array([[ 0.0413  ,  0.007618, -0.00523 , ...,  0.004845, -0.01542 ,\n",
              "           0.0444  ]], dtype=float16)),\n",
              " ('ABE59203',\n",
              "  array([[ 0.0768  ,  0.04282 ,  0.00978 , ..., -0.003504, -0.01528 ,\n",
              "           0.04138 ]], dtype=float16)),\n",
              " ('ABE59204',\n",
              "  array([[ 0.0757  , -0.06113 ,  0.04022 , ...,  0.011116,  0.01289 ,\n",
              "          -0.01588 ]], dtype=float16)),\n",
              " ('ABE59276',\n",
              "  array([[ 0.02171 , -0.003605,  0.0246  , ..., -0.01393 ,  0.0566  ,\n",
              "           0.0551  ]], dtype=float16)),\n",
              " ('ABE59344',\n",
              "  array([[-0.01695 , -0.0045  , -0.002401, ...,  0.07227 ,  0.07355 ,\n",
              "           0.0657  ]], dtype=float16)),\n",
              " ('ABE59379',\n",
              "  array([[ 0.002495, -0.00782 ,  0.006897, ..., -0.00482 , -0.03244 ,\n",
              "           0.0465  ]], dtype=float16)),\n",
              " ('ABE59385',\n",
              "  array([[-0.031   , -0.05634 ,  0.01738 , ..., -0.002232,  0.00569 ,\n",
              "          -0.03348 ]], dtype=float16)),\n",
              " ('ABE59426',\n",
              "  array([[-0.00829,  0.03552,  0.01307, ...,  0.01167, -0.00806,  0.03552]],\n",
              "        dtype=float16)),\n",
              " ('ABE59475',\n",
              "  array([[ 0.0382  , -0.02553 , -0.004448, ...,  0.0167  ,  0.0473  ,\n",
              "           0.00245 ]], dtype=float16)),\n",
              " ('ABE59487',\n",
              "  array([[-0.04214, -0.0451 , -0.04303, ...,  0.0204 ,  0.0362 ,  0.07965]],\n",
              "        dtype=float16)),\n",
              " ('ABE59504',\n",
              "  array([[ 0.0008445, -0.0676   ,  0.03033  , ..., -0.0343   ,  0.03302  ,\n",
              "           0.02252  ]], dtype=float16)),\n",
              " ('ABE59548',\n",
              "  array([[-0.01265, -0.02397, -0.02551, ...,  0.04248,  0.01668,  0.01979]],\n",
              "        dtype=float16)),\n",
              " ('ABE59647',\n",
              "  array([[ 0.03317, -0.01695,  0.02917, ...,  0.02948,  0.02945,  0.04163]],\n",
              "        dtype=float16)),\n",
              " ('ABE59672',\n",
              "  array([[ 0.03915, -0.04404,  0.04068, ...,  0.11115,  0.01289,  0.03268]],\n",
              "        dtype=float16)),\n",
              " ('ABE59713',\n",
              "  array([[ 0.014336,  0.04572 , -0.006516, ..., -0.03093 ,  0.007935,\n",
              "          -0.003353]], dtype=float16)),\n",
              " ('ABE59716',\n",
              "  array([[ 0.04666 ,  0.1225  , -0.0384  , ...,  0.007095, -0.02942 ,\n",
              "          -0.01677 ]], dtype=float16)),\n",
              " ('ABE59840',\n",
              "  array([[-0.01855 ,  0.158   ,  0.01791 , ...,  0.00969 , -0.01973 ,\n",
              "          -0.003256]], dtype=float16)),\n",
              " ('ABE59851',\n",
              "  array([[ 0.11304, -0.03873, -0.04486, ...,  0.0889 ,  0.0636 ,  0.038  ]],\n",
              "        dtype=float16)),\n",
              " ('ABE59852',\n",
              "  array([[ 0.05417 , -0.001546, -0.05084 , ..., -0.01987 ,  0.04214 ,\n",
              "           0.10974 ]], dtype=float16)),\n",
              " ('ABE59866',\n",
              "  array([[0.02132, 0.128  , 0.0656 , ..., 0.05548, 0.03387, 0.046  ]],\n",
              "        dtype=float16)),\n",
              " ('ABE59917',\n",
              "  array([[-0.0385  , -0.08356 ,  0.00696 , ...,  0.002163, -0.03882 ,\n",
              "          -0.00725 ]], dtype=float16)),\n",
              " ('ABE59927',\n",
              "  array([[ 0.02855 ,  0.06323 ,  0.04028 , ..., -0.01032 , -0.005608,\n",
              "          -0.01038 ]], dtype=float16)),\n",
              " ('ABE59987',\n",
              "  array([[0.002964, 0.01622 , 0.02744 , ..., 0.02914 , 0.03165 , 0.007248]],\n",
              "        dtype=float16)),\n",
              " ('ABE60006',\n",
              "  array([[-0.02522 ,  0.008644,  0.02353 , ...,  0.002602, -0.01938 ,\n",
              "          -0.003153]], dtype=float16)),\n",
              " ('ABE60009',\n",
              "  array([[0.0501, 0.0781, 0.0107, ..., 0.0624, 0.0097, 0.0477]],\n",
              "        dtype=float16)),\n",
              " ('ABE60115',\n",
              "  array([[ 0.04785, -0.01784, -0.00262, ...,  0.06042,  0.0685 ,  0.02077]],\n",
              "        dtype=float16)),\n",
              " ('ABE60349',\n",
              "  array([[-0.004513,  0.007397, -0.007786, ...,  0.0335  ,  0.012566,\n",
              "           0.04773 ]], dtype=float16)),\n",
              " ('ABE60476',\n",
              "  array([[-0.01604 ,  0.008545, -0.00797 , ...,  0.02484 , -0.00689 ,\n",
              "           0.03035 ]], dtype=float16)),\n",
              " ('ABE60592',\n",
              "  array([[-0.06665, -0.1423 , -0.02452, ..., -0.02739, -0.019  ,  0.0692 ]],\n",
              "        dtype=float16)),\n",
              " ('ABE60614',\n",
              "  array([[ 0.0491 , -0.01463, -0.03412, ...,  0.04773,  0.04364,  0.05212]],\n",
              "        dtype=float16)),\n",
              " ('ABE60663',\n",
              "  array([[ 0.04156 ,  0.02174 ,  0.05984 , ...,  0.0444  ,  0.01395 ,\n",
              "          -0.001986]], dtype=float16)),\n",
              " ('ABIG2_LACLC',\n",
              "  array([[ 0.0357  ,  0.0679  ,  0.03522 , ...,  0.03564 , -0.000254,\n",
              "          -0.03873 ]], dtype=float16)),\n",
              " ('ABK90831',\n",
              "  array([[ 0.0552  , -0.01837 ,  0.05856 , ..., -0.01883 ,  0.008804,\n",
              "          -0.006695]], dtype=float16)),\n",
              " ('ACAC_PYRFU',\n",
              "  array([[ 0.04303 ,  0.0622  ,  0.0437  , ...,  0.03754 , -0.001429,\n",
              "          -0.006577]], dtype=float16)),\n",
              " ('ACDE1_ARCFU',\n",
              "  array([[-0.006237, -0.04684 ,  0.02875 , ..., -0.02153 ,  0.0657  ,\n",
              "           0.03387 ]], dtype=float16)),\n",
              " ('ACDE_METJA',\n",
              "  array([[-0.00587 , -0.10406 ,  0.02835 , ..., -0.002237,  0.06573 ,\n",
              "           0.01634 ]], dtype=float16)),\n",
              " ('ACDH_THET8',\n",
              "  array([[0.0272 , 0.03183, 0.05286, ..., 0.03903, 0.03827, 0.04053]],\n",
              "        dtype=float16)),\n",
              " ('ACK38174',\n",
              "  array([[0.07367, 0.12103, 0.00812, ..., 0.02425, 0.03595, 0.05347]],\n",
              "        dtype=float16)),\n",
              " ('ACM56960',\n",
              "  array([[-0.02272, -0.04266,  0.0754 , ...,  0.072  ,  0.0918 , -0.03525]],\n",
              "        dtype=float16)),\n",
              " ('ACM57826',\n",
              "  array([[ 0.02301, -0.0322 , -0.02617, ..., -0.0479 ,  0.00819, -0.01875]],\n",
              "        dtype=float16)),\n",
              " ('ACM58056',\n",
              "  array([[-0.04483 ,  0.004677,  0.011696, ...,  0.04025 ,  0.02972 ,\n",
              "           0.01284 ]], dtype=float16)),\n",
              " ('ACM58324',\n",
              "  array([[ 0.04718,  0.0774 , -0.01765, ...,  0.02553,  0.01491, -0.00691]],\n",
              "        dtype=float16)),\n",
              " ('ACM58399',\n",
              "  array([[ 0.000684, -0.10516 , -0.01924 , ...,  0.004383, -0.002705,\n",
              "           0.02206 ]], dtype=float16)),\n",
              " ('ACM58568',\n",
              "  array([[-0.00802 ,  0.02759 , -0.01993 , ..., -0.009056,  0.0732  ,\n",
              "          -0.0538  ]], dtype=float16)),\n",
              " ('ACM58763',\n",
              "  array([[ 0.04794 , -0.05646 , -0.02101 , ...,  0.015335,  0.01554 ,\n",
              "          -0.06964 ]], dtype=float16)),\n",
              " ('ACM58771',\n",
              "  array([[ 0.0145 ,  0.02008,  0.01243, ..., -0.0115 , -0.00941, -0.02515]],\n",
              "        dtype=float16)),\n",
              " ('ACM58846',\n",
              "  array([[-0.004787,  0.0654  , -0.01656 , ...,  0.02667 , -0.0759  ,\n",
              "           0.059   ]], dtype=float16)),\n",
              " ('ACM58888',\n",
              "  array([[ 0.04822,  0.1158 ,  0.03897, ...,  0.04544,  0.02092, -0.01929]],\n",
              "        dtype=float16)),\n",
              " ('ACM59007',\n",
              "  array([[-0.004044,  0.1373  ,  0.0672  , ...,  0.09534 ,  0.01788 ,\n",
              "          -0.08264 ]], dtype=float16)),\n",
              " ('ACP2_SHIFL',\n",
              "  array([[-0.003262 , -0.0303   , -0.012924 , ..., -0.03348  ,  0.0845   ,\n",
              "           0.0006566]], dtype=float16)),\n",
              " ('ACPS_DEIRA',\n",
              "  array([[ 0.001546, -0.01117 ,  0.02473 , ...,  0.00628 ,  0.0463  ,\n",
              "           0.004887]], dtype=float16)),\n",
              " ('ACPS_MYCGE',\n",
              "  array([[-0.03357 , -0.01164 ,  0.005608, ...,  0.01994 ,  0.02696 ,\n",
              "           0.01897 ]], dtype=float16)),\n",
              " ('ACPS_THEMA',\n",
              "  array([[ 0.04907 , -0.0108  ,  0.05157 , ...,  0.0542  ,  0.007225,\n",
              "          -0.01245 ]], dtype=float16)),\n",
              " ('ACP_LACLA',\n",
              "  array([[ 0.02557 , -0.1047  , -0.005516, ...,  0.006035,  0.04886 ,\n",
              "           0.014175]], dtype=float16)),\n",
              " ('ACP_MYXXA',\n",
              "  array([[ 0.02853 , -0.092   ,  0.009476, ..., -0.03494 , -0.02026 ,\n",
              "           0.02837 ]], dtype=float16)),\n",
              " ('ACP_RICPR',\n",
              "  array([[ 0.05594, -0.06824,  0.02046, ..., -0.0344 ,  0.0577 ,  0.05594]],\n",
              "        dtype=float16)),\n",
              " ('ACP_SACEN',\n",
              "  array([[ 0.00992, -0.1047 ,  0.04373, ..., -0.02477,  0.02203,  0.02379]],\n",
              "        dtype=float16)),\n",
              " ('ACP_THEMA',\n",
              "  array([[ 0.03555, -0.0714 ,  0.11487, ...,  0.02   ,  0.05258,  0.08093]],\n",
              "        dtype=float16)),\n",
              " ('ACP_THET8',\n",
              "  array([[ 0.05634 , -0.02501 ,  0.0448  , ...,  0.001182,  0.0499  ,\n",
              "           0.07513 ]], dtype=float16)),\n",
              " ('ACYP_VIBC3',\n",
              "  array([[ 0.03384 , -0.00196 , -0.007317, ..., -0.02434 ,  0.03375 ,\n",
              "          -0.007214]], dtype=float16)),\n",
              " ('ADHS_GLUOX',\n",
              "  array([[ 0.004192 , -0.01362  ,  0.01747  , ...,  0.01627  ,  0.01964  ,\n",
              "           0.0017605]], dtype=float16)),\n",
              " ('ADJ13503',\n",
              "  array([[ 0.03864 , -0.0519  ,  0.0812  , ...,  0.002659,  0.02545 ,\n",
              "          -0.02234 ]], dtype=float16)),\n",
              " ('ADJ13580',\n",
              "  array([[ 0.01747,  0.01452, -0.02931, ...,  0.00838,  0.0816 , -0.02591]],\n",
              "        dtype=float16)),\n",
              " ('ADJ13627',\n",
              "  array([[ 0.002197, -0.03217 , -0.003819, ...,  0.05527 ,  0.04086 ,\n",
              "           0.03287 ]], dtype=float16)),\n",
              " ('ADJ13699',\n",
              "  array([[-0.00382 , -0.06116 ,  0.09985 , ...,  0.03326 ,  0.013756,\n",
              "          -0.0407  ]], dtype=float16)),\n",
              " ('ADJ13780',\n",
              "  array([[-0.001168, -0.02594 , -0.06885 , ...,  0.0689  ,  0.02995 ,\n",
              "          -0.008934]], dtype=float16)),\n",
              " ('ADJ13899',\n",
              "  array([[ 0.0496 ,  0.0738 , -0.02736, ...,  0.03302,  0.01377, -0.01424]],\n",
              "        dtype=float16)),\n",
              " ('ADJ13904',\n",
              "  array([[ 0.0812 ,  0.1216 ,  0.07263, ...,  0.0812 , -0.01454,  0.1401 ]],\n",
              "        dtype=float16)),\n",
              " ('ADJ14176',\n",
              "  array([[ 0.00936  , -0.0002575,  0.0395   , ..., -0.01366  ,  0.05957  ,\n",
              "           0.04312  ]], dtype=float16)),\n",
              " ('ADJ14285',\n",
              "  array([[ 0.0368 , -0.0487 ,  0.05618, ...,  0.01447,  0.04736,  0.00885]],\n",
              "        dtype=float16)),\n",
              " ('ADJ14328',\n",
              "  array([[ 0.03004, -0.06555,  0.03638, ..., -0.05945,  0.01942, -0.0204 ]],\n",
              "        dtype=float16)),\n",
              " ('ADJ14473',\n",
              "  array([[ 0.05978, -0.1492 ,  0.03146, ...,  0.0795 ,  0.07965,  0.02362]],\n",
              "        dtype=float16)),\n",
              " ('ADJ14479',\n",
              "  array([[ 0.01791, -0.1678 ,  0.00856, ...,  0.04694,  0.06824,  0.05295]],\n",
              "        dtype=float16)),\n",
              " ('ADJ14482',\n",
              "  array([[ 0.0524 , -0.01697,  0.0634 , ...,  0.07104,  0.09296,  0.0748 ]],\n",
              "        dtype=float16)),\n",
              " ('ADJ14523',\n",
              "  array([[ 0.02805 , -0.02156 , -0.05872 , ..., -0.00787 ,  0.0456  ,\n",
              "          -0.002176]], dtype=float16)),\n",
              " ('ADJ14537',\n",
              "  array([[ 0.01985 , -0.0841  ,  0.00713 , ...,  0.004993, -0.02972 ,\n",
              "           0.0821  ]], dtype=float16)),\n",
              " ('ADJ14570',\n",
              "  array([[ 0.01964, -0.02238,  0.0647 , ...,  0.06146,  0.05484,  0.05426]],\n",
              "        dtype=float16)),\n",
              " ('ADJ14573',\n",
              "  array([[ 0.03183 , -0.1175  , -0.06683 , ...,  0.01752 ,  0.01721 ,\n",
              "           0.001438]], dtype=float16)),\n",
              " ('ADJ14766',\n",
              "  array([[ 0.007442, -0.011635, -0.0404  , ...,  0.02695 ,  0.005848,\n",
              "          -0.05695 ]], dtype=float16)),\n",
              " ('ADJ14838',\n",
              "  array([[ 0.004604, -0.1277  , -0.03384 , ..., -0.03625 ,  0.1068  ,\n",
              "           0.02388 ]], dtype=float16)),\n",
              " ('ADJ15116',\n",
              "  array([[-0.01332, -0.08527, -0.00404, ...,  0.02362, -0.03983,  0.0598 ]],\n",
              "        dtype=float16)),\n",
              " ('ADJ15202',\n",
              "  array([[-0.00581 , -0.05203 , -0.003662, ...,  0.004658, -0.003357,\n",
              "           0.06052 ]], dtype=float16)),\n",
              " ('ADJ15305',\n",
              "  array([[ 0.0299 , -0.0668 , -0.06824, ...,  0.05115,  0.02023, -0.02919]],\n",
              "        dtype=float16)),\n",
              " ('ADJ15705',\n",
              "  array([[ 0.02722 , -0.0933  , -0.00762 , ..., -0.02687 , -0.006912,\n",
              "          -0.02374 ]], dtype=float16)),\n",
              " ('ADJ16195',\n",
              "  array([[ 0.00843, -0.01531,  0.0358 , ...,  0.04745,  0.04623,  0.04913]],\n",
              "        dtype=float16)),\n",
              " ('ADJ16468',\n",
              "  array([[-0.072   ,  0.0135  ,  0.1538  , ..., -0.05374 ,  0.01659 ,\n",
              "          -0.003826]], dtype=float16)),\n",
              " ('ADJ16512',\n",
              "  array([[ 0.01044,  0.10706, -0.04553, ..., -0.00443,  0.0465 , -0.03186]],\n",
              "        dtype=float16)),\n",
              " ('ADJ16680',\n",
              "  array([[ 0.05222 ,  0.10895 , -0.04083 , ...,  0.0254  ,  0.007298,\n",
              "           0.03317 ]], dtype=float16)),\n",
              " ('ADJ16684',\n",
              "  array([[ 0.003738,  0.004776, -0.03806 , ...,  0.03647 ,  0.0339  ,\n",
              "           0.007595]], dtype=float16)),\n",
              " ('ADJ16830',\n",
              "  array([[ 0.0473 ,  0.08075, -0.02238, ..., -0.01175,  0.04218,  0.03897]],\n",
              "        dtype=float16)),\n",
              " ('ADJ16918',\n",
              "  array([[-0.0607   , -0.04272  , -0.02771  , ..., -0.0002732, -0.0567   ,\n",
              "           0.0792   ]], dtype=float16)),\n",
              " ('ADJ17071',\n",
              "  array([[-0.00577  ,  0.0003374,  0.000804 , ...,  0.01355  ,  0.01473  ,\n",
              "          -0.02423  ]], dtype=float16)),\n",
              " ('ADJ17092',\n",
              "  array([[-0.04388, -0.03278, -0.07556, ..., -0.0314 , -0.00715,  0.04257]],\n",
              "        dtype=float16)),\n",
              " ('ADJ17152',\n",
              "  array([[-0.005665,  0.03912 , -0.00472 , ..., -0.0705  , -0.02824 ,\n",
              "           0.0418  ]], dtype=float16)),\n",
              " ('ADJ17190',\n",
              "  array([[ 0.0328  , -0.0469  , -0.0345  , ...,  0.01819 ,  0.010635,\n",
              "          -0.05927 ]], dtype=float16)),\n",
              " ('ADJ17255',\n",
              "  array([[-0.09357, -0.03275,  0.1356 , ..., -0.08826,  0.11316,  0.03134]],\n",
              "        dtype=float16)),\n",
              " ('ADJ17264',\n",
              "  array([[ 0.036   , -0.1597  , -0.05713 , ...,  0.0443  ,  0.005005,\n",
              "           0.008316]], dtype=float16)),\n",
              " ('ADL41180',\n",
              "  array([[-0.08923, -0.05603,  0.03723, ...,  0.04437,  0.0867 ,  0.03146]],\n",
              "        dtype=float16)),\n",
              " ('ADO76183',\n",
              "  array([[ 0.0313  , -0.01604 , -0.012436, ..., -0.0501  , -0.006363,\n",
              "           0.03586 ]], dtype=float16)),\n",
              " ('ADO76205',\n",
              "  array([[-0.01636 ,  0.05072 , -0.005085, ...,  0.02258 ,  0.0283  ,\n",
              "          -0.05212 ]], dtype=float16)),\n",
              " ('ADO76217',\n",
              "  array([[ 0.00961 , -0.02396 ,  0.02681 , ..., -0.03146 , -0.00439 ,\n",
              "           0.002937]], dtype=float16)),\n",
              " ('ADO76231',\n",
              "  array([[-0.009895, -0.0512  ,  0.02547 , ..., -0.00956 , -0.007133,\n",
              "          -0.005688]], dtype=float16)),\n",
              " ('ADO76242',\n",
              "  array([[-0.02684,  0.0953 ,  0.01318, ...,  0.02585,  0.00992, -0.02943]],\n",
              "        dtype=float16)),\n",
              " ('ADO76292',\n",
              "  array([[ 0.04187 ,  0.01411 , -0.03943 , ...,  0.006683,  0.01622 ,\n",
              "          -0.0848  ]], dtype=float16)),\n",
              " ('ADO76380',\n",
              "  array([[ 0.02394 , -0.002974,  0.03824 , ...,  0.0426  ,  0.04376 ,\n",
              "           0.0535  ]], dtype=float16)),\n",
              " ('ADO76451',\n",
              "  array([[-0.05112 ,  0.03668 ,  0.002337, ...,  0.02364 ,  0.02333 ,\n",
              "          -0.01282 ]], dtype=float16)),\n",
              " ('ADO76455',\n",
              "  array([[ 0.0195 , -0.08386,  0.02197, ...,  0.04028,  0.01185,  0.02206]],\n",
              "        dtype=float16)),\n",
              " ('ADO76498',\n",
              "  array([[ 0.02596 , -0.04117 ,  0.03818 , ...,  0.0577  , -0.007767,\n",
              "          -0.04764 ]], dtype=float16)),\n",
              " ('ADO76503',\n",
              "  array([[-0.004974,  0.0542  ,  0.04724 , ...,  0.013824,  0.02278 ,\n",
              "          -0.07324 ]], dtype=float16)),\n",
              " ('ADO76515',\n",
              "  array([[-0.012115, -0.0805  ,  0.05927 , ..., -0.004448, -0.005157,\n",
              "           0.0238  ]], dtype=float16)),\n",
              " ('ADO76601',\n",
              "  array([[ 0.01636 , -0.01624 ,  0.002289, ..., -0.0372  ,  0.01732 ,\n",
              "          -0.03004 ]], dtype=float16)),\n",
              " ('ADO76602',\n",
              "  array([[-0.0626 ,  0.09357,  0.02007, ...,  0.05606, -0.01633, -0.04547]],\n",
              "        dtype=float16)),\n",
              " ('ADO76640',\n",
              "  array([[-0.002913, -0.0797  ,  0.001353, ...,  0.006237, -0.01805 ,\n",
              "          -0.05234 ]], dtype=float16)),\n",
              " ('ADO76660',\n",
              "  array([[ 0.07623 ,  0.01281 , -0.007484, ...,  0.03412 , -0.05087 ,\n",
              "           0.05234 ]], dtype=float16)),\n",
              " ('ADO76701',\n",
              "  array([[-0.009865, -0.04498 , -0.029   , ...,  0.1169  ,  0.02756 ,\n",
              "          -0.02924 ]], dtype=float16)),\n",
              " ('ADO76713',\n",
              "  array([[ 0.001446, -0.0671  , -0.02245 , ...,  0.0707  ,  0.0404  ,\n",
              "           0.00492 ]], dtype=float16)),\n",
              " ('ADO76722',\n",
              "  array([[-0.01843 , -0.1006  ,  0.01046 , ..., -0.01537 , -0.003897,\n",
              "          -0.003187]], dtype=float16)),\n",
              " ('ADO76730',\n",
              "  array([[-0.02205,  0.03366, -0.03592, ...,  0.03247, -0.0177 ,  0.1407 ]],\n",
              "        dtype=float16)),\n",
              " ('ADO76746',\n",
              "  array([[-0.03062 , -0.0774  ,  0.01316 , ...,  0.04288 ,  0.00631 ,\n",
              "          -0.014084]], dtype=float16)),\n",
              " ('ADO76808',\n",
              "  array([[-0.0617 , -0.07715, -0.00411, ...,  0.09204,  0.00391, -0.03555]],\n",
              "        dtype=float16)),\n",
              " ('ADO76919',\n",
              "  array([[-0.03644,  0.0825 ,  0.05777, ..., -0.01656,  0.05542,  0.03268]],\n",
              "        dtype=float16)),\n",
              " ('ADO76947',\n",
              "  array([[ 0.0005293, -0.09485  ,  0.004883 , ..., -0.00819  ,  0.05606  ,\n",
              "          -0.01913  ]], dtype=float16)),\n",
              " ('ADO76974',\n",
              "  array([[-0.01718 , -0.0958  , -0.01504 , ...,  0.03406 ,  0.00977 ,\n",
              "          -0.000343]], dtype=float16)),\n",
              " ('ADO76985',\n",
              "  array([[-0.02805 , -0.04114 , -0.001072, ...,  0.001688,  0.03217 ,\n",
              "           0.01513 ]], dtype=float16)),\n",
              " ('ADO77006',\n",
              "  array([[ 0.002283, -0.0429  ,  0.0565  , ...,  0.0721  , -0.007553,\n",
              "           0.00583 ]], dtype=float16)),\n",
              " ('ADO77027',\n",
              "  array([[-0.03506 , -0.0264  , -0.013245, ...,  0.02327 ,  0.02931 ,\n",
              "          -0.00611 ]], dtype=float16)),\n",
              " ('ADO77028',\n",
              "  array([[-0.068   , -0.04544 , -0.006626, ...,  0.0734  ,  0.04312 ,\n",
              "           0.000993]], dtype=float16)),\n",
              " ('ADO77031',\n",
              "  array([[-0.05475 , -0.01337 ,  0.04742 , ...,  0.0381  , -0.021   ,\n",
              "           0.007336]], dtype=float16)),\n",
              " ('ADO77032',\n",
              "  array([[-0.03943 ,  0.01263 ,  0.08185 , ...,  0.0825  , -0.00864 ,\n",
              "          -0.005615]], dtype=float16)),\n",
              " ('ADO77040',\n",
              "  array([[ 0.00454 , -0.1206  ,  0.0277  , ...,  0.075   , -0.00645 ,\n",
              "          -0.002636]], dtype=float16)),\n",
              " ('ADO77080',\n",
              "  array([[ 0.05658,  0.04422,  0.10345, ...,  0.02924,  0.01567, -0.00831]],\n",
              "        dtype=float16)),\n",
              " ('ADO77087',\n",
              "  array([[-0.01398  , -0.05804  , -0.0003724, ...,  0.1115   ,  0.0497   ,\n",
              "           0.04355  ]], dtype=float16)),\n",
              " ('ADO77091',\n",
              "  array([[ 0.009254, -0.10754 , -0.0164  , ...,  0.0112  ,  0.001839,\n",
              "           0.07605 ]], dtype=float16)),\n",
              " ('ADO77168',\n",
              "  array([[ 0.04312, -0.02779,  0.02306, ...,  0.05963,  0.02129, -0.0442 ]],\n",
              "        dtype=float16)),\n",
              " ('ADO77196',\n",
              "  array([[ 0.03384,  0.06158,  0.00611, ..., -0.02736,  0.0189 ,  0.0449 ]],\n",
              "        dtype=float16)),\n",
              " ('ADO77201',\n",
              "  array([[ 0.00631 , -0.0158  , -0.0202  , ...,  0.02771 ,  0.01825 ,\n",
              "           0.001858]], dtype=float16)),\n",
              " ('ADO77213',\n",
              "  array([[ 0.01099 ,  0.0363  , -0.002302, ...,  0.03824 , -0.02042 ,\n",
              "          -0.0764  ]], dtype=float16)),\n",
              " ('ADO77239',\n",
              "  array([[ 0.01385 ,  0.01406 ,  0.02113 , ..., -0.003906,  0.02972 ,\n",
              "           0.004765]], dtype=float16)),\n",
              " ('ADO77250',\n",
              "  array([[-2.608e-02,  3.519e-02, -6.139e-06, ...,  4.068e-02, -2.556e-02,\n",
              "           2.643e-02]], dtype=float16)),\n",
              " ('ADO77289',\n",
              "  array([[ 0.0284 , -0.0901 ,  0.01857, ...,  0.05432, -0.01234,  0.02359]],\n",
              "        dtype=float16)),\n",
              " ('ADO77303',\n",
              "  array([[-0.03522,  0.04578,  0.05576, ...,  0.0383 ,  0.0317 , -0.07074]],\n",
              "        dtype=float16)),\n",
              " ('ADO77304',\n",
              "  array([[ 0.01563, -0.04224, -0.01648, ..., -0.02962,  0.01578, -0.05832]],\n",
              "        dtype=float16)),\n",
              " ('ADO77308',\n",
              "  array([[-0.02397,  0.01991, -0.01345, ..., -0.05377, -0.01509,  0.01079]],\n",
              "        dtype=float16)),\n",
              " ('ADO77324',\n",
              "  array([[ 0.0524  , -0.02605 ,  0.0252  , ..., -0.007706,  0.01297 ,\n",
              "          -0.011284]], dtype=float16)),\n",
              " ('ADO77344',\n",
              "  array([[-0.001236,  0.01834 ,  0.04178 , ...,  0.01569 ,  0.004467,\n",
              "          -0.007145]], dtype=float16)),\n",
              " ('ADO77363',\n",
              "  array([[-0.01216 , -0.007576,  0.003447, ...,  0.02814 ,  0.03305 ,\n",
              "           0.04834 ]], dtype=float16)),\n",
              " ('ADO77383',\n",
              "  array([[ 0.03787 ,  0.005592,  0.0342  , ...,  0.02771 ,  0.0191  ,\n",
              "          -0.009766]], dtype=float16)),\n",
              " ('ADO77455',\n",
              "  array([[-0.00905,  0.01675,  0.03336, ..., -0.03455,  0.05325, -0.0194 ]],\n",
              "        dtype=float16)),\n",
              " ('ADO77503',\n",
              "  array([[ 0.005737, -0.1111  , -0.003696, ..., -0.02472 ,  0.02077 ,\n",
              "           0.04184 ]], dtype=float16)),\n",
              " ('ADO77505',\n",
              "  array([[ 0.02898 , -0.1255  , -0.013794, ..., -0.03058 ,  0.07513 ,\n",
              "           0.04007 ]], dtype=float16)),\n",
              " ('ADO77511',\n",
              "  array([[-0.00809,  0.02762,  0.02234, ...,  0.0093 ,  0.02374, -0.01807]],\n",
              "        dtype=float16)),\n",
              " ('ADO77512',\n",
              "  array([[-0.02484,  0.0879 ,  0.03238, ...,  0.0693 ,  0.0708 , -0.02954]],\n",
              "        dtype=float16)),\n",
              " ('ADO77535',\n",
              "  array([[ 0.00995 , -0.04562 , -0.02615 , ..., -0.00375 ,  0.005024,\n",
              "           0.003878]], dtype=float16)),\n",
              " ('ADO77572',\n",
              "  array([[ 0.01668 ,  0.03842 ,  0.02411 , ...,  0.002913,  0.01788 ,\n",
              "          -0.02855 ]], dtype=float16)),\n",
              " ('ADO77575',\n",
              "  array([[-0.03143 , -0.04993 ,  0.0501  , ..., -0.014046,  0.04636 ,\n",
              "          -0.05707 ]], dtype=float16)),\n",
              " ('ADO77634',\n",
              "  array([[-0.00839, -0.02776,  0.02469, ..., -0.04208,  0.0218 ,  0.04047]],\n",
              "        dtype=float16)),\n",
              " ('ADO77759',\n",
              "  array([[ 0.01999, -0.06015,  0.0323 , ..., -0.02226,  0.05215, -0.03946]],\n",
              "        dtype=float16)),\n",
              " ('ADO77774',\n",
              "  array([[-0.05396 ,  0.00627 ,  0.0775  , ...,  0.0268  ,  0.002306,\n",
              "           0.05505 ]], dtype=float16)),\n",
              " ('ADO77940',\n",
              "  array([[ 0.02608,  0.06085,  0.1023 , ..., -0.00672, -0.0449 ,  0.02994]],\n",
              "        dtype=float16)),\n",
              " ('ADO77943',\n",
              "  array([[-0.052  , -0.042  ,  0.0488 , ...,  0.0292 ,  0.05838,  0.09656]],\n",
              "        dtype=float16)),\n",
              " ('ADO77979',\n",
              "  array([[ 0.02466 ,  0.02974 ,  0.02907 , ..., -0.001722,  0.01797 ,\n",
              "          -0.02182 ]], dtype=float16)),\n",
              " ('ADO77990',\n",
              "  array([[-3.6526e-03,  1.0217e-01,  1.5205e-02, ..., -5.2595e-04,\n",
              "          -8.7976e-05, -4.9561e-02]], dtype=float16)),\n",
              " ('ADO78053',\n",
              "  array([[ 0.0419  , -0.04016 ,  0.003357, ...,  0.02367 ,  0.03012 ,\n",
              "          -0.02148 ]], dtype=float16)),\n",
              " ('ADO78064',\n",
              "  array([[ 0.01169 , -0.077   , -0.02711 , ...,  0.0861  ,  0.0317  ,\n",
              "           0.001786]], dtype=float16)),\n",
              " ('ADO78072',\n",
              "  array([[ 0.01662 , -0.03455 ,  0.000302, ...,  0.03217 ,  0.01543 ,\n",
              "           0.04813 ]], dtype=float16)),\n",
              " ('ADO78074',\n",
              "  array([[ 0.0329  , -0.02785 ,  0.06226 , ...,  0.03925 ,  0.02565 ,\n",
              "           0.000977]], dtype=float16)),\n",
              " ('ADO78091',\n",
              "  array([[ 0.006554, -0.06067 ,  0.0474  , ...,  0.005135,  0.01727 ,\n",
              "          -0.00569 ]], dtype=float16)),\n",
              " ('ADO78110',\n",
              "  array([[-0.07745 , -0.0613  , -0.09015 , ...,  0.02432 ,  0.061   ,\n",
              "          -0.005955]], dtype=float16)),\n",
              " ('ADO78111',\n",
              "  array([[-0.03041, -0.0481 ,  0.01415, ..., -0.046  ,  0.06476,  0.01898]],\n",
              "        dtype=float16)),\n",
              " ('ADO78128',\n",
              "  array([[ 0.00734 , -0.02684 , -0.001952, ..., -0.03918 ,  0.01863 ,\n",
              "          -0.003263]], dtype=float16)),\n",
              " ('ADO78150',\n",
              "  array([[ 0.04077 , -0.00761 ,  0.02235 , ..., -0.03763 ,  0.0218  ,\n",
              "           0.004604]], dtype=float16)),\n",
              " ('ADO78157',\n",
              "  array([[-0.004917, -0.02606 ,  0.02983 , ...,  0.04984 , -0.01648 ,\n",
              "          -0.02522 ]], dtype=float16)),\n",
              " ('ADO78158',\n",
              "  array([[-0.008644, -0.112   , -0.01274 , ..., -0.02353 ,  0.03754 ,\n",
              "          -0.01996 ]], dtype=float16)),\n",
              " ('ADO78169',\n",
              "  array([[ 0.04044  ,  0.00529  , -0.0006948, ...,  0.02153  ,  0.002651 ,\n",
              "           0.00595  ]], dtype=float16)),\n",
              " ('ADR78324',\n",
              "  array([[ 0.00634, -0.01741,  0.0446 , ..., -0.01712,  0.0653 ,  0.01994]],\n",
              "        dtype=float16)),\n",
              " ('ADR78325',\n",
              "  array([[ 0.01476, -0.02591, -0.01352, ..., -0.06494,  0.0979 ,  0.03012]],\n",
              "        dtype=float16)),\n",
              " ('ADR78326',\n",
              "  array([[ 0.04672,  0.0413 ,  0.01084, ..., -0.0673 ,  0.06946,  0.01554]],\n",
              "        dtype=float16)),\n",
              " ('ADR78327',\n",
              "  array([[ 0.03467,  0.03055, -0.00997, ..., -0.0753 ,  0.06216,  0.02122]],\n",
              "        dtype=float16)),\n",
              " ('ADR78331',\n",
              "  array([[-0.0005474,  0.01717  ,  0.03146  , ...,  0.02235  ,  0.04913  ,\n",
              "           0.02464  ]], dtype=float16)),\n",
              " ('ADR78332',\n",
              "  array([[-0.02344 ,  0.0327  ,  0.02507 , ..., -0.013374,  0.02464 ,\n",
              "           0.04645 ]], dtype=float16)),\n",
              " ('ADR78333',\n",
              "  array([[-0.01602 , -0.03436 ,  0.0505  , ..., -0.02905 , -0.0182  ,\n",
              "           0.008286]], dtype=float16)),\n",
              " ('ADR78334',\n",
              "  array([[ 0.03897 ,  0.007187,  0.04056 , ..., -0.0635  ,  0.03915 ,\n",
              "           0.0552  ]], dtype=float16)),\n",
              " ('AEN04848',\n",
              "  array([[ 0.05063, -0.02058,  0.01723, ..., -0.03918,  0.00784,  0.01402]],\n",
              "        dtype=float16)),\n",
              " ('AEN05168',\n",
              "  array([[ 0.04453  ,  0.0001181,  0.00447  , ..., -0.011345 , -0.03122  ,\n",
              "           0.0095   ]], dtype=float16)),\n",
              " ('AEN05419',\n",
              "  array([[ 0.07275 ,  0.06152 , -0.004208, ...,  0.05185 ,  0.02234 ,\n",
              "          -0.06033 ]], dtype=float16)),\n",
              " ('AEN05955',\n",
              "  array([[ 0.00943,  0.00154, -0.01665, ...,  0.04095,  0.05035, -0.081  ]],\n",
              "        dtype=float16)),\n",
              " ('AEN06803',\n",
              "  array([[-0.04263 , -0.0195  ,  0.01979 , ..., -0.0484  ,  0.015175,\n",
              "           0.0634  ]], dtype=float16)),\n",
              " ('AEN06820',\n",
              "  array([[ 0.0344 ,  0.04065,  0.11536, ...,  0.04367,  0.00435, -0.06235]],\n",
              "        dtype=float16)),\n",
              " ('AEN06939',\n",
              "  array([[ 0.0336 , -0.0703 , -0.01172, ...,  0.01569,  0.02495, -0.0638 ]],\n",
              "        dtype=float16)),\n",
              " ('AEN07385',\n",
              "  array([[ 0.02135, -0.03937, -0.03967, ...,  0.04242,  0.0334 , -0.0185 ]],\n",
              "        dtype=float16)),\n",
              " ('AEN07489',\n",
              "  array([[ 0.01917 , -0.006622,  0.001419, ...,  0.00616 ,  0.05048 ,\n",
              "          -0.02567 ]], dtype=float16)),\n",
              " ('AEN07490',\n",
              "  array([[ 0.01221,  0.02548, -0.02625, ...,  0.0637 ,  0.03108, -0.03506]],\n",
              "        dtype=float16)),\n",
              " ('AEN07527',\n",
              "  array([[-0.03008  , -0.05212  , -0.03061  , ..., -0.0005617,  0.009544 ,\n",
              "          -0.00601  ]], dtype=float16)),\n",
              " ('AEN07718',\n",
              "  array([[-0.00859, -0.06824, -0.0668 , ..., -0.0327 , -0.02457,  0.03046]],\n",
              "        dtype=float16)),\n",
              " ('AEN07727',\n",
              "  array([[ 0.0841  ,  0.0868  , -0.05008 , ..., -0.003063, -0.00189 ,\n",
              "           0.0536  ]], dtype=float16)),\n",
              " ('AEN07728',\n",
              "  array([[-0.03003, -0.0669 ,  0.0337 , ..., -0.01533, -0.00635, -0.0164 ]],\n",
              "        dtype=float16)),\n",
              " ('AEN07738',\n",
              "  array([[ 0.06125 , -0.0831  , -0.005512, ...,  0.03656 ,  0.01239 ,\n",
              "          -0.02037 ]], dtype=float16)),\n",
              " ('AEN07750',\n",
              "  array([[ 0.01912 ,  0.010956, -0.02318 , ..., -0.007156,  0.02927 ,\n",
              "          -0.03146 ]], dtype=float16)),\n",
              " ('AFK18111',\n",
              "  array([[ 0.0117  ,  0.001906, -0.02109 , ..., -0.006687,  0.01952 ,\n",
              "          -0.02223 ]], dtype=float16)),\n",
              " ('AFK18250',\n",
              "  array([[-0.0178  , -0.01029 ,  0.04993 , ...,  0.0533  , -0.00679 ,\n",
              "          -0.003527]], dtype=float16)),\n",
              " ('AFK18532',\n",
              "  array([[ 0.0391 , -0.03458,  0.08685, ...,  0.01588,  0.00886, -0.01955]],\n",
              "        dtype=float16)),\n",
              " ('AFK18542',\n",
              "  array([[ 0.05734 , -0.08344 ,  0.01845 , ..., -0.013374,  0.03787 ,\n",
              "          -0.06247 ]], dtype=float16)),\n",
              " ('AFK18730',\n",
              "  array([[ 0.02536 ,  0.02931 , -0.007538, ...,  0.02814 ,  0.02888 ,\n",
              "          -0.04172 ]], dtype=float16)),\n",
              " ('AFK19026',\n",
              "  array([[ 0.02916, -0.03616, -0.02792, ...,  0.0349 ,  0.0249 , -0.05963]],\n",
              "        dtype=float16)),\n",
              " ('AFK19037',\n",
              "  array([[ 0.06525  , -0.1181   ,  0.0002968, ...,  0.00366  ,  0.01598  ,\n",
              "           0.07947  ]], dtype=float16)),\n",
              " ('AFK19109',\n",
              "  array([[ 0.02155  , -0.04358  ,  0.0005207, ...,  0.06696  , -0.04102  ,\n",
              "           0.04086  ]], dtype=float16)),\n",
              " ('AFK19218',\n",
              "  array([[-0.02773 , -0.0403  ,  0.034   , ..., -0.002415,  0.01207 ,\n",
              "          -0.01965 ]], dtype=float16)),\n",
              " ('AFK19338',\n",
              "  array([[ 0.04797 , -0.04395 ,  0.061   , ...,  0.007736,  0.03714 ,\n",
              "          -0.00449 ]], dtype=float16)),\n",
              " ('AFK19728',\n",
              "  array([[ 0.0597  ,  0.00977 , -0.0472  , ..., -0.03546 , -0.007545,\n",
              "          -0.01429 ]], dtype=float16)),\n",
              " ('AFK19902',\n",
              "  array([[-0.02518, -0.06573, -0.03503, ...,  0.01438,  0.04388, -0.00705]],\n",
              "        dtype=float16)),\n",
              " ('AFK19944',\n",
              "  array([[ 0.07526,  0.0732 , -0.03099, ...,  0.04337,  0.05057,  0.038  ]],\n",
              "        dtype=float16)),\n",
              " ('AFK20570',\n",
              "  array([[ 0.010155,  0.00819 ,  0.05194 , ...,  0.04337 ,  0.002728,\n",
              "          -0.06323 ]], dtype=float16)),\n",
              " ('AFK20723',\n",
              "  array([[ 0.002064, -0.05753 , -0.000436, ...,  0.02774 ,  0.0931  ,\n",
              "          -0.0669  ]], dtype=float16)),\n",
              " ('AFK20735',\n",
              "  array([[ 0.06134 , -0.02483 ,  0.014275, ..., -0.003756, -0.001515,\n",
              "           0.0303  ]], dtype=float16)),\n",
              " ('AFK20794',\n",
              "  array([[-0.002922, -0.0771  ,  0.00714 , ..., -0.0625  , -0.02782 ,\n",
              "           0.015015]], dtype=float16)),\n",
              " ('AFK21289',\n",
              "  array([[ 0.01107, -0.02719, -0.03104, ..., -0.0359 ,  0.03008,  0.02875]],\n",
              "        dtype=float16)),\n",
              " ('AFK21388',\n",
              "  array([[-0.07764 , -0.03784 , -0.00708 , ...,  0.007385,  0.0503  ,\n",
              "           0.07153 ]], dtype=float16)),\n",
              " ('AFK21429',\n",
              "  array([[ 0.02113,  0.0319 ,  0.03943, ..., -0.00808,  0.1409 ,  0.02129]],\n",
              "        dtype=float16)),\n",
              " ('AFK21534',\n",
              "  array([[ 0.0632  ,  0.0486  , -0.0734  , ..., -0.04614 ,  0.006542,\n",
              "           0.07043 ]], dtype=float16)),\n",
              " ('AFK21594',\n",
              "  array([[ 0.03488 , -0.03998 , -0.04428 , ...,  0.006744, -0.00831 ,\n",
              "          -0.05545 ]], dtype=float16)),\n",
              " ('AGC34304',\n",
              "  array([[ 0.0773 ,  0.07513,  0.06665, ...,  0.04608, -0.00877, -0.01362]],\n",
              "        dtype=float16)),\n",
              " ('AGC34314',\n",
              "  array([[ 0.010475,  0.06396 , -0.0526  , ...,  0.01336 ,  0.07153 ,\n",
              "          -0.00981 ]], dtype=float16)),\n",
              " ('AGC34344',\n",
              "  array([[ 0.0384   , -0.0122   , -0.02528  , ...,  0.0006003, -0.01538  ,\n",
              "          -0.05386  ]], dtype=float16)),\n",
              " ('AGC34361',\n",
              "  array([[ 0.00433 ,  0.002142, -0.02611 , ...,  0.03442 ,  0.0702  ,\n",
              "          -0.00701 ]], dtype=float16)),\n",
              " ('AGC34372',\n",
              "  array([[ 0.03696 ,  0.06158 , -0.005264, ..., -0.02965 ,  0.00418 ,\n",
              "          -0.0469  ]], dtype=float16)),\n",
              " ('AGC34422',\n",
              "  array([[ 0.012314,  0.03195 , -0.06082 , ..., -0.0369  ,  0.06134 ,\n",
              "          -0.01119 ]], dtype=float16)),\n",
              " ('AGC34448',\n",
              "  array([[-0.01163 , -0.0769  , -0.03995 , ...,  0.014656, -0.02171 ,\n",
              "          -0.013916]], dtype=float16)),\n",
              " ('AGC34493',\n",
              "  array([[ 0.0778 , -0.0809 , -0.03638, ...,  0.01762,  0.0373 ,  0.0362 ]],\n",
              "        dtype=float16)),\n",
              " ('AGC34495',\n",
              "  array([[ 0.008286, -0.0638  ,  0.04965 , ...,  0.0939  , -0.02391 ,\n",
              "          -0.0333  ]], dtype=float16)),\n",
              " ('AGC34524',\n",
              "  array([[ 0.01945,  0.0362 , -0.02966, ...,  0.02338,  0.1084 , -0.079  ]],\n",
              "        dtype=float16)),\n",
              " ('AGLZ_MYXXD',\n",
              "  array([[-1.490e-06, -4.370e-02,  5.460e-02, ..., -2.753e-02,  1.569e-02,\n",
              "          -4.501e-02]], dtype=float16)),\n",
              " ('AGMT_PYRHO',\n",
              "  array([[ 0.09955, -0.02335,  0.02568, ..., -0.03864,  0.0648 ,  0.03314]],\n",
              "        dtype=float16)),\n",
              " ('AGOG_PYRFU',\n",
              "  array([[ 0.05667 , -0.09973 ,  0.02838 , ..., -0.0756  , -0.00932 ,\n",
              "          -0.001713]], dtype=float16)),\n",
              " ('AHB64777',\n",
              "  array([[ 0.00257 , -0.06137 , -0.005573, ...,  0.01808 ,  0.03604 ,\n",
              "          -0.06113 ]], dtype=float16)),\n",
              " ('AHB64959',\n",
              "  array([[ 0.0335  , -0.001841,  0.03677 , ..., -0.02193 , -0.04468 ,\n",
              "           0.0344  ]], dtype=float16)),\n",
              " ('AHB65167',\n",
              "  array([[ 0.01012 , -0.013115, -0.03525 , ...,  0.03226 ,  0.06088 ,\n",
              "           0.001955]], dtype=float16)),\n",
              " ('AHB65222',\n",
              "  array([[ 0.0192 , -0.0843 , -0.04678, ...,  0.03244,  0.01591,  0.0808 ]],\n",
              "        dtype=float16)),\n",
              " ('AHB65767',\n",
              "  array([[ 0.004116, -0.10706 , -0.05472 , ..., -0.02838 , -0.0381  ,\n",
              "           0.06445 ]], dtype=float16)),\n",
              " ('AHB66041',\n",
              "  array([[ 0.005203, -0.03433 ,  0.06256 , ..., -0.00994 ,  0.05014 ,\n",
              "           0.1236  ]], dtype=float16)),\n",
              " ('AHB66885',\n",
              "  array([[-0.01524 , -0.007652,  0.04248 , ..., -0.008705, -0.006752,\n",
              "           0.03357 ]], dtype=float16)),\n",
              " ('AHB67462',\n",
              "  array([[0.001331, 0.0006  , 0.0677  , ..., 0.01516 , 0.01132 , 0.03333 ]],\n",
              "        dtype=float16)),\n",
              " ('AHB67484',\n",
              "  array([[ 0.10345 ,  0.0452  , -0.003305, ...,  0.03745 ,  0.0211  ,\n",
              "           0.02083 ]], dtype=float16)),\n",
              " ('AHB67489',\n",
              "  array([[ 0.02086,  0.0531 ,  0.0177 , ..., -0.0131 ,  0.0522 , -0.09186]],\n",
              "        dtype=float16)),\n",
              " ('AHB67637',\n",
              "  array([[ 0.0471 , -0.02538, -0.00728, ..., -0.01572,  0.0348 ,  0.05582]],\n",
              "        dtype=float16)),\n",
              " ('AHB67826',\n",
              "  array([[ 0.02995, -0.1072 ,  0.00212, ...,  0.0343 ,  0.02507,  0.03094]],\n",
              "        dtype=float16)),\n",
              " ('AHB67829',\n",
              "  array([[-0.00197, -0.01738,  0.0846 , ...,  0.03485,  0.0249 , -0.03183]],\n",
              "        dtype=float16)),\n",
              " ('AHB67849',\n",
              "  array([[ 0.02977 , -0.04865 ,  0.000776, ..., -0.03705 , -0.01017 ,\n",
              "          -0.01584 ]], dtype=float16)),\n",
              " ('AHB67856',\n",
              "  array([[ 0.03079 , -0.02516 , -0.03394 , ...,  0.04504 ,  0.02217 ,\n",
              "           0.003416]], dtype=float16)),\n",
              " ('AHB67910',\n",
              "  array([[-0.0195 , -0.07336,  0.01813, ..., -0.0314 , -0.02086, -0.02419]],\n",
              "        dtype=float16)),\n",
              " ('AHB67934',\n",
              "  array([[ 0.0532 , -0.09283, -0.05847, ...,  0.0362 , -0.00505, -0.04373]],\n",
              "        dtype=float16)),\n",
              " ('AHB67940',\n",
              "  array([[ 0.03235 , -0.00572 , -0.001658, ...,  0.005844, -0.0642  ,\n",
              "          -0.04358 ]], dtype=float16)),\n",
              " ('AHB67988',\n",
              "  array([[ 0.0182  , -0.0376  , -0.001831, ...,  0.0301  ,  0.02953 ,\n",
              "          -0.014656]], dtype=float16)),\n",
              " ('AHB68034',\n",
              "  array([[ 0.0116 ,  0.071  ,  0.0114 , ..., -0.0269 ,  0.0523 ,  0.02658]],\n",
              "        dtype=float16)),\n",
              " ('AHB68146',\n",
              "  array([[-0.01572 , -0.0346  ,  0.012314, ...,  0.0313  ,  0.084   ,\n",
              "           0.05096 ]], dtype=float16)),\n",
              " ('AHF55879',\n",
              "  array([[ 0.04834 ,  0.01116 ,  0.03513 , ..., -0.013535,  0.04376 ,\n",
              "           0.04053 ]], dtype=float16)),\n",
              " ('AHK77922',\n",
              "  array([[ 0.011185,  0.0477  ,  0.02892 , ..., -0.04898 ,  0.01048 ,\n",
              "           0.01855 ]], dtype=float16)),\n",
              " ('AHK77987',\n",
              "  array([[ 0.002245, -0.010895,  0.03134 , ...,  0.0628  , -0.0197  ,\n",
              "          -0.000285]], dtype=float16)),\n",
              " ('AHK78001',\n",
              "  array([[ 0.0009027, -0.09125  , -0.01173  , ...,  0.0825   ,  0.03708  ,\n",
              "           0.04123  ]], dtype=float16)),\n",
              " ('AHK78065',\n",
              "  array([[ 0.03354, -0.02834,  0.01808, ...,  0.04492,  0.0138 ,  0.0715 ]],\n",
              "        dtype=float16)),\n",
              " ('AHK78091',\n",
              "  array([[-0.02925,  0.1772 , -0.06354, ...,  0.1107 ,  0.05225,  0.0889 ]],\n",
              "        dtype=float16)),\n",
              " ('AHK78185',\n",
              "  array([[ 0.00811 ,  0.0587  , -0.04755 , ...,  0.09534 , -0.06335 ,\n",
              "           0.008255]], dtype=float16)),\n",
              " ('AHK78315',\n",
              "  array([[ 0.0519  , -0.02206 , -0.03123 , ..., -0.013084, -0.00939 ,\n",
              "           0.07306 ]], dtype=float16)),\n",
              " ('AHK78440',\n",
              "  array([[0.0282  , 0.001682, 0.02    , ..., 0.03906 , 0.02962 , 0.03003 ]],\n",
              "        dtype=float16)),\n",
              " ('AHK78484',\n",
              "  array([[ 0.0671  , -0.06195 ,  0.002588, ..., -0.03876 ,  0.02422 ,\n",
              "           0.0192  ]], dtype=float16)),\n",
              " ('AHK78491',\n",
              "  array([[-0.04306 , -0.03467 ,  0.010925, ...,  0.05612 ,  0.005177,\n",
              "          -0.04294 ]], dtype=float16)),\n",
              " ('AHK78628',\n",
              "  array([[ 0.01541 , -0.01852 , -0.00717 , ..., -0.010056,  0.01743 ,\n",
              "          -0.002754]], dtype=float16)),\n",
              " ('AHK78699',\n",
              "  array([[-0.03278,  0.0572 ,  0.04248, ...,  0.01158, -0.00896, -0.0277 ]],\n",
              "        dtype=float16)),\n",
              " ('AHK78794',\n",
              "  array([[0.061  , 0.01665, 0.01075, ..., 0.05338, 0.01263, 0.02399]],\n",
              "        dtype=float16)),\n",
              " ('AHK78843',\n",
              "  array([[-0.02794, -0.12396, -0.04163, ...,  0.00746, -0.03326,  0.03183]],\n",
              "        dtype=float16)),\n",
              " ('AHK78866',\n",
              "  array([[ 0.00965 , -0.02612 , -0.015015, ..., -0.03476 ,  0.01593 ,\n",
              "           0.042   ]], dtype=float16)),\n",
              " ('AHK78920',\n",
              "  array([[ 0.003332,  0.02734 ,  0.00823 , ..., -0.02724 , -0.00409 ,\n",
              "           0.03296 ]], dtype=float16)),\n",
              " ('AHK78932',\n",
              "  array([[-0.02711 , -0.02997 ,  0.04282 , ...,  0.05624 ,  0.007706,\n",
              "          -0.03885 ]], dtype=float16)),\n",
              " ('AHK78974',\n",
              "  array([[-0.00335 , -0.04837 ,  0.005665, ...,  0.013985, -0.01327 ,\n",
              "           0.04974 ]], dtype=float16)),\n",
              " ('AHK78981',\n",
              "  array([[ 0.03925 , -0.02144 , -0.02878 , ...,  0.00432 ,  0.03268 ,\n",
              "          -0.010445]], dtype=float16)),\n",
              " ('AHK79119',\n",
              "  array([[-0.02835, -0.01932, -0.01894, ...,  0.06635,  0.01666,  0.0255 ]],\n",
              "        dtype=float16)),\n",
              " ('AHK79192',\n",
              "  array([[-0.00958 , -0.0708  ,  0.05103 , ...,  0.01611 ,  0.002062,\n",
              "           0.046   ]], dtype=float16)),\n",
              " ('AHK79228',\n",
              "  array([[ 0.013435 ,  0.00164  ,  0.03226  , ..., -0.0217   ,  0.0001945,\n",
              "          -0.007107 ]], dtype=float16)),\n",
              " ('AHK79270',\n",
              "  array([[-0.0306 , -0.05048,  0.03967, ...,  0.021  , -0.01332,  0.04935]],\n",
              "        dtype=float16)),\n",
              " ('AHK79519',\n",
              "  array([[-0.0004063, -0.04614  ,  0.002922 , ...,  0.03592  ,  0.012085 ,\n",
              "          -0.0562   ]], dtype=float16)),\n",
              " ('AHK79540',\n",
              "  array([[ 0.038  ,  0.0508 ,  0.05658, ..., -0.0573 ,  0.01564,  0.01221]],\n",
              "        dtype=float16)),\n",
              " ('AHK79558',\n",
              "  array([[ 0.04495 ,  0.02742 , -0.03964 , ..., -0.003872, -0.02983 ,\n",
              "           0.01602 ]], dtype=float16)),\n",
              " ('AHK79598',\n",
              "  array([[-0.03006, -0.04138, -0.01787, ...,  0.1514 ,  0.0345 ,  0.1098 ]],\n",
              "        dtype=float16)),\n",
              " ('AHK79650',\n",
              "  array([[0.01524, 0.1604 , 0.05484, ..., 0.0654 , 0.05258, 0.1885 ]],\n",
              "        dtype=float16)),\n",
              " ('AHK79759',\n",
              "  array([[-0.02574, -0.01309,  0.0416 , ...,  0.02478, -0.0629 , -0.01787]],\n",
              "        dtype=float16)),\n",
              " ('AHK79799',\n",
              "  array([[ 0.01343, -0.04086,  0.05887, ...,  0.04254,  0.02434,  0.07007]],\n",
              "        dtype=float16)),\n",
              " ('AHK79840',\n",
              "  array([[ 0.02357, -0.02583,  0.02472, ...,  0.02626,  0.01611,  0.02994]],\n",
              "        dtype=float16)),\n",
              " ('AHK79866',\n",
              "  array([[ 0.0691 ,  0.03476, -0.00586, ...,  0.00881, -0.05267,  0.0587 ]],\n",
              "        dtype=float16)),\n",
              " ('AHK79970',\n",
              "  array([[ 0.02878 ,  0.002594, -0.005466, ..., -0.02504 , -0.002817,\n",
              "           0.02115 ]], dtype=float16)),\n",
              " ('AHK80008',\n",
              "  array([[-0.03857, -0.1604 , -0.0361 , ..., -0.02858,  0.1188 ,  0.10187]],\n",
              "        dtype=float16)),\n",
              " ('AHK80045',\n",
              "  array([[-0.003603,  0.08563 ,  0.05045 , ..., -0.0374  ,  0.01607 ,\n",
              "           0.0584  ]], dtype=float16)),\n",
              " ('AHK80061',\n",
              "  array([[ 0.02512,  0.00899,  0.03198, ...,  0.01616,  0.02936, -0.0178 ]],\n",
              "        dtype=float16)),\n",
              " ('AHK80086',\n",
              "  array([[ 0.1101  , -0.001146,  0.0924  , ..., -0.0161  ,  0.02942 ,\n",
              "           0.04044 ]], dtype=float16)),\n",
              " ('AHK80094',\n",
              "  array([[-0.06976,  0.02043,  0.01892, ..., -0.04056,  0.03607,  0.01889]],\n",
              "        dtype=float16)),\n",
              " ('AHK80121',\n",
              "  array([[ 0.01254 , -0.0739  ,  0.03333 , ...,  0.04077 ,  0.011536,\n",
              "           0.05984 ]], dtype=float16)),\n",
              " ('AHK80256',\n",
              "  array([[ 0.02605  ,  0.01947  , -0.0004718, ..., -0.007427 ,  0.0212   ,\n",
              "           0.01859  ]], dtype=float16)),\n",
              " ('AHK80290',\n",
              "  array([[-0.0332  , -0.02481 ,  0.006996, ...,  0.01235 ,  0.03052 ,\n",
              "           0.01732 ]], dtype=float16)),\n",
              " ('AHK80407',\n",
              "  array([[ 0.02403 ,  0.005527, -0.00933 , ..., -0.01194 ,  0.005165,\n",
              "           0.003448]], dtype=float16)),\n",
              " ('AHK80411',\n",
              "  array([[ 0.001643,  0.002731,  0.03177 , ...,  0.01776 ,  0.0162  ,\n",
              "          -0.01545 ]], dtype=float16)),\n",
              " ('AHK80414',\n",
              "  array([[ 0.009674, -0.005154,  0.00886 , ..., -0.006   ,  0.0453  ,\n",
              "          -0.0881  ]], dtype=float16)),\n",
              " ('AHK80417',\n",
              "  array([[ 0.06033, -0.05307,  0.00252, ..., -0.057  ,  0.03223,  0.06714]],\n",
              "        dtype=float16)),\n",
              " ('AHK80538',\n",
              "  array([[-0.01016 ,  0.00865 , -0.006317, ..., -0.03436 , -0.02292 ,\n",
              "          -0.00643 ]], dtype=float16)),\n",
              " ('AHK80539',\n",
              "  array([[-0.0257 ,  0.0451 , -0.03903, ...,  0.0254 ,  0.02547,  0.03732]],\n",
              "        dtype=float16)),\n",
              " ('AHK80547',\n",
              "  array([[-0.0169 , -0.1528 , -0.008  , ..., -0.00633,  0.085  ,  0.09064]],\n",
              "        dtype=float16)),\n",
              " ('AHK80571',\n",
              "  array([[-0.009415,  0.0656  ,  0.004444, ...,  0.1061  ,  0.0493  ,\n",
              "          -0.03384 ]], dtype=float16)),\n",
              " ('AHK80581',\n",
              "  array([[ 0.00878,  0.01276,  0.02507, ...,  0.03656,  0.04263, -0.03964]],\n",
              "        dtype=float16)),\n",
              " ('AHK80590',\n",
              "  array([[ 0.03192  , -0.03069  , -0.01581  , ..., -0.03387  , -0.0002952,\n",
              "          -0.0614   ]], dtype=float16)),\n",
              " ('AHK80600',\n",
              "  array([[-0.005478,  0.0601  ,  0.04498 , ...,  0.03763 ,  0.07074 ,\n",
              "           0.1067  ]], dtype=float16)),\n",
              " ('AHK80617',\n",
              "  array([[ 0.0463  ,  0.003859, -0.02208 , ..., -0.012085, -0.02458 ,\n",
              "           0.0682  ]], dtype=float16)),\n",
              " ('AHK80621',\n",
              "  array([[-0.02835,  0.08   ,  0.03537, ...,  0.0951 ,  0.0151 ,  0.03912]],\n",
              "        dtype=float16)),\n",
              " ('AHK80667',\n",
              "  array([[ 0.03152, -0.0223 ,  0.0462 , ...,  0.02766,  0.069  ,  0.05185]],\n",
              "        dtype=float16)),\n",
              " ('AHK80668',\n",
              "  array([[-0.01758 , -0.07135 , -0.0315  , ..., -0.009766,  0.01599 ,\n",
              "           0.04727 ]], dtype=float16)),\n",
              " ('AHK80677',\n",
              "  array([[ 0.0737  ,  0.047   , -0.01689 , ...,  0.02509 ,  0.001867,\n",
              "          -0.002958]], dtype=float16)),\n",
              " ('AHK80684',\n",
              "  array([[-0.06094, -0.03284, -0.02025, ...,  0.02245,  0.04156,  0.07837]],\n",
              "        dtype=float16)),\n",
              " ('AHK80709',\n",
              "  array([[ 0.006954, -0.09564 ,  0.01564 , ...,  0.03104 ,  0.03564 ,\n",
              "           0.01064 ]], dtype=float16)),\n",
              " ('AHK80711',\n",
              "  array([[ 0.01399  , -0.05362  ,  0.0002997, ...,  0.01234  , -0.08356  ,\n",
              "           0.01207  ]], dtype=float16)),\n",
              " ('AHK80723',\n",
              "  array([[-0.02588, -0.0643 ,  0.03766, ...,  0.02156,  0.08057,  0.04526]],\n",
              "        dtype=float16)),\n",
              " ('AHK80742',\n",
              "  array([[ 0.0514 ,  0.1259 , -0.03366, ..., -0.03146, -0.01808, -0.00544]],\n",
              "        dtype=float16)),\n",
              " ('AHK80748',\n",
              "  array([[-0.03265 , -0.0351  ,  0.00882 , ..., -0.02504 ,  0.008125,\n",
              "          -0.01141 ]], dtype=float16)),\n",
              " ('AHK80749',\n",
              "  array([[-0.02042, -0.0833 , -0.0471 , ...,  0.06058,  0.01305,  0.08124]],\n",
              "        dtype=float16)),\n",
              " ('AHK80754',\n",
              "  array([[-0.001   , -0.02635 , -0.005093, ...,  0.009   ,  0.00337 ,\n",
              "           0.04822 ]], dtype=float16)),\n",
              " ('AHK80765',\n",
              "  array([[-0.00666, -0.01235,  0.00287, ...,  0.1162 ,  0.1025 ,  0.1407 ]],\n",
              "        dtype=float16)),\n",
              " ('AHK80799',\n",
              "  array([[ 0.08746,  0.06287, -0.01156, ..., -0.1086 , -0.02338,  0.01484]],\n",
              "        dtype=float16)),\n",
              " ('AHK80832',\n",
              "  array([[0.02011, 0.0531 , 0.02284, ..., 0.04807, 0.1043 , 0.1081 ]],\n",
              "        dtype=float16)),\n",
              " ('AHPC_PSEAB',\n",
              "  array([[-0.0006995,  0.02138  , -0.00614  , ..., -0.04324  ,  0.009926 ,\n",
              "           0.0505   ]], dtype=float16)),\n",
              " ('AHZ59732',\n",
              "  array([[ 0.04327 ,  0.164   ,  0.0231  , ..., -0.0459  ,  0.007587,\n",
              "           0.03958 ]], dtype=float16)),\n",
              " ('AIPS_SACS2',\n",
              "  array([[ 0.02943 , -0.04663 ,  0.03934 , ..., -0.02356 , -0.001999,\n",
              "          -0.00457 ]], dtype=float16)),\n",
              " ('AKA86819',\n",
              "  array([[ 0.04932 ,  0.09106 ,  0.011375, ...,  0.05713 ,  0.03955 ,\n",
              "          -0.03366 ]], dtype=float16)),\n",
              " ('AK_RICPR',\n",
              "  array([[ 0.009995, -0.01544 , -0.04538 , ..., -0.02365 ,  0.03796 ,\n",
              "           0.05573 ]], dtype=float16)),\n",
              " ('ALBA1_AERPE',\n",
              "  array([[-0.001018, -0.087   ,  0.0906  , ..., -0.0521  ,  0.0902  ,\n",
              "           0.02432 ]], dtype=float16)),\n",
              " ('ALBA2_AERPE',\n",
              "  array([[-0.0115 , -0.0921 ,  0.0968 , ..., -0.0323 ,  0.0796 ,  0.02179]],\n",
              "        dtype=float16)),\n",
              " ('ALBA2_SACS2',\n",
              "  array([[ 0.03134, -0.0883 ,  0.1174 , ..., -0.04013,  0.1118 ,  0.02654]],\n",
              "        dtype=float16)),\n",
              " ('ALBA2_SULTO',\n",
              "  array([[ 0.0274 , -0.1049 ,  0.0957 , ..., -0.04288,  0.10126,  0.02399]],\n",
              "        dtype=float16)),\n",
              " ('ALC14823',\n",
              "  array([[ 0.03522,  0.03473,  0.01135, ..., -0.01458,  0.0645 , -0.00809]],\n",
              "        dtype=float16)),\n",
              " ('ALC14901',\n",
              "  array([[0.03784 , 0.004196, 0.01805 , ..., 0.008415, 0.03787 , 0.00831 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC14937',\n",
              "  array([[-0.004444, -0.04013 ,  0.0321  , ...,  0.01756 ,  0.03943 ,\n",
              "           0.001567]], dtype=float16)),\n",
              " ('ALC14964',\n",
              "  array([[ 0.013214,  0.0902  ,  0.002777, ..., -0.01663 ,  0.0324  ,\n",
              "           0.018   ]], dtype=float16)),\n",
              " ('ALC15005',\n",
              "  array([[ 0.014946, -0.034   , -0.00433 , ..., -0.03137 ,  0.0909  ,\n",
              "           0.0674  ]], dtype=float16)),\n",
              " ('ALC15093',\n",
              "  array([[ 0.04123 , -0.00645 ,  0.004242, ..., -0.01507 ,  0.03305 ,\n",
              "           0.01941 ]], dtype=float16)),\n",
              " ('ALC15135',\n",
              "  array([[-0.0252  , -0.0525  ,  0.03217 , ..., -0.003216,  0.05096 ,\n",
              "          -0.01631 ]], dtype=float16)),\n",
              " ('ALC15232',\n",
              "  array([[ 0.05933,  0.01518,  0.02492, ..., -0.01997,  0.01001,  0.00744]],\n",
              "        dtype=float16)),\n",
              " ('ALC15247',\n",
              "  array([[ 0.003614,  0.0879  ,  0.01154 , ..., -0.003422, -0.03723 ,\n",
              "          -0.0304  ]], dtype=float16)),\n",
              " ('ALC15259',\n",
              "  array([[ 0.05502, -0.08246, -0.00132, ..., -0.00447,  0.07166, -0.01487]],\n",
              "        dtype=float16)),\n",
              " ('ALC15317',\n",
              "  array([[ 0.000837 ,  0.008965 ,  0.04468  , ..., -0.0009704, -0.0368   ,\n",
              "          -0.003279 ]], dtype=float16)),\n",
              " ('ALC15355',\n",
              "  array([[ 0.03253, -0.01508,  0.02203, ...,  0.02525,  0.02934,  0.0481 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC15427',\n",
              "  array([[ 0.02293 , -0.006405,  0.04303 , ...,  0.0552  ,  0.06064 ,\n",
              "          -0.03162 ]], dtype=float16)),\n",
              " ('ALC15438',\n",
              "  array([[-0.013885, -0.02953 ,  0.10547 , ..., -0.05148 , -0.0536  ,\n",
              "           0.0553  ]], dtype=float16)),\n",
              " ('ALC15443',\n",
              "  array([[ 0.01712  ,  0.07184  ,  0.0657   , ..., -0.002352 , -0.00864  ,\n",
              "           0.0004141]], dtype=float16)),\n",
              " ('ALC15479',\n",
              "  array([[-0.03732,  0.0175 ,  0.10596, ..., -0.0658 ,  0.03625, -0.02562]],\n",
              "        dtype=float16)),\n",
              " ('ALC15577',\n",
              "  array([[-0.002935,  0.05502 , -0.0342  , ..., -0.03308 ,  0.02118 ,\n",
              "           0.03384 ]], dtype=float16)),\n",
              " ('ALC15621',\n",
              "  array([[ 0.03574 , -0.11755 , -0.004307, ..., -0.06137 ,  0.0791  ,\n",
              "          -0.01442 ]], dtype=float16)),\n",
              " ('ALC15639',\n",
              "  array([[ 0.014786, -0.06903 , -0.01889 , ..., -0.0776  ,  0.0401  ,\n",
              "           0.01357 ]], dtype=float16)),\n",
              " ('ALC15643',\n",
              "  array([[ 0.03735 , -0.0736  ,  0.0267  , ...,  0.001505,  0.0545  ,\n",
              "           0.0893  ]], dtype=float16)),\n",
              " ('ALC15651',\n",
              "  array([[0.04333 , 0.014496, 0.099   , ..., 0.03317 , 0.06854 , 0.002836]],\n",
              "        dtype=float16)),\n",
              " ('ALC15653',\n",
              "  array([[ 0.006065, -0.07056 ,  0.06616 , ..., -0.002892,  0.0462  ,\n",
              "           0.04395 ]], dtype=float16)),\n",
              " ('ALC15654',\n",
              "  array([[ 0.02577 , -0.11847 ,  0.04834 , ...,  0.006912,  0.06207 ,\n",
              "           0.035   ]], dtype=float16)),\n",
              " ('ALC15671',\n",
              "  array([[ 0.03564, -0.00675, -0.01411, ..., -0.06067,  0.0081 ,  0.0348 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC15839',\n",
              "  array([[-0.0204 , -0.02519,  0.00912, ..., -0.02629,  0.06885,  0.05865]],\n",
              "        dtype=float16)),\n",
              " ('ALC15847',\n",
              "  array([[ 0.01199, -0.00397,  0.02571, ...,  0.0369 ,  0.03915,  0.01047]],\n",
              "        dtype=float16)),\n",
              " ('ALC15863',\n",
              "  array([[ 0.01309,  0.0905 ,  0.0402 , ...,  0.0027 ,  0.0572 , -0.0321 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC15929',\n",
              "  array([[-0.003536, -0.1256  ,  0.07196 , ..., -0.03152 , -0.002037,\n",
              "           0.04022 ]], dtype=float16)),\n",
              " ('ALC15994',\n",
              "  array([[ 0.01854 , -0.02658 ,  0.011116, ...,  0.00321 , -0.013405,\n",
              "           0.04013 ]], dtype=float16)),\n",
              " ('ALC16040',\n",
              "  array([[ 0.05524, -0.0318 ,  0.0514 , ...,  0.08606,  0.05725, -0.00676]],\n",
              "        dtype=float16)),\n",
              " ('ALC16141',\n",
              "  array([[-0.0716 ,  0.0795 ,  0.08105, ...,  0.1247 ,  0.0654 ,  0.0469 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC16213',\n",
              "  array([[ 0.01461,  0.07385,  0.01083, ..., -0.03503,  0.0786 , -0.02138]],\n",
              "        dtype=float16)),\n",
              " ('ALC16241',\n",
              "  array([[ 0.05383, -0.066  ,  0.04108, ..., -0.03156,  0.01385,  0.0556 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC16262',\n",
              "  array([[ 0.007576, -0.0935  ,  0.01469 , ..., -0.001313,  0.01802 ,\n",
              "           0.0954  ]], dtype=float16)),\n",
              " ('ALC16275',\n",
              "  array([[ 0.0866 , -0.06335,  0.01036, ...,  0.05444,  0.01235, -0.01738]],\n",
              "        dtype=float16)),\n",
              " ('ALC16285',\n",
              "  array([[ 0.032   ,  0.0834  ,  0.06726 , ...,  0.007675,  0.0234  ,\n",
              "          -0.03146 ]], dtype=float16)),\n",
              " ('ALC16286',\n",
              "  array([[-0.05328 , -0.004982, -0.02588 , ..., -0.05215 , -0.02632 ,\n",
              "          -0.0229  ]], dtype=float16)),\n",
              " ('ALC16339',\n",
              "  array([[-0.004322  ,  0.02592   ,  0.02994   , ...,  0.004433  ,\n",
              "           0.002783  , -0.00011504]], dtype=float16)),\n",
              " ('ALC16381',\n",
              "  array([[ 0.0218  , -0.0603  ,  0.000769, ..., -0.05725 ,  0.1268  ,\n",
              "           0.01078 ]], dtype=float16)),\n",
              " ('ALC16424',\n",
              "  array([[ 0.03046, -0.06836,  0.05286, ...,  0.0348 ,  0.0062 ,  0.02113]],\n",
              "        dtype=float16)),\n",
              " ('ALC16459',\n",
              "  array([[-0.06885 ,  0.09204 ,  0.001401, ..., -0.01029 , -0.052   ,\n",
              "           0.0851  ]], dtype=float16)),\n",
              " ('ALC16495',\n",
              "  array([[-0.0003 ,  0.01535,  0.05826, ...,  0.01721,  0.09784,  0.01868]],\n",
              "        dtype=float16)),\n",
              " ('ALC16514',\n",
              "  array([[ 0.05658 , -0.0358  ,  0.002207, ...,  0.008064,  0.011406,\n",
              "           0.014946]], dtype=float16)),\n",
              " ('ALC16559',\n",
              "  array([[ 0.03125 ,  0.04843 ,  0.001643, ..., -0.03162 ,  0.03014 ,\n",
              "           0.03702 ]], dtype=float16)),\n",
              " ('ALC16615',\n",
              "  array([[0.05154, 0.03912, 0.0551 , ..., 0.02737, 0.05234, 0.01495]],\n",
              "        dtype=float16)),\n",
              " ('ALC16626',\n",
              "  array([[-0.002731, -0.0824  , -0.01656 , ..., -0.02525 ,  0.00564 ,\n",
              "           0.00991 ]], dtype=float16)),\n",
              " ('ALC16640',\n",
              "  array([[-0.0368 ,  0.04572,  0.05826, ...,  0.04367,  0.02824,  0.07227]],\n",
              "        dtype=float16)),\n",
              " ('ALC16664',\n",
              "  array([[ 0.02383 , -0.02362 , -0.02512 , ...,  0.003191,  0.05505 ,\n",
              "           0.02902 ]], dtype=float16)),\n",
              " ('ALC16825',\n",
              "  array([[-0.003325, -0.07684 ,  0.05603 , ...,  0.00426 ,  0.03558 ,\n",
              "          -0.01979 ]], dtype=float16)),\n",
              " ('ALC16846',\n",
              "  array([[-0.002678,  0.0656  ,  0.0213  , ..., -0.008156, -0.00697 ,\n",
              "          -0.007217]], dtype=float16)),\n",
              " ('ALC16897',\n",
              "  array([[ 0.003933, -0.00518 , -0.00332 , ...,  0.03555 ,  0.02194 ,\n",
              "           0.02798 ]], dtype=float16)),\n",
              " ('ALC16914',\n",
              "  array([[ 0.05923 , -0.002562,  0.03436 , ...,  0.01984 ,  0.04825 ,\n",
              "           0.03052 ]], dtype=float16)),\n",
              " ('ALC17043',\n",
              "  array([[-0.08984,  0.1209 ,  0.0796 , ...,  0.139  ,  0.0702 , -0.0458 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC17044',\n",
              "  array([[ 0.06122, -0.04456,  0.02939, ...,  0.02118,  0.04602,  0.0248 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC17099',\n",
              "  array([[0.00977, 0.03387, 0.06012, ..., 0.0298 , 0.0844 , 0.04202]],\n",
              "        dtype=float16)),\n",
              " ('ALC17126',\n",
              "  array([[ 0.0316 , -0.038  ,  0.0074 , ..., -0.01058,  0.0274 , -0.04288]],\n",
              "        dtype=float16)),\n",
              " ('ALC17208',\n",
              "  array([[ 0.02176,  0.06525,  0.07324, ..., -0.03683,  0.03772,  0.0832 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC17232',\n",
              "  array([[ 0.008675 ,  0.01534  ,  0.0844   , ..., -0.0002787,  0.009026 ,\n",
              "           0.02429  ]], dtype=float16)),\n",
              " ('ALC17244',\n",
              "  array([[ 0.03714,  0.02855,  0.02013, ..., -0.02966,  0.02614,  0.01079]],\n",
              "        dtype=float16)),\n",
              " ('ALC17286',\n",
              "  array([[ 0.0804 ,  0.00843,  0.00923, ...,  0.01875, -0.0331 ,  0.04486]],\n",
              "        dtype=float16)),\n",
              " ('ALC17297',\n",
              "  array([[ 0.0752 ,  0.02374,  0.02568, ..., -0.0182 ,  0.0287 ,  0.0063 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC17353',\n",
              "  array([[ 0.0628   ,  0.0007977,  0.0796   , ...,  0.01796  , -0.01027  ,\n",
              "          -0.0643   ]], dtype=float16)),\n",
              " ('ALC17387',\n",
              "  array([[ 0.03296 , -0.0077  ,  0.02281 , ...,  0.071   , -0.002398,\n",
              "           0.01241 ]], dtype=float16)),\n",
              " ('ALC17462',\n",
              "  array([[ 0.000996, -0.0892  ,  0.02492 , ..., -0.0044  ,  0.0559  ,\n",
              "           0.04108 ]], dtype=float16)),\n",
              " ('ALC17471',\n",
              "  array([[-0.012825, -0.0647  ,  0.02151 , ...,  0.0173  ,  0.04434 ,\n",
              "           0.0316  ]], dtype=float16)),\n",
              " ('ALC17482',\n",
              "  array([[-0.05185 , -0.02106 ,  0.03323 , ..., -0.00825 ,  0.005592,\n",
              "          -0.03214 ]], dtype=float16)),\n",
              " ('ALC17558',\n",
              "  array([[0.01517 , 0.03952 , 0.04892 , ..., 0.03168 , 0.004593, 0.006546]],\n",
              "        dtype=float16)),\n",
              " ('ALC17593',\n",
              "  array([[-0.014206,  0.019   ,  0.03384 , ..., -0.03238 ,  0.0683  ,\n",
              "           0.0567  ]], dtype=float16)),\n",
              " ('ALC17743',\n",
              "  array([[ 0.069  , -0.02388, -0.00939, ..., -0.0407 , -0.04852,  0.05325]],\n",
              "        dtype=float16)),\n",
              " ('ALC17803',\n",
              "  array([[ 0.01556 , -0.012955,  0.0375  , ...,  0.01721 ,  0.005726,\n",
              "          -0.07117 ]], dtype=float16)),\n",
              " ('ALC17850',\n",
              "  array([[ 0.009254, -0.00986 , -0.01207 , ..., -0.05667 ,  0.01672 ,\n",
              "           0.001948]], dtype=float16)),\n",
              " ('ALC17851',\n",
              "  array([[ 0.02228,  0.05325,  0.05713, ..., -0.00948,  0.01947,  0.01938]],\n",
              "        dtype=float16)),\n",
              " ('ALC17951',\n",
              "  array([[-0.00712, -0.0387 ,  0.01449, ..., -0.02203,  0.05945,  0.0319 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC17968',\n",
              "  array([[-0.05557 , -0.06946 ,  0.0214  , ..., -0.001082,  0.0632  ,\n",
              "           0.01112 ]], dtype=float16)),\n",
              " ('ALC18067',\n",
              "  array([[-0.01634 , -0.05    ,  0.02533 , ..., -0.01578 , -0.003975,\n",
              "           0.002342]], dtype=float16)),\n",
              " ('ALC18081',\n",
              "  array([[ 0.02002,  0.03069, -0.01648, ...,  0.01003,  0.01631,  0.0018 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC18196',\n",
              "  array([[-0.00509,  0.0379 , -0.03516, ...,  0.03207,  0.03342, -0.0334 ]],\n",
              "        dtype=float16)),\n",
              " ('ALC18200',\n",
              "  array([[ 0.02177, -0.1133 ,  0.00665, ..., -0.03096,  0.03204,  0.06213]],\n",
              "        dtype=float16)),\n",
              " ('ALC18238',\n",
              "  array([[ 0.0464  , -0.02654 ,  0.01962 , ..., -0.006397, -0.001331,\n",
              "           0.04636 ]], dtype=float16)),\n",
              " ('ALC18239',\n",
              "  array([[ 0.01217,  0.02454,  0.0369 , ...,  0.00533,  0.00557, -0.0395 ]],\n",
              "        dtype=float16)),\n",
              " ('ALD2_RHORT',\n",
              "  array([[ 0.01941 ,  0.01674 ,  0.008484, ..., -0.01091 ,  0.01602 ,\n",
              "           0.01349 ]], dtype=float16)),\n",
              " ('ALF1_SYNY3',\n",
              "  array([[ 0.03467 ,  0.00351 ,  0.003342, ..., -0.02068 ,  0.02539 ,\n",
              "           0.07306 ]], dtype=float16)),\n",
              " ('ALGG_PSEAE',\n",
              "  array([[ 0.00962 , -0.0274  ,  0.0127  , ..., -0.01154 , -0.003893,\n",
              "          -0.01074 ]], dtype=float16)),\n",
              " ('ALX_SHIFL',\n",
              "  array([[ 0.0401 ,  0.10724,  0.03114, ..., -0.04095, -0.0425 ,  0.03918]],\n",
              "        dtype=float16)),\n",
              " ('AMIR_PSEAE',\n",
              "  array([[ 0.03455 , -0.1239  ,  0.013824, ..., -0.02692 ,  0.00847 ,\n",
              "           0.03793 ]], dtype=float16)),\n",
              " ('AMPM_CHLTR',\n",
              "  array([[0.0742  , 0.01306 , 0.01481 , ..., 0.01019 , 0.03032 , 0.001176]],\n",
              "        dtype=float16)),\n",
              " ('AMRZ_PSEAE',\n",
              "  array([[ 0.03912 , -0.05222 ,  0.004715, ...,  0.012665, -0.00544 ,\n",
              "           0.01701 ]], dtype=float16)),\n",
              " ('AMZA_METKA',\n",
              "  array([[ 0.05804, -0.0266 ,  0.01362, ..., -0.02446, -0.0113 , -0.01926]],\n",
              "        dtype=float16)),\n",
              " ('ANCA_HUNT2',\n",
              "  array([[0.04395, 0.01251, 0.0495 , ..., 0.0887 , 0.03427, 0.0512 ]],\n",
              "        dtype=float16)),\n",
              " ('AOO32299',\n",
              "  array([[ 0.03    ,  0.01875 , -0.008286, ..., -0.002146, -0.00253 ,\n",
              "           0.0878  ]], dtype=float16)),\n",
              " ('APAG_XANAC',\n",
              "  array([[ 0.006298, -0.007565,  0.02118 , ..., -0.001229,  0.0337  ,\n",
              "           0.05417 ]], dtype=float16)),\n",
              " ('APE29523',\n",
              "  array([[-0.04355 , -0.05374 ,  0.04614 , ...,  0.01799 , -0.03104 ,\n",
              "           0.005875]], dtype=float16)),\n",
              " ('APE29724',\n",
              "  array([[ 0.04663 , -0.08875 ,  0.007782, ...,  0.0501  ,  0.01671 ,\n",
              "           0.00806 ]], dtype=float16)),\n",
              " ('APE29847',\n",
              "  array([[ 0.0637 ,  0.01118,  0.0666 , ...,  0.0831 , -0.03015, -0.04056]],\n",
              "        dtype=float16)),\n",
              " ('APE29967',\n",
              "  array([[ 0.05478, -0.03464, -0.03796, ..., -0.0216 , -0.0115 , -0.01706]],\n",
              "        dtype=float16)),\n",
              " ('APE2_AERPE',\n",
              "  array([[ 0.02296 , -0.0494  ,  0.02257 , ..., -0.00838 , -0.005737,\n",
              "           0.03607 ]], dtype=float16)),\n",
              " ('APE30159',\n",
              "  array([[-0.05188,  0.02016, -0.00836, ...,  0.03047,  0.02565, -0.01266]],\n",
              "        dtype=float16)),\n",
              " ('APE30160',\n",
              "  array([[-0.002758,  0.004562,  0.03317 , ...,  0.0824  ,  0.0358  ,\n",
              "          -0.00073 ]], dtype=float16)),\n",
              " ('APE30368',\n",
              "  array([[-0.01336, -0.0778 , -0.01965, ..., -0.0514 ,  0.05652, -0.01446]],\n",
              "        dtype=float16)),\n",
              " ('APE30818',\n",
              "  array([[-0.00942,  0.0993 ,  0.02426, ...,  0.0272 ,  0.01304, -0.03366]],\n",
              "        dtype=float16)),\n",
              " ('APE31379',\n",
              "  array([[-0.005848, -0.02847 ,  0.02156 , ...,  0.044   , -0.02863 ,\n",
              "           0.005905]], dtype=float16)),\n",
              " ('APE31391',\n",
              "  array([[-0.02414,  0.03082, -0.01813, ...,  0.08356,  0.04047,  0.03476]],\n",
              "        dtype=float16)),\n",
              " ('APE31405',\n",
              "  array([[-0.0493  ,  0.1132  ,  0.05466 , ...,  0.042   ,  0.01214 ,\n",
              "           0.005024]], dtype=float16)),\n",
              " ('APE31665',\n",
              "  array([[ 0.002977, -0.01125 ,  0.00669 , ...,  0.092   , -0.0082  ,\n",
              "          -0.06696 ]], dtype=float16)),\n",
              " ('APE31689',\n",
              "  array([[0.002474, 0.00894 , 0.00448 , ..., 0.08777 , 0.04352 , 0.03787 ]],\n",
              "        dtype=float16)),\n",
              " ('APE31922',\n",
              "  array([[-0.002983, -0.1097  , -0.03418 , ...,  0.06604 , -0.0346  ,\n",
              "          -0.00466 ]], dtype=float16)),\n",
              " ('APE32080',\n",
              "  array([[-0.02196 , -0.1428  ,  0.002226, ...,  0.04068 ,  0.0297  ,\n",
              "          -0.01927 ]], dtype=float16)),\n",
              " ('APE32086',\n",
              "  array([[ 0.0664 ,  0.0984 ,  0.0675 , ..., -0.03073,  0.01094,  0.02625]],\n",
              "        dtype=float16)),\n",
              " ('APE32089',\n",
              "  array([[ 0.0761 , -0.01602, -0.0716 , ..., -0.05792,  0.02637,  0.03207]],\n",
              "        dtype=float16)),\n",
              " ('APW96311',\n",
              "  array([[ 0.02577, -0.02269, -0.03525, ...,  0.07886,  0.0408 , -0.01197]],\n",
              "        dtype=float16)),\n",
              " ('APW97692',\n",
              "  array([[-0.06433, -0.0702 , -0.03796, ...,  0.02995,  0.00693,  0.02197]],\n",
              "        dtype=float16)),\n",
              " ('APW98881',\n",
              "  array([[ 0.0272   , -0.01817  ,  0.03006  , ...,  0.006763 ,  0.0003579,\n",
              "           0.007004 ]], dtype=float16)),\n",
              " ('APW99198',\n",
              "  array([[ 0.03143, -0.03934, -0.047  , ...,  0.01434,  0.03897,  0.00542]],\n",
              "        dtype=float16)),\n",
              " ('APW99379',\n",
              "  array([[ 0.04062 , -0.013214, -0.03183 , ..., -0.01124 ,  0.02621 ,\n",
              "          -0.01286 ]], dtype=float16)),\n",
              " ('APX00272',\n",
              "  array([[-0.01215 , -0.0849  ,  0.001743, ...,  0.05215 ,  0.01131 ,\n",
              "          -0.001536]], dtype=float16)),\n",
              " ('AQDA2_RHOER',\n",
              "  array([[ 0.01022 , -0.03656 , -0.002333, ..., -0.04874 ,  0.02605 ,\n",
              "          -0.00301 ]], dtype=float16)),\n",
              " ('AQDR_RHOER',\n",
              "  array([[ 0.02618 , -0.03787 ,  0.005512, ..., -0.01463 ,  0.03406 ,\n",
              "           0.009026]], dtype=float16)),\n",
              " ('AQPM_METTM',\n",
              "  array([[ 0.06683,  0.07983,  0.04645, ..., -0.09045,  0.07294,  0.00285]],\n",
              "        dtype=float16)),\n",
              " ('ARCC_SYNY3',\n",
              "  array([[ 0.03754,  0.03247,  0.01496, ..., -0.02666,  0.03143,  0.02795]],\n",
              "        dtype=float16)),\n",
              " ('ARCH_THEMA',\n",
              "  array([[ 0.03607 , -0.1064  ,  0.08856 , ...,  0.05643 ,  0.001233,\n",
              "           0.0179  ]], dtype=float16)),\n",
              " ('ARE29957',\n",
              "  array([[-0.02206,  0.05527,  0.01417, ..., -0.01425,  0.04614,  0.03006]],\n",
              "        dtype=float16)),\n",
              " ('ARE29958',\n",
              "  array([[0.02422 , 0.01628 , 0.01068 , ..., 0.01956 , 0.002861, 0.022   ]],\n",
              "        dtype=float16)),\n",
              " ('ARE_SACSO',\n",
              "  array([[ 0.0813 ,  0.00617,  0.0465 , ..., -0.02443,  0.0768 ,  0.02156]],\n",
              "        dtype=float16)),\n",
              " ('ARFB_METJA',\n",
              "  array([[ 0.04956, -0.05334,  0.05856, ..., -0.01183,  0.05743,  0.02437]],\n",
              "        dtype=float16)),\n",
              " ('ARGB_PYRFU',\n",
              "  array([[ 0.04987 , -0.03552 ,  0.0098  , ..., -0.007133,  0.01584 ,\n",
              "           0.043   ]], dtype=float16)),\n",
              " ('ARGB_THEMA',\n",
              "  array([[ 0.0873 ,  0.033  , -0.01271, ...,  0.01204,  0.06555,  0.05417]],\n",
              "        dtype=float16)),\n",
              " ('ARGB_YERPE',\n",
              "  array([[ 0.06207 ,  0.03091 , -0.005245, ..., -0.01462 , -0.00666 ,\n",
              "           0.03123 ]], dtype=float16)),\n",
              " ('ARGC_LACLA',\n",
              "  array([[-0.02007 , -0.01567 ,  0.0139  , ...,  0.003504,  0.0654  ,\n",
              "           0.05963 ]], dtype=float16)),\n",
              " ('ARGDC_SACS2',\n",
              "  array([[ 0.07196,  0.00719,  0.03793, ..., -0.03546,  0.01008, -0.02324]],\n",
              "        dtype=float16)),\n",
              " ('ARGD_METJA',\n",
              "  array([[0.0873 , 0.02898, 0.03033, ..., 0.00816, 0.0563 , 0.0477 ]],\n",
              "        dtype=float16)),\n",
              " ('ARGD_SULSO',\n",
              "  array([[ 0.06635 , -0.001349,  0.02184 , ...,  0.003214,  0.04956 ,\n",
              "           0.02809 ]], dtype=float16)),\n",
              " ('ARGR_BACHD',\n",
              "  array([[ 0.02496,  0.00917, -0.02036, ...,  0.01281,  0.04785,  0.02046]],\n",
              "        dtype=float16)),\n",
              " ('ARGR_LACLA',\n",
              "  array([[ 0.0003612, -0.03102  ,  0.01048  , ..., -0.003384 ,  0.0716   ,\n",
              "          -0.0003252]], dtype=float16)),\n",
              " ('ARGR_VIBVY',\n",
              "  array([[-1.597e-05, -7.782e-02, -4.443e-02, ..., -1.526e-02,  1.527e-02,\n",
              "           1.758e-02]], dtype=float16)),\n",
              " ('ARGR_YERPE',\n",
              "  array([[-0.002905, -0.0545  , -0.02786 , ..., -0.002836,  0.002396,\n",
              "           0.00962 ]], dtype=float16)),\n",
              " ('ARNR1_SULAC',\n",
              "  array([[-1.752e-02, -3.809e-02,  6.076e-02, ...,  1.877e-02,  2.626e-03,\n",
              "           5.978e-05]], dtype=float16)),\n",
              " ('AROA_YERPE',\n",
              "  array([[ 0.06946,  0.0714 ,  0.0345 , ..., -0.02304, -0.03683,  0.05997]],\n",
              "        dtype=float16)),\n",
              " ('AROC_SULSO',\n",
              "  array([[ 0.03696 ,  0.003185,  0.04233 , ..., -0.01563 ,  0.04877 ,\n",
              "           0.02614 ]], dtype=float16)),\n",
              " ('AROD_LACLA',\n",
              "  array([[ 0.02751, -0.04034, -0.01004, ...,  0.00242,  0.0372 ,  0.02264]],\n",
              "        dtype=float16)),\n",
              " ('AROD_SULSO',\n",
              "  array([[ 0.0677  , -0.0735  ,  0.04376 , ...,  0.006775, -0.00915 ,\n",
              "           0.0478  ]], dtype=float16)),\n",
              " ('AROD_THEVO',\n",
              "  array([[ 0.0539 , -0.07904,  0.03366, ...,  0.02307,  0.0163 ,  0.0386 ]],\n",
              "        dtype=float16)),\n",
              " ('AROK_ARCFU',\n",
              "  array([[ 0.1008  , -0.0614  ,  0.005413, ...,  0.02132 ,  0.03775 ,\n",
              "          -0.03006 ]], dtype=float16)),\n",
              " ('AROK_SHIFL',\n",
              "  array([[ 0.071   ,  0.002432, -0.0488  , ..., -0.0468  ,  0.01472 ,\n",
              "           0.04132 ]], dtype=float16)),\n",
              " ('AROQ_THET8',\n",
              "  array([[ 0.08673 ,  0.0415  ,  0.08484 , ..., -0.010574,  0.02788 ,\n",
              "           0.04013 ]], dtype=float16)),\n",
              " ('ARSC_ECOLI',\n",
              "  array([[ 0.05493 ,  0.04947 ,  0.02449 , ..., -0.02292 , -0.000621,\n",
              "           0.0548  ]], dtype=float16)),\n",
              " ('ASK17857',\n",
              "  array([[ 0.0202  ,  0.04285 , -0.01448 , ...,  0.002092,  0.02765 ,\n",
              "          -0.05664 ]], dtype=float16)),\n",
              " ('ASK17877',\n",
              "  array([[ 0.01118 , -0.0548  ,  0.006134, ...,  0.0352  ,  0.07495 ,\n",
              "          -0.0937  ]], dtype=float16)),\n",
              " ('ASK17995',\n",
              "  array([[-0.007576, -0.10144 , -0.01953 , ..., -0.001656,  0.02399 ,\n",
              "           0.01625 ]], dtype=float16)),\n",
              " ('ASK18045',\n",
              "  array([[-0.00481 , -0.124   ,  0.003544, ..., -0.04218 , -0.0383  ,\n",
              "           0.04385 ]], dtype=float16)),\n",
              " ('ASK18076',\n",
              "  array([[ 0.0347  , -0.04257 , -0.0447  , ..., -0.005604, -0.01478 ,\n",
              "          -0.00731 ]], dtype=float16)),\n",
              " ('ASK18153',\n",
              "  array([[ 0.0425 , -0.01747,  0.02739, ..., -0.04788, -0.01839,  0.0394 ]],\n",
              "        dtype=float16)),\n",
              " ('ASK18373',\n",
              "  array([[ 0.0169  , -0.07434 ,  0.000692, ..., -0.0314  ,  0.03114 ,\n",
              "          -0.04883 ]], dtype=float16)),\n",
              " ('ASK18387',\n",
              "  array([[ 0.02972, -0.1525 ,  0.044  , ...,  0.0628 ,  0.0345 , -0.015  ]],\n",
              "        dtype=float16)),\n",
              " ('ASK18399',\n",
              "  array([[ 0.0455 , -0.0908 ,  0.0739 , ..., -0.06384,  0.0329 ,  0.0186 ]],\n",
              "        dtype=float16)),\n",
              " ('ASK18416',\n",
              "  array([[ 0.0773 , -0.08594,  0.02417, ..., -0.05966,  0.06744, -0.00823]],\n",
              "        dtype=float16)),\n",
              " ('ASK18418',\n",
              "  array([[-0.000793, -0.04938 ,  0.03815 , ..., -0.01035 ,  0.04358 ,\n",
              "           0.003136]], dtype=float16)),\n",
              " ('ASK18430',\n",
              "  array([[-0.01013 , -0.0688  ,  0.04602 , ..., -0.010216,  0.0518  ,\n",
              "          -0.03476 ]], dtype=float16)),\n",
              " ('ASK18735',\n",
              "  array([[ 0.02632 ,  0.02904 ,  0.0449  , ..., -0.005505, -0.03488 ,\n",
              "           0.0812  ]], dtype=float16)),\n",
              " ('ASK18748',\n",
              "  array([[-0.01782 , -0.02168 , -0.0184  , ..., -0.002415,  0.02751 ,\n",
              "           0.0428  ]], dtype=float16)),\n",
              " ('ASK18762',\n",
              "  array([[ 0.0787  ,  0.10864 , -0.001636, ..., -0.03424 , -0.02658 ,\n",
              "           0.02686 ]], dtype=float16)),\n",
              " ('ASK18850',\n",
              "  array([[ 0.1045  , -0.03014 , -0.02428 , ..., -0.05673 ,  0.003374,\n",
              "          -0.03198 ]], dtype=float16)),\n",
              " ('ASK18873',\n",
              "  array([[ 0.011986, -0.0209  ,  0.02145 , ...,  0.01674 ,  0.01772 ,\n",
              "          -0.04062 ]], dtype=float16)),\n",
              " ('ASK18874',\n",
              "  array([[ 0.0638 , -0.0371 , -0.02037, ..., -0.01105, -0.02203,  0.053  ]],\n",
              "        dtype=float16)),\n",
              " ('ASK18883',\n",
              "  array([[ 0.00411, -0.0815 ,  0.04053, ...,  0.07025,  0.0147 , -0.0223 ]],\n",
              "        dtype=float16)),\n",
              " ('ASK19007',\n",
              "  array([[ 0.0346 ,  0.01709,  0.0477 , ..., -0.022  ,  0.04642,  0.03253]],\n",
              "        dtype=float16)),\n",
              " ('ASK19223',\n",
              "  array([[ 0.019  ,  0.06635, -0.01335, ...,  0.07697,  0.04605,  0.03644]],\n",
              "        dtype=float16)),\n",
              " ('ASK19250',\n",
              "  array([[ 0.05585 ,  0.0083  , -0.01101 , ..., -0.05408 ,  0.0243  ,\n",
              "           0.009705]], dtype=float16)),\n",
              " ('ASK19253',\n",
              "  array([[ 0.07733, -0.09454,  0.03632, ..., -0.03268,  0.00979, -0.0323 ]],\n",
              "        dtype=float16)),\n",
              " ('ASK19352',\n",
              "  array([[-0.004414, -0.06155 , -0.0182  , ..., -0.04712 ,  0.002113,\n",
              "          -0.014336]], dtype=float16)),\n",
              " ('ASK20594',\n",
              "  array([[ 0.06586 ,  0.005978,  0.193   , ..., -0.11346 , -0.05493 ,\n",
              "           0.002184]], dtype=float16)),\n",
              " ('ASK20685',\n",
              "  array([[ 0.09094 , -0.05994 ,  0.04184 , ...,  0.005604, -0.03723 ,\n",
              "           0.01516 ]], dtype=float16)),\n",
              " ('ASK20698',\n",
              "  array([[-0.01875, -0.07404,  0.1302 , ...,  0.03458,  0.0801 ,  0.1326 ]],\n",
              "        dtype=float16)),\n",
              " ('ASK20704',\n",
              "  array([[ 0.0353  , -0.01438 ,  0.002068, ...,  0.001474,  0.0296  ,\n",
              "          -0.02655 ]], dtype=float16)),\n",
              " ('ASK20969',\n",
              "  array([[ 0.03293, -0.00854,  0.02948, ...,  0.05984, -0.00705,  0.0706 ]],\n",
              "        dtype=float16)),\n",
              " ('ASK21115',\n",
              "  array([[ 0.02312, -0.02946,  0.03488, ...,  0.0696 ,  0.0306 ,  0.02058]],\n",
              "        dtype=float16)),\n",
              " ('ASK21240',\n",
              "  array([[-0.003788,  0.02199 , -0.01884 , ..., -0.01468 ,  0.02412 ,\n",
              "           0.0463  ]], dtype=float16)),\n",
              " ('ASK21320',\n",
              "  array([[ 0.05835, -0.0399 ,  0.0301 , ..., -0.04245, -0.01251,  0.02034]],\n",
              "        dtype=float16)),\n",
              " ('ASK21644',\n",
              "  array([[-0.00415, -0.0686 , -0.00376, ..., -0.0318 ,  0.01886,  0.0924 ]],\n",
              "        dtype=float16)),\n",
              " ('ASK21736',\n",
              "  array([[-0.01585 , -0.03195 , -0.01374 , ...,  0.004818, -0.01598 ,\n",
              "          -0.0329  ]], dtype=float16)),\n",
              " ('ASK21739',\n",
              "  array([[0.01651, 0.04648, 0.01225, ..., 0.01018, 0.0628 , 0.01706]],\n",
              "        dtype=float16)),\n",
              " ('ASK21797',\n",
              "  array([[ 0.02486, -0.00795, -0.00447, ..., -0.00962, -0.0772 , -0.02165]],\n",
              "        dtype=float16)),\n",
              " ('ASK21842',\n",
              "  array([[ 0.0962  ,  0.003525,  0.06934 , ...,  0.0763  , -0.05313 ,\n",
              "          -0.008125]], dtype=float16)),\n",
              " ('ASNC_ECOLI',\n",
              "  array([[ 0.01028 ,  0.02496 , -0.011986, ...,  0.00873 ,  0.0174  ,\n",
              "           0.002153]], dtype=float16)),\n",
              " ('ASR2_YERPE',\n",
              "  array([[-0.0206 ,  0.1177 ,  0.01345, ...,  0.1006 ,  0.04193,  0.05978]],\n",
              "        dtype=float16)),\n",
              " ('ASU77152',\n",
              "  array([[-0.003153, -0.01222 ,  0.06366 , ..., -0.0325  , -0.02827 ,\n",
              "           0.07104 ]], dtype=float16)),\n",
              " ('ASU77199',\n",
              "  array([[-0.03748 , -0.01938 , -0.009834, ...,  0.0083  , -0.003565,\n",
              "          -0.0656  ]], dtype=float16)),\n",
              " ('ASU77264',\n",
              "  array([[ 0.01435, -0.0802 ,  0.0291 , ..., -0.02756,  0.02657, -0.05014]],\n",
              "        dtype=float16)),\n",
              " ('ASU77718',\n",
              "  array([[-0.007385,  0.0376  , -0.01083 , ...,  0.07135 ,  0.006927,\n",
              "          -0.02592 ]], dtype=float16)),\n",
              " ('ASU77731',\n",
              "  array([[-0.00657, -0.1072 ,  0.03546, ...,  0.01255, -0.03848, -0.02731]],\n",
              "        dtype=float16)),\n",
              " ('ASU77770',\n",
              "  array([[-0.0275 ,  0.02231,  0.06027, ...,  0.07025,  0.00429,  0.05176]],\n",
              "        dtype=float16)),\n",
              " ('ASU77779',\n",
              "  array([[ 0.002995, -0.00485 , -0.01993 , ...,  0.01138 , -0.02473 ,\n",
              "           0.02724 ]], dtype=float16)),\n",
              " ('ASU77861',\n",
              "  array([[-0.075   , -0.1208  ,  0.04514 , ...,  0.0525  ,  0.03833 ,\n",
              "           0.001057]], dtype=float16)),\n",
              " ('ASU78140',\n",
              "  array([[ 0.03625, -0.0719 ,  0.0393 , ...,  0.04034,  0.048  , -0.0513 ]],\n",
              "        dtype=float16)),\n",
              " ('ASU78414',\n",
              "  array([[ 0.0753 , -0.03983,  0.03268, ...,  0.03638,  0.02614,  0.03262]],\n",
              "        dtype=float16)),\n",
              " ('ASU78631',\n",
              "  array([[-0.131  , -0.1212 , -0.0188 , ..., -0.1278 , -0.01578, -0.1522 ]],\n",
              "        dtype=float16)),\n",
              " ('ASU78648',\n",
              "  array([[-0.00933 , -0.04092 ,  0.01653 , ..., -0.0468  , -0.0305  ,\n",
              "          -0.007225]], dtype=float16)),\n",
              " ('ASU78712',\n",
              "  array([[ 0.03577 , -0.0964  ,  0.02063 , ...,  0.0358  ,  0.00755 ,\n",
              "          -0.002888]], dtype=float16)),\n",
              " ('ASU78847',\n",
              "  array([[ 0.008995, -0.015236, -0.02333 , ...,  0.02885 ,  0.04276 ,\n",
              "          -0.02399 ]], dtype=float16)),\n",
              " ('ASU78943',\n",
              "  array([[ 0.00867, -0.03616,  0.03696, ...,  0.02202, -0.10345,  0.0743 ]],\n",
              "        dtype=float16)),\n",
              " ('ASU79038',\n",
              "  array([[-0.01543,  0.05237,  0.02245, ...,  0.06256,  0.0447 , -0.03336]],\n",
              "        dtype=float16)),\n",
              " ('ASU79176',\n",
              "  array([[ 0.007343,  0.033   ,  0.004562, ...,  0.06152 , -0.003302,\n",
              "          -0.05734 ]], dtype=float16)),\n",
              " ('ASU80202',\n",
              "  array([[ 0.04626, -0.0584 ,  0.01446, ...,  0.03625,  0.01327,  0.0385 ]],\n",
              "        dtype=float16)),\n",
              " ('ASU80721',\n",
              "  array([[ 0.05817, -0.02144, -0.00409, ...,  0.02554,  0.01049, -0.00368]],\n",
              "        dtype=float16)),\n",
              " ('ASU80828',\n",
              "  array([[ 0.01455, -0.04202,  0.06586, ..., -0.0395 ,  0.00644,  0.00659]],\n",
              "        dtype=float16)),\n",
              " ('ATJ81411',\n",
              "  array([[ 0.02342, -0.02492, -0.03433, ...,  0.03143,  0.0278 , -0.05823]],\n",
              "        dtype=float16)),\n",
              " ('ATJ81941',\n",
              "  array([[-0.01476, -0.1027 ,  0.03522, ...,  0.00143,  0.02647, -0.02773]],\n",
              "        dtype=float16)),\n",
              " ('ATJ82019',\n",
              "  array([[-0.02133,  0.03836, -0.04446, ..., -0.0145 ,  0.01617,  0.0068 ]],\n",
              "        dtype=float16)),\n",
              " ('ATJ82512',\n",
              "  array([[0.066  , 0.04086, 0.07745, ..., 0.0494 , 0.01072, 0.04376]],\n",
              "        dtype=float16)),\n",
              " ('ATJ83044',\n",
              "  array([[ 0.00908 ,  0.09515 ,  0.08606 , ..., -0.013374,  0.02577 ,\n",
              "           0.0631  ]], dtype=float16)),\n",
              " ('ATJ83236',\n",
              "  array([[0.10223  , 0.0494   , 0.04242  , ..., 0.0968   , 0.05438  ,\n",
              "          0.0004227]], dtype=float16)),\n",
              " ('ATJ83396',\n",
              "  array([[-0.0845 ,  0.04837, -0.0214 , ...,  0.00919,  0.02922, -0.01714]],\n",
              "        dtype=float16)),\n",
              " ('ATJ83686',\n",
              "  array([[-0.01443, -0.02092,  0.04572, ...,  0.0666 , -0.002  , -0.02397]],\n",
              "        dtype=float16)),\n",
              " ('ATJ84404',\n",
              "  array([[ 0.00786 ,  0.015434,  0.03069 , ..., -0.05548 , -0.01894 ,\n",
              "          -0.05045 ]], dtype=float16)),\n",
              " ('ATJ84415',\n",
              "  array([[-0.007164,  0.02704 ,  0.04095 , ..., -0.01166 ,  0.02708 ,\n",
              "           0.04944 ]], dtype=float16)),\n",
              " ('ATJ84674',\n",
              "  array([[ 0.03833,  0.0884 ,  0.02814, ..., -0.02336, -0.01201,  0.04535]],\n",
              "        dtype=float16)),\n",
              " ('ATPD_MYCGE',\n",
              "  array([[-0.03723 , -0.0414  , -0.005474, ...,  0.0741  ,  0.07965 ,\n",
              "           0.08887 ]], dtype=float16)),\n",
              " ('ATPD_RICPR',\n",
              "  array([[-0.03735, -0.02542, -0.0619 , ...,  0.01701,  0.03674,  0.08746]],\n",
              "        dtype=float16)),\n",
              " ('ATPE_LACLA',\n",
              "  array([[ 0.004017, -0.01156 , -0.0061  , ...,  0.007233,  0.04922 ,\n",
              "           0.0527  ]], dtype=float16)),\n",
              " ('ATPE_MYCGE',\n",
              "  array([[-0.05817, -0.02843,  0.04367, ...,  0.01645,  0.07056,  0.0836 ]],\n",
              "        dtype=float16)),\n",
              " ('ATPE_PARDP',\n",
              "  array([[-0.02995, -0.0397 ,  0.0286 , ...,  0.02145,  0.01587,  0.06934]],\n",
              "        dtype=float16)),\n",
              " ('ATPE_RICPR',\n",
              "  array([[-0.0496 ,  0.03653, -0.126  , ..., -0.07666, -0.03214,  0.03424]],\n",
              "        dtype=float16)),\n",
              " ('ATPE_SYNY3',\n",
              "  array([[ 0.01377 ,  0.01245 , -0.002779, ..., -0.02068 , -0.02425 ,\n",
              "           0.03058 ]], dtype=float16)),\n",
              " ('ATPE_THEMA',\n",
              "  array([[0.006382, 0.001198, 0.05743 , ..., 0.01826 , 0.0925  , 0.02216 ]],\n",
              "        dtype=float16)),\n",
              " ('ATPF_SYNY3',\n",
              "  array([[-0.0268  , -0.0959  , -0.000988, ...,  0.04922 ,  0.03452 ,\n",
              "           0.03247 ]], dtype=float16)),\n",
              " ('ATPG_ECOLI',\n",
              "  array([[ 0.04214 ,  0.02492 ,  0.015236, ..., -0.0309  , -0.00571 ,\n",
              "           0.05692 ]], dtype=float16)),\n",
              " ('ATPL_MYCGE',\n",
              "  array([[-0.02063,  0.02472,  0.04587, ..., -0.02493,  0.0702 ,  0.01561]],\n",
              "        dtype=float16)),\n",
              " ('ATPL_RICPR',\n",
              "  array([[-0.02177 ,  0.06067 ,  0.0569  , ..., -0.011505,  0.10095 ,\n",
              "           0.01377 ]], dtype=float16)),\n",
              " ('ATPL_SULTO',\n",
              "  array([[ 0.00931,  0.0524 ,  0.1001 , ..., -0.02524,  0.0394 , -0.01567]],\n",
              "        dtype=float16)),\n",
              " ('ATSE_AGRFC',\n",
              "  array([[-0.005573, -0.05185 , -0.01074 , ..., -0.04352 ,  0.03568 ,\n",
              "          -0.01593 ]], dtype=float16)),\n",
              " ('ATW86845',\n",
              "  array([[ 0.010445, -0.07434 , -0.05927 , ..., -0.00793 ,  0.01613 ,\n",
              "          -0.002754]], dtype=float16)),\n",
              " ('ATW86924',\n",
              "  array([[ 0.01244,  0.05603,  0.05185, ...,  0.03326,  0.01942, -0.02966]],\n",
              "        dtype=float16)),\n",
              " ('ATW87025',\n",
              "  array([[ 0.05453 ,  0.02525 , -0.02765 , ..., -0.006493,  0.0584  ,\n",
              "          -0.005703]], dtype=float16)),\n",
              " ('ATW87079',\n",
              "  array([[-0.02147 , -0.03143 ,  0.012146, ...,  0.00993 ,  0.007107,\n",
              "           0.02176 ]], dtype=float16)),\n",
              " ('ATW87082',\n",
              "  array([[-0.01848 , -0.01252 ,  0.00256 , ...,  0.01814 , -0.01234 ,\n",
              "           0.008705]], dtype=float16)),\n",
              " ('ATW87106',\n",
              "  array([[ 0.05753, -0.0867 , -0.02515, ..., -0.02922,  0.0287 ,  0.06204]],\n",
              "        dtype=float16)),\n",
              " ('ATW87234',\n",
              "  array([[-0.0005927, -0.02667  ,  0.001212 , ...,  0.001439 , -0.02643  ,\n",
              "          -0.01279  ]], dtype=float16)),\n",
              " ('ATW87277',\n",
              "  array([[0.02316, 0.0779 , 0.01886, ..., 0.06055, 0.0403 , 0.0294 ]],\n",
              "        dtype=float16)),\n",
              " ('ATW87384',\n",
              "  array([[ 0.0736 , -0.04486,  0.104  , ...,  0.04877,  0.02887,  0.01446]],\n",
              "        dtype=float16)),\n",
              " ('ATW87693',\n",
              "  array([[ 0.001838 , -0.0722   ,  0.01878  , ...,  0.04837  ,  0.01584  ,\n",
              "           0.0006104]], dtype=float16)),\n",
              " ('ATW87694',\n",
              "  array([[ 0.00638 , -0.06537 ,  0.01663 , ...,  0.00293 , -0.05472 ,\n",
              "           0.002352]], dtype=float16)),\n",
              " ('ATW87782',\n",
              "  array([[ 0.02242  , -0.0469   ,  0.01637  , ..., -0.06683  ,  0.02448  ,\n",
              "           0.0004592]], dtype=float16)),\n",
              " ('ATW87952',\n",
              "  array([[ 0.006073,  0.0877  ,  0.05246 , ...,  0.05664 ,  0.0182  ,\n",
              "          -0.05582 ]], dtype=float16)),\n",
              " ('ATW88066',\n",
              "  array([[ 0.06107, -0.04004, -0.02934, ..., -0.03897,  0.032  ,  0.02928]],\n",
              "        dtype=float16)),\n",
              " ('ATW88105',\n",
              "  array([[ 0.01648 , -0.02376 ,  0.012344, ...,  0.0658  ,  0.03406 ,\n",
              "           0.04477 ]], dtype=float16)),\n",
              " ('ATW88120',\n",
              "  array([[ 0.05215 , -0.01689 ,  0.007133, ..., -0.0097  ,  0.03125 ,\n",
              "           0.02914 ]], dtype=float16)),\n",
              " ('ATW88165',\n",
              "  array([[ 0.1252  , -0.04517 ,  0.06384 , ...,  0.04355 , -0.03452 ,\n",
              "           0.011475]], dtype=float16)),\n",
              " ('ATW88189',\n",
              "  array([[-0.007187, -0.0358  ,  0.0483  , ..., -0.02142 ,  0.02542 ,\n",
              "           0.006634]], dtype=float16)),\n",
              " ('ATW88191',\n",
              "  array([[ 0.03644 ,  0.04684 ,  0.04846 , ...,  0.011375,  0.001963,\n",
              "          -0.01467 ]], dtype=float16)),\n",
              " ('ATW88229',\n",
              "  array([[ 0.03662,  0.01533,  0.0783 , ...,  0.0346 , -0.00907, -0.0506 ]],\n",
              "        dtype=float16)),\n",
              " ('ATW88241',\n",
              "  array([[ 0.0665 ,  0.0709 ,  0.01342, ...,  0.02318,  0.043  , -0.05716]],\n",
              "        dtype=float16)),\n",
              " ('ATW88279',\n",
              "  array([[ 0.0949  , -0.07135 , -0.0399  , ..., -0.013664,  0.07245 ,\n",
              "          -0.0636  ]], dtype=float16)),\n",
              " ('ATW88313',\n",
              "  array([[-0.01221 , -0.04163 , -0.0297  , ...,  0.009186, -0.003761,\n",
              "          -0.02455 ]], dtype=float16)),\n",
              " ('ATW88323',\n",
              "  array([[-0.01062 , -0.10144 , -0.0496  , ...,  0.012054, -0.02347 ,\n",
              "           0.06726 ]], dtype=float16)),\n",
              " ('ATW88335',\n",
              "  array([[ 0.00139, -0.0452 ,  0.01055, ...,  0.0799 , -0.03806,  0.01457]],\n",
              "        dtype=float16)),\n",
              " ('ATW88751',\n",
              "  array([[ 0.02063, -0.03995,  0.0364 , ...,  0.02145,  0.03867, -0.06036]],\n",
              "        dtype=float16)),\n",
              " ('ATW88855',\n",
              "  array([[ 0.04642, -0.0662 ,  0.04324, ...,  0.04056,  0.05685,  0.03078]],\n",
              "        dtype=float16)),\n",
              " ('ATW89032',\n",
              "  array([[-0.0276 , -0.0391 , -0.05493, ..., -0.0354 , -0.0763 ,  0.03763]],\n",
              "        dtype=float16)),\n",
              " ('ATW89181',\n",
              "  array([[-0.01281, -0.0191 , -0.02332, ...,  0.0352 ,  0.01949,  0.05295]],\n",
              "        dtype=float16)),\n",
              " ('ATW89299',\n",
              "  array([[ 0.03412 , -0.006134, -0.00697 , ...,  0.02785 ,  0.03125 ,\n",
              "          -0.001183]], dtype=float16)),\n",
              " ('ATW89549',\n",
              "  array([[ 0.001987,  0.02225 ,  0.0572  , ...,  0.0668  , -0.00504 ,\n",
              "          -0.0592  ]], dtype=float16)),\n",
              " ('ATW89550',\n",
              "  array([[ 0.01289,  0.02441,  0.0203 , ..., -0.00406,  0.0226 ,  0.01432]],\n",
              "        dtype=float16)),\n",
              " ('ATW89567',\n",
              "  array([[ 0.0301  , -0.06683 ,  0.06995 , ...,  0.001597,  0.0209  ,\n",
              "           0.005474]], dtype=float16)),\n",
              " ('ATW89681',\n",
              "  array([[ 0.03192, -0.0327 ,  0.08246, ...,  0.01414,  0.02188,  0.1215 ]],\n",
              "        dtype=float16)),\n",
              " ('ATW89899',\n",
              "  array([[ 0.005722, -0.05756 , -0.01784 , ..., -0.04245 ,  0.05768 ,\n",
              "          -0.02164 ]], dtype=float16)),\n",
              " ('ATW90113',\n",
              "  array([[ 0.04956 , -0.0338  , -0.03238 , ...,  0.003496,  0.01959 ,\n",
              "          -0.02576 ]], dtype=float16)),\n",
              " ('ATW90137',\n",
              "  array([[ 0.0226 , -0.05505, -0.04465, ...,  0.0694 ,  0.0172 , -0.0415 ]],\n",
              "        dtype=float16)),\n",
              " ('AVP39970',\n",
              "  array([[ 0.02583, -0.0862 , -0.0437 , ...,  0.01287, -0.0699 , -0.0203 ]],\n",
              "        dtype=float16)),\n",
              " ('AVP39971',\n",
              "  array([[ 0.02586, -0.02113,  0.0879 , ...,  0.0644 ,  0.02568, -0.08264]],\n",
              "        dtype=float16)),\n",
              " ('AVV32309',\n",
              "  array([[-0.02174 , -0.0901  , -0.001852, ..., -0.0226  ,  0.006958,\n",
              "          -0.005405]], dtype=float16)),\n",
              " ('AVV32416',\n",
              "  array([[-0.0689  , -0.031   ,  0.05975 , ..., -0.012474,  0.005913,\n",
              "           0.0767  ]], dtype=float16)),\n",
              " ('AVV32492',\n",
              "  array([[-0.009   , -0.004387,  0.000844, ...,  0.01738 ,  0.06824 ,\n",
              "          -0.00949 ]], dtype=float16)),\n",
              " ('AVV32567',\n",
              "  array([[-0.02754, -0.0908 , -0.01724, ...,  0.0605 , -0.058  , -0.02397]],\n",
              "        dtype=float16)),\n",
              " ('AVV32832',\n",
              "  array([[ 0.01599 , -0.02011 , -0.0697  , ...,  0.007057,  0.02557 ,\n",
              "          -0.06067 ]], dtype=float16)),\n",
              " ('AVV32881',\n",
              "  array([[ 0.02306,  0.0512 , -0.02545, ...,  0.121  , -0.04813,  0.00659]],\n",
              "        dtype=float16)),\n",
              " ('AVV33007',\n",
              "  array([[ 0.04727 ,  0.1213  , -0.007053, ...,  0.02211 , -0.02943 ,\n",
              "           0.0095  ]], dtype=float16)),\n",
              " ('AVV33016',\n",
              "  array([[-0.01843 , -0.0586  ,  0.04053 , ..., -0.001011, -0.01033 ,\n",
              "           0.00865 ]], dtype=float16)),\n",
              " ('AVV33027',\n",
              "  array([[ 0.0557 ,  0.08435, -0.01958, ..., -0.02498,  0.01211,  0.03696]],\n",
              "        dtype=float16)),\n",
              " ('AVV33114',\n",
              "  array([[ 0.04297 , -0.02245 , -0.02133 , ...,  0.0726  ,  0.007755,\n",
              "           0.006145]], dtype=float16)),\n",
              " ('AVV33209',\n",
              "  array([[ 0.00913 , -0.0732  , -0.011406, ..., -0.0797  ,  0.03702 ,\n",
              "           0.0784  ]], dtype=float16)),\n",
              " ('AVV33216',\n",
              "  array([[-0.015495,  0.02028 , -0.003809, ...,  0.2045  ,  0.03165 ,\n",
              "           0.1039  ]], dtype=float16)),\n",
              " ('AVV33309',\n",
              "  array([[-0.03476 ,  0.007736,  0.04742 , ...,  0.01895 , -0.00868 ,\n",
              "           0.00926 ]], dtype=float16)),\n",
              " ('AVV33481',\n",
              "  array([[-0.0295 , -0.0754 ,  0.0682 , ..., -0.01474,  0.01182,  0.04245]],\n",
              "        dtype=float16)),\n",
              " ('AVV33505',\n",
              "  array([[-0.02039 ,  0.0454  , -0.015396, ...,  0.04074 , -0.001227,\n",
              "           0.076   ]], dtype=float16)),\n",
              " ('AVV33755',\n",
              "  array([[-0.03012 , -0.0479  , -0.01587 , ...,  0.01678 ,  0.009705,\n",
              "          -0.03952 ]], dtype=float16)),\n",
              " ('AVV33799',\n",
              "  array([[-0.02379 , -0.0262  ,  0.007687, ...,  0.12317 ,  0.0942  ,\n",
              "           0.01034 ]], dtype=float16)),\n",
              " ('AVV33917',\n",
              "  array([[-0.03134,  0.05173,  0.0485 , ...,  0.10297,  0.0995 , -0.02089]],\n",
              "        dtype=float16)),\n",
              " ('AVV33953',\n",
              "  array([[-0.02225,  0.09705,  0.05658, ...,  0.05902,  0.0684 ,  0.02716]],\n",
              "        dtype=float16)),\n",
              " ('AVV33954',\n",
              "  array([[ 0.03888 ,  0.0319  ,  0.02844 , ...,  0.0861  , -0.005573,\n",
              "          -0.0303  ]], dtype=float16)),\n",
              " ('AVV33956',\n",
              "  array([[ 0.01398 ,  0.01706 ,  0.0466  , ...,  0.005394, -0.04187 ,\n",
              "           0.05954 ]], dtype=float16)),\n",
              " ('AVV34024',\n",
              "  array([[-0.07324 , -0.005474, -0.012924, ...,  0.08344 , -0.05753 ,\n",
              "           0.04245 ]], dtype=float16)),\n",
              " ('AVV34765',\n",
              "  array([[-0.03653 , -0.04257 ,  0.0449  , ...,  0.006355,  0.06305 ,\n",
              "           0.0902  ]], dtype=float16)),\n",
              " ('AVV34898',\n",
              "  array([[-0.00995 ,  0.0214  ,  0.05704 , ..., -0.02939 ,  0.02841 ,\n",
              "          -0.014206]], dtype=float16)),\n",
              " ('AVV35123',\n",
              "  array([[-0.04834 ,  0.01042 ,  0.0546  , ..., -0.02266 , -0.006374,\n",
              "           0.02026 ]], dtype=float16)),\n",
              " ('AVV35166',\n",
              "  array([[-0.01432 ,  0.10114 ,  0.003893, ...,  0.06854 ,  0.0453  ,\n",
              "          -0.02203 ]], dtype=float16)),\n",
              " ('AVV35231',\n",
              "  array([[ 0.1151 ,  0.02313,  0.185  , ...,  0.10596, -0.0578 ,  0.0675 ]],\n",
              "        dtype=float16)),\n",
              " ('AWB26259',\n",
              "  array([[ 0.0546 , -0.0117 ,  0.07733, ...,  0.01984,  0.03662, -0.02983]],\n",
              "        dtype=float16)),\n",
              " ('AWB26573',\n",
              "  array([[ 0.027   ,  0.03854 , -0.02646 , ...,  0.11536 ,  0.019   ,\n",
              "           0.002092]], dtype=float16)),\n",
              " ('AWB26598',\n",
              "  array([[-0.0354 ,  0.03207, -0.00712, ...,  0.0525 ,  0.037  ,  0.01532]],\n",
              "        dtype=float16)),\n",
              " ('AWB26684',\n",
              "  array([[ 0.09436 , -0.06335 , -0.001709, ...,  0.04565 ,  0.0701  ,\n",
              "          -0.01133 ]], dtype=float16)),\n",
              " ('AWB26801',\n",
              "  array([[-0.004  , -0.0531 , -0.05096, ..., -0.02217, -0.06024,  0.0552 ]],\n",
              "        dtype=float16)),\n",
              " ('AWB26815',\n",
              "  array([[-8.430e-03, -2.873e-02,  4.601e-05, ..., -2.541e-02, -3.760e-02,\n",
              "          -6.329e-02]], dtype=float16)),\n",
              " ('AWB27436',\n",
              "  array([[ 0.03265,  0.0332 ,  0.05286, ..., -0.02084,  0.0256 ,  0.0407 ]],\n",
              "        dtype=float16)),\n",
              " ('AWB27507',\n",
              "  array([[ 0.0616 , -0.06137,  0.0377 , ...,  0.116  ,  0.01572,  0.03506]],\n",
              "        dtype=float16)),\n",
              " ('AWB27646',\n",
              "  array([[ 0.02206 , -0.005116,  0.03882 , ...,  0.013916,  0.05432 ,\n",
              "          -0.01686 ]], dtype=float16)),\n",
              " ('AWB27664',\n",
              "  array([[ 0.01768 , -0.009926, -0.01898 , ...,  0.02196 ,  0.0482  ,\n",
              "          -0.00242 ]], dtype=float16)),\n",
              " ('AWB27991',\n",
              "  array([[ 0.06335,  0.04712,  0.1545 , ...,  0.02298,  0.0509 , -0.02765]],\n",
              "        dtype=float16)),\n",
              " ('AWB28312',\n",
              "  array([[ 0.07935 ,  0.0697  ,  0.01883 , ...,  0.009285, -0.000356,\n",
              "          -0.002481]], dtype=float16)),\n",
              " ('AWB28342',\n",
              "  array([[-0.0215  ,  0.0468  , -0.03857 , ...,  0.0633  ,  0.05774 ,\n",
              "           0.004547]], dtype=float16)),\n",
              " ('AWB28389',\n",
              "  array([[ 0.02773 , -0.05777 , -0.012535, ...,  0.004883,  0.004646,\n",
              "          -0.01077 ]], dtype=float16)),\n",
              " ('AWB28462',\n",
              "  array([[ 0.01715 , -0.08954 , -0.02293 , ...,  0.01875 ,  0.03433 ,\n",
              "           0.004967]], dtype=float16)),\n",
              " ('AWB28574',\n",
              "  array([[-0.02081 , -0.09406 , -0.006084, ...,  0.0651  ,  0.005962,\n",
              "           0.01066 ]], dtype=float16)),\n",
              " ('AZUP_METEA',\n",
              "  array([[-0.01436,  0.05624,  0.04102, ...,  0.03708, -0.02338,  0.00534]],\n",
              "        dtype=float16)),\n",
              " ('BADR_RHOPA',\n",
              "  array([[ 0.0084  , -0.03024 , -0.01767 , ..., -0.02922 ,  0.006695,\n",
              "           0.02533 ]], dtype=float16)),\n",
              " ('BAUB_PSEAE',\n",
              "  array([[ 0.06042 ,  0.02818 , -0.0083  , ..., -0.03955 ,  0.03152 ,\n",
              "           0.012985]], dtype=float16)),\n",
              " ('BBI47718',\n",
              "  array([[-0.005306, -0.02934 , -0.04144 , ...,  0.05832 , -0.004246,\n",
              "           0.01897 ]], dtype=float16)),\n",
              " ('BBI47881',\n",
              "  array([[-0.06995 , -0.01863 ,  0.03952 , ...,  0.003637,  0.003471,\n",
              "           0.01079 ]], dtype=float16)),\n",
              " ('BBI48003',\n",
              "  array([[-0.02243 , -0.006187,  0.04745 , ...,  0.0583  ,  0.06335 ,\n",
              "           0.0139  ]], dtype=float16)),\n",
              " ('BBI48020',\n",
              "  array([[-0.00397,  0.02705,  0.04675, ..., -0.06757, -0.04068,  0.02591]],\n",
              "        dtype=float16)),\n",
              " ('BBI48029',\n",
              "  array([[ 0.03198  , -0.0217   , -0.0006366, ..., -0.04376  ,  0.0385   ,\n",
              "           0.0844   ]], dtype=float16)),\n",
              " ('BBI48031',\n",
              "  array([[ 0.02562 , -0.03323 ,  0.008644, ...,  0.01976 ,  0.02832 ,\n",
              "           0.0853  ]], dtype=float16)),\n",
              " ('BBI48036',\n",
              "  array([[ 0.01854 ,  0.004208,  0.0627  , ...,  0.0135  , -0.03806 ,\n",
              "          -0.0567  ]], dtype=float16)),\n",
              " ('BBI48092',\n",
              "  array([[-0.003895, -0.05673 , -0.007164, ..., -0.04675 ,  0.0407  ,\n",
              "           0.01107 ]], dtype=float16)),\n",
              " ('BBI48130',\n",
              "  array([[-0.00771, -0.04422,  0.01653, ...,  0.02185,  0.00546,  0.01567]],\n",
              "        dtype=float16)),\n",
              " ('BBI48135',\n",
              "  array([[-0.00404, -0.084  ,  0.071  , ...,  0.05334,  0.02367,  0.05603]],\n",
              "        dtype=float16)),\n",
              " ('BBI48348',\n",
              "  array([[-0.05426 , -0.02782 ,  0.0499  , ...,  0.04352 ,  0.02888 ,\n",
              "           0.006893]], dtype=float16)),\n",
              " ('BBI48360',\n",
              "  array([[-0.04584, -0.03433,  0.02325, ..., -0.01756, -0.01119,  0.08234]],\n",
              "        dtype=float16)),\n",
              " ('BBI48414',\n",
              "  array([[-0.07214,  0.0371 ,  0.02412, ..., -0.0694 , -0.01025, -0.0772 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI48423',\n",
              "  array([[ 0.01507 , -0.06604 ,  0.03644 , ...,  0.02635 ,  0.006645,\n",
              "           0.02483 ]], dtype=float16)),\n",
              " ('BBI48466',\n",
              "  array([[-0.00617 ,  0.0288  ,  0.04965 , ...,  0.017   , -0.01566 ,\n",
              "           0.007717]], dtype=float16)),\n",
              " ('BBI48583',\n",
              "  array([[ 0.02232,  0.06604,  0.02354, ...,  0.0237 ,  0.0306 , -0.05658]],\n",
              "        dtype=float16)),\n",
              " ('BBI48597',\n",
              "  array([[ 0.001123,  0.05618 ,  0.0191  , ...,  0.003334,  0.03195 ,\n",
              "          -0.06085 ]], dtype=float16)),\n",
              " ('BBI48600',\n",
              "  array([[ 0.02434 , -0.03653 ,  0.006454, ..., -0.01248 ,  0.009186,\n",
              "           0.06088 ]], dtype=float16)),\n",
              " ('BBI48616',\n",
              "  array([[0.02806, 0.04584, 0.00542, ..., 0.02724, 0.0329 , 0.08936]],\n",
              "        dtype=float16)),\n",
              " ('BBI48661',\n",
              "  array([[ 0.0006933,  0.09326  ,  0.01466  , ...,  0.02718  , -0.00671  ,\n",
              "           0.02795  ]], dtype=float16)),\n",
              " ('BBI48739',\n",
              "  array([[ 0.03323 ,  0.05807 , -0.02763 , ..., -0.01008 , -0.01562 ,\n",
              "           0.002897]], dtype=float16)),\n",
              " ('BBI48824',\n",
              "  array([[-0.0849 , -0.036  ,  0.05557, ...,  0.02777,  0.03812, -0.0219 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI48870',\n",
              "  array([[-0.03537 ,  0.004612,  0.03226 , ..., -0.00929 , -0.01625 ,\n",
              "          -0.0354  ]], dtype=float16)),\n",
              " ('BBI48906',\n",
              "  array([[ 0.00952,  0.0445 ,  0.01082, ..., -0.00998, -0.0393 , -0.02849]],\n",
              "        dtype=float16)),\n",
              " ('BBI48925',\n",
              "  array([[0.003817, 0.04654 , 0.001031, ..., 0.03424 , 0.02586 , 0.02475 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI48933',\n",
              "  array([[ 0.002213, -0.0695  , -0.01069 , ...,  0.003529, -0.02065 ,\n",
              "          -0.01523 ]], dtype=float16)),\n",
              " ('BBI48975',\n",
              "  array([[ 0.02286,  0.0172 ,  0.01197, ..., -0.00807,  0.02129, -0.0472 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI49010',\n",
              "  array([[-0.062  , -0.00983,  0.05084, ..., -0.00359,  0.00638,  0.04312]],\n",
              "        dtype=float16)),\n",
              " ('BBI49047',\n",
              "  array([[-0.01248 , -0.02457 ,  0.02737 , ...,  0.003414, -0.0358  ,\n",
              "           0.03256 ]], dtype=float16)),\n",
              " ('BBI49108',\n",
              "  array([[ 0.012085,  0.0357  , -0.02882 , ..., -0.01637 ,  0.04422 ,\n",
              "           0.0283  ]], dtype=float16)),\n",
              " ('BBI49127',\n",
              "  array([[-0.03354, -0.05368,  0.04144, ...,  0.05585,  0.07007,  0.0841 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI49153',\n",
              "  array([[-0.0395  ,  0.05698 ,  0.04214 , ...,  0.002937,  0.0353  ,\n",
              "           0.0501  ]], dtype=float16)),\n",
              " ('BBI49176',\n",
              "  array([[-0.0915 , -0.02197,  0.07465, ...,  0.0524 ,  0.05612,  0.07684]],\n",
              "        dtype=float16)),\n",
              " ('BBI49270',\n",
              "  array([[ 0.004986, -0.0372  ,  0.05753 , ...,  0.042   ,  0.0408  ,\n",
              "           0.00793 ]], dtype=float16)),\n",
              " ('BBI49271',\n",
              "  array([[ 0.02675 ,  0.04794 ,  0.01128 , ...,  0.00432 , -0.002638,\n",
              "           0.00481 ]], dtype=float16)),\n",
              " ('BBI49306',\n",
              "  array([[ 0.02853 , -0.02232 ,  0.02745 , ..., -0.006226, -0.03262 ,\n",
              "          -0.004143]], dtype=float16)),\n",
              " ('BBI49423',\n",
              "  array([[-0.05194, -0.07336,  0.01912, ..., -0.02344,  0.05566,  0.08356]],\n",
              "        dtype=float16)),\n",
              " ('BBI49536',\n",
              "  array([[ 0.0666  , -0.0262  , -0.005856, ..., -0.0361  ,  0.006775,\n",
              "           0.0345  ]], dtype=float16)),\n",
              " ('BBI49637',\n",
              "  array([[ 0.01234 ,  0.0813  ,  0.0399  , ...,  0.005615, -0.005524,\n",
              "           0.01505 ]], dtype=float16)),\n",
              " ('BBI49648',\n",
              "  array([[-0.00736,  0.03433,  0.02916, ..., -0.0481 ,  0.0117 , -0.00392]],\n",
              "        dtype=float16)),\n",
              " ('BBI49668',\n",
              "  array([[-0.01009,  0.01463, -0.03072, ..., -0.00255,  0.01116,  0.02855]],\n",
              "        dtype=float16)),\n",
              " ('BBI49723',\n",
              "  array([[ 0.034  , -0.0589 ,  0.07935, ..., -0.02277, -0.0523 ,  0.01027]],\n",
              "        dtype=float16)),\n",
              " ('BBI49800',\n",
              "  array([[ 0.02232,  0.02045,  0.03998, ..., -0.00513,  0.0554 ,  0.02339]],\n",
              "        dtype=float16)),\n",
              " ('BBI49851',\n",
              "  array([[-0.0158 , -0.00286,  0.01807, ...,  0.01041,  0.026  ,  0.02657]],\n",
              "        dtype=float16)),\n",
              " ('BBI49920',\n",
              "  array([[-0.07385, -0.0662 ,  0.06537, ...,  0.02196,  0.06854, -0.00883]],\n",
              "        dtype=float16)),\n",
              " ('BBI49982',\n",
              "  array([[ 0.0362  ,  0.11536 ,  0.04102 , ..., -0.005833,  0.02191 ,\n",
              "           0.00461 ]], dtype=float16)),\n",
              " ('BBI49996',\n",
              "  array([[ 0.0196 ,  0.03165,  0.01415, ...,  0.02577,  0.01013, -0.01785]],\n",
              "        dtype=float16)),\n",
              " ('BBI50041',\n",
              "  array([[ 0.0346 ,  0.0736 , -0.03296, ...,  0.00667,  0.00813,  0.0512 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI50097',\n",
              "  array([[ 0.04987,  0.11017, -0.01363, ..., -0.0085 , -0.00607,  0.04636]],\n",
              "        dtype=float16)),\n",
              " ('BBI50187',\n",
              "  array([[-0.005592, -0.074   , -0.04602 , ..., -0.04526 , -0.03525 ,\n",
              "          -0.01403 ]], dtype=float16)),\n",
              " ('BBI50262',\n",
              "  array([[ 0.01325,  0.0586 , -0.01117, ...,  0.05478,  0.01945,  0.02371]],\n",
              "        dtype=float16)),\n",
              " ('BBI50325',\n",
              "  array([[ 0.01717 , -0.004227,  0.0164  , ..., -0.02473 ,  0.0329  ,\n",
              "           0.01369 ]], dtype=float16)),\n",
              " ('BBI50368',\n",
              "  array([[ 0.02585 , -0.0705  , -0.05225 , ...,  0.005722, -0.006428,\n",
              "           0.05673 ]], dtype=float16)),\n",
              " ('BBI50437',\n",
              "  array([[-0.01895, -0.0374 ,  0.04352, ...,  0.047  ,  0.0428 ,  0.01672]],\n",
              "        dtype=float16)),\n",
              " ('BBI50605',\n",
              "  array([[-0.05048 , -0.01817 ,  0.00871 , ..., -0.03284 ,  0.001966,\n",
              "          -0.006786]], dtype=float16)),\n",
              " ('BBI50667',\n",
              "  array([[-0.02667 , -0.0446  ,  0.002382, ...,  0.0715  , -0.03976 ,\n",
              "           0.06647 ]], dtype=float16)),\n",
              " ('BBI50700',\n",
              "  array([[ 0.08093,  0.0827 ,  0.00961, ..., -0.02211,  0.00673,  0.01826]],\n",
              "        dtype=float16)),\n",
              " ('BBI50726',\n",
              "  array([[-0.019  , -0.0804 , -0.03485, ..., -0.06128,  0.02942,  0.01814]],\n",
              "        dtype=float16)),\n",
              " ('BBI50730',\n",
              "  array([[-0.03415 , -0.0605  ,  0.04855 , ..., -0.04343 ,  0.02182 ,\n",
              "          -0.004078]], dtype=float16)),\n",
              " ('BBI50801',\n",
              "  array([[-0.002935,  0.03232 ,  0.05563 , ...,  0.03116 ,  0.01151 ,\n",
              "           0.00998 ]], dtype=float16)),\n",
              " ('BBI50815',\n",
              "  array([[ 0.0424  ,  0.00975 ,  0.007168, ..., -0.013535,  0.01924 ,\n",
              "           0.02689 ]], dtype=float16)),\n",
              " ('BBI50849',\n",
              "  array([[-0.002203, -0.09784 ,  0.009445, ...,  0.002579, -0.02379 ,\n",
              "          -0.02159 ]], dtype=float16)),\n",
              " ('BBI50958',\n",
              "  array([[-0.01776 ,  0.0386  , -0.006996, ..., -0.01726 , -0.001294,\n",
              "          -0.03336 ]], dtype=float16)),\n",
              " ('BBI51083',\n",
              "  array([[ 0.02013, -0.10504,  0.02843, ..., -0.0634 ,  0.02768, -0.03363]],\n",
              "        dtype=float16)),\n",
              " ('BBI51086',\n",
              "  array([[ 0.05002,  0.03854,  0.0262 , ...,  0.02481,  0.01259, -0.01903]],\n",
              "        dtype=float16)),\n",
              " ('BBI51087',\n",
              "  array([[ 0.02176,  0.05554, -0.03458, ...,  0.0457 ,  0.04858, -0.02748]],\n",
              "        dtype=float16)),\n",
              " ('BBI51113',\n",
              "  array([[ 0.0185  , -0.003632,  0.0535  , ...,  0.04117 ,  0.05737 ,\n",
              "          -0.05472 ]], dtype=float16)),\n",
              " ('BBI51156',\n",
              "  array([[-0.00519, -0.0809 , -0.0378 , ...,  0.03262, -0.00854,  0.01004]],\n",
              "        dtype=float16)),\n",
              " ('BBI51202',\n",
              "  array([[-0.001201, -0.01329 ,  0.01551 , ...,  0.06555 ,  0.003893,\n",
              "           0.03069 ]], dtype=float16)),\n",
              " ('BBI51207',\n",
              "  array([[-0.008286,  0.0394  ,  0.010414, ..., -0.02046 ,  0.01373 ,\n",
              "           0.02437 ]], dtype=float16)),\n",
              " ('BBI51276',\n",
              "  array([[-0.0136  , -0.04025 ,  0.03223 , ...,  0.01567 , -0.003695,\n",
              "           0.05524 ]], dtype=float16)),\n",
              " ('BBI51351',\n",
              "  array([[ 0.04245 ,  0.06744 ,  0.02075 , ..., -0.007698,  0.01301 ,\n",
              "           0.04758 ]], dtype=float16)),\n",
              " ('BBI51394',\n",
              "  array([[ 0.00631 , -0.0765  , -0.00537 , ..., -0.009605, -0.01129 ,\n",
              "           0.02927 ]], dtype=float16)),\n",
              " ('BBI51403',\n",
              "  array([[-0.011314, -0.05713 , -0.01836 , ..., -0.0166  ,  0.02223 ,\n",
              "           0.09906 ]], dtype=float16)),\n",
              " ('BBI51410',\n",
              "  array([[-0.0642  , -0.007122,  0.03108 , ...,  0.03683 ,  0.04407 ,\n",
              "           0.0622  ]], dtype=float16)),\n",
              " ('BBI51424',\n",
              "  array([[-0.0353  ,  0.01179 ,  0.006466, ..., -0.002186,  0.068   ,\n",
              "           0.03177 ]], dtype=float16)),\n",
              " ('BBI51451',\n",
              "  array([[ 0.0099  ,  0.001412, -0.05768 , ..., -0.01851 , -0.007523,\n",
              "           0.00657 ]], dtype=float16)),\n",
              " ('BBI51466',\n",
              "  array([[ 0.0413 ,  0.03099, -0.01619, ...,  0.0262 , -0.0259 , -0.0331 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI51487',\n",
              "  array([[-0.03925,  0.01383,  0.05276, ...,  0.06885,  0.07367,  0.0842 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI51616',\n",
              "  array([[ 1.378e-02,  2.106e-03, -5.054e-02, ...,  2.921e-06,  1.105e-02,\n",
              "          -6.366e-02]], dtype=float16)),\n",
              " ('BBI51617',\n",
              "  array([[ 0.01141,  0.01695, -0.02151, ...,  0.01596,  0.03326, -0.05783]],\n",
              "        dtype=float16)),\n",
              " ('BBI51622',\n",
              "  array([[ 0.04532, -0.0637 , -0.03238, ...,  0.0225 , -0.01831, -0.05978]],\n",
              "        dtype=float16)),\n",
              " ('BBI51647',\n",
              "  array([[-0.0295 ,  0.00765,  0.02248, ...,  0.0114 , -0.02985,  0.0104 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI51657',\n",
              "  array([[-0.0329  , -0.009575,  0.0226  , ..., -0.005436,  0.001482,\n",
              "          -0.05222 ]], dtype=float16)),\n",
              " ('BBI51690',\n",
              "  array([[-0.02347 , -0.02771 ,  0.01168 , ...,  0.002806,  0.002918,\n",
              "          -0.0108  ]], dtype=float16)),\n",
              " ('BBI51705',\n",
              "  array([[ 0.04608, -0.00829,  0.0483 , ..., -0.03232,  0.04   ,  0.0505 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI51754',\n",
              "  array([[-0.05304 , -0.007008, -0.00959 , ...,  0.010254, -0.01208 ,\n",
              "           0.0491  ]], dtype=float16)),\n",
              " ('BBI51916',\n",
              "  array([[-0.0511  ,  0.02109 ,  0.02827 , ..., -0.005035,  0.01055 ,\n",
              "          -0.00635 ]], dtype=float16)),\n",
              " ('BBI51927',\n",
              "  array([[-0.01707 , -0.03305 ,  0.05182 , ..., -0.009964,  0.02266 ,\n",
              "          -0.02731 ]], dtype=float16)),\n",
              " ('BBI51977',\n",
              "  array([[-0.003382,  0.02837 ,  0.02638 , ...,  0.02502 , -0.02313 ,\n",
              "          -0.0372  ]], dtype=float16)),\n",
              " ('BBI51987',\n",
              "  array([[-0.01245 ,  0.005302, -0.02739 , ..., -0.001016,  0.009926,\n",
              "           0.03348 ]], dtype=float16)),\n",
              " ('BBI52031',\n",
              "  array([[-0.03976 ,  0.00881 ,  0.04025 , ..., -0.003248,  0.0264  ,\n",
              "           0.05023 ]], dtype=float16)),\n",
              " ('BBI52036',\n",
              "  array([[-0.02582 , -0.014885,  0.04065 , ..., -0.02292 ,  0.008064,\n",
              "          -0.00489 ]], dtype=float16)),\n",
              " ('BBI52111',\n",
              "  array([[-0.006573,  0.02136 , -0.07306 , ..., -0.05103 , -0.0284  ,\n",
              "           0.093   ]], dtype=float16)),\n",
              " ('BBI52128',\n",
              "  array([[ 0.045   ,  0.0498  , -0.008095, ...,  0.01683 ,  0.007614,\n",
              "           0.04633 ]], dtype=float16)),\n",
              " ('BBI52152',\n",
              "  array([[-0.01522 , -0.02226 ,  0.03925 , ..., -0.02023 ,  0.006508,\n",
              "           0.03296 ]], dtype=float16)),\n",
              " ('BBI52217',\n",
              "  array([[-0.00894 , -0.05774 , -0.003191, ..., -0.005184,  0.02121 ,\n",
              "           0.0171  ]], dtype=float16)),\n",
              " ('BBI52224',\n",
              "  array([[ 0.0158  , -0.02332 ,  0.05112 , ...,  0.04465 ,  0.04453 ,\n",
              "           0.013596]], dtype=float16)),\n",
              " ('BBI52234',\n",
              "  array([[ 0.010506,  0.00884 ,  0.05933 , ..., -0.02711 ,  0.05035 ,\n",
              "          -0.011024]], dtype=float16)),\n",
              " ('BBI52251',\n",
              "  array([[ 0.03162, -0.0718 ,  0.02061, ..., -0.0372 ,  0.00513, -0.0111 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI52306',\n",
              "  array([[-0.02414 , -0.07654 ,  0.005787, ..., -0.04248 ,  0.06027 ,\n",
              "          -0.0453  ]], dtype=float16)),\n",
              " ('BBI52376',\n",
              "  array([[ 0.0817  ,  0.000325,  0.00723 , ..., -0.02626 , -0.01738 ,\n",
              "          -0.005646]], dtype=float16)),\n",
              " ('BBI52420',\n",
              "  array([[ 0.01614,  0.05106,  0.04807, ...,  0.01023,  0.0256 , -0.01195]],\n",
              "        dtype=float16)),\n",
              " ('BBI52471',\n",
              "  array([[ 0.02933,  0.011  ,  0.04114, ..., -0.02504,  0.01093,  0.02484]],\n",
              "        dtype=float16)),\n",
              " ('BBI52502',\n",
              "  array([[ 0.01555, -0.0789 , -0.00354, ...,  0.02196,  0.05798,  0.02774]],\n",
              "        dtype=float16)),\n",
              " ('BBI52622',\n",
              "  array([[-0.03226 ,  0.00467 ,  0.011444, ...,  0.013824, -0.0206  ,\n",
              "           0.00419 ]], dtype=float16)),\n",
              " ('BBI52634',\n",
              "  array([[ 0.02698, -0.05417,  0.04114, ..., -0.0452 ,  0.03146,  0.0614 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI52847',\n",
              "  array([[ 0.05106,  0.01768, -0.02997, ...,  0.02098,  0.0273 , -0.02002]],\n",
              "        dtype=float16)),\n",
              " ('BBI52863',\n",
              "  array([[-0.01515, -0.07916, -0.00887, ..., -0.0177 ,  0.02446,  0.07965]],\n",
              "        dtype=float16)),\n",
              " ('BBI52967',\n",
              "  array([[ 0.01654, -0.02682, -0.0823 , ..., -0.04883, -0.01633, -0.056  ]],\n",
              "        dtype=float16)),\n",
              " ('BBI52968',\n",
              "  array([[ 0.0405  , -0.00675 ,  0.04968 , ..., -0.002747, -0.02844 ,\n",
              "          -0.008125]], dtype=float16)),\n",
              " ('BBI52977',\n",
              "  array([[-0.02452  ,  0.006058 , -0.02493  , ..., -0.03091  ,  0.0003824,\n",
              "          -0.00839  ]], dtype=float16)),\n",
              " ('BBI53114',\n",
              "  array([[0.03223 , 0.08215 , 0.01639 , ..., 0.003952, 0.013   , 0.03772 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI53122',\n",
              "  array([[-0.0475   , -0.02945  ,  0.0014715, ..., -0.00856  ,  0.01996  ,\n",
              "          -0.002632 ]], dtype=float16)),\n",
              " ('BBI53278',\n",
              "  array([[ 0.034  , -0.05365, -0.04886, ..., -0.02068, -0.02069,  0.03665]],\n",
              "        dtype=float16)),\n",
              " ('BBI53283',\n",
              "  array([[ 0.01114, -0.0187 , -0.00394, ..., -0.02588, -0.0487 , -0.02876]],\n",
              "        dtype=float16)),\n",
              " ('BBI53316',\n",
              "  array([[-4.776e-03,  2.915e-05,  1.199e-03, ...,  9.621e-03, -4.440e-02,\n",
              "           1.527e-02]], dtype=float16)),\n",
              " ('BBI53323',\n",
              "  array([[ 0.01903, -0.02925, -0.0646 , ..., -0.01448,  0.01852, -0.00329]],\n",
              "        dtype=float16)),\n",
              " ('BBI53361',\n",
              "  array([[-0.05652  , -0.0217   ,  0.00383  , ..., -0.02388  , -0.0008183,\n",
              "           0.04437  ]], dtype=float16)),\n",
              " ('BBI53363',\n",
              "  array([[-0.01608,  0.0842 , -0.029  , ...,  0.02896,  0.02786, -0.0471 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI53375',\n",
              "  array([[0.06555 , 0.04376 , 0.02007 , ..., 0.02415 , 0.02101 , 0.006954]],\n",
              "        dtype=float16)),\n",
              " ('BBI53384',\n",
              "  array([[-0.03873 , -0.02448 ,  0.03592 , ...,  0.009415, -0.05573 ,\n",
              "           0.06793 ]], dtype=float16)),\n",
              " ('BBI53451',\n",
              "  array([[ 0.00728,  0.04608, -0.02187, ...,  0.0715 ,  0.0417 , -0.01736]],\n",
              "        dtype=float16)),\n",
              " ('BBI53480',\n",
              "  array([[ 0.06216  ,  0.0436   ,  0.003222 , ...,  0.0007434, -0.009254 ,\n",
              "           0.0003462]], dtype=float16)),\n",
              " ('BBI53482',\n",
              "  array([[ 5.881e-02,  9.790e-02,  1.381e-02, ...,  2.489e-02, -2.748e-05,\n",
              "           2.364e-02]], dtype=float16)),\n",
              " ('BBI53503',\n",
              "  array([[ 0.02432,  0.04135,  0.0371 , ..., -0.02322,  0.04343,  0.05835]],\n",
              "        dtype=float16)),\n",
              " ('BBI53507',\n",
              "  array([[-0.03842 ,  0.005493,  0.01833 , ...,  0.06366 ,  0.02083 ,\n",
              "           0.02069 ]], dtype=float16)),\n",
              " ('BBI53533',\n",
              "  array([[-0.02122 , -0.05408 ,  0.0353  , ..., -0.0425  , -0.00859 ,\n",
              "           0.000983]], dtype=float16)),\n",
              " ('BBI53700',\n",
              "  array([[0.05783, 0.00866, 0.06885, ..., 0.0332 , 0.04233, 0.0387 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI53761',\n",
              "  array([[-0.04947 ,  0.1108  ,  0.021   , ...,  0.02686 ,  0.003412,\n",
              "           0.01665 ]], dtype=float16)),\n",
              " ('BBI53778',\n",
              "  array([[-0.0333  , -0.01437 ,  0.015465, ...,  0.0637  , -0.03137 ,\n",
              "           0.0367  ]], dtype=float16)),\n",
              " ('BBI53784',\n",
              "  array([[-0.0388  , -0.0992  ,  0.02728 , ...,  0.05304 ,  0.003845,\n",
              "          -0.06396 ]], dtype=float16)),\n",
              " ('BBI53799',\n",
              "  array([[-0.0351 , -0.03394,  0.04874, ..., -0.02156,  0.0521 ,  0.0425 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI53825',\n",
              "  array([[-0.08954,  0.07605,  0.03494, ...,  0.00785,  0.04224, -0.02534]],\n",
              "        dtype=float16)),\n",
              " ('BBI53828',\n",
              "  array([[-0.003565, -0.03873 , -0.01761 , ..., -0.0311  , -0.004593,\n",
              "           0.01144 ]], dtype=float16)),\n",
              " ('BBI53864',\n",
              "  array([[ 0.0714  , -0.05283 ,  0.001496, ..., -0.05475 , -0.02719 ,\n",
              "          -0.05176 ]], dtype=float16)),\n",
              " ('BBI53900',\n",
              "  array([[-0.02438 , -0.0232  ,  0.009026, ..., -0.02843 ,  0.11096 ,\n",
              "          -0.01138 ]], dtype=float16)),\n",
              " ('BBI54056',\n",
              "  array([[ 0.04855 ,  0.02776 ,  0.0151  , ..., -0.001213,  0.0355  ,\n",
              "           0.01551 ]], dtype=float16)),\n",
              " ('BBI54085',\n",
              "  array([[ 0.00036  , -0.0204   , -0.007347 , ..., -0.0546   ,  0.0244   ,\n",
              "           0.0004685]], dtype=float16)),\n",
              " ('BBI54152',\n",
              "  array([[-0.01049 ,  0.014366, -0.02089 , ..., -0.01811 ,  0.000534,\n",
              "          -0.01246 ]], dtype=float16)),\n",
              " ('BBI54300',\n",
              "  array([[-0.04102 ,  0.06366 , -0.02808 , ...,  0.1322  , -0.005745,\n",
              "           0.02408 ]], dtype=float16)),\n",
              " ('BBI54370',\n",
              "  array([[-0.05133,  0.03525,  0.05597, ...,  0.06586,  0.01214,  0.03296]],\n",
              "        dtype=float16)),\n",
              " ('BBI54452',\n",
              "  array([[-0.0227  ,  0.0319  ,  0.005043, ...,  0.02081 ,  0.003384,\n",
              "           0.01186 ]], dtype=float16)),\n",
              " ('BBI54457',\n",
              "  array([[-1.348e-03,  7.361e-02, -1.907e-05, ...,  7.565e-03, -1.030e-02,\n",
              "          -3.333e-02]], dtype=float16)),\n",
              " ('BBI54473',\n",
              "  array([[ 0.01566,  0.05264, -0.00907, ...,  0.03577, -0.00701,  0.03436]],\n",
              "        dtype=float16)),\n",
              " ('BBI54521',\n",
              "  array([[ 0.0217 ,  0.00703, -0.0424 , ..., -0.03104,  0.03564,  0.02931]],\n",
              "        dtype=float16)),\n",
              " ('BBI54574',\n",
              "  array([[ 0.0297  ,  0.05774 , -0.0603  , ...,  0.009094, -0.0068  ,\n",
              "           0.00832 ]], dtype=float16)),\n",
              " ('BBI54628',\n",
              "  array([[-0.01595, -0.0845 ,  0.02995, ..., -0.05426,  0.0722 ,  0.03754]],\n",
              "        dtype=float16)),\n",
              " ('BBI54768',\n",
              "  array([[-0.05606 ,  0.006287,  0.05145 , ...,  0.0887  ,  0.0563  ,\n",
              "           0.02243 ]], dtype=float16)),\n",
              " ('BBI54807',\n",
              "  array([[-0.01516, -0.03735, -0.0402 , ...,  0.0061 , -0.0472 ,  0.02463]],\n",
              "        dtype=float16)),\n",
              " ('BBI54853',\n",
              "  array([[-0.02371,  0.04163,  0.10004, ...,  0.01559,  0.02368,  0.01585]],\n",
              "        dtype=float16)),\n",
              " ('BBI54854',\n",
              "  array([[-0.03061  , -0.0007515,  0.014626 , ...,  0.002352 , -0.02338  ,\n",
              "          -0.046    ]], dtype=float16)),\n",
              " ('BBI69945',\n",
              "  array([[ 0.03238 , -0.00746 , -0.04437 , ...,  0.002747, -0.002365,\n",
              "           0.0737  ]], dtype=float16)),\n",
              " ('BBI70053',\n",
              "  array([[ 0.0197  ,  0.001838, -0.002384, ..., -0.04544 ,  0.06854 ,\n",
              "           0.02998 ]], dtype=float16)),\n",
              " ('BBI70130',\n",
              "  array([[ 0.001082, -0.03983 , -0.004566, ...,  0.08655 , -0.03525 ,\n",
              "           0.0538  ]], dtype=float16)),\n",
              " ('BBI70220',\n",
              "  array([[-0.01155,  0.02635,  0.00953, ...,  0.02393, -0.01489,  0.03073]],\n",
              "        dtype=float16)),\n",
              " ('BBI70246',\n",
              "  array([[-0.0269,  0.0819,  0.0368, ...,  0.0669,  0.0102,  0.0638]],\n",
              "        dtype=float16)),\n",
              " ('BBI70264',\n",
              "  array([[ 0.001448,  0.05585 , -0.010254, ..., -0.008835, -0.0315  ,\n",
              "           0.015396]], dtype=float16)),\n",
              " ('BBI70286',\n",
              "  array([[-0.06134,  0.04654,  0.01903, ...,  0.04358,  0.02983,  0.05798]],\n",
              "        dtype=float16)),\n",
              " ('BBI70288',\n",
              "  array([[-0.0294 ,  0.04575,  0.02258, ...,  0.05255,  0.00531,  0.05917]],\n",
              "        dtype=float16)),\n",
              " ('BBI70321',\n",
              "  array([[-0.03265  ,  0.1007   ,  0.02003  , ..., -0.0418   ,  0.0007997,\n",
              "           0.001899 ]], dtype=float16)),\n",
              " ('BBI70353',\n",
              "  array([[ 0.00521,  0.04462, -0.01265, ..., -0.0241 , -0.0419 , -0.03427]],\n",
              "        dtype=float16)),\n",
              " ('BBI70501',\n",
              "  array([[ 0.01164,  0.02156,  0.01974, ...,  0.05484,  0.01685, -0.04587]],\n",
              "        dtype=float16)),\n",
              " ('BBI70510',\n",
              "  array([[ 0.0068  , -0.09076 ,  0.02916 , ..., -0.0243  ,  0.0882  ,\n",
              "           0.006805]], dtype=float16)),\n",
              " ('BBI70521',\n",
              "  array([[-0.05136, -0.073  ,  0.03983, ...,  0.03876,  0.01997,  0.02295]],\n",
              "        dtype=float16)),\n",
              " ('BBI70522',\n",
              "  array([[ 0.000387, -0.0981  ,  0.02852 , ...,  0.01906 ,  0.07294 ,\n",
              "           0.0352  ]], dtype=float16)),\n",
              " ('BBI70524',\n",
              "  array([[ 0.04987, -0.1025 ,  0.01383, ...,  0.00768,  0.1426 ,  0.0426 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI70529',\n",
              "  array([[-0.00886,  0.02216,  0.01627, ..., -0.02286,  0.02757,  0.04373]],\n",
              "        dtype=float16)),\n",
              " ('BBI70583',\n",
              "  array([[-0.004246,  0.06573 ,  0.02698 , ...,  0.01582 , -0.007698,\n",
              "           0.03864 ]], dtype=float16)),\n",
              " ('BBI70689',\n",
              "  array([[-0.05035 ,  0.05652 ,  0.04468 , ...,  0.02539 , -0.01504 ,\n",
              "          -0.004997]], dtype=float16)),\n",
              " ('BBI70832',\n",
              "  array([[ 0.006947, -0.0218  ,  0.02362 , ...,  0.11285 , -0.005272,\n",
              "          -0.004807]], dtype=float16)),\n",
              " ('BBI70841',\n",
              "  array([[-0.0362  , -0.007458,  0.0802  , ..., -0.0204  ,  0.02274 ,\n",
              "          -0.0487  ]], dtype=float16)),\n",
              " ('BBI70850',\n",
              "  array([[ 0.0603  ,  0.0558  ,  0.002462, ..., -0.01287 , -0.003925,\n",
              "           0.05954 ]], dtype=float16)),\n",
              " ('BBI70853',\n",
              "  array([[-0.0427  ,  0.01735 , -0.009705, ...,  0.0253  ,  0.01572 ,\n",
              "          -0.001811]], dtype=float16)),\n",
              " ('BBI70854',\n",
              "  array([[-0.002995, -0.02864 , -0.0281  , ...,  0.02478 ,  0.05807 ,\n",
              "          -0.01797 ]], dtype=float16)),\n",
              " ('BBI71112',\n",
              "  array([[ 0.003515,  0.00134 , -0.00549 , ...,  0.03708 ,  0.007935,\n",
              "          -0.014656]], dtype=float16)),\n",
              " ('BBI71128',\n",
              "  array([[ 0.0386 ,  0.04352, -0.01608, ...,  0.01073, -0.02379, -0.0437 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI71132',\n",
              "  array([[ 0.06366,  0.0853 ,  0.032  , ..., -0.0972 , -0.02579, -0.02364]],\n",
              "        dtype=float16)),\n",
              " ('BBI71265',\n",
              "  array([[ 0.00624,  0.01325, -0.01537, ..., -0.05133, -0.04034,  0.04483]],\n",
              "        dtype=float16)),\n",
              " ('BBI71304',\n",
              "  array([[-0.04572 ,  0.0752  ,  0.03506 , ..., -0.00876 , -0.002272,\n",
              "           0.07135 ]], dtype=float16)),\n",
              " ('BBI71318',\n",
              "  array([[-0.004814,  0.014534, -0.01846 , ..., -0.01741 , -0.05896 ,\n",
              "           0.03436 ]], dtype=float16)),\n",
              " ('BBI71475',\n",
              "  array([[-0.03108,  0.0613 ,  0.0869 , ...,  0.0832 ,  0.04538,  0.01584]],\n",
              "        dtype=float16)),\n",
              " ('BBI71571',\n",
              "  array([[-0.003963,  0.01924 ,  0.05524 , ...,  0.03278 ,  0.02817 ,\n",
              "           0.02628 ]], dtype=float16)),\n",
              " ('BBI71676',\n",
              "  array([[ 0.04587 , -0.11224 ,  0.004784, ..., -0.04584 ,  0.03952 ,\n",
              "           0.05966 ]], dtype=float16)),\n",
              " ('BBI71743',\n",
              "  array([[0.02277 , 0.04813 , 0.01082 , ..., 0.04373 , 0.001891, 0.02997 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI71805',\n",
              "  array([[-0.00967 ,  0.06915 ,  0.004955, ...,  0.0418  ,  0.00605 ,\n",
              "           0.05176 ]], dtype=float16)),\n",
              " ('BBI71854',\n",
              "  array([[-0.01271 , -0.011986,  0.04517 , ...,  0.04858 , -0.02031 ,\n",
              "           0.02924 ]], dtype=float16)),\n",
              " ('BBI71858',\n",
              "  array([[-0.0769 ,  0.0111 ,  0.02235, ...,  0.03223,  0.02733,  0.02075]],\n",
              "        dtype=float16)),\n",
              " ('BBI71898',\n",
              "  array([[ 0.03366 ,  0.004345, -0.007664, ...,  0.0944  ,  0.04358 ,\n",
              "           0.011604]], dtype=float16)),\n",
              " ('BBI71930',\n",
              "  array([[ 0.0324 ,  0.0601 ,  0.0808 , ...,  0.0786 ,  0.0771 , -0.00554]],\n",
              "        dtype=float16)),\n",
              " ('BBI71974',\n",
              "  array([[ 0.06714  , -0.0004358, -0.00485  , ...,  0.04935  ,  0.0172   ,\n",
              "           0.0444   ]], dtype=float16)),\n",
              " ('BBI71982',\n",
              "  array([[ 0.0439  ,  0.03455 ,  0.001999, ..., -0.068   ,  0.03464 ,\n",
              "           0.0638  ]], dtype=float16)),\n",
              " ('BBI72155',\n",
              "  array([[ 0.04544,  0.03546,  0.01124, ...,  0.0118 , -0.01588,  0.0784 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI72166',\n",
              "  array([[-0.015114,  0.02275 ,  0.00885 , ..., -0.0343  ,  0.09186 ,\n",
              "           0.00752 ]], dtype=float16)),\n",
              " ('BBI72178',\n",
              "  array([[ 0.007008, -0.004456, -0.002705, ...,  0.012245, -0.01499 ,\n",
              "           0.01394 ]], dtype=float16)),\n",
              " ('BBI72334',\n",
              "  array([[-0.01205 ,  0.01475 ,  0.00923 , ..., -0.02945 ,  0.011696,\n",
              "           0.0579  ]], dtype=float16)),\n",
              " ('BBI72537',\n",
              "  array([[-0.01787 , -0.0319  , -0.0386  , ...,  0.007256, -0.00609 ,\n",
              "           0.02856 ]], dtype=float16)),\n",
              " ('BBI72614',\n",
              "  array([[ 0.02559,  0.07184,  0.0304 , ..., -0.01129, -0.0313 ,  0.01122]],\n",
              "        dtype=float16)),\n",
              " ('BBI72625',\n",
              "  array([[-0.0762  ,  0.01906 , -0.02122 , ..., -0.01888 ,  0.000901,\n",
              "          -0.04514 ]], dtype=float16)),\n",
              " ('BBI72655',\n",
              "  array([[ 0.014206 , -0.04565  ,  0.01518  , ...,  0.0004132,  0.0791   ,\n",
              "           0.004387 ]], dtype=float16)),\n",
              " ('BBI72692',\n",
              "  array([[ 2.159e-02, -7.385e-02, -4.480e-02, ...,  2.415e-02, -8.720e-05,\n",
              "           2.007e-02]], dtype=float16)),\n",
              " ('BBI72710',\n",
              "  array([[ 0.007404, -0.08154 ,  0.001293, ..., -0.02745 ,  0.05472 ,\n",
              "          -0.0477  ]], dtype=float16)),\n",
              " ('BBI72727',\n",
              "  array([[ 0.00808 ,  0.04733 , -0.03857 , ..., -0.03537 ,  0.0377  ,\n",
              "          -0.005043]], dtype=float16)),\n",
              " ('BBI72882',\n",
              "  array([[ 0.02307,  0.06714,  0.03738, ...,  0.07886,  0.0329 , -0.00803]],\n",
              "        dtype=float16)),\n",
              " ('BBI72918',\n",
              "  array([[-0.01787 ,  0.06354 ,  0.013245, ...,  0.02034 ,  0.02946 ,\n",
              "           0.02705 ]], dtype=float16)),\n",
              " ('BBI72928',\n",
              "  array([[-0.01756, -0.0753 , -0.07697, ..., -0.04648,  0.00398,  0.0508 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI72999',\n",
              "  array([[ 0.00241 ,  0.0675  ,  0.0368  , ...,  0.000545, -0.01791 ,\n",
              "          -0.0258  ]], dtype=float16)),\n",
              " ('BBI73185',\n",
              "  array([[ 0.06287 ,  0.005665,  0.003649, ..., -0.00881 ,  0.02817 ,\n",
              "           0.04657 ]], dtype=float16)),\n",
              " ('BBI73211',\n",
              "  array([[ 0.00259 ,  0.04373 ,  0.01917 , ..., -0.07153 , -0.01587 ,\n",
              "           0.007156]], dtype=float16)),\n",
              " ('BBI73327',\n",
              "  array([[ 0.02971, -0.05707, -0.03445, ..., -0.05624, -0.02287,  0.02904]],\n",
              "        dtype=float16)),\n",
              " ('BBI73384',\n",
              "  array([[ 0.01466 ,  0.02441 , -0.0158  , ...,  0.02672 , -0.002272,\n",
              "          -0.0733  ]], dtype=float16)),\n",
              " ('BBI73767',\n",
              "  array([[ 0.007553, -0.03043 , -0.00846 , ...,  0.0375  , -0.0528  ,\n",
              "           0.0368  ]], dtype=float16)),\n",
              " ('BBI73788',\n",
              "  array([[ 0.0366  , -0.03223 , -0.001202, ..., -0.0321  ,  0.0455  ,\n",
              "           0.01505 ]], dtype=float16)),\n",
              " ('BBI73790',\n",
              "  array([[ 0.003101,  0.0125  ,  0.03333 , ..., -0.003126, -0.0489  ,\n",
              "          -0.03516 ]], dtype=float16)),\n",
              " ('BBI73871',\n",
              "  array([[-0.0322  , -0.007214, -0.007996, ...,  0.01674 , -0.032   ,\n",
              "           0.03406 ]], dtype=float16)),\n",
              " ('BBI73921',\n",
              "  array([[-0.03546 ,  0.009834,  0.002407, ...,  0.0593  ,  0.004982,\n",
              "          -0.01522 ]], dtype=float16)),\n",
              " ('BBI74003',\n",
              "  array([[-0.02339 , -0.000915,  0.01756 , ...,  0.02042 ,  0.02913 ,\n",
              "           0.02264 ]], dtype=float16)),\n",
              " ('BBI74046',\n",
              "  array([[-0.00901, -0.0249 ,  0.01636, ..., -0.03897,  0.063  ,  0.04315]],\n",
              "        dtype=float16)),\n",
              " ('BBI74129',\n",
              "  array([[ 0.005806,  0.06143 ,  0.03665 , ...,  0.01271 , -0.03012 ,\n",
              "           0.02887 ]], dtype=float16)),\n",
              " ('BBI74150',\n",
              "  array([[ 0.0522 ,  0.0193 , -0.01455, ..., -0.00896,  0.0299 ,  0.0717 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI74194',\n",
              "  array([[-0.01207  , -0.07794  , -0.0005565, ...,  0.0526   , -0.04108  ,\n",
              "           0.09326  ]], dtype=float16)),\n",
              " ('BBI74220',\n",
              "  array([[ 0.03766 , -0.004143, -0.04715 , ...,  0.01542 , -0.02122 ,\n",
              "           0.05603 ]], dtype=float16)),\n",
              " ('BBI74262',\n",
              "  array([[-0.0461 , -0.1277 ,  0.03748, ..., -0.0534 ,  0.01518,  0.1143 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI74383',\n",
              "  array([[-0.02913 ,  0.03476 ,  0.03087 , ...,  0.0733  ,  0.01091 ,\n",
              "          -0.002855]], dtype=float16)),\n",
              " ('BBI74503',\n",
              "  array([[ 0.0999  ,  0.04083 , -0.01978 , ..., -0.0384  ,  0.007473,\n",
              "          -0.02124 ]], dtype=float16)),\n",
              " ('BBI74539',\n",
              "  array([[ 0.01133 , -0.0407  ,  0.05078 , ...,  0.08435 ,  0.001255,\n",
              "          -0.0461  ]], dtype=float16)),\n",
              " ('BBI74745',\n",
              "  array([[-0.0388  , -0.00802 ,  0.07666 , ...,  0.003515, -0.02    ,\n",
              "           0.03452 ]], dtype=float16)),\n",
              " ('BBI74757',\n",
              "  array([[ 0.0256  , -0.005093,  0.005463, ...,  0.03061 , -0.0225  ,\n",
              "           0.04498 ]], dtype=float16)),\n",
              " ('BBI74767',\n",
              "  array([[ 0.03134, -0.01087, -0.02287, ...,  0.00804, -0.01822,  0.00701]],\n",
              "        dtype=float16)),\n",
              " ('BBI74835',\n",
              "  array([[-0.057   ,  0.00933 ,  0.0329  , ...,  0.02255 ,  0.08295 ,\n",
              "          -0.014084]], dtype=float16)),\n",
              " ('BBI74874',\n",
              "  array([[ 0.0482 , -0.02165, -0.01513, ..., -0.04883,  0.02649,  0.03952]],\n",
              "        dtype=float16)),\n",
              " ('BBI74933',\n",
              "  array([[ 0.003172,  0.05658 ,  0.0562  , ..., -0.01303 , -0.004147,\n",
              "           0.008484]], dtype=float16)),\n",
              " ('BBI75008',\n",
              "  array([[ 0.00938 ,  0.09894 ,  0.04944 , ..., -0.002392,  0.0317  ,\n",
              "          -0.014656]], dtype=float16)),\n",
              " ('BBI75011',\n",
              "  array([[ 0.0446  ,  0.05463 ,  0.000948, ..., -0.0336  ,  0.04517 ,\n",
              "           0.02954 ]], dtype=float16)),\n",
              " ('BBI75080',\n",
              "  array([[ 0.03833,  0.05966, -0.02226, ...,  0.0787 , -0.02327,  0.01741]],\n",
              "        dtype=float16)),\n",
              " ('BBI75150',\n",
              "  array([[ 0.007618,  0.03976 ,  0.0544  , ..., -0.0112  ,  0.0459  ,\n",
              "           0.02487 ]], dtype=float16)),\n",
              " ('BBI75416',\n",
              "  array([[ 0.02907 , -0.01874 ,  0.000623, ...,  0.04437 ,  0.06003 ,\n",
              "          -0.003576]], dtype=float16)),\n",
              " ('BBI75486',\n",
              "  array([[-0.001149, -0.0327  , -0.01016 , ...,  0.03384 ,  0.0816  ,\n",
              "           0.0481  ]], dtype=float16)),\n",
              " ('BBI75575',\n",
              "  array([[ 0.0158 ,  0.00819,  0.06494, ..., -0.0085 ,  0.0388 ,  0.05823]],\n",
              "        dtype=float16)),\n",
              " ('BBI75607',\n",
              "  array([[ 0.02942 ,  0.02635 ,  0.01113 , ..., -0.011566, -0.02518 ,\n",
              "           0.02415 ]], dtype=float16)),\n",
              " ('BBI75614',\n",
              "  array([[-0.013596,  0.00425 ,  0.0619  , ...,  0.01064 ,  0.04556 ,\n",
              "          -0.01688 ]], dtype=float16)),\n",
              " ('BBI75633',\n",
              "  array([[-0.02611 , -0.0354  ,  0.01825 , ...,  0.006382, -0.00223 ,\n",
              "           0.00799 ]], dtype=float16)),\n",
              " ('BBI75687',\n",
              "  array([[ 0.003036,  0.03015 ,  0.02528 , ...,  0.03995 ,  0.05554 ,\n",
              "          -0.0405  ]], dtype=float16)),\n",
              " ('BBI75688',\n",
              "  array([[ 0.03583 ,  0.02998 , -0.002737, ...,  0.0693  ,  0.00572 ,\n",
              "          -0.02913 ]], dtype=float16)),\n",
              " ('BBI75693',\n",
              "  array([[-0.02068 , -0.057   , -0.0224  , ...,  0.01082 ,  0.0282  ,\n",
              "          -0.003742]], dtype=float16)),\n",
              " ('BBI75695',\n",
              "  array([[-0.00972 , -0.01622 ,  0.03598 , ...,  0.013275,  0.0273  ,\n",
              "          -0.01947 ]], dtype=float16)),\n",
              " ('BBI75715',\n",
              "  array([[ 0.01212,  0.07245, -0.02919, ...,  0.01221,  0.03333, -0.02661]],\n",
              "        dtype=float16)),\n",
              " ('BBI75798',\n",
              "  array([[-0.00663, -0.05383,  0.00751, ...,  0.00818, -0.0884 ,  0.0229 ]],\n",
              "        dtype=float16)),\n",
              " ('BBI76104',\n",
              "  array([[ 0.00835,  0.04495,  0.03705, ...,  0.02307, -0.04193,  0.06934]],\n",
              "        dtype=float16)),\n",
              " ('BBI76141',\n",
              "  array([[-0.007774,  0.0851  , -0.01692 , ...,  0.05017 , -0.01327 ,\n",
              "           0.06714 ]], dtype=float16)),\n",
              " ('BBI76194',\n",
              "  array([[-0.01749 , -0.1726  , -0.007763, ...,  0.03415 ,  0.01066 ,\n",
              "           0.0722  ]], dtype=float16)),\n",
              " ('BBI76244',\n",
              "  array([[-0.02489  , -0.0011835, -0.0364   , ..., -0.02188  , -0.03168  ,\n",
              "           0.01185  ]], dtype=float16)),\n",
              " ('BBI76264',\n",
              "  array([[ 0.012115, -0.05194 ,  0.06494 , ...,  0.03354 ,  0.05487 ,\n",
              "           0.0665  ]], dtype=float16)),\n",
              " ('BBI76296',\n",
              "  array([[-0.02701 ,  0.01704 , -0.001091, ...,  0.00931 , -0.02429 ,\n",
              "           0.02283 ]], dtype=float16)),\n",
              " ('BBI76302',\n",
              "  array([[-0.01819  , -0.0004723, -0.04288  , ..., -0.07135  , -0.0001374,\n",
              "           0.0319   ]], dtype=float16)),\n",
              " ('BBM05086',\n",
              "  array([[ 0.01639 ,  0.03796 ,  0.069   , ..., -0.01316 , -0.04303 ,\n",
              "          -0.003918]], dtype=float16)),\n",
              " ('BBM05097',\n",
              "  array([[-0.03925,  0.0735 ,  0.05438, ...,  0.01008,  0.01678,  0.00829]],\n",
              "        dtype=float16)),\n",
              " ('BBM05121',\n",
              "  array([[-0.01793, -0.01304, -0.00246, ...,  0.01582,  0.00836,  0.02692]],\n",
              "        dtype=float16)),\n",
              " ('BBM05171',\n",
              "  array([[-0.05267, -0.01232,  0.0834 , ...,  0.03146,  0.00906, -0.0798 ]],\n",
              "        dtype=float16)),\n",
              " ('BBM05172',\n",
              "  array([[-0.006298 , -0.00223  , -0.02127  , ...,  0.0321   ,  0.0004556,\n",
              "           0.0411   ]], dtype=float16)),\n",
              " ('BBM05252',\n",
              "  array([[-0.0506 ,  0.03108, -0.04947, ..., -0.0223 ,  0.0502 ,  0.06415]],\n",
              "        dtype=float16)),\n",
              " ('BBM05256',\n",
              "  array([[-0.07324, -0.1017 ,  0.05612, ...,  0.0593 ,  0.0361 ,  0.00793]],\n",
              "        dtype=float16)),\n",
              " ('BBM05313',\n",
              "  array([[-0.04816 ,  0.003218,  0.02579 , ...,  0.00848 , -0.01718 ,\n",
              "           0.0384  ]], dtype=float16)),\n",
              " ('BBM05347',\n",
              "  array([[-0.025   , -0.0892  ,  0.05325 , ...,  0.0223  ,  0.04428 ,\n",
              "          -0.001759]], dtype=float16)),\n",
              " ('BBM05441',\n",
              "  array([[ 0.003084,  0.0679  ,  0.02284 , ..., -0.01265 ,  0.01988 ,\n",
              "           0.03244 ]], dtype=float16)),\n",
              " ('BBM05470',\n",
              "  array([[-0.03378,  0.0194 ,  0.05392, ...,  0.05475, -0.01906,  0.0206 ]],\n",
              "        dtype=float16)),\n",
              " ('BBM05476',\n",
              "  array([[-0.014  , -0.042  ,  0.01566, ..., -0.0038 ,  0.02707,  0.0324 ]],\n",
              "        dtype=float16)),\n",
              " ('BBM05478',\n",
              "  array([[-0.02638,  0.01504, -0.00853, ...,  0.0489 , -0.0286 , -0.1188 ]],\n",
              "        dtype=float16)),\n",
              " ('BBM05479',\n",
              "  array([[-0.02573 , -0.0185  , -0.03183 , ..., -0.03372 , -0.01547 ,\n",
              "          -0.006565]], dtype=float16)),\n",
              " ('BBM05513',\n",
              "  array([[-0.0458  ,  0.0951  ,  0.009155, ...,  0.02602 , -0.00577 ,\n",
              "          -0.01248 ]], dtype=float16)),\n",
              " ('BBM05536',\n",
              "  array([[-0.0199  , -0.0719  , -0.01063 , ..., -0.002714,  0.055   ,\n",
              "          -0.04422 ]], dtype=float16)),\n",
              " ('BBM05548',\n",
              "  array([[ 0.01077, -0.00619,  0.06866, ...,  0.02846, -0.03177,  0.02606]],\n",
              "        dtype=float16)),\n",
              " ('BBM05559',\n",
              "  array([[ 0.02118, -0.0692 ,  0.02599, ...,  0.03827, -0.05884,  0.0501 ]],\n",
              "        dtype=float16)),\n",
              " ('BBM05566',\n",
              "  array([[ 0.072   ,  0.066   , -0.04352 , ...,  0.002083,  0.02252 ,\n",
              "           0.04382 ]], dtype=float16)),\n",
              " ('BBM05596',\n",
              "  array([[-0.008354,  0.0587  , -0.0327  , ..., -0.01697 , -0.02946 ,\n",
              "          -0.01416 ]], dtype=float16)),\n",
              " ('BBM05657',\n",
              "  array([[0.03305  , 0.0001708, 0.01485  , ..., 0.002605 , 0.02647  ,\n",
              "          0.02966  ]], dtype=float16)),\n",
              " ('BBM05676',\n",
              "  array([[ 0.03455 , -0.02478 , -0.005604, ..., -0.01441 , -0.05615 ,\n",
              "          -0.03998 ]], dtype=float16)),\n",
              " ('BBM05681',\n",
              "  array([[-0.01501 ,  0.003433,  0.01077 , ..., -0.0251  , -0.00824 ,\n",
              "           0.00488 ]], dtype=float16)),\n",
              " ('BBM05691',\n",
              "  array([[ 0.005276, -0.1104  ,  0.01627 , ...,  0.01265 ,  0.003569,\n",
              "           0.0691  ]], dtype=float16)),\n",
              " ('BBM05692',\n",
              "  array([[-0.0292 ,  0.04404, -0.07715, ..., -0.0551 ,  0.0753 ,  0.0745 ]],\n",
              "        dtype=float16)),\n",
              " ('BBM05786',\n",
              "  array([[-0.0357 , -0.1509 ,  0.0746 , ...,  0.07385,  0.0445 ,  0.1531 ]],\n",
              "        dtype=float16)),\n",
              " ('BBM05848',\n",
              "  array([[ 0.0248 ,  0.08185,  0.019  , ..., -0.04947, -0.03918, -0.02423]],\n",
              "        dtype=float16)),\n",
              " ('BBM05872',\n",
              "  array([[-0.0417  , -0.03882 ,  0.007545, ...,  0.03357 ,  0.014   ,\n",
              "          -0.09625 ]], dtype=float16)),\n",
              " ('BBM05925',\n",
              "  array([[-0.01182,  0.03354, -0.02441, ...,  0.04602, -0.02397,  0.0677 ]],\n",
              "        dtype=float16)),\n",
              " ('BBM05936',\n",
              "  array([[-0.00973  , -0.0003335,  0.02817  , ...,  0.01968  ,  0.02959  ,\n",
              "           0.01125  ]], dtype=float16)),\n",
              " ('BBM06008',\n",
              "  array([[-0.04062 , -0.05    , -0.03198 , ...,  0.00713 , -0.01219 ,\n",
              "           0.001789]], dtype=float16)),\n",
              " ('BBM06060',\n",
              "  array([[ 0.00978, -0.06033,  0.02061, ...,  0.04803,  0.0444 ,  0.0477 ]],\n",
              "        dtype=float16)),\n",
              " ('BBM06125',\n",
              "  array([[ 0.03137, -0.0167 ,  0.05365, ..., -0.05353,  0.0422 ,  0.0495 ]],\n",
              "        dtype=float16)),\n",
              " ('BBM06157',\n",
              "  array([[-0.0687  ,  0.001772,  0.03114 , ..., -0.017   ,  0.02501 ,\n",
              "          -0.00933 ]], dtype=float16)),\n",
              " ('BBM06190',\n",
              "  array([[ 0.05844, -0.03436,  0.05502, ...,  0.07916,  0.02893,  0.01627]],\n",
              "        dtype=float16)),\n",
              " ...]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "proteins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfNnO9qltX6v"
      },
      "outputs": [],
      "source": [
        "# Basic Protocol 3 — Step 5\n",
        "annotations = read_csv('haloAdd.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t36iDvOQti9m",
        "outputId": "90a53815-5c9d-44c6-9373-03a7bd61b31e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"annotations[:3]\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"identifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"QSG09462\",\n          \"QSG11440\",\n          \"BCB06597\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"MRFFDRLAERIDAVDSVVSVGLDPDPDRLPESVADADLPRFQFNRRIIDATHEHAACYKPNAAFYEGPDGWAALEETIAYAHGKGVPVLLDAKRGDIGNTARQYASALDPDGLDADAITVNPYLGRDSLEPFLQREDNGVFVLGRTSNPGGADLQDLELATGEPLYERVAALADLWNDNDNVGLVVGATNLDELQSIREAVPDLPFLVPGVGAQGGDAEAAVEHGLVEWDGPEASGLDVGLVNSSRGIIFAGEEARGDADAYFGAAGQAARQLAARLEQFR\",\n          \"MTRVIHTGDTHLGYQQYHEPARREDFLSAFRQVIEDAVAEDVDAVVHAGDLFHDRRPGLADIMGTLSVLRTLEDASIPFLAIVGNHETKRDAQWLDLFESLGLATRLGAEPVTIDGTAFYGLDYVPKSQRSSLAYDFEPNDADHAALVAHGLFQPFDHGDWDAEAVLAESPVDFDAMLLGDDHTPKRAEVGDTWLTYCGSTERTSGSERDDRGYNLVTFDEGVDIRRRGLPTREFVFVDVALEAGEGYGRVRDRVLQHDLEDAVVIVTIEGDGEPITPAEVETVALEDGALVARVNDRREIEPDEEVSVSFADPDDAVRERIRELGLSPAARDIDETVRASKVADSNVADRVQQRVAGIVEQADPGAFEAAEGEPDAASSDDASDTGSAEVAQSDGDGQATMEEYL\",\n          \"MLRVAITERPQWRELAHQLGFHFHTIEGEPYWTEDAYYQFTLTQIEQDIEDPTEALHEMCMDAVDRVCQSDALLHQLNIPAQMWGVIRASWRNGQPHLYGRMDFAYSGNGPAKLLELNYDTPTSIYEAGFFQWLWLEQVIEQRLLPAHADQYNSIQERMIAALAHIGQRLERDPPASPALHFASIKAHEEDRATVAYLQDCALQAGLNAPFIHIEDIGYQPNTGHGCFVDLENRPIRALFKLYPWEEMSDDLFGELLPMMQTHWFEPPWKAILSNKGILPLLWQWHEGHPNLLPAYFDTSDGTSLTPGWVRKPFFSREGSNIELMTTSGQYEAVDGPYTDNPRILQAYHPLPRFGERHALIGSWVVGDKACGIGIREDVGKITKDSSCFVPHAIV\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e98e5f67-eaea-4b3d-a028-c8b6cc45486c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>identifier</th>\n",
              "      <th>sequence</th>\n",
              "      <th>label</th>\n",
              "      <th>set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>QSG09462</td>\n",
              "      <td>MRFFDRLAERIDAVDSVVSVGLDPDPDRLPESVADADLPRFQFNRR...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>QSG11440</td>\n",
              "      <td>MTRVIHTGDTHLGYQQYHEPARREDFLSAFRQVIEDAVAEDVDAVV...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BCB06597</td>\n",
              "      <td>MLRVAITERPQWRELAHQLGFHFHTIEGEPYWTEDAYYQFTLTQIE...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e98e5f67-eaea-4b3d-a028-c8b6cc45486c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e98e5f67-eaea-4b3d-a028-c8b6cc45486c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e98e5f67-eaea-4b3d-a028-c8b6cc45486c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb918c90-2f62-491c-8dda-be763813e8eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb918c90-2f62-491c-8dda-be763813e8eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb918c90-2f62-491c-8dda-be763813e8eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  identifier                                           sequence  label    set\n",
              "0   QSG09462  MRFFDRLAERIDAVDSVVSVGLDPDPDRLPESVADADLPRFQFNRR...      1  train\n",
              "1   QSG11440  MTRVIHTGDTHLGYQQYHEPARREDFLSAFRQVIEDAVAEDVDAVV...      1  train\n",
              "2   BCB06597  MLRVAITERPQWRELAHQLGFHFHTIEGEPYWTEDAYYQFTLTQIE...      1  train"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "annotations[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdwva6fUtkxW"
      },
      "outputs": [],
      "source": [
        "# Basic Protocol 3 — Step 6\n",
        "train_set = annotations[annotations.set == \"train\"]\n",
        "test_set = annotations[annotations.set == \"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsPlLP3utmt0",
        "outputId": "6181e21b-669e-4d5b-c9b2-f015f038dc6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The train set contains 5670 samples, and we will test on 1356 samples.\n"
          ]
        }
      ],
      "source": [
        "print(f\"The train set contains {len(train_set)} samples, and we will test on {len(test_set)} samples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN1PpTc3tw-o",
        "outputId": "62cecd8c-0f6b-474f-ce5a-0f809c68e803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5670\n",
            "5670\n"
          ]
        }
      ],
      "source": [
        "# Basic Protocol 3 — Step 7\n",
        "\n",
        "training_embeddings = list()\n",
        "training_identifiers = train_set.identifier.values\n",
        "training_labels = train_set.label.values\n",
        "print(len(training_identifiers))\n",
        "print(len(training_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUcj3y3TfiKq"
      },
      "outputs": [],
      "source": [
        "#train_set.identifier.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfK4RZisuE63",
        "outputId": "c9d6cfbf-a812-40f7-eb54-8b430778a6d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1356\n",
            "1356\n"
          ]
        }
      ],
      "source": [
        "testing_embeddings = list()\n",
        "testing_identifiers = test_set.identifier.values\n",
        "testing_labels = test_set.label.values\n",
        "print(len(testing_identifiers))\n",
        "print(len(testing_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeo0RsDewH6e"
      },
      "outputs": [],
      "source": [
        "seq = dict(proteins)\n",
        "delete = list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw7Gs-Ovu1gR"
      },
      "outputs": [],
      "source": [
        "for identifier in training_identifiers:\n",
        "        if identifier in seq:\n",
        "            embedding = seq[identifier]\n",
        "            training_embeddings.append(embedding)\n",
        "        else:\n",
        "          delete.append(identifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu95EwOVxceu"
      },
      "outputs": [],
      "source": [
        "for identifier in testing_identifiers:\n",
        "        if identifier in seq:\n",
        "            embedding = seq[identifier]\n",
        "            testing_embeddings.append(embedding)\n",
        "        else:\n",
        "          delete.append(identifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4MLuHQj_uwv",
        "outputId": "5bb72267-ae57-4494-fc42-f7a1b8ef8054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([], dtype=int64),)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.where(testing_identifiers=='AAC82940')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQEfhzAXAPwm"
      },
      "outputs": [],
      "source": [
        "#testing_identifiers = np.delete(testing_identifiers,0)\n",
        "#testing_labels = np.delete(testing_labels,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq2HsFdtxkpE"
      },
      "outputs": [],
      "source": [
        "# A sanity check: make sure that the numbers are equal!\n",
        "assert(len(training_identifiers) == len(training_embeddings))\n",
        "assert(len(testing_identifiers) == len(testing_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53rhy2OK_XLY"
      },
      "outputs": [],
      "source": [
        "#training_embeddings[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wechMxz8RnJK"
      },
      "outputs": [],
      "source": [
        "#training_identifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-NdRoqfSYej",
        "outputId": "e04b2cf6-719b-4580-dc05-c592b6cccaa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(delete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ukLJcps5Cm",
        "outputId": "1947f017-9ca5-4858-9dc3-74b5187be2b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "delete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZOHJFqNvNsJ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RjStFxt_YIq",
        "outputId": "c7851851-5607-44f7-de6a-0c79606ac3c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5670, 1024)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arr_train = np.array(training_embeddings)\n",
        "nsample, nx, ny = arr_train.shape\n",
        "train_dataset = arr_train.reshape((nsample, nx*ny))\n",
        "train_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwtSoASGAPK8",
        "outputId": "0e67aa87-5987-4574-c419-c95f64b6f662"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1356, 1024)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arr_test = np.array(testing_embeddings)\n",
        "nsample, nx, ny = arr_test.shape\n",
        "test_dataset = arr_test.reshape((nsample, nx*ny))\n",
        "test_dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eEXVSpeI8Un"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6VLSupfI-mW"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import confusion_matrix, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPuwO3lT6h93"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7cjQl3Y6h9_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVSgV_nzJAGf",
        "outputId": "2dba9ef6-7020-4f21-dbce-8814254db472"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9166666666666666"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr = LogisticRegression()\n",
        "lr_history = lr.fit(train_dataset, training_labels)\n",
        "lr.score(test_dataset,testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1TOPLJ2cqnH"
      },
      "outputs": [],
      "source": [
        "#grid_scorer = {'accuracy':make_scorer(accuracy_score),'f1':make_scorer(f1_score),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}\n",
        "grid_scorer = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'mcc': make_scorer(matthews_corrcoef, greater_is_better=True),\n",
        "    'sensitivity': make_scorer(recall_score, greater_is_better=True),\n",
        "    'specificity': make_scorer(specificity_score, greater_is_better=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6-zdbj-U8ij",
        "outputId": "f50cdc0a-b5a3-428b-851b-0e8d86ddb63e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'fit_time': array([0.28014112, 0.25235176, 0.39020586, 0.20420432, 0.40042663,\n",
              "        0.38557482, 0.32178807, 0.29788184, 0.18996334, 0.29649019]),\n",
              " 'score_time': array([0.01524138, 0.01035142, 0.01155972, 0.01208377, 0.02999878,\n",
              "        0.01018643, 0.01033807, 0.01037693, 0.01932526, 0.01058984]),\n",
              " 'test_accuracy': array([0.84479718, 0.8659612 , 0.95238095, 0.9382716 , 0.94708995,\n",
              "        0.98412698, 0.90299824, 0.91534392, 0.88183422, 0.94885362]),\n",
              " 'test_f1': array([0.88359788, 0.9047619 , 0.96423841, 0.95351926, 0.96      ,\n",
              "        0.98820446, 0.93133583, 0.94044665, 0.91309987, 0.96361355]),\n",
              " 'test_mcc': array([0.65203863, 0.68429547, 0.89466205, 0.86374325, 0.88477898,\n",
              "        0.96433104, 0.77371057, 0.80466699, 0.72853382, 0.88455614]),\n",
              " 'test_sensitivity': array([0.86753247, 0.93766234, 0.94545455, 0.93246753, 0.93506494,\n",
              "        0.97922078, 0.96883117, 0.98441558, 0.91428571, 1.        ]),\n",
              " 'test_specificity': array([0.7967033 , 0.71428571, 0.96703297, 0.95054945, 0.97252747,\n",
              "        0.99450549, 0.76373626, 0.76923077, 0.81318681, 0.84153005])}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = cross_validate(lr, train_dataset, training_labels, cv=10, scoring=grid_scorer)\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI-jvgsPdI9b",
        "outputId": "6bcd5386-820e-487f-9cb8-74313d91d45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc: 0.9400352733686067\n",
            "f1: 0.9561629706034038\n",
            "mcc: 0.8615548281853282\n",
            "sn: 0.9633671083398285\n",
            "sp: 0.8907193849533224\n",
            "sd_acc: 0.00306910616799386\n",
            "sd_f1: 0.0022977659036415785\n",
            "sd_mcc: 0.007118133792628047\n",
            "sd_sn: 0.0029367463448052547\n",
            "sd_sp: 0.007103684625377653\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.89      0.91      1821\n",
            "           1       0.95      0.96      0.96      3849\n",
            "\n",
            "    accuracy                           0.94      5670\n",
            "   macro avg       0.93      0.93      0.93      5670\n",
            "weighted avg       0.94      0.94      0.94      5670\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.00306910616799386, 0.007118133792628047, 0.0022977659036415785)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_training_labels = lr.predict(train_dataset)\n",
        "error_rate(training_labels, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjQLJMtyJNtD",
        "outputId": "a992ce66-c231-4f61-c5ad-6fc2f0cf695c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our model has an accuracy of 0.92\n"
          ]
        }
      ],
      "source": [
        "predicted_testing_labels = lr.predict(test_dataset)\n",
        "accuracy = accuracy_score(testing_labels, predicted_testing_labels)\n",
        "\n",
        "print(f\"Our model has an accuracy of {accuracy:.2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxjhmdcwJXsD",
        "outputId": "a2ac0bae-53f7-4c57-e726-06efc6e78afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc: 0.9166666666666666\n",
            "f1: 0.951356005165734\n",
            "mcc: 0.661622415311926\n",
            "sn: 0.9452523524379812\n",
            "sp: 0.7379679144385026\n",
            "sd_acc: 0.007277948499593558\n",
            "sd_f1: 0.004414707382146375\n",
            "sd_mcc: 0.02932068155882423\n",
            "sd_sn: 0.006736633390781546\n",
            "sd_sp: 0.03265649496772899\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.74      0.71       187\n",
            "           1       0.96      0.95      0.95      1169\n",
            "\n",
            "    accuracy                           0.92      1356\n",
            "   macro avg       0.82      0.84      0.83      1356\n",
            "weighted avg       0.92      0.92      0.92      1356\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.007277948499593558, 0.02932068155882423, 0.004414707382146375)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "error_rate(testing_labels, predicted_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StaqqQaVUnzM"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(train_dataset)\n",
        "df.to_excel('/content/t5_train_dataset.xlsx')\n",
        "df =pd.DataFrame(training_labels)\n",
        "df.to_excel('/content/t5_training_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_training_labels)\n",
        "df.to_excel('/content/t5_pred_train_labels.xlsx')\n",
        "\n",
        "df =pd.DataFrame(test_dataset)\n",
        "df.to_excel('/content/t5_test_dataset.xlsx')\n",
        "df =pd.DataFrame(testing_labels)\n",
        "df.to_excel('/content/t5_testing_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_testing_labels)\n",
        "df.to_excel('/content/t5_pred_test_labels.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPUQwR-eKR38"
      },
      "outputs": [],
      "source": [
        "classes = np.unique(testing_labels)\n",
        "\n",
        "confusion_matrix_data = confusion_matrix(testing_labels, predicted_testing_labels, labels=classes)\n",
        "conf_matrix(confusion_matrix_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKcFQmFG1Ikk"
      },
      "outputs": [],
      "source": [
        "TP = confusion_matrix_data[1,1]\n",
        "TN = confusion_matrix_data[0,0]\n",
        "FP = confusion_matrix_data[0,1]\n",
        "FN = confusion_matrix_data[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If-wEyne1Ja0"
      },
      "outputs": [],
      "source": [
        "sn = TP / float(TP + FN)\n",
        "print(sn)\n",
        "sp = TN / float(TN + FP)\n",
        "print(sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwjJoJZiOqqC"
      },
      "outputs": [],
      "source": [
        "#lr.save_weights('/result/LR.h5')\n",
        "print(lr.coef_.shape)\n",
        "lr_weights = lr.coef_\n",
        "print(lr_weights)\n",
        "print(np.max(lr_weights))\n",
        "print(np.min(lr_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWEHw1DOYWmX"
      },
      "source": [
        "### MLP with Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVg8VB-J0AXe"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqBy5Mh50AXe"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aL0cByplYWmX"
      },
      "outputs": [],
      "source": [
        "# Basic Protocol 3 — Step 8\n",
        "\n",
        "multilayerperceptron = MLPClassifier(solver='lbfgs', random_state=10, max_iter=1000)\n",
        "\n",
        "parameters = {\n",
        "    'hidden_layer_sizes': [((32),)],\n",
        "    #'learning_rate_init': [0.001, 0.0001, 0.01],\n",
        "    'solver':['adam'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt_H5F3yOVsC"
      },
      "outputs": [],
      "source": [
        "#grid_scorer = {'accuracy':make_scorer(accuracy_score),'f1':make_scorer(f1_score),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}\n",
        "grid_scorer = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'mcc': make_scorer(matthews_corrcoef, greater_is_better=True),\n",
        "    'sensitivity': make_scorer(recall_score, greater_is_better=True),\n",
        "    'specificity': make_scorer(specificity_score, greater_is_better=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTm5DnkJYWmY"
      },
      "outputs": [],
      "source": [
        "# Basic Protocol 3 — Step 9\n",
        "\n",
        "classifiers = GridSearchCV(multilayerperceptron, parameters, cv=10, scoring=grid_scorer, refit='mcc')\n",
        "history = classifiers.fit(train_dataset, training_labels)\n",
        "classifier = classifiers.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nrZe2hRYWmY",
        "outputId": "96921f67-7f12-4f2e-f660-448de0b00590"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'alpha': 0.0001,\n",
              " 'batch_size': 'auto',\n",
              " 'beta_1': 0.9,\n",
              " 'beta_2': 0.999,\n",
              " 'early_stopping': False,\n",
              " 'epsilon': 1e-08,\n",
              " 'hidden_layer_sizes': (32,),\n",
              " 'learning_rate': 'constant',\n",
              " 'learning_rate_init': 0.001,\n",
              " 'max_fun': 15000,\n",
              " 'max_iter': 1000,\n",
              " 'momentum': 0.9,\n",
              " 'n_iter_no_change': 10,\n",
              " 'nesterovs_momentum': True,\n",
              " 'power_t': 0.5,\n",
              " 'random_state': 10,\n",
              " 'shuffle': True,\n",
              " 'solver': 'adam',\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': False,\n",
              " 'warm_start': False}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjLgtgFwYWmY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "kMYQTWrF_05C",
        "outputId": "cac06ac7-4217-42c1-a3ba-b56578bc910d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0b4f9a2b-7fc6-4437-a64b-3262f5d29285\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_hidden_layer_sizes</th>\n",
              "      <th>param_solver</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_accuracy</th>\n",
              "      <th>split1_test_accuracy</th>\n",
              "      <th>split2_test_accuracy</th>\n",
              "      <th>...</th>\n",
              "      <th>split3_test_specificity</th>\n",
              "      <th>split4_test_specificity</th>\n",
              "      <th>split5_test_specificity</th>\n",
              "      <th>split6_test_specificity</th>\n",
              "      <th>split7_test_specificity</th>\n",
              "      <th>split8_test_specificity</th>\n",
              "      <th>split9_test_specificity</th>\n",
              "      <th>mean_test_specificity</th>\n",
              "      <th>std_test_specificity</th>\n",
              "      <th>rank_test_specificity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34.047645</td>\n",
              "      <td>7.983818</td>\n",
              "      <td>0.025004</td>\n",
              "      <td>0.008223</td>\n",
              "      <td>(32,)</td>\n",
              "      <td>adam</td>\n",
              "      <td>{'hidden_layer_sizes': (32,), 'solver': 'adam'}</td>\n",
              "      <td>0.816578</td>\n",
              "      <td>0.858907</td>\n",
              "      <td>0.940035</td>\n",
              "      <td>...</td>\n",
              "      <td>0.972527</td>\n",
              "      <td>0.972527</td>\n",
              "      <td>0.983516</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.741758</td>\n",
              "      <td>0.82967</td>\n",
              "      <td>0.808743</td>\n",
              "      <td>0.859995</td>\n",
              "      <td>0.101416</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 72 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b4f9a2b-7fc6-4437-a64b-3262f5d29285')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0b4f9a2b-7fc6-4437-a64b-3262f5d29285 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0b4f9a2b-7fc6-4437-a64b-3262f5d29285');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0      34.047645      7.983818         0.025004        0.008223   \n",
              "\n",
              "  param_hidden_layer_sizes param_solver  \\\n",
              "0                    (32,)         adam   \n",
              "\n",
              "                                            params  split0_test_accuracy  \\\n",
              "0  {'hidden_layer_sizes': (32,), 'solver': 'adam'}              0.816578   \n",
              "\n",
              "   split1_test_accuracy  split2_test_accuracy  ...  split3_test_specificity  \\\n",
              "0              0.858907              0.940035  ...                 0.972527   \n",
              "\n",
              "   split4_test_specificity  split5_test_specificity  split6_test_specificity  \\\n",
              "0                 0.972527                 0.983516                 0.824176   \n",
              "\n",
              "   split7_test_specificity  split8_test_specificity  split9_test_specificity  \\\n",
              "0                 0.741758                  0.82967                 0.808743   \n",
              "\n",
              "   mean_test_specificity  std_test_specificity  rank_test_specificity  \n",
              "0               0.859995              0.101416                      1  \n",
              "\n",
              "[1 rows x 72 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DataFrame(classifiers.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYyWaZPRYWmY"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(classifiers.cv_results_)\n",
        "new_path = '/content/test.xls'\n",
        "writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/HaloMLPRev.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5Efby3KSn5j",
        "outputId": "221ea5af-b7b3-4e6c-fa11-99014ead83bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc: 1.0\n",
            "f1: 1.0\n",
            "mcc: 1.0\n",
            "sn: 1.0\n",
            "sp: 1.0\n",
            "sd_acc: 0.0\n",
            "sd_f1: 0.0\n",
            "sd_mcc: 0.0\n",
            "sd_sn: 0.0\n",
            "sd_sp: 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1821\n",
            "           1       1.00      1.00      1.00      3849\n",
            "\n",
            "    accuracy                           1.00      5670\n",
            "   macro avg       1.00      1.00      1.00      5670\n",
            "weighted avg       1.00      1.00      1.00      5670\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0, 0.0, 0.0)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_training_labels = classifier.predict(train_dataset)\n",
        "error_rate(training_labels, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFmSr5CYWmY",
        "outputId": "2a6e328c-c531-4042-fe55-ff0a5d351fdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc: 0.8923303834808259\n",
            "f1: 0.9363557105492589\n",
            "mcc: 0.59249245167194\n",
            "sn: 0.9187339606501284\n",
            "sp: 0.7272727272727273\n",
            "sd_acc: 0.008231167889748727\n",
            "sd_f1: 0.0051357567160452795\n",
            "sd_mcc: 0.02963649346061585\n",
            "sd_sn: 0.007957908878732378\n",
            "sd_sp: 0.032206966420659754\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.73      0.65       187\n",
            "           1       0.95      0.92      0.94      1169\n",
            "\n",
            "    accuracy                           0.89      1356\n",
            "   macro avg       0.77      0.82      0.79      1356\n",
            "weighted avg       0.90      0.89      0.90      1356\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.008231167889748727, 0.02963649346061585, 0.0051357567160452795)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Basic Protocol 3 — Step 10\n",
        "predicted_mlp = classifier.predict(test_dataset)\n",
        "accuracy = accuracy_score(testing_labels, predicted_mlp)\n",
        "error_rate(testing_labels, predicted_mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzHq6kceTcLo"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(train_dataset)\n",
        "df.to_excel('/content/mlp_train_dataset.xlsx')\n",
        "df =pd.DataFrame(training_labels)\n",
        "df.to_excel('/content/mlp_training_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_training_labels)\n",
        "df.to_excel('/content/mlp_pred_train_labels.xlsx')\n",
        "\n",
        "df =pd.DataFrame(test_dataset)\n",
        "df.to_excel('/content/mlp_test_dataset.xlsx')\n",
        "df =pd.DataFrame(testing_labels)\n",
        "df.to_excel('/content/mlp_testing_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_mlp)\n",
        "df.to_excel('/content/mlp_pred_test_labels.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcNJ7wpHYWmZ",
        "outputId": "db5b29f8-2e8f-469a-b628-0d4281c71a1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
            "0      34.047645      7.983818         0.025004        0.008223   \n",
            "\n",
            "  param_hidden_layer_sizes param_solver  \\\n",
            "0                    (32,)         adam   \n",
            "\n",
            "                                            params  split0_test_accuracy  \\\n",
            "0  {'hidden_layer_sizes': (32,), 'solver': 'adam'}              0.816578   \n",
            "\n",
            "   split1_test_accuracy  split2_test_accuracy  ...  split3_test_specificity  \\\n",
            "0              0.858907              0.940035  ...                 0.972527   \n",
            "\n",
            "   split4_test_specificity  split5_test_specificity  split6_test_specificity  \\\n",
            "0                 0.972527                 0.983516                 0.824176   \n",
            "\n",
            "   split7_test_specificity  split8_test_specificity  split9_test_specificity  \\\n",
            "0                 0.741758                  0.82967                 0.808743   \n",
            "\n",
            "   mean_test_specificity  std_test_specificity  rank_test_specificity  \n",
            "0               0.859995              0.101416                      1  \n",
            "\n",
            "[1 rows x 72 columns]\n"
          ]
        }
      ],
      "source": [
        "from pandas import DataFrame\n",
        "cv_results = DataFrame(classifiers.cv_results_)\n",
        "print(cv_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shDKP9qpYWmZ"
      },
      "outputs": [],
      "source": [
        "# Further metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Data visualization\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "--hK-XOJYWmZ",
        "outputId": "f8177d47-07ff-4cdb-aecd-524eb96298f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-286145be1eb1>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + labels)\n",
            "<ipython-input-12-286145be1eb1>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + labels)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classes = np.unique(testing_labels)\n",
        "\n",
        "confusion_matrix_data = confusion_matrix(testing_labels, predicted_mlp, labels=classes)\n",
        "conf_matrix(confusion_matrix_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azx1iNma1Lyc",
        "outputId": "d8bc1b35-e1da-41c5-89f7-241e1511b5c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1074 136 51 95\n",
            "0.9187339606501284\n",
            "0.7272727272727273\n"
          ]
        }
      ],
      "source": [
        "TP = confusion_matrix_data[1,1]\n",
        "TN = confusion_matrix_data[0,0]\n",
        "FP = confusion_matrix_data[0,1]\n",
        "FN = confusion_matrix_data[1,0]\n",
        "\n",
        "print(TP,TN, FP, FN)\n",
        "\n",
        "sn = TP / float(TP + FN)\n",
        "print(sn)\n",
        "sp = TN / float(TN + FP)\n",
        "print(sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEr6vBTFY8wz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC6sZ0D_kgZj"
      },
      "source": [
        "### CNN with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S7uiM5ykoYz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Dropout, Activation\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GycVI1SWkoY0"
      },
      "outputs": [],
      "source": [
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D, AveragePooling1D\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SW6lCZkuvLH"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od56RcTJuvLH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2wBaT28koY0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJcrkuiokoY0"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHoLG0YFkoY0"
      },
      "outputs": [],
      "source": [
        "n_timesteps, n_features, n_outputs =train_dataset.shape[0], train_dataset.shape[1], Y_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpfyojPuYKtg"
      },
      "outputs": [],
      "source": [
        "n_epochs = 30 # 30\n",
        "n_epochs_cv = 10 # 10  # reduce number of epochs for cross validation for performance reason\n",
        "\n",
        "n_cv = 10\n",
        "validation_ratio = 0.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lavUwJEZPC9T"
      },
      "outputs": [],
      "source": [
        "def create_cnn_model(pool_type='max', conv_activation='relu', dropout_rate=0.0, kernel=1, optimizer='adam'):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # first layer: convolution\n",
        "    #model.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(Conv1D(filters=128, kernel_size=kernel, activation='relu',input_shape=(n_features,1)))\n",
        "    # second series of layers: convolution, pooling, and dropout\n",
        "    model.add(Conv1D(32, kernel_size=kernel, activation=conv_activation))\n",
        "    if pool_type == 'max':\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "    if pool_type == 'average':\n",
        "        model.add(AveragePooling1D(pool_size=2))\n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    # third series of layers: convolution, pooling, and dropout\n",
        "    model.add(Conv1D(64, kernel_size=kernel, activation=conv_activation))   # 32   10\n",
        "    if pool_type == 'max':\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "    if pool_type == 'average':\n",
        "        model.add(AveragePooling1D(pool_size=2))\n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Conv1D(64, kernel_size=kernel, activation=conv_activation))   # 32   10\n",
        "    if pool_type == 'max':\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "    if pool_type == 'average':\n",
        "        model.add(AveragePooling1D(pool_size=2))\n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    # fourth series\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='sigmoid')) # 64\n",
        "    # add a dropout layer if rate is not null\n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer= optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'],\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLA3JilNT1UC"
      },
      "outputs": [],
      "source": [
        "cnn = create_cnn_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGjva7x6T7mx",
        "outputId": "bf62ed13-67b0-4a73-87d9-f467fd7f79c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 1024, 128)         256       \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 1024, 32)          4128      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 512, 32)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 512, 64)           2112      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 256, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 256, 64)           4160      \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 128, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                524352    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,073\n",
            "Trainable params: 535,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByEiiFAnO6v5",
        "outputId": "418a0ecb-3e5c-4447-815f-d65e820d6eff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-71-d50523f4b107>:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_cnn_model, verbose=1)\n"
          ]
        }
      ],
      "source": [
        "# optimize model\n",
        "start = time()\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_cnn_model, verbose=1)\n",
        "# define parameters and values for grid search\n",
        "param_grid = {\n",
        "    'pool_type': ['max','average'],\n",
        "    'conv_activation': ['relu', 'tanh'],\n",
        "    #'epochs': [3,5,10],\n",
        "    'kernel':[1,2,3,4,5],\n",
        "    'optimizer':['adam','sgd']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY9VpwzjPqNw"
      },
      "outputs": [],
      "source": [
        "#grid_scorer = {'accuracy':make_scorer(accuracy_score),'f1':make_scorer(f1_score),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}\n",
        "grid_scorer = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'mcc': make_scorer(matthews_corrcoef, greater_is_better=True),\n",
        "    'sensitivity': make_scorer(recall_score, greater_is_better=True),\n",
        "    'specificity': make_scorer(specificity_score, greater_is_better=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4AjzaBaZDkC",
        "outputId": "447c4160-fdc2-4649-faa8-82898d37796d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "178/178 [==============================] - 13s 62ms/step - loss: 0.5255 - accuracy: 0.7369 - recall: 0.9350 - precision: 0.7434 - true_positives: 3599.0000 - true_negatives: 579.0000 - false_positives: 1242.0000 - false_negatives: 250.0000\n"
          ]
        }
      ],
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=10, scoring=grid_scorer, refit='mcc')\n",
        "grid_result = grid.fit(train_dataset, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rITE0rSjYKz7"
      },
      "outputs": [],
      "source": [
        "classifier = grid.best_estimator_\n",
        "best_model = grid.best_estimator_.model\n",
        "best_model.save('/content/drive/MyDrive/Halophilic/T5cnnNath.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YXH7b_VacCie",
        "outputId": "046f2929-56c9-4b2f-ec1d-c333e8ed4f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "178/178 [==============================] - 3s 15ms/step\n",
            "acc: 0.8865961199294533\n",
            "f1: 0.9162214983713356\n",
            "mcc: 0.7408148355491271\n",
            "sn: 0.9134840218238504\n",
            "sp: 0.829763866007688\n",
            "sd_acc: 0.0041102229426688945\n",
            "sd_f1: 0.00319467135228275\n",
            "sd_mcc: 0.009413589457963587\n",
            "sd_sn: 0.004411215081085853\n",
            "sd_sp: 0.008914463485109703\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.83      0.82      1821\n",
            "           1       0.92      0.91      0.92      3849\n",
            "\n",
            "    accuracy                           0.89      5670\n",
            "   macro avg       0.87      0.87      0.87      5670\n",
            "weighted avg       0.89      0.89      0.89      5670\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0041102229426688945, 0.009413589457963587, 0.00319467135228275)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_training_labels = classifier.predict(train_dataset)\n",
        "error_rate(training_labels, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ilgVWiL4cGtR",
        "outputId": "63cc2bf0-756a-4874-f71c-840308b09588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 1s 15ms/step\n",
            "acc: 0.8606194690265486\n",
            "f1: 0.9174311926605505\n",
            "mcc: 0.4764181163559633\n",
            "sn: 0.8982035928143712\n",
            "sp: 0.6256684491978609\n",
            "sd_acc: 0.00911696335917904\n",
            "sd_f1: 0.005778330298079742\n",
            "sd_mcc: 0.0319598048669442\n",
            "sd_sn: 0.008553428633777347\n",
            "sd_sp: 0.03515271033408181\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.63      0.55       187\n",
            "           1       0.94      0.90      0.92      1169\n",
            "\n",
            "    accuracy                           0.86      1356\n",
            "   macro avg       0.72      0.76      0.74      1356\n",
            "weighted avg       0.88      0.86      0.87      1356\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.00911696335917904, 0.0319598048669442, 0.005778330298079742)"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_cnn = classifier.predict(test_dataset)\n",
        "error_rate(testing_labels, predicted_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GvU3yNNhgdFO"
      },
      "outputs": [],
      "source": [
        "def display_cv_results(search_results):\n",
        "    print('Best score = {:.4f} using {}'.format(search_results.best_score_, search_results.best_params_))\n",
        "    means = search_results.cv_results_['mean_test_score']\n",
        "    stds = search_results.cv_results_['std_test_score']\n",
        "    params = search_results.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "        print('mean test accuracy +/- std = {:.4f} +/- {:.4f} with: {}'.format(mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pdc9syuZgPDy"
      },
      "outputs": [],
      "source": [
        "# summarize results\n",
        "#print('time for grid search = {:.0f} sec'.format(time()-start))\n",
        "#display_cv_results(grid_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Tn8hczYMdLy5"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(grid.cv_results_)\n",
        "#new_path = '/content/test.xls'\n",
        "#writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/HaloCNNRev.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5UoXcPndi1td",
        "outputId": "e77fed17-db71-4917-b51f-1a8964e05472"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbose': 1,\n",
              " 'conv_activation': 'relu',\n",
              " 'kernel': 3,\n",
              " 'optimizer': 'adam',\n",
              " 'pool_type': 'max',\n",
              " 'build_fn': <function __main__.create_cnn_model(pool_type='max', conv_activation='relu', dropout_rate=0.0, kernel=1, optimizer='adam')>}"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = grid.best_estimator_\n",
        "\n",
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45PkomX_j9dy"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(train_dataset)\n",
        "df.to_excel('/content/cnn_train_dataset.xlsx')\n",
        "df =pd.DataFrame(training_labels)\n",
        "df.to_excel('/content/cnn_training_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_training_labels)\n",
        "df.to_excel('/content/cnn_pred_train_labels.xlsx')\n",
        "\n",
        "df =pd.DataFrame(test_dataset)\n",
        "df.to_excel('/content/cnn_test_dataset.xlsx')\n",
        "df =pd.DataFrame(testing_labels)\n",
        "df.to_excel('/content/cnn_testing_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_cnn)\n",
        "df.to_excel('/content/cnn_pred_test_labels.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2e7ei0hoj9dy"
      },
      "outputs": [],
      "source": [
        "from pandas import DataFrame\n",
        "cv_results = DataFrame(grid.cv_results_)\n",
        "\n",
        "#cv_results[['param_conv_activation','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R1Ut3Y2ej9dy"
      },
      "outputs": [],
      "source": [
        "# Further metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Data visualization\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EvD7KRaBj9dy",
        "outputId": "b0c7785c-bd78-4359-b8b7-45963932bfec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-286145be1eb1>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + labels)\n",
            "<ipython-input-12-286145be1eb1>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + labels)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array([[ 117,   70],\n",
              "       [ 119, 1050]])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = np.unique(testing_labels)\n",
        "\n",
        "confusion_matrix_data = confusion_matrix(testing_labels, predicted_cnn, labels=classes)\n",
        "conf_matrix(confusion_matrix_data)\n",
        "confusion_matrix_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "guHyXf_vj9dy"
      },
      "outputs": [],
      "source": [
        "TP = confusion_matrix_data[1,1]\n",
        "TN = confusion_matrix_data[0,0]\n",
        "FP = confusion_matrix_data[0,1]\n",
        "FN = confusion_matrix_data[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FpqxYh-7j9dy",
        "outputId": "916dd727-42a1-43c8-c94e-7a8206ded0d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8982035928143712\n"
          ]
        }
      ],
      "source": [
        "sn = TP / float(TP + FN)\n",
        "print(sn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPGTyFCcj9dy"
      },
      "outputs": [],
      "source": [
        "sp = TN / float(TN + FP)\n",
        "print(sp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tgM9DaT4iGC"
      },
      "source": [
        "### RNN with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK16axrl4iGE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Bidirectional, Input, Embedding, LSTM, Dropout, Dense, InputLayer, GRU\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from time import time\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1GErIWQWyRF"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtwPIv02WyRH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUc3tuPW4iGE"
      },
      "outputs": [],
      "source": [
        "max_length = 1280"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE7qx0Ef4iGF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omdigfpk4iGF"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og6-h7Hl4iGF"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train[1,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY61j3y24iGG"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vibk8C8t4iGG"
      },
      "outputs": [],
      "source": [
        "def create_rnn_model(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam'):\n",
        "    x_input = layers.Input(input_shape)\n",
        "    #emb = Embedding(21, units, input_length=max_length)(x_input)\n",
        "    rnn = SimpleRNN(units, activity_regularizer=l2(regularizer), return_sequences = True)(x_input) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x = Dropout(dropout_rate)(rnn)\n",
        "    rnn2 =SimpleRNN(units, activity_regularizer=l2(dropout_rate))(x) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x2 = Dropout(dropout_rate)(rnn2)\n",
        "    # softmax classifier\n",
        "    x_output = Dense(1, activation='sigmoid')(x2)\n",
        "\n",
        "    model = Model(inputs=x_input, outputs=x_output)\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_init),#solver,#\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fx-WbXR4iGG"
      },
      "outputs": [],
      "source": [
        "rnn_model = create_rnn_model()\n",
        "rnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZ8aG71e4iGH"
      },
      "outputs": [],
      "source": [
        "start = time()\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_rnn_model, verbose=1, epochs=3)\n",
        "# define parameters and values for grid search\n",
        "\n",
        "parameters = {\n",
        "    'units':[50,100], # 1024\n",
        "    #'learning_rate_init': [0.001, 0.01],\n",
        "    'solver':['sgd','adam'],\n",
        "    #'epochs':[2,3,5,10]\n",
        "    'dropout_rate':[0.0,0.05, 0.1], #0.05\n",
        "    'regularizer':[0.0,0.05, 0.1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0Us0Bmf4iGH"
      },
      "outputs": [],
      "source": [
        "metrics = {'accuracy':make_scorer(accuracy_score,greater_is_better=True),'f1':make_scorer(f1_score,greater_is_better=True),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VId_Vtu64iGI"
      },
      "outputs": [],
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=parameters, n_jobs=-1, cv=10, scoring=metrics, refit='mcc')\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6V4U-0E4iGI"
      },
      "outputs": [],
      "source": [
        "classifier = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxZTjoZX4iGJ"
      },
      "outputs": [],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU7pc4Fz4iGJ"
      },
      "outputs": [],
      "source": [
        "#cv_results = DataFrame(grid.cv_results_)\n",
        "\n",
        "#cv_results[['param_units','param_dropout_rate','param_regularizer','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGc8apIR4iGJ"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(grid.cv_results_)\n",
        "new_path = '/content/test.xls'\n",
        "writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/T5RNNNath.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtA2NV_z4iGK"
      },
      "outputs": [],
      "source": [
        "predicted_training_labels = classifier.predict(X_train)\n",
        "predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "predicted_training_labels = np.reshape(predicted_training_labels,(len(predicted_training_labels),)).astype(int)\n",
        "error_rate(Y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZNsQYdJ4iGL"
      },
      "outputs": [],
      "source": [
        "predicted_rnn = classifier.predict(X_test)\n",
        "predicted_rnn = np.where(predicted_rnn > 0.5, 1, 0)\n",
        "predicted_rnn = np.reshape(predicted_rnn,(len(predicted_rnn),)).astype(int)\n",
        "error_rate(Y_test, predicted_rnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08-efAVMAMpe"
      },
      "source": [
        "### GRU with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkFKB2K0AMpe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Bidirectional, Input, Embedding, LSTM, Dropout, Dense, InputLayer, GRU\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from time import time\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpOrZtVaUy7L"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMBmAb4dUy7L"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqOBv6FqAMpe"
      },
      "outputs": [],
      "source": [
        "max_length = 1280"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIgk3kMWAMpf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jekKhU6uAMpf"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LtStluIAMpf"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train[1,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRScf_IEAMpf"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAw2m_sEAMpf"
      },
      "outputs": [],
      "source": [
        "def create_gru_model(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam'):\n",
        "    x_input = layers.Input(input_shape)\n",
        "    #emb = Embedding(21, units, input_length=max_length)(x_input)\n",
        "    gru = GRU(units, activity_regularizer=l2(regularizer), return_sequences = True)(x_input) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x = Dropout(dropout_rate)(gru)\n",
        "    gru2 =GRU(units, activity_regularizer=l2(dropout_rate))(x) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x2 = Dropout(dropout_rate)(gru2)\n",
        "    # softmax classifier\n",
        "    x_output = Dense(1, activation='sigmoid')(x2)\n",
        "\n",
        "    model = Model(inputs=x_input, outputs=x_output)\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_init),#solver,#\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWjZhNmaAMpf"
      },
      "outputs": [],
      "source": [
        "gru_model = create_gru_model()\n",
        "gru_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEngQp4tAMpf"
      },
      "outputs": [],
      "source": [
        "start = time()\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_gru_model, verbose=1, batch_size = 256)\n",
        "# define parameters and values for grid search\n",
        "\n",
        "parameters = {\n",
        "    'units':[50,100], # 1024\n",
        "    #'learning_rate_init': [0.001, 0.01],\n",
        "    'solver':['adam','sgd'],\n",
        "    #'epochs':[3,5,10]\n",
        "    'dropout_rate':[0.0,0.05, 0.1], #0.05\n",
        "    'regularizer':[0.0,0.05, 0.1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhB4jEx8AMpg"
      },
      "outputs": [],
      "source": [
        "metrics = {'accuracy':make_scorer(accuracy_score,greater_is_better=True),'f1':make_scorer(f1_score,greater_is_better=True),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFG1wNb2AMpg"
      },
      "outputs": [],
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=parameters, n_jobs=-1, cv=10, scoring=metrics, refit='mcc')\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE1zJUaAAMpg"
      },
      "outputs": [],
      "source": [
        "classifier = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL5EUnbHAMpg"
      },
      "outputs": [],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF8zMX5jAMpg"
      },
      "outputs": [],
      "source": [
        "#cv_results = DataFrame(grid.cv_results_)\n",
        "\n",
        "#cv_results[['param_units','param_dropout_rate','param_regularizer','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIC-yOznAMpg"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(grid.cv_results_)\n",
        "new_path = '/content/test.xls'\n",
        "writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/T5GRUNath.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyNEgPlWAMpg"
      },
      "outputs": [],
      "source": [
        "predicted_training_labels = classifier.predict(X_train)\n",
        "predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "predicted_training_labels = np.reshape(predicted_training_labels,(len(predicted_training_labels),)).astype(int)\n",
        "error_rate(Y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4jGE6nUAMpg"
      },
      "outputs": [],
      "source": [
        "predicted_gru = classifier.predict(X_test)\n",
        "predicted_gru = np.where(predicted_gru > 0.5, 1, 0)\n",
        "predicted_gru = np.reshape(predicted_gru,(len(predicted_gru),)).astype(int)\n",
        "error_rate(Y_test, predicted_gru)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E76ef8-KUQkP"
      },
      "source": [
        "### LSTM with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88td3Dd4UUSl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Bidirectional, Input, Embedding, LSTM, Dropout, Dense, InputLayer\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from time import time\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckcUO-v09XUY"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu3pXV8o9XUZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eByT44Fj8Mvw"
      },
      "outputs": [],
      "source": [
        "max_length = 1280"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpWikkLDVESA"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVdkEABDUKuw"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd_XYxWoJ8Uw"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train[1,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhJ5yPWsVESB"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bABscCD2UdFT"
      },
      "outputs": [],
      "source": [
        "def create_lstm_model(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam'):\n",
        "    x_input = layers.Input(input_shape)\n",
        "    #emb = Embedding(21, units, input_length=max_length)(x_input)\n",
        "    lstm = LSTM(units, activity_regularizer=l2(regularizer))(x_input) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x = Dropout(dropout_rate)(lstm)\n",
        "    #lstm2 =LSTM(units, activity_regularizer=l2(dropout_rate))(x) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    #x2 = Dropout(dropout_rate)(lstm2)\n",
        "    # softmax classifier\n",
        "    x_output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=x_input, outputs=x_output)\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=solver,#tf.keras.optimizers.Adam(learning_rate=learning_rate_init),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRwnsQ75Ue-6"
      },
      "outputs": [],
      "source": [
        "lstm_model = create_lstm_model()\n",
        "lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdZ6JgxYUg-G"
      },
      "outputs": [],
      "source": [
        "start = time()\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_lstm_model, verbose=1)\n",
        "# define parameters and values for grid search\n",
        "\n",
        "parameters = {\n",
        "    'units':[50,100], # 1024\n",
        "    #'learning_rate_init': [0.001, 0.01],\n",
        "    'solver':['adam','sgd'],\n",
        "    #'epochs':[3,5,10],\n",
        "    'dropout_rate':[0.0,0.05, 0.1], #0.05\n",
        "    'regularizer':[0.0,0.05, 0.1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hos-hNI7UpOs"
      },
      "outputs": [],
      "source": [
        "metrics = {'accuracy':make_scorer(accuracy_score,greater_is_better=True),'f1':make_scorer(f1_score,greater_is_better=True),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0Xa7AQTUqIO"
      },
      "outputs": [],
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=parameters, n_jobs=-1, cv=10, scoring=metrics, refit='mcc')\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qttmg9ayVGeL"
      },
      "outputs": [],
      "source": [
        "classifier = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zvaGtn0VGeL"
      },
      "outputs": [],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_kGV3S6VGeL"
      },
      "outputs": [],
      "source": [
        "#cv_results = DataFrame(grid.cv_results_)\n",
        "\n",
        "#cv_results[['param_units','param_dropout_rate','param_regularizer','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYpncXoMTPWa"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(grid.cv_results_)\n",
        "new_path = '/content/test.xls'\n",
        "writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/T5LSTMNath.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsMHQT0K8vHE"
      },
      "outputs": [],
      "source": [
        "predicted_training_labels = classifier.predict(X_train)\n",
        "predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "predicted_training_labels = np.reshape(predicted_training_labels,(len(predicted_training_labels),)).astype(int)\n",
        "error_rate(Y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKqfkrJb1SP-"
      },
      "outputs": [],
      "source": [
        "predicted_lstm = classifier.predict(X_test)\n",
        "predicted_lstm = np.where(predicted_lstm > 0.5, 1, 0)\n",
        "predicted_lstm = np.reshape(predicted_lstm,(len(predicted_lstm),)).astype(int)\n",
        "error_rate(Y_test, predicted_lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gghPVbbuLbqN"
      },
      "source": [
        "### BiLSTM with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-ZqdqeELYEp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Bidirectional, Input, Embedding, LSTM, Dropout, Dense, InputLayer\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from sklearn.metrics import make_scorer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc2u5VPF9ZN_"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z0kkcZp9ZN_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAHT7mSNVGrU"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD_Jcu4ST67v"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2z79_qvLZCo"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train[1,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUwEv4vzSISY"
      },
      "outputs": [],
      "source": [
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Sn7HB60VGrV"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN7ZQUqrWfW8"
      },
      "outputs": [],
      "source": [
        "num_words = 22\n",
        "num_classes = 1\n",
        "n_cv = 3\n",
        "num_hiddens = 1280\n",
        "num_steps = 10\n",
        "num_layers = 1\n",
        "max_length = 2560"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8Q4lB7lDArN"
      },
      "outputs": [],
      "source": [
        "def create_blstm_model1(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam'):\n",
        "    x_input = Input(input_shape)\n",
        "    #emb = Embedding(21, units, input_length=max_length)(x_input)\n",
        "    bi_rnn = Bidirectional(LSTM(units, activity_regularizer=l2(dropout_rate),return_sequences=True))(x_input) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x = Dropout(dropout_rate)(bi_rnn)\n",
        "    bi_rnn2 = Bidirectional(LSTM(units, activity_regularizer=l2(dropout_rate)))(x) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x2 = Dropout(dropout_rate)(bi_rnn2)\n",
        "    x_output = Dense(1, activation='sigmoid')(x2)\n",
        "\n",
        "    model = Model(inputs=x_input, outputs=x_output)\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_init),#solver,#\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9nPpnnK_FNC"
      },
      "outputs": [],
      "source": [
        "#blstm = create_blstm_model()\n",
        "blstm1 = create_blstm_model1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boSIUOE0CVJ3"
      },
      "outputs": [],
      "source": [
        "#blstm.summary()\n",
        "blstm1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp0OAX3B_Q7p"
      },
      "outputs": [],
      "source": [
        "# Early Stopping\n",
        "#es = EarlyStopping(monitor='val_loss', patience=150, verbose=1)\n",
        "\n",
        "#history = blstm1.fit(train_pad, y_train,\n",
        "#                        validation_data=(val_pad, y_val),\n",
        "#                        callbacks=[es],\n",
        "#                        epochs=3, batch_size=256, verbose=1\n",
        "#                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF5onWhjNYEl"
      },
      "outputs": [],
      "source": [
        "#predicted_training_labels = blstm1.predict(train_pad)\n",
        "#predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "#predicted_training_labels = np.reshape(predicted_training_labels,(len(predicted_training_labels),)).astype(int)\n",
        "#error_rate(y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7qRQrGxNg9C"
      },
      "outputs": [],
      "source": [
        "#predicted_testing_labels = blstm1.predict(val_pad)\n",
        "#predicted_testing_labels = np.where(predicted_testing_labels > 0.5, 1, 0)\n",
        "#predicted_testing_labels = np.reshape(predicted_testing_labels,(len(predicted_testing_labels),)).astype(int)\n",
        "#error_rate(y_val, predicted_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMK08riVVajL"
      },
      "outputs": [],
      "source": [
        "start = time()\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_blstm_model1, verbose=1)\n",
        "# define parameters and values for grid search\n",
        "\n",
        "parameters = {\n",
        "    'units':[50,100],\n",
        "    #'learning_rate_init': [0.001, 0.01],\n",
        "    #'epochs': [2,3,5,10],\n",
        "    'solver':['adam','sgd'],\n",
        "    #'dropout_rate':[0.0,0.05, 0.1],\n",
        "    #'regularizer':[0.0,0.05, 0.1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SgWBn54OyM"
      },
      "outputs": [],
      "source": [
        "metrics = {'accuracy':make_scorer(accuracy_score,greater_is_better=True),'f1':make_scorer(f1_score,greater_is_better=True),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5gZrhg7XrYk"
      },
      "outputs": [],
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=parameters, n_jobs=-1, cv=10, scoring=metrics, refit='mcc')\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s34hMuo0Z2w2"
      },
      "outputs": [],
      "source": [
        "classifier = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xmAALc4Z-hd"
      },
      "outputs": [],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmF350wmb3Bf"
      },
      "outputs": [],
      "source": [
        "#cv_results = DataFrame(grid.cv_results_)\n",
        "\n",
        "#cv_results[['param_units','param_activation','param_dropout_rate','param_regularizer','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnu0uvNzb3C0"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(grid.cv_results_)\n",
        "new_path = '/content/test.xls'\n",
        "writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/T5BLSTMNath.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toJ9ceVVcEVU"
      },
      "outputs": [],
      "source": [
        "predicted_training_labels = classifier.predict(X_train)\n",
        "predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "predicted_training_labels = np.reshape(predicted_training_labels,(len(predicted_training_labels),)).astype(int)\n",
        "error_rate(Y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRn-66gpcEWu"
      },
      "outputs": [],
      "source": [
        "predicted_blstm = classifier.predict(X_test)\n",
        "predicted_blstm = np.where(predicted_blstm > 0.5, 1, 0)\n",
        "predicted_blstm = np.reshape(predicted_blstm,(len(predicted_blstm),)).astype(int)\n",
        "error_rate(Y_test, predicted_blstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtyKU7eecPix"
      },
      "outputs": [],
      "source": [
        "classes = np.unique(Y_test)\n",
        "\n",
        "confusion_matrix_data = confusion_matrix(Y_test, predicted_blstm, labels=classes)\n",
        "conf_matrix(confusion_matrix_data)\n",
        "confusion_matrix_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN1mqv4CMmVU"
      },
      "source": [
        "# CapsNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knA6FmN4MotK"
      },
      "outputs": [],
      "source": [
        "def load_data_embedding():\n",
        "    SEED = 42\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "    random.seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    tf.random.set_seed(SEED)\n",
        "    # the data, shuffled and split between train and test sets\n",
        "\n",
        "    # create train dataset\n",
        "\n",
        "    arr_train = np.array(training_embeddings)\n",
        "    nsample, nx, ny = arr_train.shape\n",
        "    train_dataset = arr_train.reshape((nsample, nx*ny))\n",
        "\n",
        "\n",
        "    # create test dataset\n",
        "\n",
        "    arr_test = np.array(testing_embeddings)\n",
        "    nsample, nx, ny = arr_test.shape\n",
        "    test_dataset = arr_test.reshape((nsample, nx*ny))\n",
        "\n",
        "\n",
        "\n",
        "    # encode labels\n",
        "    labels_train_encoded = to_categorical(\n",
        "        training_labels, num_classes=2, dtype=\"float32\"\n",
        "    )  # (14189, 2)\n",
        "    labels_test_encoded = to_categorical(\n",
        "        testing_labels, num_classes=2, dtype=\"float32\"\n",
        "    )  # (2272, 2)\n",
        "\n",
        "\n",
        "\n",
        "    return train_dataset, labels_train_encoded, test_dataset, labels_test_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqYe_d5nfDI5"
      },
      "source": [
        "## Persiapan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRur-rK-byUo"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    InputLayer,\n",
        "    LSTM,\n",
        "    Bidirectional,\n",
        "    Embedding,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Convolution1D,\n",
        "    MaxPooling1D,\n",
        "    BatchNormalization,\n",
        ")\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCkCLosvbyRY"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def create_dataset(data_path: str) -> Tuple[List[str], List[int]]:\n",
        "    dataset = pd.read_csv(data_path)\n",
        "    dataset = dataset.sample(frac=1).reset_index(drop=True)  # shuffle the dataset\n",
        "    return list(dataset[\"sequence\"]), list(dataset[\"label\"])\n",
        "\n",
        "\n",
        "def split_dataset(\n",
        "    sequences_list: List[str], labels_list: List[int], train_size: float = 0.8\n",
        ") -> Tuple[List[str], List[str], List[str], List[int], List[int], List[int]]:\n",
        "    dataset = pd.DataFrame({\"sequence\": sequences_list, \"label\": labels_list})\n",
        "    dataset = dataset.sample(frac=1, random_state=1)\n",
        "    train, remaining = train_test_split(dataset, train_size=train_size, random_state=2)\n",
        "    valid, test = train_test_split(remaining, test_size=0.5, random_state=3)\n",
        "    x_train, x_valid, x_test = train[\"sequence\"], valid[\"sequence\"], test[\"sequence\"]\n",
        "    y_train, y_valid, y_test = train[\"label\"], valid[\"label\"], test[\"label\"]\n",
        "    return (\n",
        "        list(x_train),\n",
        "        list(x_valid),\n",
        "        list(x_test),\n",
        "        list(y_train),\n",
        "        list(y_valid),\n",
        "        list(y_test),\n",
        "    )\n",
        "\n",
        "\n",
        "def one_hot_encoding(\n",
        "    sequence: str,\n",
        "    max_seq_length: int = 1000,\n",
        "    CONSIDERED_AA: str = \"ACDEFGHIKLMNPQRSTVWY\",\n",
        "):\n",
        "    # adapt sequence size\n",
        "    if len(sequence) > max_seq_length:\n",
        "        # short the sequence\n",
        "        sequence = sequence[:max_seq_length]\n",
        "    else:\n",
        "        # pad the sequence\n",
        "        sequence = sequence + \".\" * (max_seq_length - len(sequence))\n",
        "\n",
        "    # encode sequence\n",
        "    encoded_sequence = np.zeros((max_seq_length, len(CONSIDERED_AA)))  # (1000, 20)\n",
        "    for i, amino_acid in enumerate(sequence):\n",
        "        if amino_acid in CONSIDERED_AA:\n",
        "            encoded_sequence[i][CONSIDERED_AA.index(amino_acid)] = 1\n",
        "    model_input = np.expand_dims(encoded_sequence, 0)  # add batch dimension\n",
        "\n",
        "    return model_input  # (1, 1000, 20)\n",
        "\n",
        "\n",
        "def preprocess_word_embedding_encoding(\n",
        "    sequence: str,\n",
        "    max_seq_length: int = 1000,\n",
        "    CONSIDERED_AA: str = \"ACDEFGHIKLMNPQRSTVWY\",\n",
        "):\n",
        "    # amino acids encoding\n",
        "    aa_mapping = {aa: i + 1 for i, aa in enumerate(CONSIDERED_AA)}\n",
        "\n",
        "    # adapt sequence size\n",
        "    if len(sequence) > max_seq_length:\n",
        "        # short the sequence\n",
        "        sequence = sequence[:max_seq_length]\n",
        "    else:\n",
        "        # pad the sequence\n",
        "        sequence = sequence + \".\" * (max_seq_length - len(sequence))\n",
        "\n",
        "    # encode sequence\n",
        "    encoded_sequence = np.zeros((max_seq_length,))  # (1000,)\n",
        "    for i, amino_acid in enumerate(sequence):\n",
        "        if amino_acid in CONSIDERED_AA:\n",
        "            encoded_sequence[i] = aa_mapping[amino_acid]\n",
        "    model_input = np.expand_dims(encoded_sequence, 0)  # add batch dimension\n",
        "\n",
        "    return model_input  # (1, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuJmxbeZQI66"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall_keras\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision_keras\n",
        "\n",
        "\n",
        "def specificity(y_true, y_pred):\n",
        "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
        "    return tn / (tn + fp + K.epsilon())\n",
        "\n",
        "\n",
        "def negative_predictive_value(y_true, y_pred):\n",
        "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
        "    return tn / (tn + fn + K.epsilon())\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
        "\n",
        "def f1_score_metric(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true * y_pred, 'float32'), axis=0)\n",
        "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float32'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float32'), axis=0)\n",
        "\n",
        "    precision = tp / (tp + fp + K.epsilon())\n",
        "    recall = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
        "    return f1\n",
        "\n",
        "\n",
        "\n",
        "def fbeta(y_true, y_pred, beta=2):\n",
        "    y_pred = K.clip(y_pred, 0, 1)\n",
        "\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
        "    fp = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)), axis=1)\n",
        "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    num = (1 + beta ** 2) * (p * r)\n",
        "    den = (beta ** 2 * p + r + K.epsilon())\n",
        "    return K.mean(num / den)\n",
        "\n",
        "\n",
        "def matthews_correlation_coefficient(y_true, y_pred):\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
        "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
        "\n",
        "    num = tp * tn - fp * fn\n",
        "    den = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
        "    return num / K.sqrt(den + K.epsilon())\n",
        "\n",
        "\n",
        "def equal_error_rate(y_true, y_pred):\n",
        "    n_imp = tf.count_nonzero(tf.equal(y_true, 0), dtype=tf.float32) + tf.constant(K.epsilon())\n",
        "    n_gen = tf.count_nonzero(tf.equal(y_true, 1), dtype=tf.float32) + tf.constant(K.epsilon())\n",
        "\n",
        "    scores_imp = tf.boolean_mask(y_pred, tf.equal(y_true, 0))\n",
        "    scores_gen = tf.boolean_mask(y_pred, tf.equal(y_true, 1))\n",
        "\n",
        "    loop_vars = (tf.constant(0.0), tf.constant(1.0), tf.constant(0.0))\n",
        "    cond = lambda t, fpr, fnr: tf.greater_equal(fpr, fnr)\n",
        "    body = lambda t, fpr, fnr: (\n",
        "        t + 0.001,\n",
        "        tf.divide(tf.count_nonzero(tf.greater_equal(scores_imp, t), dtype=tf.float32), n_imp),\n",
        "        tf.divide(tf.count_nonzero(tf.less(scores_gen, t), dtype=tf.float32), n_gen)\n",
        "    )\n",
        "    t, fpr, fnr = tf.while_loop(cond, body, loop_vars, back_prop=False)\n",
        "    eer = (fpr + fnr) / 2\n",
        "\n",
        "    return eer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5EyVVT2ZF2x"
      },
      "source": [
        "## Capsule Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjwTGDQFbyKA"
      },
      "outputs": [],
      "source": [
        "from keras.backend import *\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "\n",
        "#own_batch_dot = batch_dot  # force standard implementation\n",
        "\n",
        "# import of batch_dot operation from TF 1.13\n",
        "# https://github.com/tensorflow/tensorflow/blob/v1.13.1/tensorflow/python/keras/backend.py\n",
        "\n",
        "def own_batch_dot(x, y, axes=None):\n",
        "  if isinstance(axes, int):\n",
        "    axes = (axes, axes)\n",
        "  x_ndim = ndim(x)\n",
        "  y_ndim = ndim(y)\n",
        "  if axes is None:\n",
        "    # behaves like tf.batch_matmul as default\n",
        "    axes = [x_ndim - 1, y_ndim - 2]\n",
        "  if x_ndim > y_ndim:\n",
        "    diff = x_ndim - y_ndim\n",
        "    y = array_ops.reshape(y,\n",
        "                          array_ops.concat(\n",
        "                              [array_ops.shape(y), [1] * (diff)], axis=0))\n",
        "  elif y_ndim > x_ndim:\n",
        "    diff = y_ndim - x_ndim\n",
        "    x = array_ops.reshape(x,\n",
        "                          array_ops.concat(\n",
        "                              [array_ops.shape(x), [1] * (diff)], axis=0))\n",
        "  else:\n",
        "    diff = 0\n",
        "  if ndim(x) == 2 and ndim(y) == 2:\n",
        "    if axes[0] == axes[1]:\n",
        "      out = math_ops.reduce_sum(math_ops.multiply(x, y), axes[0])\n",
        "    else:\n",
        "      out = math_ops.reduce_sum(\n",
        "          math_ops.multiply(array_ops.transpose(x, [1, 0]), y), axes[1])\n",
        "  else:\n",
        "    adj_x = None if axes[0] == ndim(x) - 1 else True\n",
        "    adj_y = True if axes[1] == ndim(y) - 1 else None\n",
        "    out = math_ops.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n",
        "  if diff:\n",
        "    if x_ndim > y_ndim:\n",
        "      idx = x_ndim + y_ndim - 3\n",
        "    else:\n",
        "      idx = x_ndim - 1\n",
        "    out = array_ops.squeeze(out, list(range(idx, idx + diff)))\n",
        "  if ndim(out) == 1:\n",
        "    out = expand_dims(out, 1)\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9zKkB2KZKtT"
      },
      "outputs": [],
      "source": [
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras import initializers, layers\n",
        "\n",
        "class Length(layers.Layer):\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
        "            # compute lengths of capsules\n",
        "            x = K.sqrt(K.sum(K.square(inputs), -1))\n",
        "            # generate the mask which is a one-hot code.\n",
        "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
        "            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=tf.shape(x)[1])\n",
        "\n",
        "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
        "        # mask.shape=[None, num_capsule]\n",
        "        # masked.shape=[None, num_capsule * dim_capsule]\n",
        "        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n",
        "        return masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:  # no true label provided\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, num_capsule, dim_capsule, num_routing=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.num_routing = num_routing\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "\n",
        "        # Transform matrix\n",
        "        self.W = self.add_weight(shape=(self.num_capsule, self.input_num_capsule,\n",
        "                                        self.dim_capsule, self.input_dim_capsule),\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
        "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n",
        "        inputs_expand = K.expand_dims(inputs, 1)\n",
        "\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule]\n",
        "        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
        "\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
        "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule]\n",
        "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
        "        # Regard the first two dimensions as `batch` dimension,\n",
        "        # then matmul: [input_dim_capsule] x [dim_capsule, input_dim_capsule]^T -> [dim_capsule].\n",
        "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
        "        inputs_hat = K.map_fn(lambda x: own_batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
        "\n",
        "\n",
        "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
        "        # In forward pass, `inputs_hat_stopped` = `inputs_hat`;\n",
        "        # In backward, no gradient can flow from `inputs_hat_stopped` back to `inputs_hat`.\n",
        "        inputs_hat_stopped = K.stop_gradient(inputs_hat)\n",
        "\n",
        "        # The prior for coupling coefficient, initialized as zeros.\n",
        "        # b.shape = [None, self.num_capsule, self.input_num_capsule].\n",
        "        b = tf.zeros(shape=(K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule))\n",
        "\n",
        "        assert self.num_routing > 0, 'The num_routing should be > 0.'\n",
        "        for i in range(self.num_routing):\n",
        "            # c.shape=[batch_size, num_capsule, input_num_capsule]\n",
        "            c = tf.nn.softmax(b, axis=1)\n",
        "\n",
        "            # At last iteration, use `inputs_hat` to compute `outputs` in order to backpropagate gradient\n",
        "            if i == self.num_routing - 1:\n",
        "                # c.shape =  [batch_size, num_capsule, input_num_capsule]\n",
        "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "                # The first two dimensions as `batch` dimension,\n",
        "                # then matmal: [input_num_capsule] x [input_num_capsule, dim_capsule] -> [dim_capsule].\n",
        "                # outputs.shape=[None, num_capsule, dim_capsule]\n",
        "                outputs = squash(own_batch_dot(c, inputs_hat, [2, 2]))  # [None, 10, 16]\n",
        "            else:  # Otherwise, use `inputs_hat_stopped` to update `b`. No gradients flow on this path.\n",
        "                outputs = squash(own_batch_dot(c, inputs_hat_stopped, [2, 2]))\n",
        "\n",
        "                # outputs.shape =  [None, num_capsule, dim_capsule]\n",
        "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "                # The first two dimensions as `batch` dimension,\n",
        "                # then matmal: [dim_capsule] x [input_num_capsule, dim_capsule]^T -> [input_num_capsule].\n",
        "                # b.shape=[batch_size, num_capsule, input_num_capsule]\n",
        "                b += own_batch_dot(outputs, inputs_hat_stopped, [2, 3])\n",
        "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "\n",
        "    output = layers.Conv1D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d')(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY1Mu25zZKqe"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import json\n",
        "from keras import layers, models, optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
        "\n",
        "#%%\n",
        "\n",
        "def CapsNet(input_shape,top_words, maxlen, n_class, routings):\n",
        "\n",
        "    x = layers.Input(shape=input_shape)\n",
        "    conv1 = layers.Conv1D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "\n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=8, num_routing=routings,\n",
        "                             name='digitcaps')(primarycaps)\n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='capsnet')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
        "\n",
        "    # Shared Decoder model in training and prediction\n",
        "    decoder = models.Sequential(name='decoder')\n",
        "    dec_3 = decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid', input_dim=10*n_class))\n",
        "#    dec_1 = decoder.add(layers.Dense(16, activation='relu', input_dim=10*n_class))\n",
        "#    dec_2 = decoder.add(layers.Dense(16, activation='relu'))\n",
        "#    decoder.add(layers.Dropout(0.40))\n",
        "#    dec_3 = decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    dec_4 = decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "\n",
        "    # Models for training and evaluation (prediction)\n",
        "    train_model = models.Model(x,out_caps) #masked_by_y\n",
        "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
        "\n",
        "    # manipulate model\n",
        "    # noise = layers.Input(shape=(n_class, 10))\n",
        "    # noised_digitcaps = layers.Add()([digitcaps, noise])\n",
        "    # masked_noised_y = Mask()([noised_digitcaps, y])\n",
        "    # manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
        "    # return train_model, eval_model, manipulate_model\n",
        "    return train_model, eval_model\n",
        "\n",
        "\n",
        "def margin_loss(y_true, y_pred):\n",
        "\n",
        "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return K.mean(K.sum(L, 1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTLdM6xsZfXN"
      },
      "source": [
        "## Persiapan Kfold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3Tmg3PYcBFw"
      },
      "outputs": [],
      "source": [
        "X_train,y_train,X_test,y_test = load_data_embedding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p9nauvMS_nt",
        "outputId": "c7dd8a01-366a-401f-edc6-5bc0089d1abe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5670,)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[:,1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqQiYmsVTPlU",
        "outputId": "4deeb162-e022-4fc0-e8e5-609a05b0961b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5670\n"
          ]
        }
      ],
      "source": [
        "# split into samples (e.g. 14188/1 = 14188)\n",
        "samples_train = list()\n",
        "length = 1\n",
        "n=5670\n",
        "# step over the 5,000 in jumps of 200\n",
        "for i in range(0,n,length):\n",
        " # grab from i to i + 200\n",
        " sample_train = X_train[i:i+length]\n",
        " samples_train.append(sample_train)\n",
        "print(len(samples_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbrC4YK1XuWL",
        "outputId": "c7377402-19d7-4ebc-d85a-7c3c49d7fa6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1356\n"
          ]
        }
      ],
      "source": [
        "samples_test = list()\n",
        "length = 1\n",
        "n=1356\n",
        "# step over the 5,000 in jumps of 200\n",
        "for i in range(0,n,length):\n",
        " # grab from i to i + 200\n",
        " sample_test = X_test[i:i+length]\n",
        " samples_test.append(sample_test)\n",
        "print(len(samples_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4JrOFq8U0nz",
        "outputId": "17c69078-cad8-47d2-f0bb-214fd1e12767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5670, 1, 1024)\n",
            "(1356, 1, 1024)\n"
          ]
        }
      ],
      "source": [
        "# convert list of arrays into 2d array\n",
        "from numpy import array\n",
        "data_train = array(samples_train)\n",
        "data_test = array(samples_test)\n",
        "print(data_train.shape)\n",
        "print(data_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwURdpVsZF0o"
      },
      "outputs": [],
      "source": [
        "# data_train = data_train.reshape((len(samples_train), 32, 32))\n",
        "# data_test = data_test.reshape((len(samples_test), 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtW51cDLU0ih",
        "outputId": "534cff9b-ae2a-4a43-fea2-da20533d441a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5670, 1024, 1)\n",
            "(1356, 1024, 1)\n"
          ]
        }
      ],
      "source": [
        "data_train = data_train.reshape((len(samples_train), 1024,1))\n",
        "data_test = data_test.reshape((len(samples_test), 1024, 1))\n",
        "print(data_train.shape)\n",
        "print(data_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns8b4eBOov-7",
        "outputId": "31a9fe20-b25f-4db8-ef9f-cc55c346df5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1024,)"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[1000].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSDO3L0oU0fG",
        "outputId": "fe4083a1-db49-483f-ff8a-ee9914a52336"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5670, 1024, 1)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG0RY8hdmsv2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "inputs = np.concatenate((data_train, data_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFedio1PY8NV",
        "outputId": "3efab51d-1de4-40d7-a876-62e9ff46f888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7026, 1024, 1)\n",
            "(7026, 2)\n"
          ]
        }
      ],
      "source": [
        "print(inputs.shape)\n",
        "print(targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56SItDZhnX3a"
      },
      "source": [
        "## Training Capsule Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SHBrYf7FcBAA",
        "outputId": "b2939792-7dfe-434f-ba85-3358bbfc2741"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/backend.py:7250: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1024, 1)]         0         \n",
            "                                                                 \n",
            " conv1 (Conv1D)              (None, 1016, 256)         2560      \n",
            "                                                                 \n",
            " primarycap_conv2d (Conv1D)  (None, 504, 256)          590080    \n",
            "                                                                 \n",
            " primarycap_reshape (Reshap  (None, 16128, 8)          0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            " primarycap_squash (Lambda)  (None, 16128, 8)          0         \n",
            "                                                                 \n",
            " digitcaps (CapsuleLayer)    (None, 2, 8)              2064384   \n",
            "                                                                 \n",
            " capsnet (Length)            (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2657024 (10.14 MB)\n",
            "Trainable params: 2657024 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/30\n",
            "45/45 [==============================] - 66s 1s/step - loss: 0.8100 - accuracy: 0.5044 - specificity: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - matthews_correlation_coefficient: 0.0000e+00 - f1: nan\n",
            "Epoch 2/30\n",
            "45/45 [==============================] - 66s 1s/step - loss: 0.4731 - accuracy: 0.6788 - specificity: 0.4658 - precision: 0.5317 - recall: 0.5982 - auc: 0.5520 - matthews_correlation_coefficient: 0.0704 - f1: nan\n",
            "Epoch 3/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.1877 - accuracy: 0.6801 - specificity: 0.4323 - precision: 0.5916 - recall: 0.8273 - auc: 0.7092 - matthews_correlation_coefficient: 0.2774 - f1: 0.6938\n",
            "Epoch 4/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0939 - accuracy: 0.8663 - specificity: 0.7107 - precision: 0.7659 - recall: 0.9450 - auc: 0.9334 - matthews_correlation_coefficient: 0.6745 - f1: 0.8457\n",
            "Epoch 5/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0691 - accuracy: 0.9083 - specificity: 0.8068 - precision: 0.8321 - recall: 0.9563 - auc: 0.9618 - matthews_correlation_coefficient: 0.7724 - f1: 0.8898\n",
            "Epoch 6/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0574 - accuracy: 0.9189 - specificity: 0.8355 - precision: 0.8555 - recall: 0.9670 - auc: 0.9744 - matthews_correlation_coefficient: 0.8108 - f1: 0.9079\n",
            "Epoch 7/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0537 - accuracy: 0.9279 - specificity: 0.8485 - precision: 0.8643 - recall: 0.9697 - auc: 0.9781 - matthews_correlation_coefficient: 0.8247 - f1: 0.9144\n",
            "Epoch 8/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0506 - accuracy: 0.9342 - specificity: 0.8657 - precision: 0.8773 - recall: 0.9693 - auc: 0.9801 - matthews_correlation_coefficient: 0.8411 - f1: 0.9222\n",
            "Epoch 9/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0490 - accuracy: 0.9354 - specificity: 0.8662 - precision: 0.8797 - recall: 0.9697 - auc: 0.9818 - matthews_correlation_coefficient: 0.8410 - f1: 0.9222\n",
            "Epoch 10/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0460 - accuracy: 0.9414 - specificity: 0.8750 - precision: 0.8856 - recall: 0.9739 - auc: 0.9839 - matthews_correlation_coefficient: 0.8536 - f1: 0.9282\n",
            "Epoch 11/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0433 - accuracy: 0.9432 - specificity: 0.8831 - precision: 0.8938 - recall: 0.9781 - auc: 0.9857 - matthews_correlation_coefficient: 0.8654 - f1: 0.9339\n",
            "Epoch 12/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0411 - accuracy: 0.9466 - specificity: 0.8940 - precision: 0.9015 - recall: 0.9781 - auc: 0.9869 - matthews_correlation_coefficient: 0.8759 - f1: 0.9389\n",
            "Epoch 13/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0409 - accuracy: 0.9487 - specificity: 0.8955 - precision: 0.9029 - recall: 0.9788 - auc: 0.9871 - matthews_correlation_coefficient: 0.8776 - f1: 0.9398\n",
            "Epoch 14/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0378 - accuracy: 0.9506 - specificity: 0.9007 - precision: 0.9068 - recall: 0.9820 - auc: 0.9887 - matthews_correlation_coefficient: 0.8864 - f1: 0.9440\n",
            "Epoch 15/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0366 - accuracy: 0.9524 - specificity: 0.9028 - precision: 0.9100 - recall: 0.9861 - auc: 0.9897 - matthews_correlation_coefficient: 0.8922 - f1: 0.9467\n",
            "Epoch 16/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0346 - accuracy: 0.9568 - specificity: 0.9146 - precision: 0.9199 - recall: 0.9859 - auc: 0.9907 - matthews_correlation_coefficient: 0.9033 - f1: 0.9522\n",
            "Epoch 17/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0329 - accuracy: 0.9559 - specificity: 0.9159 - precision: 0.9219 - recall: 0.9885 - auc: 0.9914 - matthews_correlation_coefficient: 0.9069 - f1: 0.9539\n",
            "Epoch 18/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0317 - accuracy: 0.9619 - specificity: 0.9205 - precision: 0.9256 - recall: 0.9898 - auc: 0.9919 - matthews_correlation_coefficient: 0.9130 - f1: 0.9568\n",
            "Epoch 19/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0302 - accuracy: 0.9638 - specificity: 0.9227 - precision: 0.9277 - recall: 0.9917 - auc: 0.9928 - matthews_correlation_coefficient: 0.9166 - f1: 0.9586\n",
            "Epoch 20/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0295 - accuracy: 0.9658 - specificity: 0.9282 - precision: 0.9322 - recall: 0.9924 - auc: 0.9932 - matthews_correlation_coefficient: 0.9228 - f1: 0.9617\n",
            "Epoch 21/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0265 - accuracy: 0.9684 - specificity: 0.9397 - precision: 0.9432 - recall: 0.9951 - auc: 0.9939 - matthews_correlation_coefficient: 0.9365 - f1: 0.9684\n",
            "Epoch 22/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0256 - accuracy: 0.9698 - specificity: 0.9380 - precision: 0.9424 - recall: 0.9952 - auc: 0.9945 - matthews_correlation_coefficient: 0.9351 - f1: 0.9677\n",
            "Epoch 23/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0239 - accuracy: 0.9730 - specificity: 0.9444 - precision: 0.9475 - recall: 0.9959 - auc: 0.9951 - matthews_correlation_coefficient: 0.9420 - f1: 0.9711\n",
            "Epoch 24/30\n",
            "45/45 [==============================] - 67s 1s/step - loss: 0.0223 - accuracy: 0.9739 - specificity: 0.9482 - precision: 0.9511 - recall: 0.9975 - auc: 0.9955 - matthews_correlation_coefficient: 0.9471 - f1: 0.9736\n",
            "Epoch 25/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0225 - accuracy: 0.9751 - specificity: 0.9506 - precision: 0.9528 - recall: 0.9966 - auc: 0.9956 - matthews_correlation_coefficient: 0.9485 - f1: 0.9743\n",
            "Epoch 26/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0200 - accuracy: 0.9788 - specificity: 0.9531 - precision: 0.9567 - recall: 0.9986 - auc: 0.9961 - matthews_correlation_coefficient: 0.9529 - f1: 0.9765\n",
            "Epoch 27/30\n",
            "45/45 [==============================] - 67s 1s/step - loss: 0.0184 - accuracy: 0.9804 - specificity: 0.9604 - precision: 0.9616 - recall: 0.9988 - auc: 0.9967 - matthews_correlation_coefficient: 0.9600 - f1: 0.9800\n",
            "Epoch 28/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0178 - accuracy: 0.9825 - specificity: 0.9623 - precision: 0.9642 - recall: 0.9989 - auc: 0.9967 - matthews_correlation_coefficient: 0.9620 - f1: 0.9811\n",
            "Epoch 29/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0165 - accuracy: 0.9847 - specificity: 0.9661 - precision: 0.9679 - recall: 0.9995 - auc: 0.9970 - matthews_correlation_coefficient: 0.9663 - f1: 0.9832\n",
            "Epoch 30/30\n",
            "45/45 [==============================] - 64s 1s/step - loss: 0.0172 - accuracy: 0.9852 - specificity: 0.9625 - precision: 0.9641 - recall: 0.9986 - auc: 0.9970 - matthews_correlation_coefficient: 0.9619 - f1: 0.9810\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 74s 1s/step - loss: 0.0265 - accuracy: 0.9723 - specificity: 0.9423 - precision: 0.9447 - recall: 0.9881 - auc: 0.9928 - matthews_correlation_coefficient: 0.9319 - f1: 0.9662\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 72s 1s/step - loss: 0.0225 - accuracy: 0.9761 - specificity: 0.9527 - precision: 0.9544 - recall: 0.9923 - auc: 0.9948 - matthews_correlation_coefficient: 0.9457 - f1: 0.9730\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 72s 1s/step - loss: 0.0199 - accuracy: 0.9788 - specificity: 0.9572 - precision: 0.9587 - recall: 0.9951 - auc: 0.9958 - matthews_correlation_coefficient: 0.9529 - f1: 0.9765\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 72s 1s/step - loss: 0.0187 - accuracy: 0.9810 - specificity: 0.9595 - precision: 0.9614 - recall: 0.9964 - auc: 0.9963 - matthews_correlation_coefficient: 0.9567 - f1: 0.9784\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 73s 1s/step - loss: 0.0165 - accuracy: 0.9842 - specificity: 0.9659 - precision: 0.9668 - recall: 0.9979 - auc: 0.9967 - matthews_correlation_coefficient: 0.9644 - f1: 0.9822\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 72s 1s/step - loss: 0.0150 - accuracy: 0.9851 - specificity: 0.9700 - precision: 0.9705 - recall: 0.9991 - auc: 0.9970 - matthews_correlation_coefficient: 0.9696 - f1: 0.9848\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 72s 1s/step - loss: 0.0156 - accuracy: 0.9866 - specificity: 0.9678 - precision: 0.9689 - recall: 0.9991 - auc: 0.9971 - matthews_correlation_coefficient: 0.9675 - f1: 0.9838\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 75s 2s/step - loss: 0.0136 - accuracy: 0.9889 - specificity: 0.9723 - precision: 0.9728 - recall: 0.9998 - auc: 0.9974 - matthews_correlation_coefficient: 0.9727 - f1: 0.9863\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 71s 1s/step - loss: 0.0130 - accuracy: 0.9891 - specificity: 0.9745 - precision: 0.9750 - recall: 0.9998 - auc: 0.9975 - matthews_correlation_coefficient: 0.9747 - f1: 0.9874\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 74s 1s/step - loss: 0.0119 - accuracy: 0.9896 - specificity: 0.9773 - precision: 0.9776 - recall: 0.9998 - auc: 0.9978 - matthews_correlation_coefficient: 0.9775 - f1: 0.9888\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 71s 1s/step - loss: 0.0109 - accuracy: 0.9910 - specificity: 0.9786 - precision: 0.9792 - recall: 0.9997 - auc: 0.9979 - matthews_correlation_coefficient: 0.9786 - f1: 0.9893\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0100 - accuracy: 0.9921 - specificity: 0.9816 - precision: 0.9820 - recall: 1.0000 - auc: 0.9980 - matthews_correlation_coefficient: 0.9819 - f1: 0.9909\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 71s 1s/step - loss: 0.0094 - accuracy: 0.9919 - specificity: 0.9821 - precision: 0.9824 - recall: 1.0000 - auc: 0.9980 - matthews_correlation_coefficient: 0.9823 - f1: 0.9912\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 73s 1s/step - loss: 0.0091 - accuracy: 0.9924 - specificity: 0.9820 - precision: 0.9823 - recall: 1.0000 - auc: 0.9984 - matthews_correlation_coefficient: 0.9822 - f1: 0.9911\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 79s 2s/step - loss: 0.0089 - accuracy: 0.9929 - specificity: 0.9816 - precision: 0.9820 - recall: 1.0000 - auc: 0.9983 - matthews_correlation_coefficient: 0.9819 - f1: 0.9910\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0083 - accuracy: 0.9945 - specificity: 0.9842 - precision: 0.9843 - recall: 1.0000 - auc: 0.9986 - matthews_correlation_coefficient: 0.9844 - f1: 0.9922\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0088 - accuracy: 0.9941 - specificity: 0.9824 - precision: 0.9827 - recall: 0.9998 - auc: 0.9986 - matthews_correlation_coefficient: 0.9822 - f1: 0.9911\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 89s 2s/step - loss: 0.0082 - accuracy: 0.9946 - specificity: 0.9833 - precision: 0.9838 - recall: 0.9997 - auc: 0.9985 - matthews_correlation_coefficient: 0.9832 - f1: 0.9916\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 87s 2s/step - loss: 0.0077 - accuracy: 0.9959 - specificity: 0.9866 - precision: 0.9866 - recall: 1.0000 - auc: 0.9987 - matthews_correlation_coefficient: 0.9867 - f1: 0.9933\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0074 - accuracy: 0.9959 - specificity: 0.9853 - precision: 0.9858 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9855 - f1: 0.9927\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0065 - accuracy: 0.9970 - specificity: 0.9866 - precision: 0.9870 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9867 - f1: 0.9933\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0062 - accuracy: 0.9970 - specificity: 0.9886 - precision: 0.9886 - recall: 1.0000 - auc: 0.9991 - matthews_correlation_coefficient: 0.9887 - f1: 0.9943\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 85s 2s/step - loss: 0.0060 - accuracy: 0.9972 - specificity: 0.9882 - precision: 0.9884 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9883 - f1: 0.9942\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0059 - accuracy: 0.9972 - specificity: 0.9874 - precision: 0.9881 - recall: 1.0000 - auc: 0.9991 - matthews_correlation_coefficient: 0.9876 - f1: 0.9938\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 79s 2s/step - loss: 0.0061 - accuracy: 0.9975 - specificity: 0.9878 - precision: 0.9883 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9879 - f1: 0.9940\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0057 - accuracy: 0.9978 - specificity: 0.9893 - precision: 0.9895 - recall: 1.0000 - auc: 0.9991 - matthews_correlation_coefficient: 0.9894 - f1: 0.9947\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0053 - accuracy: 0.9975 - specificity: 0.9903 - precision: 0.9903 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9904 - f1: 0.9952\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0055 - accuracy: 0.9978 - specificity: 0.9891 - precision: 0.9894 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9893 - f1: 0.9946\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0044 - accuracy: 0.9981 - specificity: 0.9905 - precision: 0.9909 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9906 - f1: 0.9953\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0053 - accuracy: 0.9979 - specificity: 0.9902 - precision: 0.9901 - recall: 1.0000 - auc: 0.9991 - matthews_correlation_coefficient: 0.9903 - f1: 0.9951\n",
            "Score for fold 1: loss of 0.04104024916887283; accuracy of 96.01706862449646%; specificity of 0.8874633312225342; precision of 0.8967320322990417; recall of 0.9758179187774658; auc of 0.9877076745033264; matthews_correlation_coefficient of 0.8682308793067932; f1 of 0.9355682730674744\n",
            "22/22 [==============================] - 3s 124ms/step\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1024, 1)]         0         \n",
            "                                                                 \n",
            " conv1 (Conv1D)              (None, 1016, 256)         2560      \n",
            "                                                                 \n",
            " primarycap_conv2d (Conv1D)  (None, 504, 256)          590080    \n",
            "                                                                 \n",
            " primarycap_reshape (Reshap  (None, 16128, 8)          0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            " primarycap_squash (Lambda)  (None, 16128, 8)          0         \n",
            "                                                                 \n",
            " digitcaps (CapsuleLayer)    (None, 2, 8)              2064384   \n",
            "                                                                 \n",
            " capsnet (Length)            (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2657024 (10.14 MB)\n",
            "Trainable params: 2657024 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.8100 - accuracy: 0.5414 - specificity: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - matthews_correlation_coefficient: 0.0000e+00 - f1: nan\n",
            "Epoch 2/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.3199 - accuracy: 0.6788 - specificity: 0.3813 - precision: 0.5431 - recall: 0.7397 - auc: 0.5954 - matthews_correlation_coefficient: 0.1206 - f1: nan\n",
            "Epoch 3/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.1726 - accuracy: 0.7007 - specificity: 0.5046 - precision: 0.6241 - recall: 0.8272 - auc: 0.7575 - matthews_correlation_coefficient: 0.3588 - f1: 0.7132\n",
            "Epoch 4/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0941 - accuracy: 0.8730 - specificity: 0.7274 - precision: 0.7756 - recall: 0.9402 - auc: 0.9266 - matthews_correlation_coefficient: 0.6865 - f1: 0.8508\n",
            "Epoch 5/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0713 - accuracy: 0.9016 - specificity: 0.7993 - precision: 0.8269 - recall: 0.9577 - auc: 0.9587 - matthews_correlation_coefficient: 0.7689 - f1: 0.8881\n",
            "Epoch 6/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0619 - accuracy: 0.9143 - specificity: 0.8215 - precision: 0.8443 - recall: 0.9649 - auc: 0.9694 - matthews_correlation_coefficient: 0.7958 - f1: 0.9010\n",
            "Epoch 7/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0546 - accuracy: 0.9250 - specificity: 0.8482 - precision: 0.8641 - recall: 0.9704 - auc: 0.9765 - matthews_correlation_coefficient: 0.8251 - f1: 0.9147\n",
            "Epoch 8/30\n",
            "45/45 [==============================] - 68s 2s/step - loss: 0.0511 - accuracy: 0.9305 - specificity: 0.8595 - precision: 0.8729 - recall: 0.9716 - auc: 0.9794 - matthews_correlation_coefficient: 0.8370 - f1: 0.9203\n",
            "Epoch 9/30\n",
            "45/45 [==============================] - 65s 1s/step - loss: 0.0500 - accuracy: 0.9316 - specificity: 0.8600 - precision: 0.8744 - recall: 0.9702 - auc: 0.9806 - matthews_correlation_coefficient: 0.8353 - f1: 0.9195\n",
            "Epoch 10/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0478 - accuracy: 0.9363 - specificity: 0.8694 - precision: 0.8816 - recall: 0.9755 - auc: 0.9826 - matthews_correlation_coefficient: 0.8500 - f1: 0.9265\n",
            "Epoch 11/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0446 - accuracy: 0.9418 - specificity: 0.8799 - precision: 0.8914 - recall: 0.9767 - auc: 0.9849 - matthews_correlation_coefficient: 0.8609 - f1: 0.9318\n",
            "Epoch 12/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0417 - accuracy: 0.9474 - specificity: 0.8882 - precision: 0.8970 - recall: 0.9787 - auc: 0.9864 - matthews_correlation_coefficient: 0.8710 - f1: 0.9366\n",
            "Epoch 13/30\n",
            "45/45 [==============================] - 68s 2s/step - loss: 0.0422 - accuracy: 0.9467 - specificity: 0.8906 - precision: 0.8989 - recall: 0.9769 - auc: 0.9862 - matthews_correlation_coefficient: 0.8717 - f1: 0.9369\n",
            "Epoch 14/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0388 - accuracy: 0.9485 - specificity: 0.8969 - precision: 0.9046 - recall: 0.9822 - auc: 0.9880 - matthews_correlation_coefficient: 0.8831 - f1: 0.9424\n",
            "Epoch 15/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0374 - accuracy: 0.9519 - specificity: 0.9043 - precision: 0.9111 - recall: 0.9829 - auc: 0.9891 - matthews_correlation_coefficient: 0.8902 - f1: 0.9458\n",
            "Epoch 16/30\n",
            "45/45 [==============================] - 69s 2s/step - loss: 0.0355 - accuracy: 0.9545 - specificity: 0.9103 - precision: 0.9160 - recall: 0.9847 - auc: 0.9902 - matthews_correlation_coefficient: 0.8979 - f1: 0.9496\n",
            "Epoch 17/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0338 - accuracy: 0.9573 - specificity: 0.9132 - precision: 0.9190 - recall: 0.9868 - auc: 0.9909 - matthews_correlation_coefficient: 0.9025 - f1: 0.9518\n",
            "Epoch 18/30\n",
            "45/45 [==============================] - 69s 2s/step - loss: 0.0325 - accuracy: 0.9594 - specificity: 0.9190 - precision: 0.9236 - recall: 0.9887 - auc: 0.9915 - matthews_correlation_coefficient: 0.9104 - f1: 0.9556\n",
            "Epoch 19/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0316 - accuracy: 0.9610 - specificity: 0.9187 - precision: 0.9244 - recall: 0.9898 - auc: 0.9923 - matthews_correlation_coefficient: 0.9107 - f1: 0.9558\n",
            "Epoch 20/30\n",
            "45/45 [==============================] - 69s 2s/step - loss: 0.0301 - accuracy: 0.9653 - specificity: 0.9248 - precision: 0.9288 - recall: 0.9915 - auc: 0.9928 - matthews_correlation_coefficient: 0.9187 - f1: 0.9597\n",
            "Epoch 21/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0281 - accuracy: 0.9668 - specificity: 0.9344 - precision: 0.9382 - recall: 0.9928 - auc: 0.9935 - matthews_correlation_coefficient: 0.9291 - f1: 0.9648\n",
            "Epoch 22/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0266 - accuracy: 0.9688 - specificity: 0.9338 - precision: 0.9390 - recall: 0.9956 - auc: 0.9943 - matthews_correlation_coefficient: 0.9315 - f1: 0.9659\n",
            "Epoch 23/30\n",
            "45/45 [==============================] - 69s 2s/step - loss: 0.0250 - accuracy: 0.9711 - specificity: 0.9416 - precision: 0.9449 - recall: 0.9947 - auc: 0.9948 - matthews_correlation_coefficient: 0.9381 - f1: 0.9692\n",
            "Epoch 24/30\n",
            "45/45 [==============================] - 69s 2s/step - loss: 0.0240 - accuracy: 0.9730 - specificity: 0.9436 - precision: 0.9483 - recall: 0.9968 - auc: 0.9953 - matthews_correlation_coefficient: 0.9422 - f1: 0.9712\n",
            "Epoch 25/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0237 - accuracy: 0.9739 - specificity: 0.9459 - precision: 0.9485 - recall: 0.9972 - auc: 0.9954 - matthews_correlation_coefficient: 0.9441 - f1: 0.9722\n",
            "Epoch 26/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0215 - accuracy: 0.9764 - specificity: 0.9488 - precision: 0.9524 - recall: 0.9984 - auc: 0.9959 - matthews_correlation_coefficient: 0.9487 - f1: 0.9744\n",
            "Epoch 27/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0196 - accuracy: 0.9792 - specificity: 0.9570 - precision: 0.9589 - recall: 0.9993 - auc: 0.9966 - matthews_correlation_coefficient: 0.9573 - f1: 0.9787\n",
            "Epoch 28/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0187 - accuracy: 0.9815 - specificity: 0.9578 - precision: 0.9600 - recall: 0.9993 - auc: 0.9967 - matthews_correlation_coefficient: 0.9580 - f1: 0.9790\n",
            "Epoch 29/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0178 - accuracy: 0.9829 - specificity: 0.9623 - precision: 0.9643 - recall: 0.9995 - auc: 0.9969 - matthews_correlation_coefficient: 0.9627 - f1: 0.9813\n",
            "Epoch 30/30\n",
            "45/45 [==============================] - 69s 2s/step - loss: 0.0184 - accuracy: 0.9834 - specificity: 0.9601 - precision: 0.9618 - recall: 0.9989 - auc: 0.9970 - matthews_correlation_coefficient: 0.9599 - f1: 0.9800\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0262 - accuracy: 0.9715 - specificity: 0.9425 - precision: 0.9448 - recall: 0.9886 - auc: 0.9932 - matthews_correlation_coefficient: 0.9322 - f1: 0.9664\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0235 - accuracy: 0.9771 - specificity: 0.9473 - precision: 0.9495 - recall: 0.9926 - auc: 0.9952 - matthews_correlation_coefficient: 0.9411 - f1: 0.9707\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0216 - accuracy: 0.9766 - specificity: 0.9502 - precision: 0.9525 - recall: 0.9951 - auc: 0.9959 - matthews_correlation_coefficient: 0.9465 - f1: 0.9734\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0189 - accuracy: 0.9817 - specificity: 0.9577 - precision: 0.9592 - recall: 0.9973 - auc: 0.9967 - matthews_correlation_coefficient: 0.9557 - f1: 0.9779\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0178 - accuracy: 0.9834 - specificity: 0.9613 - precision: 0.9625 - recall: 0.9981 - auc: 0.9970 - matthews_correlation_coefficient: 0.9602 - f1: 0.9802\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0162 - accuracy: 0.9854 - specificity: 0.9659 - precision: 0.9671 - recall: 0.9991 - auc: 0.9973 - matthews_correlation_coefficient: 0.9657 - f1: 0.9829\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0153 - accuracy: 0.9872 - specificity: 0.9695 - precision: 0.9705 - recall: 0.9995 - auc: 0.9975 - matthews_correlation_coefficient: 0.9696 - f1: 0.9848\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 79s 2s/step - loss: 0.0138 - accuracy: 0.9880 - specificity: 0.9695 - precision: 0.9702 - recall: 0.9995 - auc: 0.9977 - matthews_correlation_coefficient: 0.9695 - f1: 0.9848\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0131 - accuracy: 0.9889 - specificity: 0.9730 - precision: 0.9738 - recall: 0.9997 - auc: 0.9979 - matthews_correlation_coefficient: 0.9731 - f1: 0.9865\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0123 - accuracy: 0.9904 - specificity: 0.9753 - precision: 0.9761 - recall: 0.9998 - auc: 0.9981 - matthews_correlation_coefficient: 0.9755 - f1: 0.9878\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 79s 2s/step - loss: 0.0117 - accuracy: 0.9929 - specificity: 0.9767 - precision: 0.9774 - recall: 1.0000 - auc: 0.9980 - matthews_correlation_coefficient: 0.9771 - f1: 0.9885\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0108 - accuracy: 0.9926 - specificity: 0.9801 - precision: 0.9805 - recall: 1.0000 - auc: 0.9983 - matthews_correlation_coefficient: 0.9803 - f1: 0.9902\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0101 - accuracy: 0.9932 - specificity: 0.9816 - precision: 0.9817 - recall: 1.0000 - auc: 0.9984 - matthews_correlation_coefficient: 0.9818 - f1: 0.9909\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 76s 2s/step - loss: 0.0104 - accuracy: 0.9934 - specificity: 0.9813 - precision: 0.9817 - recall: 1.0000 - auc: 0.9986 - matthews_correlation_coefficient: 0.9816 - f1: 0.9908\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 75s 2s/step - loss: 0.0094 - accuracy: 0.9938 - specificity: 0.9809 - precision: 0.9820 - recall: 1.0000 - auc: 0.9985 - matthews_correlation_coefficient: 0.9812 - f1: 0.9906\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 75s 1s/step - loss: 0.0095 - accuracy: 0.9930 - specificity: 0.9809 - precision: 0.9812 - recall: 0.9998 - auc: 0.9986 - matthews_correlation_coefficient: 0.9810 - f1: 0.9905\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 75s 2s/step - loss: 0.0081 - accuracy: 0.9948 - specificity: 0.9837 - precision: 0.9843 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9839 - f1: 0.9920\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 74s 1s/step - loss: 0.0076 - accuracy: 0.9953 - specificity: 0.9855 - precision: 0.9855 - recall: 1.0000 - auc: 0.9989 - matthews_correlation_coefficient: 0.9856 - f1: 0.9928\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 76s 2s/step - loss: 0.0078 - accuracy: 0.9956 - specificity: 0.9852 - precision: 0.9852 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9853 - f1: 0.9927\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0071 - accuracy: 0.9964 - specificity: 0.9855 - precision: 0.9858 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9857 - f1: 0.9929\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0070 - accuracy: 0.9967 - specificity: 0.9851 - precision: 0.9854 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9852 - f1: 0.9926\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0070 - accuracy: 0.9968 - specificity: 0.9870 - precision: 0.9875 - recall: 1.0000 - auc: 0.9989 - matthews_correlation_coefficient: 0.9872 - f1: 0.9936\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0066 - accuracy: 0.9972 - specificity: 0.9875 - precision: 0.9875 - recall: 0.9998 - auc: 0.9992 - matthews_correlation_coefficient: 0.9875 - f1: 0.9937\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 84s 2s/step - loss: 0.0056 - accuracy: 0.9976 - specificity: 0.9892 - precision: 0.9897 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9893 - f1: 0.9947\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 84s 2s/step - loss: 0.0054 - accuracy: 0.9978 - specificity: 0.9902 - precision: 0.9901 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9902 - f1: 0.9951\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 85s 2s/step - loss: 0.0053 - accuracy: 0.9978 - specificity: 0.9887 - precision: 0.9887 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9888 - f1: 0.9944\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 89s 2s/step - loss: 0.0060 - accuracy: 0.9978 - specificity: 0.9886 - precision: 0.9891 - recall: 1.0000 - auc: 0.9993 - matthews_correlation_coefficient: 0.9887 - f1: 0.9943\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 90s 2s/step - loss: 0.0055 - accuracy: 0.9979 - specificity: 0.9895 - precision: 0.9895 - recall: 1.0000 - auc: 0.9993 - matthews_correlation_coefficient: 0.9896 - f1: 0.9948\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 86s 2s/step - loss: 0.0053 - accuracy: 0.9981 - specificity: 0.9894 - precision: 0.9898 - recall: 1.0000 - auc: 0.9993 - matthews_correlation_coefficient: 0.9895 - f1: 0.9947\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 86s 2s/step - loss: 0.0052 - accuracy: 0.9981 - specificity: 0.9893 - precision: 0.9895 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9894 - f1: 0.9947\n",
            "Score for fold 2: loss of 0.05241813138127327; accuracy of 94.73684430122375%; specificity of 0.8531891107559204; precision of 0.8686224222183228; recall of 0.9687055349349976; auc of 0.9787833094596863; matthews_correlation_coefficient of 0.8278372287750244; f1 of 0.9170706272125244\n",
            "22/22 [==============================] - 4s 156ms/step\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1024, 1)]         0         \n",
            "                                                                 \n",
            " conv1 (Conv1D)              (None, 1016, 256)         2560      \n",
            "                                                                 \n",
            " primarycap_conv2d (Conv1D)  (None, 504, 256)          590080    \n",
            "                                                                 \n",
            " primarycap_reshape (Reshap  (None, 16128, 8)          0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            " primarycap_squash (Lambda)  (None, 16128, 8)          0         \n",
            "                                                                 \n",
            " digitcaps (CapsuleLayer)    (None, 2, 8)              2064384   \n",
            "                                                                 \n",
            " capsnet (Length)            (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2657024 (10.14 MB)\n",
            "Trainable params: 2657024 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/30\n",
            "45/45 [==============================] - 81s 2s/step - loss: 0.8100 - accuracy: 0.6337 - specificity: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - matthews_correlation_coefficient: 0.0000e+00 - f1: nan\n",
            "Epoch 2/30\n",
            "45/45 [==============================] - 79s 2s/step - loss: 0.3829 - accuracy: 0.6788 - specificity: 0.4200 - precision: 0.5348 - recall: 0.6591 - auc: 0.5663 - matthews_correlation_coefficient: 0.0869 - f1: nan\n",
            "Epoch 3/30\n",
            "45/45 [==============================] - 75s 2s/step - loss: 0.1830 - accuracy: 0.6815 - specificity: 0.4672 - precision: 0.6061 - recall: 0.8206 - auc: 0.7232 - matthews_correlation_coefficient: 0.3036 - f1: 0.6995\n",
            "Epoch 4/30\n",
            "45/45 [==============================] - 75s 2s/step - loss: 0.0931 - accuracy: 0.8693 - specificity: 0.7255 - precision: 0.7751 - recall: 0.9450 - auc: 0.9318 - matthews_correlation_coefficient: 0.6885 - f1: 0.8522\n",
            "Epoch 5/30\n",
            "45/45 [==============================] - 78s 2s/step - loss: 0.0741 - accuracy: 0.9002 - specificity: 0.7881 - precision: 0.8180 - recall: 0.9543 - auc: 0.9554 - matthews_correlation_coefficient: 0.7549 - f1: 0.8814\n",
            "Epoch 6/30\n",
            "45/45 [==============================] - 76s 2s/step - loss: 0.0642 - accuracy: 0.9131 - specificity: 0.8201 - precision: 0.8427 - recall: 0.9607 - auc: 0.9674 - matthews_correlation_coefficient: 0.7896 - f1: 0.8980\n",
            "Epoch 7/30\n",
            "45/45 [==============================] - 76s 2s/step - loss: 0.0582 - accuracy: 0.9229 - specificity: 0.8358 - precision: 0.8550 - recall: 0.9665 - auc: 0.9732 - matthews_correlation_coefficient: 0.8098 - f1: 0.9074\n",
            "Epoch 8/30\n",
            "45/45 [==============================] - 77s 2s/step - loss: 0.0542 - accuracy: 0.9279 - specificity: 0.8525 - precision: 0.8673 - recall: 0.9684 - auc: 0.9769 - matthews_correlation_coefficient: 0.8273 - f1: 0.9158\n",
            "Epoch 9/30\n",
            "45/45 [==============================] - 78s 2s/step - loss: 0.0525 - accuracy: 0.9286 - specificity: 0.8516 - precision: 0.8680 - recall: 0.9697 - auc: 0.9785 - matthews_correlation_coefficient: 0.8271 - f1: 0.9157\n",
            "Epoch 10/30\n",
            "45/45 [==============================] - 78s 2s/step - loss: 0.0493 - accuracy: 0.9344 - specificity: 0.8660 - precision: 0.8790 - recall: 0.9739 - auc: 0.9813 - matthews_correlation_coefficient: 0.8448 - f1: 0.9240\n",
            "Epoch 11/30\n",
            "45/45 [==============================] - 82s 2s/step - loss: 0.0464 - accuracy: 0.9395 - specificity: 0.8704 - precision: 0.8833 - recall: 0.9748 - auc: 0.9837 - matthews_correlation_coefficient: 0.8497 - f1: 0.9264\n",
            "Epoch 12/30\n",
            "45/45 [==============================] - 82s 2s/step - loss: 0.0445 - accuracy: 0.9434 - specificity: 0.8806 - precision: 0.8903 - recall: 0.9774 - auc: 0.9847 - matthews_correlation_coefficient: 0.8629 - f1: 0.9327\n",
            "Epoch 13/30\n",
            "45/45 [==============================] - 81s 2s/step - loss: 0.0437 - accuracy: 0.9432 - specificity: 0.8863 - precision: 0.8961 - recall: 0.9776 - auc: 0.9853 - matthews_correlation_coefficient: 0.8686 - f1: 0.9353\n",
            "Epoch 14/30\n",
            "45/45 [==============================] - 78s 2s/step - loss: 0.0413 - accuracy: 0.9503 - specificity: 0.8898 - precision: 0.8988 - recall: 0.9785 - auc: 0.9866 - matthews_correlation_coefficient: 0.8727 - f1: 0.9373\n",
            "Epoch 15/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0393 - accuracy: 0.9506 - specificity: 0.8979 - precision: 0.9055 - recall: 0.9817 - auc: 0.9880 - matthews_correlation_coefficient: 0.8829 - f1: 0.9423\n",
            "Epoch 16/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0383 - accuracy: 0.9536 - specificity: 0.9042 - precision: 0.9106 - recall: 0.9829 - auc: 0.9888 - matthews_correlation_coefficient: 0.8905 - f1: 0.9460\n",
            "Epoch 17/30\n",
            "45/45 [==============================] - 77s 2s/step - loss: 0.0376 - accuracy: 0.9545 - specificity: 0.9041 - precision: 0.9113 - recall: 0.9841 - auc: 0.9891 - matthews_correlation_coefficient: 0.8907 - f1: 0.9461\n",
            "Epoch 18/30\n",
            "45/45 [==============================] - 80s 2s/step - loss: 0.0354 - accuracy: 0.9566 - specificity: 0.9106 - precision: 0.9163 - recall: 0.9848 - auc: 0.9901 - matthews_correlation_coefficient: 0.8984 - f1: 0.9498\n",
            "Epoch 19/30\n",
            "45/45 [==============================] - 76s 2s/step - loss: 0.0350 - accuracy: 0.9552 - specificity: 0.9091 - precision: 0.9159 - recall: 0.9873 - auc: 0.9907 - matthews_correlation_coefficient: 0.8992 - f1: 0.9502\n",
            "Epoch 20/30\n",
            "45/45 [==============================] - 77s 2s/step - loss: 0.0334 - accuracy: 0.9584 - specificity: 0.9186 - precision: 0.9236 - recall: 0.9899 - auc: 0.9915 - matthews_correlation_coefficient: 0.9113 - f1: 0.9561\n",
            "Epoch 21/30\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.0319 - accuracy: 0.9621 - specificity: 0.9224 - precision: 0.9280 - recall: 0.9894 - auc: 0.9920 - matthews_correlation_coefficient: 0.9143 - f1: 0.9576\n",
            "Epoch 22/30\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.0304 - accuracy: 0.9626 - specificity: 0.9248 - precision: 0.9307 - recall: 0.9917 - auc: 0.9928 - matthews_correlation_coefficient: 0.9190 - f1: 0.9598\n",
            "Epoch 23/30\n",
            "45/45 [==============================] - 74s 2s/step - loss: 0.0291 - accuracy: 0.9651 - specificity: 0.9307 - precision: 0.9349 - recall: 0.9929 - auc: 0.9933 - matthews_correlation_coefficient: 0.9258 - f1: 0.9632\n",
            "Epoch 24/30\n",
            "45/45 [==============================] - 78s 2s/step - loss: 0.0282 - accuracy: 0.9675 - specificity: 0.9296 - precision: 0.9354 - recall: 0.9933 - auc: 0.9936 - matthews_correlation_coefficient: 0.9252 - f1: 0.9628\n",
            "Epoch 25/30\n",
            "45/45 [==============================] - 78s 2s/step - loss: 0.0278 - accuracy: 0.9686 - specificity: 0.9351 - precision: 0.9386 - recall: 0.9951 - auc: 0.9939 - matthews_correlation_coefficient: 0.9322 - f1: 0.9663\n",
            "Epoch 26/30\n",
            "45/45 [==============================] - 76s 2s/step - loss: 0.0258 - accuracy: 0.9713 - specificity: 0.9382 - precision: 0.9426 - recall: 0.9958 - auc: 0.9945 - matthews_correlation_coefficient: 0.9354 - f1: 0.9679\n",
            "Epoch 27/30\n",
            "45/45 [==============================] - 74s 2s/step - loss: 0.0242 - accuracy: 0.9739 - specificity: 0.9456 - precision: 0.9479 - recall: 0.9974 - auc: 0.9952 - matthews_correlation_coefficient: 0.9444 - f1: 0.9723\n",
            "Epoch 28/30\n",
            "45/45 [==============================] - 75s 2s/step - loss: 0.0232 - accuracy: 0.9762 - specificity: 0.9484 - precision: 0.9512 - recall: 0.9979 - auc: 0.9954 - matthews_correlation_coefficient: 0.9476 - f1: 0.9739\n",
            "Epoch 29/30\n",
            "45/45 [==============================] - 80s 2s/step - loss: 0.0221 - accuracy: 0.9769 - specificity: 0.9522 - precision: 0.9548 - recall: 0.9981 - auc: 0.9958 - matthews_correlation_coefficient: 0.9515 - f1: 0.9758\n",
            "Epoch 30/30\n",
            "45/45 [==============================] - 79s 2s/step - loss: 0.0213 - accuracy: 0.9776 - specificity: 0.9541 - precision: 0.9565 - recall: 0.9968 - auc: 0.9960 - matthews_correlation_coefficient: 0.9520 - f1: 0.9761\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 88s 2s/step - loss: 0.0307 - accuracy: 0.9628 - specificity: 0.9319 - precision: 0.9351 - recall: 0.9866 - auc: 0.9911 - matthews_correlation_coefficient: 0.9202 - f1: 0.9605\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 85s 2s/step - loss: 0.0282 - accuracy: 0.9663 - specificity: 0.9379 - precision: 0.9409 - recall: 0.9902 - auc: 0.9932 - matthews_correlation_coefficient: 0.9297 - f1: 0.9651\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 84s 2s/step - loss: 0.0253 - accuracy: 0.9706 - specificity: 0.9428 - precision: 0.9458 - recall: 0.9940 - auc: 0.9944 - matthews_correlation_coefficient: 0.9383 - f1: 0.9693\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 87s 2s/step - loss: 0.0222 - accuracy: 0.9733 - specificity: 0.9507 - precision: 0.9534 - recall: 0.9970 - auc: 0.9953 - matthews_correlation_coefficient: 0.9489 - f1: 0.9745\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 87s 2s/step - loss: 0.0212 - accuracy: 0.9771 - specificity: 0.9530 - precision: 0.9547 - recall: 0.9970 - auc: 0.9959 - matthews_correlation_coefficient: 0.9511 - f1: 0.9756\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 85s 2s/step - loss: 0.0202 - accuracy: 0.9788 - specificity: 0.9551 - precision: 0.9571 - recall: 0.9979 - auc: 0.9961 - matthews_correlation_coefficient: 0.9541 - f1: 0.9771\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0188 - accuracy: 0.9812 - specificity: 0.9582 - precision: 0.9605 - recall: 0.9987 - auc: 0.9966 - matthews_correlation_coefficient: 0.9579 - f1: 0.9790\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0172 - accuracy: 0.9842 - specificity: 0.9643 - precision: 0.9653 - recall: 0.9997 - auc: 0.9969 - matthews_correlation_coefficient: 0.9647 - f1: 0.9824\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0164 - accuracy: 0.9859 - specificity: 0.9682 - precision: 0.9690 - recall: 0.9997 - auc: 0.9973 - matthews_correlation_coefficient: 0.9685 - f1: 0.9843\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 76s 2s/step - loss: 0.0151 - accuracy: 0.9880 - specificity: 0.9698 - precision: 0.9708 - recall: 0.9997 - auc: 0.9975 - matthews_correlation_coefficient: 0.9701 - f1: 0.9850\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0141 - accuracy: 0.9875 - specificity: 0.9716 - precision: 0.9725 - recall: 1.0000 - auc: 0.9976 - matthews_correlation_coefficient: 0.9720 - f1: 0.9860\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0134 - accuracy: 0.9878 - specificity: 0.9741 - precision: 0.9744 - recall: 1.0000 - auc: 0.9977 - matthews_correlation_coefficient: 0.9745 - f1: 0.9873\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0125 - accuracy: 0.9900 - specificity: 0.9751 - precision: 0.9761 - recall: 1.0000 - auc: 0.9981 - matthews_correlation_coefficient: 0.9755 - f1: 0.9878\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0114 - accuracy: 0.9924 - specificity: 0.9777 - precision: 0.9782 - recall: 0.9998 - auc: 0.9982 - matthews_correlation_coefficient: 0.9779 - f1: 0.9889\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0107 - accuracy: 0.9929 - specificity: 0.9789 - precision: 0.9795 - recall: 0.9998 - auc: 0.9984 - matthews_correlation_coefficient: 0.9790 - f1: 0.9895\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0102 - accuracy: 0.9927 - specificity: 0.9808 - precision: 0.9809 - recall: 1.0000 - auc: 0.9986 - matthews_correlation_coefficient: 0.9810 - f1: 0.9905\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0098 - accuracy: 0.9927 - specificity: 0.9816 - precision: 0.9817 - recall: 1.0000 - auc: 0.9984 - matthews_correlation_coefficient: 0.9818 - f1: 0.9909\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0086 - accuracy: 0.9938 - specificity: 0.9834 - precision: 0.9837 - recall: 1.0000 - auc: 0.9986 - matthews_correlation_coefficient: 0.9836 - f1: 0.9918\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0088 - accuracy: 0.9943 - specificity: 0.9844 - precision: 0.9844 - recall: 0.9997 - auc: 0.9987 - matthews_correlation_coefficient: 0.9842 - f1: 0.9921\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0081 - accuracy: 0.9953 - specificity: 0.9841 - precision: 0.9844 - recall: 1.0000 - auc: 0.9989 - matthews_correlation_coefficient: 0.9843 - f1: 0.9922\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0083 - accuracy: 0.9956 - specificity: 0.9849 - precision: 0.9852 - recall: 1.0000 - auc: 0.9989 - matthews_correlation_coefficient: 0.9851 - f1: 0.9925\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0074 - accuracy: 0.9957 - specificity: 0.9851 - precision: 0.9858 - recall: 1.0000 - auc: 0.9989 - matthews_correlation_coefficient: 0.9853 - f1: 0.9926\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 79s 2s/step - loss: 0.0072 - accuracy: 0.9962 - specificity: 0.9862 - precision: 0.9863 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9864 - f1: 0.9932\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0068 - accuracy: 0.9964 - specificity: 0.9862 - precision: 0.9863 - recall: 1.0000 - auc: 0.9991 - matthews_correlation_coefficient: 0.9864 - f1: 0.9932\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0065 - accuracy: 0.9960 - specificity: 0.9877 - precision: 0.9877 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9878 - f1: 0.9939\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0062 - accuracy: 0.9965 - specificity: 0.9873 - precision: 0.9878 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9875 - f1: 0.9937\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0058 - accuracy: 0.9970 - specificity: 0.9892 - precision: 0.9892 - recall: 1.0000 - auc: 0.9993 - matthews_correlation_coefficient: 0.9893 - f1: 0.9947\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0061 - accuracy: 0.9972 - specificity: 0.9886 - precision: 0.9886 - recall: 1.0000 - auc: 0.9991 - matthews_correlation_coefficient: 0.9887 - f1: 0.9944\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0057 - accuracy: 0.9972 - specificity: 0.9889 - precision: 0.9889 - recall: 1.0000 - auc: 0.9993 - matthews_correlation_coefficient: 0.9890 - f1: 0.9945\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0053 - accuracy: 0.9973 - specificity: 0.9890 - precision: 0.9892 - recall: 1.0000 - auc: 0.9994 - matthews_correlation_coefficient: 0.9891 - f1: 0.9945\n",
            "Score for fold 3: loss of 0.04414036497473717; accuracy of 96.72830700874329%; specificity of 0.8446664214134216; precision of 0.8639200925827026; recall of 0.9843527674674988; auc of 0.9894457459449768; matthews_correlation_coefficient of 0.8379242420196533; f1 of 0.9207940697669983\n",
            "22/22 [==============================] - 3s 129ms/step\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 1024, 1)]         0         \n",
            "                                                                 \n",
            " conv1 (Conv1D)              (None, 1016, 256)         2560      \n",
            "                                                                 \n",
            " primarycap_conv2d (Conv1D)  (None, 504, 256)          590080    \n",
            "                                                                 \n",
            " primarycap_reshape (Reshap  (None, 16128, 8)          0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            " primarycap_squash (Lambda)  (None, 16128, 8)          0         \n",
            "                                                                 \n",
            " digitcaps (CapsuleLayer)    (None, 2, 8)              2064384   \n",
            "                                                                 \n",
            " capsnet (Length)            (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2657024 (10.14 MB)\n",
            "Trainable params: 2657024 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/30\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.8100 - accuracy: 0.6233 - specificity: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - matthews_correlation_coefficient: 0.0000e+00 - f1: nan\n",
            "Epoch 2/30\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.3223 - accuracy: 0.6788 - specificity: 0.3944 - precision: 0.5475 - recall: 0.7250 - auc: 0.5933 - matthews_correlation_coefficient: 0.1256 - f1: nan\n",
            "Epoch 3/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.1641 - accuracy: 0.7231 - specificity: 0.4842 - precision: 0.6250 - recall: 0.8697 - auc: 0.7826 - matthews_correlation_coefficient: 0.3838 - f1: 0.7308\n",
            "Epoch 4/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0927 - accuracy: 0.8737 - specificity: 0.7345 - precision: 0.7784 - recall: 0.9342 - auc: 0.9305 - matthews_correlation_coefficient: 0.6865 - f1: 0.8497\n",
            "Epoch 5/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0748 - accuracy: 0.8974 - specificity: 0.7843 - precision: 0.8151 - recall: 0.9534 - auc: 0.9555 - matthews_correlation_coefficient: 0.7503 - f1: 0.8793\n",
            "Epoch 6/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0649 - accuracy: 0.9120 - specificity: 0.8239 - precision: 0.8448 - recall: 0.9584 - auc: 0.9668 - matthews_correlation_coefficient: 0.7905 - f1: 0.8984\n",
            "Epoch 7/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0582 - accuracy: 0.9182 - specificity: 0.8405 - precision: 0.8580 - recall: 0.9668 - auc: 0.9735 - matthews_correlation_coefficient: 0.8145 - f1: 0.9097\n",
            "Epoch 8/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0542 - accuracy: 0.9272 - specificity: 0.8509 - precision: 0.8674 - recall: 0.9695 - auc: 0.9771 - matthews_correlation_coefficient: 0.8277 - f1: 0.9158\n",
            "Epoch 9/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0520 - accuracy: 0.9314 - specificity: 0.8536 - precision: 0.8698 - recall: 0.9681 - auc: 0.9794 - matthews_correlation_coefficient: 0.8278 - f1: 0.9159\n",
            "Epoch 10/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0489 - accuracy: 0.9362 - specificity: 0.8667 - precision: 0.8794 - recall: 0.9721 - auc: 0.9818 - matthews_correlation_coefficient: 0.8436 - f1: 0.9234\n",
            "Epoch 11/30\n",
            "45/45 [==============================] - 74s 2s/step - loss: 0.0456 - accuracy: 0.9411 - specificity: 0.8746 - precision: 0.8867 - recall: 0.9744 - auc: 0.9844 - matthews_correlation_coefficient: 0.8531 - f1: 0.9280\n",
            "Epoch 12/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0433 - accuracy: 0.9432 - specificity: 0.8854 - precision: 0.8945 - recall: 0.9762 - auc: 0.9856 - matthews_correlation_coefficient: 0.8660 - f1: 0.9341\n",
            "Epoch 13/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0434 - accuracy: 0.9464 - specificity: 0.8846 - precision: 0.8941 - recall: 0.9757 - auc: 0.9854 - matthews_correlation_coefficient: 0.8649 - f1: 0.9336\n",
            "Epoch 14/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0399 - accuracy: 0.9487 - specificity: 0.8954 - precision: 0.9028 - recall: 0.9797 - auc: 0.9875 - matthews_correlation_coefficient: 0.8790 - f1: 0.9404\n",
            "Epoch 15/30\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.0384 - accuracy: 0.9497 - specificity: 0.9021 - precision: 0.9091 - recall: 0.9825 - auc: 0.9886 - matthews_correlation_coefficient: 0.8878 - f1: 0.9446\n",
            "Epoch 16/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0368 - accuracy: 0.9541 - specificity: 0.9040 - precision: 0.9104 - recall: 0.9822 - auc: 0.9896 - matthews_correlation_coefficient: 0.8896 - f1: 0.9456\n",
            "Epoch 17/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0353 - accuracy: 0.9563 - specificity: 0.9101 - precision: 0.9161 - recall: 0.9843 - auc: 0.9903 - matthews_correlation_coefficient: 0.8966 - f1: 0.9489\n",
            "Epoch 18/30\n",
            "45/45 [==============================] - 74s 2s/step - loss: 0.0337 - accuracy: 0.9577 - specificity: 0.9153 - precision: 0.9209 - recall: 0.9871 - auc: 0.9911 - matthews_correlation_coefficient: 0.9052 - f1: 0.9531\n",
            "Epoch 19/30\n",
            "45/45 [==============================] - 74s 2s/step - loss: 0.0333 - accuracy: 0.9589 - specificity: 0.9125 - precision: 0.9193 - recall: 0.9880 - auc: 0.9915 - matthews_correlation_coefficient: 0.9032 - f1: 0.9521\n",
            "Epoch 20/30\n",
            "45/45 [==============================] - 75s 2s/step - loss: 0.0311 - accuracy: 0.9623 - specificity: 0.9237 - precision: 0.9279 - recall: 0.9919 - auc: 0.9924 - matthews_correlation_coefficient: 0.9182 - f1: 0.9594\n",
            "Epoch 21/30\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.0295 - accuracy: 0.9649 - specificity: 0.9295 - precision: 0.9337 - recall: 0.9905 - auc: 0.9930 - matthews_correlation_coefficient: 0.9221 - f1: 0.9613\n",
            "Epoch 22/30\n",
            "45/45 [==============================] - 79s 2s/step - loss: 0.0280 - accuracy: 0.9668 - specificity: 0.9308 - precision: 0.9357 - recall: 0.9929 - auc: 0.9937 - matthews_correlation_coefficient: 0.9259 - f1: 0.9632\n",
            "Epoch 23/30\n",
            "45/45 [==============================] - 77s 2s/step - loss: 0.0266 - accuracy: 0.9684 - specificity: 0.9369 - precision: 0.9401 - recall: 0.9944 - auc: 0.9941 - matthews_correlation_coefficient: 0.9331 - f1: 0.9668\n",
            "Epoch 24/30\n",
            "45/45 [==============================] - 75s 2s/step - loss: 0.0258 - accuracy: 0.9693 - specificity: 0.9383 - precision: 0.9433 - recall: 0.9951 - auc: 0.9946 - matthews_correlation_coefficient: 0.9352 - f1: 0.9678\n",
            "Epoch 25/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0262 - accuracy: 0.9720 - specificity: 0.9398 - precision: 0.9429 - recall: 0.9963 - auc: 0.9946 - matthews_correlation_coefficient: 0.9379 - f1: 0.9691\n",
            "Epoch 26/30\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.0235 - accuracy: 0.9727 - specificity: 0.9445 - precision: 0.9483 - recall: 0.9966 - auc: 0.9953 - matthews_correlation_coefficient: 0.9422 - f1: 0.9712\n",
            "Epoch 27/30\n",
            "45/45 [==============================] - 75s 2s/step - loss: 0.0217 - accuracy: 0.9771 - specificity: 0.9512 - precision: 0.9538 - recall: 0.9986 - auc: 0.9960 - matthews_correlation_coefficient: 0.9511 - f1: 0.9756\n",
            "Epoch 28/30\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.0205 - accuracy: 0.9778 - specificity: 0.9532 - precision: 0.9553 - recall: 0.9988 - auc: 0.9962 - matthews_correlation_coefficient: 0.9531 - f1: 0.9766\n",
            "Epoch 29/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0202 - accuracy: 0.9799 - specificity: 0.9559 - precision: 0.9582 - recall: 0.9991 - auc: 0.9965 - matthews_correlation_coefficient: 0.9561 - f1: 0.9781\n",
            "Epoch 30/30\n",
            "45/45 [==============================] - 73s 2s/step - loss: 0.0186 - accuracy: 0.9820 - specificity: 0.9579 - precision: 0.9597 - recall: 0.9984 - auc: 0.9967 - matthews_correlation_coefficient: 0.9572 - f1: 0.9786\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0306 - accuracy: 0.9666 - specificity: 0.9326 - precision: 0.9366 - recall: 0.9861 - auc: 0.9915 - matthews_correlation_coefficient: 0.9200 - f1: 0.9604\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0264 - accuracy: 0.9709 - specificity: 0.9416 - precision: 0.9439 - recall: 0.9905 - auc: 0.9941 - matthews_correlation_coefficient: 0.9336 - f1: 0.9670\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0229 - accuracy: 0.9772 - specificity: 0.9500 - precision: 0.9520 - recall: 0.9948 - auc: 0.9958 - matthews_correlation_coefficient: 0.9459 - f1: 0.9731\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0202 - accuracy: 0.9805 - specificity: 0.9548 - precision: 0.9566 - recall: 0.9972 - auc: 0.9963 - matthews_correlation_coefficient: 0.9530 - f1: 0.9766\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0193 - accuracy: 0.9828 - specificity: 0.9576 - precision: 0.9594 - recall: 0.9981 - auc: 0.9967 - matthews_correlation_coefficient: 0.9567 - f1: 0.9784\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 93s 2s/step - loss: 0.0172 - accuracy: 0.9843 - specificity: 0.9644 - precision: 0.9656 - recall: 0.9987 - auc: 0.9971 - matthews_correlation_coefficient: 0.9638 - f1: 0.9819\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 87s 2s/step - loss: 0.0158 - accuracy: 0.9861 - specificity: 0.9681 - precision: 0.9692 - recall: 0.9994 - auc: 0.9975 - matthews_correlation_coefficient: 0.9681 - f1: 0.9840\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 84s 2s/step - loss: 0.0148 - accuracy: 0.9883 - specificity: 0.9700 - precision: 0.9705 - recall: 0.9998 - auc: 0.9977 - matthews_correlation_coefficient: 0.9704 - f1: 0.9852\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 84s 2s/step - loss: 0.0144 - accuracy: 0.9883 - specificity: 0.9733 - precision: 0.9741 - recall: 0.9998 - auc: 0.9978 - matthews_correlation_coefficient: 0.9735 - f1: 0.9868\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 79s 2s/step - loss: 0.0128 - accuracy: 0.9899 - specificity: 0.9743 - precision: 0.9749 - recall: 1.0000 - auc: 0.9981 - matthews_correlation_coefficient: 0.9747 - f1: 0.9874\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 71s 1s/step - loss: 0.0123 - accuracy: 0.9904 - specificity: 0.9760 - precision: 0.9765 - recall: 1.0000 - auc: 0.9982 - matthews_correlation_coefficient: 0.9764 - f1: 0.9882\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0113 - accuracy: 0.9915 - specificity: 0.9795 - precision: 0.9799 - recall: 0.9998 - auc: 0.9984 - matthews_correlation_coefficient: 0.9796 - f1: 0.9898\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0111 - accuracy: 0.9918 - specificity: 0.9785 - precision: 0.9794 - recall: 1.0000 - auc: 0.9984 - matthews_correlation_coefficient: 0.9788 - f1: 0.9894\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 73s 1s/step - loss: 0.0104 - accuracy: 0.9927 - specificity: 0.9812 - precision: 0.9823 - recall: 1.0000 - auc: 0.9985 - matthews_correlation_coefficient: 0.9815 - f1: 0.9908\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0094 - accuracy: 0.9937 - specificity: 0.9824 - precision: 0.9832 - recall: 1.0000 - auc: 0.9987 - matthews_correlation_coefficient: 0.9826 - f1: 0.9913\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 90s 2s/step - loss: 0.0089 - accuracy: 0.9941 - specificity: 0.9841 - precision: 0.9841 - recall: 1.0000 - auc: 0.9989 - matthews_correlation_coefficient: 0.9842 - f1: 0.9921\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 94s 2s/step - loss: 0.0083 - accuracy: 0.9945 - specificity: 0.9859 - precision: 0.9861 - recall: 1.0000 - auc: 0.9989 - matthews_correlation_coefficient: 0.9860 - f1: 0.9930\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0086 - accuracy: 0.9957 - specificity: 0.9839 - precision: 0.9840 - recall: 1.0000 - auc: 0.9989 - matthews_correlation_coefficient: 0.9841 - f1: 0.9921\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0079 - accuracy: 0.9956 - specificity: 0.9875 - precision: 0.9875 - recall: 1.0000 - auc: 0.9991 - matthews_correlation_coefficient: 0.9876 - f1: 0.9938\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0079 - accuracy: 0.9964 - specificity: 0.9862 - precision: 0.9863 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9864 - f1: 0.9932\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0077 - accuracy: 0.9962 - specificity: 0.9866 - precision: 0.9866 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9867 - f1: 0.9934\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.0071 - accuracy: 0.9967 - specificity: 0.9876 - precision: 0.9878 - recall: 1.0000 - auc: 0.9993 - matthews_correlation_coefficient: 0.9877 - f1: 0.9939\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 82s 2s/step - loss: 0.0064 - accuracy: 0.9970 - specificity: 0.9889 - precision: 0.9889 - recall: 1.0000 - auc: 0.9993 - matthews_correlation_coefficient: 0.9890 - f1: 0.9945\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.0054 - accuracy: 0.9973 - specificity: 0.9914 - precision: 0.9914 - recall: 1.0000 - auc: 0.9994 - matthews_correlation_coefficient: 0.9915 - f1: 0.9957\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 79s 2s/step - loss: 0.0056 - accuracy: 0.9978 - specificity: 0.9916 - precision: 0.9915 - recall: 1.0000 - auc: 0.9994 - matthews_correlation_coefficient: 0.9916 - f1: 0.9958\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 79s 2s/step - loss: 0.0054 - accuracy: 0.9978 - specificity: 0.9923 - precision: 0.9925 - recall: 1.0000 - auc: 0.9994 - matthews_correlation_coefficient: 0.9923 - f1: 0.9962\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0055 - accuracy: 0.9983 - specificity: 0.9922 - precision: 0.9922 - recall: 1.0000 - auc: 0.9994 - matthews_correlation_coefficient: 0.9922 - f1: 0.9961\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0050 - accuracy: 0.9986 - specificity: 0.9920 - precision: 0.9920 - recall: 1.0000 - auc: 0.9994 - matthews_correlation_coefficient: 0.9921 - f1: 0.9960\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0045 - accuracy: 0.9987 - specificity: 0.9921 - precision: 0.9923 - recall: 1.0000 - auc: 0.9996 - matthews_correlation_coefficient: 0.9922 - f1: 0.9961\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 77s 2s/step - loss: 0.0044 - accuracy: 0.9989 - specificity: 0.9936 - precision: 0.9936 - recall: 0.9998 - auc: 0.9997 - matthews_correlation_coefficient: 0.9935 - f1: 0.9967\n",
            "Score for fold 4: loss of 0.04277412220835686; accuracy of 96.30156755447388%; specificity of 0.8717466592788696; precision of 0.8847631216049194; recall of 0.9829303026199341; auc of 0.9869377613067627; matthews_correlation_coefficient of 0.8614959120750427; f1 of 0.9322197437286377\n",
            "22/22 [==============================] - 3s 132ms/step\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 1024, 1)]         0         \n",
            "                                                                 \n",
            " conv1 (Conv1D)              (None, 1016, 256)         2560      \n",
            "                                                                 \n",
            " primarycap_conv2d (Conv1D)  (None, 504, 256)          590080    \n",
            "                                                                 \n",
            " primarycap_reshape (Reshap  (None, 16128, 8)          0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            " primarycap_squash (Lambda)  (None, 16128, 8)          0         \n",
            "                                                                 \n",
            " digitcaps (CapsuleLayer)    (None, 2, 8)              2064384   \n",
            "                                                                 \n",
            " capsnet (Length)            (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2657024 (10.14 MB)\n",
            "Trainable params: 2657024 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/30\n",
            "45/45 [==============================] - 69s 1s/step - loss: 0.8100 - accuracy: 0.6670 - specificity: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - matthews_correlation_coefficient: 0.0000e+00 - f1: nan\n",
            "Epoch 2/30\n",
            "45/45 [==============================] - 68s 2s/step - loss: 0.3353 - accuracy: 0.6788 - specificity: 0.4102 - precision: 0.5468 - recall: 0.7153 - auc: 0.5980 - matthews_correlation_coefficient: 0.1262 - f1: nan\n",
            "Epoch 3/30\n",
            "45/45 [==============================] - 66s 1s/step - loss: 0.1699 - accuracy: 0.6991 - specificity: 0.5180 - precision: 0.6413 - recall: 0.8665 - auc: 0.7716 - matthews_correlation_coefficient: 0.4163 - f1: 0.7389\n",
            "Epoch 4/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0921 - accuracy: 0.8670 - specificity: 0.7310 - precision: 0.7785 - recall: 0.9427 - auc: 0.9335 - matthews_correlation_coefficient: 0.6895 - f1: 0.8527\n",
            "Epoch 5/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0677 - accuracy: 0.9071 - specificity: 0.8024 - precision: 0.8296 - recall: 0.9610 - auc: 0.9627 - matthews_correlation_coefficient: 0.7750 - f1: 0.8911\n",
            "Epoch 6/30\n",
            "45/45 [==============================] - 65s 1s/step - loss: 0.0620 - accuracy: 0.9171 - specificity: 0.8323 - precision: 0.8515 - recall: 0.9628 - auc: 0.9685 - matthews_correlation_coefficient: 0.8034 - f1: 0.9043\n",
            "Epoch 7/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0556 - accuracy: 0.9257 - specificity: 0.8436 - precision: 0.8603 - recall: 0.9709 - auc: 0.9757 - matthews_correlation_coefficient: 0.8219 - f1: 0.9131\n",
            "Epoch 8/30\n",
            "45/45 [==============================] - 64s 1s/step - loss: 0.0512 - accuracy: 0.9312 - specificity: 0.8645 - precision: 0.8779 - recall: 0.9716 - auc: 0.9792 - matthews_correlation_coefficient: 0.8421 - f1: 0.9227\n",
            "Epoch 9/30\n",
            "45/45 [==============================] - 69s 2s/step - loss: 0.0502 - accuracy: 0.9330 - specificity: 0.8608 - precision: 0.8755 - recall: 0.9709 - auc: 0.9805 - matthews_correlation_coefficient: 0.8374 - f1: 0.9205\n",
            "Epoch 10/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0471 - accuracy: 0.9370 - specificity: 0.8743 - precision: 0.8860 - recall: 0.9755 - auc: 0.9827 - matthews_correlation_coefficient: 0.8541 - f1: 0.9285\n",
            "Epoch 11/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0447 - accuracy: 0.9418 - specificity: 0.8799 - precision: 0.8905 - recall: 0.9757 - auc: 0.9849 - matthews_correlation_coefficient: 0.8600 - f1: 0.9313\n",
            "Epoch 12/30\n",
            "45/45 [==============================] - 65s 1s/step - loss: 0.0420 - accuracy: 0.9473 - specificity: 0.8887 - precision: 0.8975 - recall: 0.9790 - auc: 0.9865 - matthews_correlation_coefficient: 0.8720 - f1: 0.9371\n",
            "Epoch 13/30\n",
            "45/45 [==============================] - 60s 1s/step - loss: 0.0413 - accuracy: 0.9476 - specificity: 0.8936 - precision: 0.9023 - recall: 0.9790 - auc: 0.9869 - matthews_correlation_coefficient: 0.8762 - f1: 0.9390\n",
            "Epoch 14/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0388 - accuracy: 0.9515 - specificity: 0.8983 - precision: 0.9055 - recall: 0.9817 - auc: 0.9882 - matthews_correlation_coefficient: 0.8838 - f1: 0.9428\n",
            "Epoch 15/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0359 - accuracy: 0.9534 - specificity: 0.9081 - precision: 0.9149 - recall: 0.9855 - auc: 0.9899 - matthews_correlation_coefficient: 0.8964 - f1: 0.9489\n",
            "Epoch 16/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0355 - accuracy: 0.9559 - specificity: 0.9112 - precision: 0.9168 - recall: 0.9854 - auc: 0.9903 - matthews_correlation_coefficient: 0.8992 - f1: 0.9502\n",
            "Epoch 17/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0337 - accuracy: 0.9571 - specificity: 0.9170 - precision: 0.9224 - recall: 0.9877 - auc: 0.9913 - matthews_correlation_coefficient: 0.9070 - f1: 0.9540\n",
            "Epoch 18/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0318 - accuracy: 0.9593 - specificity: 0.9211 - precision: 0.9257 - recall: 0.9887 - auc: 0.9919 - matthews_correlation_coefficient: 0.9123 - f1: 0.9566\n",
            "Epoch 19/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0309 - accuracy: 0.9633 - specificity: 0.9231 - precision: 0.9276 - recall: 0.9901 - auc: 0.9926 - matthews_correlation_coefficient: 0.9155 - f1: 0.9581\n",
            "Epoch 20/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0300 - accuracy: 0.9644 - specificity: 0.9280 - precision: 0.9320 - recall: 0.9914 - auc: 0.9929 - matthews_correlation_coefficient: 0.9217 - f1: 0.9611\n",
            "Epoch 21/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0269 - accuracy: 0.9677 - specificity: 0.9364 - precision: 0.9401 - recall: 0.9942 - auc: 0.9940 - matthews_correlation_coefficient: 0.9325 - f1: 0.9664\n",
            "Epoch 22/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0256 - accuracy: 0.9693 - specificity: 0.9372 - precision: 0.9416 - recall: 0.9961 - auc: 0.9946 - matthews_correlation_coefficient: 0.9352 - f1: 0.9678\n",
            "Epoch 23/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0248 - accuracy: 0.9730 - specificity: 0.9428 - precision: 0.9463 - recall: 0.9945 - auc: 0.9950 - matthews_correlation_coefficient: 0.9390 - f1: 0.9696\n",
            "Epoch 24/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0236 - accuracy: 0.9743 - specificity: 0.9452 - precision: 0.9486 - recall: 0.9961 - auc: 0.9955 - matthews_correlation_coefficient: 0.9428 - f1: 0.9715\n",
            "Epoch 25/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0240 - accuracy: 0.9750 - specificity: 0.9459 - precision: 0.9484 - recall: 0.9958 - auc: 0.9954 - matthews_correlation_coefficient: 0.9426 - f1: 0.9714\n",
            "Epoch 26/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0212 - accuracy: 0.9767 - specificity: 0.9501 - precision: 0.9532 - recall: 0.9979 - auc: 0.9961 - matthews_correlation_coefficient: 0.9493 - f1: 0.9747\n",
            "Epoch 27/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0192 - accuracy: 0.9817 - specificity: 0.9582 - precision: 0.9600 - recall: 0.9986 - auc: 0.9968 - matthews_correlation_coefficient: 0.9577 - f1: 0.9789\n",
            "Epoch 28/30\n",
            "45/45 [==============================] - 66s 1s/step - loss: 0.0183 - accuracy: 0.9817 - specificity: 0.9602 - precision: 0.9623 - recall: 0.9991 - auc: 0.9968 - matthews_correlation_coefficient: 0.9602 - f1: 0.9801\n",
            "Epoch 29/30\n",
            "45/45 [==============================] - 74s 2s/step - loss: 0.0179 - accuracy: 0.9838 - specificity: 0.9623 - precision: 0.9643 - recall: 0.9995 - auc: 0.9969 - matthews_correlation_coefficient: 0.9626 - f1: 0.9813\n",
            "Epoch 30/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0176 - accuracy: 0.9845 - specificity: 0.9627 - precision: 0.9642 - recall: 0.9989 - auc: 0.9969 - matthews_correlation_coefficient: 0.9624 - f1: 0.9812\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 76s 2s/step - loss: 0.0283 - accuracy: 0.9711 - specificity: 0.9402 - precision: 0.9421 - recall: 0.9858 - auc: 0.9927 - matthews_correlation_coefficient: 0.9272 - f1: 0.9639\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0242 - accuracy: 0.9741 - specificity: 0.9461 - precision: 0.9487 - recall: 0.9919 - auc: 0.9948 - matthews_correlation_coefficient: 0.9390 - f1: 0.9697\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0208 - accuracy: 0.9779 - specificity: 0.9549 - precision: 0.9568 - recall: 0.9949 - auc: 0.9962 - matthews_correlation_coefficient: 0.9509 - f1: 0.9756\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 73s 1s/step - loss: 0.0189 - accuracy: 0.9824 - specificity: 0.9603 - precision: 0.9617 - recall: 0.9968 - auc: 0.9966 - matthews_correlation_coefficient: 0.9580 - f1: 0.9790\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 73s 1s/step - loss: 0.0178 - accuracy: 0.9840 - specificity: 0.9629 - precision: 0.9640 - recall: 0.9981 - auc: 0.9970 - matthews_correlation_coefficient: 0.9618 - f1: 0.9809\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0166 - accuracy: 0.9843 - specificity: 0.9639 - precision: 0.9656 - recall: 0.9987 - auc: 0.9972 - matthews_correlation_coefficient: 0.9634 - f1: 0.9817\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0154 - accuracy: 0.9859 - specificity: 0.9693 - precision: 0.9701 - recall: 0.9995 - auc: 0.9974 - matthews_correlation_coefficient: 0.9694 - f1: 0.9847\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0147 - accuracy: 0.9885 - specificity: 0.9709 - precision: 0.9720 - recall: 0.9995 - auc: 0.9976 - matthews_correlation_coefficient: 0.9709 - f1: 0.9855\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0139 - accuracy: 0.9881 - specificity: 0.9741 - precision: 0.9744 - recall: 1.0000 - auc: 0.9977 - matthews_correlation_coefficient: 0.9745 - f1: 0.9873\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 67s 1s/step - loss: 0.0129 - accuracy: 0.9896 - specificity: 0.9766 - precision: 0.9771 - recall: 0.9997 - auc: 0.9980 - matthews_correlation_coefficient: 0.9767 - f1: 0.9883\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0118 - accuracy: 0.9913 - specificity: 0.9777 - precision: 0.9782 - recall: 0.9998 - auc: 0.9981 - matthews_correlation_coefficient: 0.9779 - f1: 0.9890\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0114 - accuracy: 0.9921 - specificity: 0.9767 - precision: 0.9774 - recall: 0.9998 - auc: 0.9982 - matthews_correlation_coefficient: 0.9769 - f1: 0.9885\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0102 - accuracy: 0.9935 - specificity: 0.9816 - precision: 0.9817 - recall: 1.0000 - auc: 0.9983 - matthews_correlation_coefficient: 0.9818 - f1: 0.9909\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 73s 1s/step - loss: 0.0094 - accuracy: 0.9932 - specificity: 0.9820 - precision: 0.9821 - recall: 0.9998 - auc: 0.9986 - matthews_correlation_coefficient: 0.9821 - f1: 0.9911\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 74s 1s/step - loss: 0.0090 - accuracy: 0.9927 - specificity: 0.9828 - precision: 0.9834 - recall: 1.0000 - auc: 0.9986 - matthews_correlation_coefficient: 0.9830 - f1: 0.9915\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 73s 1s/step - loss: 0.0093 - accuracy: 0.9940 - specificity: 0.9826 - precision: 0.9829 - recall: 0.9998 - auc: 0.9986 - matthews_correlation_coefficient: 0.9826 - f1: 0.9913\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 72s 1s/step - loss: 0.0092 - accuracy: 0.9943 - specificity: 0.9823 - precision: 0.9824 - recall: 1.0000 - auc: 0.9987 - matthews_correlation_coefficient: 0.9826 - f1: 0.9913\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0078 - accuracy: 0.9946 - specificity: 0.9848 - precision: 0.9849 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9850 - f1: 0.9925\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 83s 2s/step - loss: 0.0076 - accuracy: 0.9959 - specificity: 0.9851 - precision: 0.9854 - recall: 1.0000 - auc: 0.9989 - matthews_correlation_coefficient: 0.9852 - f1: 0.9926\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 97s 2s/step - loss: 0.0075 - accuracy: 0.9956 - specificity: 0.9855 - precision: 0.9855 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9856 - f1: 0.9928\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 97s 2s/step - loss: 0.0075 - accuracy: 0.9964 - specificity: 0.9859 - precision: 0.9864 - recall: 0.9998 - auc: 0.9990 - matthews_correlation_coefficient: 0.9859 - f1: 0.9930\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 88s 2s/step - loss: 0.0067 - accuracy: 0.9965 - specificity: 0.9876 - precision: 0.9878 - recall: 1.0000 - auc: 0.9991 - matthews_correlation_coefficient: 0.9877 - f1: 0.9939\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 74s 1s/step - loss: 0.0071 - accuracy: 0.9968 - specificity: 0.9859 - precision: 0.9864 - recall: 0.9998 - auc: 0.9991 - matthews_correlation_coefficient: 0.9859 - f1: 0.9930\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0059 - accuracy: 0.9972 - specificity: 0.9897 - precision: 0.9897 - recall: 1.0000 - auc: 0.9993 - matthews_correlation_coefficient: 0.9898 - f1: 0.9949\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0058 - accuracy: 0.9973 - specificity: 0.9891 - precision: 0.9891 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9892 - f1: 0.9946\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0051 - accuracy: 0.9975 - specificity: 0.9904 - precision: 0.9906 - recall: 1.0000 - auc: 0.9994 - matthews_correlation_coefficient: 0.9905 - f1: 0.9952\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0044 - accuracy: 0.9978 - specificity: 0.9928 - precision: 0.9928 - recall: 1.0000 - auc: 0.9994 - matthews_correlation_coefficient: 0.9929 - f1: 0.9964\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0050 - accuracy: 0.9978 - specificity: 0.9914 - precision: 0.9914 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9915 - f1: 0.9957\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0052 - accuracy: 0.9979 - specificity: 0.9900 - precision: 0.9900 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9901 - f1: 0.9950\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0056 - accuracy: 0.9986 - specificity: 0.9900 - precision: 0.9900 - recall: 0.9998 - auc: 0.9994 - matthews_correlation_coefficient: 0.9899 - f1: 0.9950\n",
            "Score for fold 5: loss of 0.040382687002420425; accuracy of 96.15931510925293%; specificity of 0.8830645084381104; precision of 0.893782377243042; recall of 0.9815078377723694; auc of 0.9861526489257812; matthews_correlation_coefficient of 0.8697393536567688; f1 of 0.9365365505218506\n",
            "22/22 [==============================] - 3s 113ms/step\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 1024, 1)]         0         \n",
            "                                                                 \n",
            " conv1 (Conv1D)              (None, 1016, 256)         2560      \n",
            "                                                                 \n",
            " primarycap_conv2d (Conv1D)  (None, 504, 256)          590080    \n",
            "                                                                 \n",
            " primarycap_reshape (Reshap  (None, 16128, 8)          0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            " primarycap_squash (Lambda)  (None, 16128, 8)          0         \n",
            "                                                                 \n",
            " digitcaps (CapsuleLayer)    (None, 2, 8)              2064384   \n",
            "                                                                 \n",
            " capsnet (Length)            (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2657024 (10.14 MB)\n",
            "Trainable params: 2657024 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.8100 - accuracy: 0.5961 - specificity: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - matthews_correlation_coefficient: 0.0000e+00 - f1: nan\n",
            "Epoch 2/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.4271 - accuracy: 0.6788 - specificity: 0.5312 - precision: 0.5493 - recall: 0.5637 - auc: 0.5660 - matthews_correlation_coefficient: 0.1009 - f1: nan\n",
            "Epoch 3/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.1653 - accuracy: 0.7273 - specificity: 0.5028 - precision: 0.6273 - recall: 0.8487 - auc: 0.7837 - matthews_correlation_coefficient: 0.3765 - f1: 0.7261\n",
            "Epoch 4/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0863 - accuracy: 0.8758 - specificity: 0.7536 - precision: 0.7929 - recall: 0.9407 - auc: 0.9397 - matthews_correlation_coefficient: 0.7084 - f1: 0.8606\n",
            "Epoch 5/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0702 - accuracy: 0.9034 - specificity: 0.7996 - precision: 0.8270 - recall: 0.9554 - auc: 0.9605 - matthews_correlation_coefficient: 0.7672 - f1: 0.8872\n",
            "Epoch 6/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0632 - accuracy: 0.9136 - specificity: 0.8254 - precision: 0.8464 - recall: 0.9608 - auc: 0.9688 - matthews_correlation_coefficient: 0.7949 - f1: 0.9003\n",
            "Epoch 7/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0574 - accuracy: 0.9213 - specificity: 0.8412 - precision: 0.8585 - recall: 0.9660 - auc: 0.9744 - matthews_correlation_coefficient: 0.8142 - f1: 0.9095\n",
            "Epoch 8/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0544 - accuracy: 0.9249 - specificity: 0.8508 - precision: 0.8667 - recall: 0.9690 - auc: 0.9767 - matthews_correlation_coefficient: 0.8267 - f1: 0.9153\n",
            "Epoch 9/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0533 - accuracy: 0.9261 - specificity: 0.8534 - precision: 0.8687 - recall: 0.9684 - auc: 0.9781 - matthews_correlation_coefficient: 0.8276 - f1: 0.9158\n",
            "Epoch 10/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0501 - accuracy: 0.9319 - specificity: 0.8647 - precision: 0.8775 - recall: 0.9732 - auc: 0.9809 - matthews_correlation_coefficient: 0.8428 - f1: 0.9230\n",
            "Epoch 11/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0469 - accuracy: 0.9376 - specificity: 0.8732 - precision: 0.8856 - recall: 0.9748 - auc: 0.9835 - matthews_correlation_coefficient: 0.8523 - f1: 0.9276\n",
            "Epoch 12/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0452 - accuracy: 0.9414 - specificity: 0.8788 - precision: 0.8890 - recall: 0.9757 - auc: 0.9842 - matthews_correlation_coefficient: 0.8590 - f1: 0.9308\n",
            "Epoch 13/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0457 - accuracy: 0.9402 - specificity: 0.8787 - precision: 0.8895 - recall: 0.9755 - auc: 0.9837 - matthews_correlation_coefficient: 0.8593 - f1: 0.9309\n",
            "Epoch 14/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0424 - accuracy: 0.9448 - specificity: 0.8863 - precision: 0.8955 - recall: 0.9794 - auc: 0.9860 - matthews_correlation_coefficient: 0.8703 - f1: 0.9362\n",
            "Epoch 15/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0412 - accuracy: 0.9464 - specificity: 0.8943 - precision: 0.9022 - recall: 0.9799 - auc: 0.9869 - matthews_correlation_coefficient: 0.8777 - f1: 0.9398\n",
            "Epoch 16/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0391 - accuracy: 0.9511 - specificity: 0.9002 - precision: 0.9070 - recall: 0.9802 - auc: 0.9884 - matthews_correlation_coefficient: 0.8839 - f1: 0.9428\n",
            "Epoch 17/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0377 - accuracy: 0.9515 - specificity: 0.9035 - precision: 0.9104 - recall: 0.9840 - auc: 0.9891 - matthews_correlation_coefficient: 0.8899 - f1: 0.9457\n",
            "Epoch 18/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0360 - accuracy: 0.9547 - specificity: 0.9084 - precision: 0.9141 - recall: 0.9854 - auc: 0.9898 - matthews_correlation_coefficient: 0.8969 - f1: 0.9491\n",
            "Epoch 19/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0349 - accuracy: 0.9570 - specificity: 0.9071 - precision: 0.9148 - recall: 0.9866 - auc: 0.9907 - matthews_correlation_coefficient: 0.8963 - f1: 0.9487\n",
            "Epoch 20/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0338 - accuracy: 0.9578 - specificity: 0.9143 - precision: 0.9195 - recall: 0.9892 - auc: 0.9913 - matthews_correlation_coefficient: 0.9066 - f1: 0.9538\n",
            "Epoch 21/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0316 - accuracy: 0.9617 - specificity: 0.9245 - precision: 0.9291 - recall: 0.9896 - auc: 0.9921 - matthews_correlation_coefficient: 0.9165 - f1: 0.9586\n",
            "Epoch 22/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0299 - accuracy: 0.9621 - specificity: 0.9256 - precision: 0.9317 - recall: 0.9914 - auc: 0.9930 - matthews_correlation_coefficient: 0.9193 - f1: 0.9600\n",
            "Epoch 23/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0282 - accuracy: 0.9658 - specificity: 0.9338 - precision: 0.9377 - recall: 0.9931 - auc: 0.9937 - matthews_correlation_coefficient: 0.9285 - f1: 0.9645\n",
            "Epoch 24/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0273 - accuracy: 0.9674 - specificity: 0.9350 - precision: 0.9400 - recall: 0.9942 - auc: 0.9941 - matthews_correlation_coefficient: 0.9312 - f1: 0.9658\n",
            "Epoch 25/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0268 - accuracy: 0.9686 - specificity: 0.9379 - precision: 0.9411 - recall: 0.9954 - auc: 0.9943 - matthews_correlation_coefficient: 0.9351 - f1: 0.9677\n",
            "Epoch 26/30\n",
            "45/45 [==============================] - 65s 1s/step - loss: 0.0249 - accuracy: 0.9700 - specificity: 0.9410 - precision: 0.9459 - recall: 0.9965 - auc: 0.9948 - matthews_correlation_coefficient: 0.9394 - f1: 0.9698\n",
            "Epoch 27/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0229 - accuracy: 0.9755 - specificity: 0.9497 - precision: 0.9520 - recall: 0.9975 - auc: 0.9956 - matthews_correlation_coefficient: 0.9485 - f1: 0.9743\n",
            "Epoch 28/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0219 - accuracy: 0.9767 - specificity: 0.9512 - precision: 0.9538 - recall: 0.9984 - auc: 0.9958 - matthews_correlation_coefficient: 0.9508 - f1: 0.9755\n",
            "Epoch 29/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0209 - accuracy: 0.9781 - specificity: 0.9535 - precision: 0.9559 - recall: 0.9988 - auc: 0.9961 - matthews_correlation_coefficient: 0.9534 - f1: 0.9767\n",
            "Epoch 30/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0205 - accuracy: 0.9794 - specificity: 0.9559 - precision: 0.9579 - recall: 0.9982 - auc: 0.9963 - matthews_correlation_coefficient: 0.9552 - f1: 0.9776\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0301 - accuracy: 0.9643 - specificity: 0.9323 - precision: 0.9351 - recall: 0.9859 - auc: 0.9918 - matthews_correlation_coefficient: 0.9200 - f1: 0.9604\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0258 - accuracy: 0.9704 - specificity: 0.9417 - precision: 0.9443 - recall: 0.9915 - auc: 0.9939 - matthews_correlation_coefficient: 0.9346 - f1: 0.9675\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0256 - accuracy: 0.9742 - specificity: 0.9419 - precision: 0.9448 - recall: 0.9932 - auc: 0.9948 - matthews_correlation_coefficient: 0.9367 - f1: 0.9685\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0215 - accuracy: 0.9772 - specificity: 0.9530 - precision: 0.9544 - recall: 0.9965 - auc: 0.9957 - matthews_correlation_coefficient: 0.9506 - f1: 0.9754\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0202 - accuracy: 0.9807 - specificity: 0.9577 - precision: 0.9592 - recall: 0.9976 - auc: 0.9963 - matthews_correlation_coefficient: 0.9562 - f1: 0.9782\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0188 - accuracy: 0.9826 - specificity: 0.9609 - precision: 0.9624 - recall: 0.9987 - auc: 0.9965 - matthews_correlation_coefficient: 0.9605 - f1: 0.9803\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0176 - accuracy: 0.9840 - specificity: 0.9633 - precision: 0.9650 - recall: 0.9991 - auc: 0.9969 - matthews_correlation_coefficient: 0.9631 - f1: 0.9816\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0169 - accuracy: 0.9851 - specificity: 0.9676 - precision: 0.9689 - recall: 0.9987 - auc: 0.9970 - matthews_correlation_coefficient: 0.9669 - f1: 0.9835\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0152 - accuracy: 0.9883 - specificity: 0.9693 - precision: 0.9701 - recall: 1.0000 - auc: 0.9973 - matthews_correlation_coefficient: 0.9699 - f1: 0.9849\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0142 - accuracy: 0.9889 - specificity: 0.9718 - precision: 0.9729 - recall: 0.9998 - auc: 0.9975 - matthews_correlation_coefficient: 0.9721 - f1: 0.9861\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0135 - accuracy: 0.9888 - specificity: 0.9737 - precision: 0.9747 - recall: 0.9998 - auc: 0.9976 - matthews_correlation_coefficient: 0.9739 - f1: 0.9870\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0125 - accuracy: 0.9913 - specificity: 0.9770 - precision: 0.9777 - recall: 0.9998 - auc: 0.9979 - matthews_correlation_coefficient: 0.9772 - f1: 0.9886\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0120 - accuracy: 0.9919 - specificity: 0.9772 - precision: 0.9779 - recall: 0.9998 - auc: 0.9981 - matthews_correlation_coefficient: 0.9774 - f1: 0.9887\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0109 - accuracy: 0.9923 - specificity: 0.9789 - precision: 0.9796 - recall: 1.0000 - auc: 0.9982 - matthews_correlation_coefficient: 0.9792 - f1: 0.9896\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0106 - accuracy: 0.9919 - specificity: 0.9808 - precision: 0.9809 - recall: 0.9997 - auc: 0.9981 - matthews_correlation_coefficient: 0.9807 - f1: 0.9904\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0109 - accuracy: 0.9932 - specificity: 0.9812 - precision: 0.9815 - recall: 1.0000 - auc: 0.9984 - matthews_correlation_coefficient: 0.9814 - f1: 0.9907\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0101 - accuracy: 0.9943 - specificity: 0.9816 - precision: 0.9817 - recall: 0.9998 - auc: 0.9984 - matthews_correlation_coefficient: 0.9816 - f1: 0.9908\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0093 - accuracy: 0.9951 - specificity: 0.9824 - precision: 0.9827 - recall: 0.9998 - auc: 0.9987 - matthews_correlation_coefficient: 0.9825 - f1: 0.9912\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0086 - accuracy: 0.9956 - specificity: 0.9855 - precision: 0.9855 - recall: 1.0000 - auc: 0.9987 - matthews_correlation_coefficient: 0.9856 - f1: 0.9928\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0078 - accuracy: 0.9954 - specificity: 0.9868 - precision: 0.9870 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9869 - f1: 0.9935\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0076 - accuracy: 0.9959 - specificity: 0.9873 - precision: 0.9874 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9875 - f1: 0.9937\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0081 - accuracy: 0.9956 - specificity: 0.9870 - precision: 0.9875 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9872 - f1: 0.9936\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0073 - accuracy: 0.9964 - specificity: 0.9874 - precision: 0.9877 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9875 - f1: 0.9938\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0068 - accuracy: 0.9965 - specificity: 0.9870 - precision: 0.9875 - recall: 0.9998 - auc: 0.9989 - matthews_correlation_coefficient: 0.9870 - f1: 0.9935\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0063 - accuracy: 0.9967 - specificity: 0.9894 - precision: 0.9894 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9895 - f1: 0.9947\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0056 - accuracy: 0.9967 - specificity: 0.9916 - precision: 0.9915 - recall: 0.9998 - auc: 0.9991 - matthews_correlation_coefficient: 0.9915 - f1: 0.9957\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0054 - accuracy: 0.9975 - specificity: 0.9905 - precision: 0.9904 - recall: 1.0000 - auc: 0.9991 - matthews_correlation_coefficient: 0.9905 - f1: 0.9953\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0051 - accuracy: 0.9970 - specificity: 0.9904 - precision: 0.9906 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9905 - f1: 0.9952\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0053 - accuracy: 0.9978 - specificity: 0.9898 - precision: 0.9898 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9899 - f1: 0.9950\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0049 - accuracy: 0.9976 - specificity: 0.9916 - precision: 0.9918 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9917 - f1: 0.9959\n",
            "Score for fold 6: loss of 0.049868762493133545; accuracy of 93.45661401748657%; specificity of 0.8574504852294922; precision of 0.8722860813140869; recall of 0.9715505242347717; auc of 0.9817941188812256; matthews_correlation_coefficient of 0.835854709148407; f1 of 0.9210283756256104\n",
            "22/22 [==============================] - 3s 123ms/step\n",
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 1024, 1)]         0         \n",
            "                                                                 \n",
            " conv1 (Conv1D)              (None, 1016, 256)         2560      \n",
            "                                                                 \n",
            " primarycap_conv2d (Conv1D)  (None, 504, 256)          590080    \n",
            "                                                                 \n",
            " primarycap_reshape (Reshap  (None, 16128, 8)          0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            " primarycap_squash (Lambda)  (None, 16128, 8)          0         \n",
            "                                                                 \n",
            " digitcaps (CapsuleLayer)    (None, 2, 8)              2064384   \n",
            "                                                                 \n",
            " capsnet (Length)            (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2657024 (10.14 MB)\n",
            "Trainable params: 2657024 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/30\n",
            "45/45 [==============================] - 65s 1s/step - loss: 0.8100 - accuracy: 0.6340 - specificity: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - matthews_correlation_coefficient: 0.0000e+00 - f1: nan\n",
            "Epoch 2/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.3515 - accuracy: 0.6788 - specificity: 0.3886 - precision: 0.5400 - recall: 0.7217 - auc: 0.5793 - matthews_correlation_coefficient: 0.1104 - f1: nan\n",
            "Epoch 3/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.1623 - accuracy: 0.7217 - specificity: 0.5218 - precision: 0.6387 - recall: 0.8462 - auc: 0.7955 - matthews_correlation_coefficient: 0.3942 - f1: 0.7298\n",
            "Epoch 4/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0814 - accuracy: 0.8843 - specificity: 0.7708 - precision: 0.8058 - recall: 0.9469 - auc: 0.9456 - matthews_correlation_coefficient: 0.7307 - f1: 0.8709\n",
            "Epoch 5/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0635 - accuracy: 0.9104 - specificity: 0.8172 - precision: 0.8407 - recall: 0.9623 - auc: 0.9678 - matthews_correlation_coefficient: 0.7890 - f1: 0.8975\n",
            "Epoch 6/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0606 - accuracy: 0.9166 - specificity: 0.8306 - precision: 0.8508 - recall: 0.9644 - auc: 0.9705 - matthews_correlation_coefficient: 0.8038 - f1: 0.9044\n",
            "Epoch 7/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0544 - accuracy: 0.9275 - specificity: 0.8416 - precision: 0.8590 - recall: 0.9705 - auc: 0.9770 - matthews_correlation_coefficient: 0.8195 - f1: 0.9119\n",
            "Epoch 8/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0516 - accuracy: 0.9296 - specificity: 0.8582 - precision: 0.8726 - recall: 0.9723 - auc: 0.9791 - matthews_correlation_coefficient: 0.8368 - f1: 0.9202\n",
            "Epoch 9/30\n",
            "45/45 [==============================] - 65s 1s/step - loss: 0.0511 - accuracy: 0.9310 - specificity: 0.8579 - precision: 0.8725 - recall: 0.9704 - auc: 0.9799 - matthews_correlation_coefficient: 0.8341 - f1: 0.9190\n",
            "Epoch 10/30\n",
            "45/45 [==============================] - 64s 1s/step - loss: 0.0478 - accuracy: 0.9360 - specificity: 0.8686 - precision: 0.8814 - recall: 0.9765 - auc: 0.9826 - matthews_correlation_coefficient: 0.8506 - f1: 0.9267\n",
            "Epoch 11/30\n",
            "45/45 [==============================] - 69s 2s/step - loss: 0.0446 - accuracy: 0.9409 - specificity: 0.8758 - precision: 0.8880 - recall: 0.9772 - auc: 0.9850 - matthews_correlation_coefficient: 0.8576 - f1: 0.9302\n",
            "Epoch 12/30\n",
            "45/45 [==============================] - 67s 1s/step - loss: 0.0420 - accuracy: 0.9448 - specificity: 0.8847 - precision: 0.8943 - recall: 0.9799 - auc: 0.9862 - matthews_correlation_coefficient: 0.8692 - f1: 0.9357\n",
            "Epoch 13/30\n",
            "45/45 [==============================] - 67s 1s/step - loss: 0.0424 - accuracy: 0.9462 - specificity: 0.8892 - precision: 0.8978 - recall: 0.9778 - auc: 0.9860 - matthews_correlation_coefficient: 0.8713 - f1: 0.9367\n",
            "Epoch 14/30\n",
            "45/45 [==============================] - 70s 2s/step - loss: 0.0397 - accuracy: 0.9492 - specificity: 0.8937 - precision: 0.9021 - recall: 0.9829 - auc: 0.9876 - matthews_correlation_coefficient: 0.8810 - f1: 0.9413\n",
            "Epoch 15/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0376 - accuracy: 0.9519 - specificity: 0.9003 - precision: 0.9077 - recall: 0.9840 - auc: 0.9890 - matthews_correlation_coefficient: 0.8876 - f1: 0.9446\n",
            "Epoch 16/30\n",
            "45/45 [==============================] - 71s 2s/step - loss: 0.0358 - accuracy: 0.9549 - specificity: 0.9056 - precision: 0.9121 - recall: 0.9859 - auc: 0.9901 - matthews_correlation_coefficient: 0.8950 - f1: 0.9481\n",
            "Epoch 17/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0341 - accuracy: 0.9563 - specificity: 0.9125 - precision: 0.9185 - recall: 0.9882 - auc: 0.9907 - matthews_correlation_coefficient: 0.9034 - f1: 0.9522\n",
            "Epoch 18/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0329 - accuracy: 0.9586 - specificity: 0.9186 - precision: 0.9236 - recall: 0.9894 - auc: 0.9914 - matthews_correlation_coefficient: 0.9108 - f1: 0.9558\n",
            "Epoch 19/30\n",
            "45/45 [==============================] - 64s 1s/step - loss: 0.0321 - accuracy: 0.9600 - specificity: 0.9155 - precision: 0.9216 - recall: 0.9892 - auc: 0.9919 - matthews_correlation_coefficient: 0.9078 - f1: 0.9543\n",
            "Epoch 20/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0308 - accuracy: 0.9631 - specificity: 0.9242 - precision: 0.9283 - recall: 0.9912 - auc: 0.9926 - matthews_correlation_coefficient: 0.9178 - f1: 0.9593\n",
            "Epoch 21/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0284 - accuracy: 0.9668 - specificity: 0.9320 - precision: 0.9357 - recall: 0.9924 - auc: 0.9933 - matthews_correlation_coefficient: 0.9261 - f1: 0.9633\n",
            "Epoch 22/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0272 - accuracy: 0.9674 - specificity: 0.9317 - precision: 0.9370 - recall: 0.9944 - auc: 0.9939 - matthews_correlation_coefficient: 0.9283 - f1: 0.9644\n",
            "Epoch 23/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0260 - accuracy: 0.9698 - specificity: 0.9399 - precision: 0.9433 - recall: 0.9940 - auc: 0.9943 - matthews_correlation_coefficient: 0.9356 - f1: 0.9680\n",
            "Epoch 24/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0245 - accuracy: 0.9730 - specificity: 0.9407 - precision: 0.9449 - recall: 0.9975 - auc: 0.9949 - matthews_correlation_coefficient: 0.9400 - f1: 0.9701\n",
            "Epoch 25/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.0247 - accuracy: 0.9728 - specificity: 0.9426 - precision: 0.9454 - recall: 0.9956 - auc: 0.9950 - matthews_correlation_coefficient: 0.9390 - f1: 0.9696\n",
            "Epoch 26/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0231 - accuracy: 0.9739 - specificity: 0.9450 - precision: 0.9488 - recall: 0.9968 - auc: 0.9955 - matthews_correlation_coefficient: 0.9434 - f1: 0.9718\n",
            "Epoch 27/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0204 - accuracy: 0.9787 - specificity: 0.9549 - precision: 0.9569 - recall: 0.9984 - auc: 0.9962 - matthews_correlation_coefficient: 0.9544 - f1: 0.9772\n",
            "Epoch 28/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.0199 - accuracy: 0.9787 - specificity: 0.9568 - precision: 0.9590 - recall: 0.9989 - auc: 0.9964 - matthews_correlation_coefficient: 0.9567 - f1: 0.9784\n",
            "Epoch 29/30\n",
            "45/45 [==============================] - 67s 1s/step - loss: 0.0181 - accuracy: 0.9820 - specificity: 0.9590 - precision: 0.9612 - recall: 0.9993 - auc: 0.9970 - matthews_correlation_coefficient: 0.9593 - f1: 0.9797\n",
            "Epoch 30/30\n",
            "45/45 [==============================] - 72s 2s/step - loss: 0.0187 - accuracy: 0.9836 - specificity: 0.9617 - precision: 0.9633 - recall: 0.9988 - auc: 0.9970 - matthews_correlation_coefficient: 0.9612 - f1: 0.9806\n",
            "Epoch 1/30\n",
            "50/50 [==============================] - 78s 2s/step - loss: 0.0286 - accuracy: 0.9677 - specificity: 0.9330 - precision: 0.9366 - recall: 0.9881 - auc: 0.9921 - matthews_correlation_coefficient: 0.9228 - f1: 0.9618\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0244 - accuracy: 0.9720 - specificity: 0.9422 - precision: 0.9448 - recall: 0.9929 - auc: 0.9946 - matthews_correlation_coefficient: 0.9366 - f1: 0.9685\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0230 - accuracy: 0.9745 - specificity: 0.9458 - precision: 0.9481 - recall: 0.9943 - auc: 0.9951 - matthews_correlation_coefficient: 0.9415 - f1: 0.9709\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0215 - accuracy: 0.9779 - specificity: 0.9504 - precision: 0.9527 - recall: 0.9965 - auc: 0.9958 - matthews_correlation_coefficient: 0.9482 - f1: 0.9742\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0188 - accuracy: 0.9812 - specificity: 0.9579 - precision: 0.9597 - recall: 0.9978 - auc: 0.9964 - matthews_correlation_coefficient: 0.9566 - f1: 0.9784\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0176 - accuracy: 0.9836 - specificity: 0.9619 - precision: 0.9628 - recall: 0.9987 - auc: 0.9969 - matthews_correlation_coefficient: 0.9614 - f1: 0.9807\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0166 - accuracy: 0.9867 - specificity: 0.9629 - precision: 0.9649 - recall: 0.9991 - auc: 0.9970 - matthews_correlation_coefficient: 0.9628 - f1: 0.9814\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0145 - accuracy: 0.9885 - specificity: 0.9705 - precision: 0.9710 - recall: 0.9997 - auc: 0.9974 - matthews_correlation_coefficient: 0.9707 - f1: 0.9854\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0132 - accuracy: 0.9896 - specificity: 0.9721 - precision: 0.9732 - recall: 0.9998 - auc: 0.9977 - matthews_correlation_coefficient: 0.9724 - f1: 0.9862\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0126 - accuracy: 0.9904 - specificity: 0.9746 - precision: 0.9752 - recall: 0.9998 - auc: 0.9978 - matthews_correlation_coefficient: 0.9749 - f1: 0.9874\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 71s 1s/step - loss: 0.0116 - accuracy: 0.9923 - specificity: 0.9779 - precision: 0.9783 - recall: 0.9997 - auc: 0.9981 - matthews_correlation_coefficient: 0.9779 - f1: 0.9890\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 71s 1s/step - loss: 0.0114 - accuracy: 0.9924 - specificity: 0.9777 - precision: 0.9782 - recall: 1.0000 - auc: 0.9981 - matthews_correlation_coefficient: 0.9780 - f1: 0.9890\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 71s 1s/step - loss: 0.0112 - accuracy: 0.9924 - specificity: 0.9781 - precision: 0.9788 - recall: 0.9998 - auc: 0.9981 - matthews_correlation_coefficient: 0.9783 - f1: 0.9891\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 71s 1s/step - loss: 0.0100 - accuracy: 0.9945 - specificity: 0.9810 - precision: 0.9814 - recall: 1.0000 - auc: 0.9984 - matthews_correlation_coefficient: 0.9813 - f1: 0.9906\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 71s 1s/step - loss: 0.0098 - accuracy: 0.9945 - specificity: 0.9799 - precision: 0.9805 - recall: 0.9998 - auc: 0.9985 - matthews_correlation_coefficient: 0.9800 - f1: 0.9900\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 72s 1s/step - loss: 0.0092 - accuracy: 0.9956 - specificity: 0.9820 - precision: 0.9823 - recall: 1.0000 - auc: 0.9984 - matthews_correlation_coefficient: 0.9822 - f1: 0.9911\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 71s 1s/step - loss: 0.0093 - accuracy: 0.9953 - specificity: 0.9831 - precision: 0.9832 - recall: 1.0000 - auc: 0.9985 - matthews_correlation_coefficient: 0.9833 - f1: 0.9917\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0087 - accuracy: 0.9957 - specificity: 0.9839 - precision: 0.9840 - recall: 1.0000 - auc: 0.9986 - matthews_correlation_coefficient: 0.9841 - f1: 0.9920\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0079 - accuracy: 0.9959 - specificity: 0.9838 - precision: 0.9846 - recall: 1.0000 - auc: 0.9988 - matthews_correlation_coefficient: 0.9841 - f1: 0.9920\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0074 - accuracy: 0.9960 - specificity: 0.9864 - precision: 0.9864 - recall: 0.9998 - auc: 0.9988 - matthews_correlation_coefficient: 0.9864 - f1: 0.9932\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0070 - accuracy: 0.9962 - specificity: 0.9858 - precision: 0.9858 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9859 - f1: 0.9930\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0069 - accuracy: 0.9964 - specificity: 0.9872 - precision: 0.9872 - recall: 0.9998 - auc: 0.9990 - matthews_correlation_coefficient: 0.9872 - f1: 0.9936\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0064 - accuracy: 0.9965 - specificity: 0.9876 - precision: 0.9878 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9877 - f1: 0.9939\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 70s 1s/step - loss: 0.0062 - accuracy: 0.9967 - specificity: 0.9872 - precision: 0.9872 - recall: 1.0000 - auc: 0.9989 - matthews_correlation_coefficient: 0.9873 - f1: 0.9937\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0063 - accuracy: 0.9968 - specificity: 0.9871 - precision: 0.9874 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9872 - f1: 0.9936\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0064 - accuracy: 0.9973 - specificity: 0.9863 - precision: 0.9866 - recall: 1.0000 - auc: 0.9990 - matthews_correlation_coefficient: 0.9865 - f1: 0.9932\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0056 - accuracy: 0.9972 - specificity: 0.9880 - precision: 0.9880 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9881 - f1: 0.9940\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 68s 1s/step - loss: 0.0052 - accuracy: 0.9973 - specificity: 0.9908 - precision: 0.9908 - recall: 1.0000 - auc: 0.9993 - matthews_correlation_coefficient: 0.9909 - f1: 0.9954\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0050 - accuracy: 0.9970 - specificity: 0.9909 - precision: 0.9911 - recall: 1.0000 - auc: 0.9992 - matthews_correlation_coefficient: 0.9909 - f1: 0.9955\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 69s 1s/step - loss: 0.0050 - accuracy: 0.9981 - specificity: 0.9900 - precision: 0.9900 - recall: 1.0000 - auc: 0.9994 - matthews_correlation_coefficient: 0.9901 - f1: 0.9950\n",
            "Score for fold 7: loss of 0.04125642031431198; accuracy of 97.15099930763245%; specificity of 0.8712120652198792; precision of 0.8844672441482544; recall of 0.9814814925193787; auc of 0.9874696731567383; matthews_correlation_coefficient of 0.8595354557037354; f1 of 0.9314661622047424\n",
            "22/22 [==============================] - 3s 115ms/step\n",
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 1024, 1)]         0         \n",
            "                                                                 \n",
            " conv1 (Conv1D)              (None, 1016, 256)         2560      \n",
            "                                                                 \n",
            " primarycap_conv2d (Conv1D)  (None, 504, 256)          590080    \n",
            "                                                                 \n",
            " primarycap_reshape (Reshap  (None, 16128, 8)          0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            " primarycap_squash (Lambda)  (None, 16128, 8)          0         \n",
            "                                                                 \n",
            " digitcaps (CapsuleLayer)    (None, 2, 8)              2064384   \n",
            "                                                                 \n",
            " capsnet (Length)            (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2657024 (10.14 MB)\n",
            "Trainable params: 2657024 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/30\n",
            "45/45 [==============================] - 63s 1s/step - loss: 0.8100 - accuracy: 0.6492 - specificity: 1.0000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - matthews_correlation_coefficient: 0.0000e+00 - f1: nan\n",
            "Epoch 2/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.2588 - accuracy: 0.6788 - specificity: 0.3538 - precision: 0.5553 - recall: 0.7998 - auc: 0.6481 - matthews_correlation_coefficient: 0.1564 - f1: nan\n",
            "Epoch 3/30\n",
            "45/45 [==============================] - 62s 1s/step - loss: 0.1693 - accuracy: 0.7085 - specificity: 0.5686 - precision: 0.6524 - recall: 0.8169 - auc: 0.7824 - matthews_correlation_coefficient: 0.4099 - f1: 0.7261\n",
            "Epoch 4/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0866 - accuracy: 0.8758 - specificity: 0.7604 - precision: 0.7979 - recall: 0.9425 - auc: 0.9394 - matthews_correlation_coefficient: 0.7173 - f1: 0.8647\n",
            "Epoch 5/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0689 - accuracy: 0.9037 - specificity: 0.8069 - precision: 0.8323 - recall: 0.9549 - auc: 0.9618 - matthews_correlation_coefficient: 0.7726 - f1: 0.8898\n",
            "Epoch 6/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0625 - accuracy: 0.9178 - specificity: 0.8276 - precision: 0.8477 - recall: 0.9607 - auc: 0.9693 - matthews_correlation_coefficient: 0.7976 - f1: 0.9015\n",
            "Epoch 7/30\n",
            "45/45 [==============================] - 61s 1s/step - loss: 0.0541 - accuracy: 0.9261 - specificity: 0.8469 - precision: 0.8634 - recall: 0.9698 - auc: 0.9771 - matthews_correlation_coefficient: 0.8237 - f1: 0.9139\n",
            "Epoch 8/30\n",
            "37/45 [=======================>......] - ETA: 11s - loss: 0.0501 - accuracy: 0.9310 - specificity: 0.8642 - precision: 0.8774 - recall: 0.9715 - auc: 0.9803 - matthews_correlation_coefficient: 0.8412 - f1: 0.9223"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from keras.layers import LeakyReLU, Dense, Input, Embedding, Dropout, Bidirectional, GRU, Flatten, SpatialDropout1D, concatenate,LSTM,Conv1D\n",
        "\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "sp_per_fold = []\n",
        "prec_per_fold = []\n",
        "sn_per_fold = []\n",
        "AUC_per_fold = []\n",
        "MCC_per_fold = []\n",
        "f1_per_fold = []\n",
        "\n",
        "tprs = []\n",
        "\n",
        "aucs = []\n",
        "conf_matrix_list_of_arrays = []\n",
        "\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "i = 1\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# seed = 7\n",
        "# np.random.seed(seed)\n",
        "\n",
        "epoch=30\n",
        "# unpacking the data\n",
        "# (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "# set amino acids to consider\n",
        "CONSIDERED_AA = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "\n",
        "# embedding and convolution parameters\n",
        "MAX_SEQ_LENGTH = 1024\n",
        "VOCAB_SIZE = len(CONSIDERED_AA)\n",
        "# EMBEDDING_SIZE = 128\n",
        "# plt.figure(1)\n",
        "plt.figure(figsize=(6,6), dpi= 1000)\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "# kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "\n",
        "  model, eval_model = CapsNet(data_train[1,:].shape, VOCAB_SIZE, MAX_SEQ_LENGTH, n_class=2, routings=2)\n",
        "  model.summary()\n",
        "\n",
        "   # compile the model\n",
        "  model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss=[margin_loss, 'binary_crossentropy'],\n",
        "                  # loss_weights=[1., 0.392],\n",
        "                  metrics=[\"accuracy\", specificity, \"Precision\", \"Recall\", \"AUC\", matthews_correlation_coefficient, f1_score_metric])\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=128,\n",
        "              epochs=epoch,\n",
        "              # validation_split=0.05,\n",
        "              verbose=1)\n",
        "    # Generate generalization metrics\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; {model.metrics_names[2]} of {scores[2]}; {model.metrics_names[3]} of {scores[3]}; {model.metrics_names[4]} of {scores[4]}; {model.metrics_names[5]} of {scores[5]}; {model.metrics_names[6]} of {scores[6]}; {model.metrics_names[7]} of {scores[7]}')\n",
        "  acc_per_fold.append(scores[1])\n",
        "  loss_per_fold.append(scores[0])\n",
        "  sp_per_fold.append(scores[2])\n",
        "  prec_per_fold.append(scores[3])\n",
        "  sn_per_fold.append(scores[4])\n",
        "  AUC_per_fold.append(scores[5])\n",
        "  MCC_per_fold.append(scores[6])\n",
        "  f1_per_fold.append(scores[7])\n",
        "\n",
        "  y_pred_keras = model.predict(inputs[test])\n",
        "\n",
        "  conf_matrix = confusion_matrix(targets[test].argmax(axis=1), y_pred_keras.argmax(axis=1))\n",
        "  conf_matrix_list_of_arrays .append(conf_matrix)\n",
        "\n",
        "  fpr, tpr, thresholds = roc_curve(targets[test].ravel(), y_pred_keras.ravel())\n",
        "  tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  aucs.append(roc_auc)\n",
        "\n",
        "  plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (fold_no, roc_auc))\n",
        "\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}% - Specificity: {sp_per_fold[i]} - Precision: {prec_per_fold[i]} - Sensitivity: {sn_per_fold[i]} - AUC: {AUC_per_fold[i]} - MCC: {MCC_per_fold[i]} - F1 Score: {f1_per_fold[i]}')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print(f'> Specificity: {np.mean(sp_per_fold)}(+- {np.std(sp_per_fold)})')\n",
        "print(f'> Precision: {np.mean(prec_per_fold)}(+- {np.std(prec_per_fold)})')\n",
        "print(f'> Sensitivity: {np.mean(sn_per_fold)}(+- {np.std(sn_per_fold)})')\n",
        "print(f'> AUC: {np.mean(AUC_per_fold)}')\n",
        "print(f'> MCC: {np.mean(MCC_per_fold)}(+- {np.std(MCC_per_fold)})')\n",
        "print(f'> F1 Score: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print('------------------------------------------------------------------------')\n",
        "\n",
        "plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "plt.plot(mean_fpr, mean_tpr, color='blue',\n",
        "         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "# image = plt.figure(figsize=(16,10), dpi= 200)\n",
        "\n",
        "plt.savefig(\"Halo_capsNet.JPG\",dpi=1000)\n",
        "plt.show()\n",
        "\n",
        "mean_of_conf_matrix_arrays = np.mean(conf_matrix_list_of_arrays, axis=0)\n",
        "# plt.savefig(\"DPB\",dpi=500)\n",
        "# tf.keras.models.save_model(model, filepath=\"/gdrive/MyDrive/DNA Binding Protein/Dbp app/logs3/model blstm Adam 100 epoch reduce plateu one hot 128 sequence 600\",save_format='hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX2Z2vZQlJZg",
        "outputId": "ffd9101b-3fee-47c1-8f38-5d81f0840f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Capsule Weights: [[[[[-1.87365711e-02  1.90469474e-02  1.23590138e-02 ...\n",
            "     -9.91970673e-03 -1.23347668e-02  9.17982217e-03]\n",
            "    [ 1.45173175e-02 -1.88027155e-02 -1.42189655e-02 ...\n",
            "      1.20781716e-02  1.25991143e-02 -9.88515653e-03]\n",
            "    [-1.92040447e-04 -1.99138955e-03 -1.69343979e-03 ...\n",
            "      4.68239561e-03  5.39083267e-03 -4.13122261e-03]\n",
            "    ...\n",
            "    [-1.60918187e-03  3.02869244e-03  4.22363495e-03 ...\n",
            "      5.63466968e-03 -3.76739958e-03  2.75701354e-03]\n",
            "    [ 1.89286973e-02 -1.42917670e-02 -1.59262326e-02 ...\n",
            "      8.48493259e-03  1.40284793e-02 -8.09320621e-03]\n",
            "    [-1.47713104e-03  3.88735998e-03 -2.99810432e-03 ...\n",
            "      3.77755379e-04  3.56308417e-03  2.56932946e-03]]\n",
            "\n",
            "   [[-1.53839001e-02  7.01922970e-03  1.62807014e-02 ...\n",
            "     -1.24657638e-02  2.04033982e-02  1.17523717e-02]\n",
            "    [ 1.38396509e-02 -1.04512237e-02 -1.68552287e-02 ...\n",
            "      1.27300927e-02 -1.63304619e-02 -1.81014333e-02]\n",
            "    [ 4.79727285e-03 -5.21894637e-03 -3.85912659e-04 ...\n",
            "      1.16661424e-03 -3.35578551e-03 -2.27432069e-03]\n",
            "    ...\n",
            "    [-9.30335591e-05 -3.34548578e-03  6.80991448e-04 ...\n",
            "     -6.67130481e-03  2.69444450e-03  5.53208124e-03]\n",
            "    [ 1.50748491e-02 -7.59754516e-03 -1.52580068e-02 ...\n",
            "      1.01888170e-02 -1.89220365e-02 -1.53932432e-02]\n",
            "    [-1.97601318e-03 -3.89714929e-04 -1.16437511e-03 ...\n",
            "      3.31660826e-03  4.26113419e-03 -2.56625935e-03]]\n",
            "\n",
            "   [[ 9.97527502e-03  9.69400909e-03 -3.19555239e-03 ...\n",
            "      7.50323152e-03  9.28097777e-03 -1.20879421e-02]\n",
            "    [-1.25973253e-02 -1.16211763e-02  1.15029085e-04 ...\n",
            "     -1.20616285e-02 -1.42958807e-02  1.56651437e-02]\n",
            "    [-3.94947873e-03 -3.28011985e-04  2.00268207e-03 ...\n",
            "     -1.17662502e-03  7.18105468e-04  4.94838879e-03]\n",
            "    ...\n",
            "    [-2.56930187e-04  5.05703269e-03  2.70374306e-03 ...\n",
            "     -1.03165559e-03 -2.12673307e-03  4.56035807e-04]\n",
            "    [-1.40915047e-02 -1.16445972e-02  3.30505474e-03 ...\n",
            "     -7.35095423e-03 -1.18147470e-02  1.40997870e-02]\n",
            "    [ 6.17318728e-04 -1.85832591e-03  3.95909185e-03 ...\n",
            "     -7.64458033e-04 -1.26763468e-03 -1.22525916e-03]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-8.60120356e-03  1.21059092e-02  8.84174649e-03 ...\n",
            "     -1.40895471e-02 -2.02989182e-03 -7.37895304e-03]\n",
            "    [ 7.22637726e-03 -1.17867216e-02 -7.79314619e-03 ...\n",
            "      8.36534612e-03  4.11878666e-03  8.93115718e-03]\n",
            "    [-1.83749211e-03 -6.38731348e-04  2.46076728e-04 ...\n",
            "     -8.19136112e-05 -1.00518308e-04  8.28793331e-04]\n",
            "    ...\n",
            "    [ 1.57238205e-03 -9.95399547e-04 -3.50241223e-03 ...\n",
            "     -1.53183495e-03  1.91630342e-03  1.58558236e-04]\n",
            "    [ 8.65467358e-03 -1.24817491e-02 -9.08392575e-03 ...\n",
            "      1.22303683e-02  2.79921805e-03  7.07825925e-03]\n",
            "    [-7.91145582e-03  9.92653519e-03  6.70670345e-03 ...\n",
            "     -3.75530310e-03  1.63304736e-03 -2.62266118e-03]]\n",
            "\n",
            "   [[-1.78943798e-02 -3.04393377e-02 -6.74049109e-02 ...\n",
            "     -3.17150056e-02 -7.03230351e-02 -7.19882324e-02]\n",
            "    [ 1.50368465e-02  2.83875447e-02  6.99597150e-02 ...\n",
            "      3.28360759e-02  6.98483735e-02  6.77920207e-02]\n",
            "    [ 5.61009021e-03  1.59207862e-02  3.23644355e-02 ...\n",
            "      6.58961758e-03  4.43741120e-02  1.86071862e-02]\n",
            "    ...\n",
            "    [ 6.01619715e-03  9.45599005e-03 -2.49945018e-02 ...\n",
            "     -5.06964605e-03 -3.48365270e-02 -5.88493124e-02]\n",
            "    [ 1.73142273e-02  2.86977980e-02  7.24836737e-02 ...\n",
            "      2.90740933e-02  6.91650212e-02  7.42760077e-02]\n",
            "    [ 1.49683207e-02  1.38375990e-03 -4.13788296e-02 ...\n",
            "     -1.06677730e-02 -1.20350540e-01 -5.21647297e-02]]\n",
            "\n",
            "   [[-6.97716465e-03  7.25911884e-03 -9.87607799e-03 ...\n",
            "      8.19256809e-03 -7.95334671e-03 -1.26044890e-02]\n",
            "    [ 7.23764068e-03 -6.66061323e-03  1.07062059e-02 ...\n",
            "     -1.07844453e-02  9.38643143e-03  9.84152220e-03]\n",
            "    [ 2.46881088e-03  1.30899658e-03 -1.15324183e-04 ...\n",
            "      8.26892152e-04 -1.68179406e-03  3.45135829e-03]\n",
            "    ...\n",
            "    [-1.68761425e-03 -1.72227016e-03 -8.90749914e-04 ...\n",
            "      1.23932434e-03  6.02553226e-03 -2.88566062e-03]\n",
            "    [ 7.75562506e-03 -5.22243930e-03  7.59060821e-03 ...\n",
            "     -9.66217648e-03  1.11227138e-02  1.03616007e-02]\n",
            "    [-2.73533282e-04  2.84284556e-06  1.67585595e-03 ...\n",
            "     -4.64385143e-03 -3.06942640e-03 -3.34420684e-03]]]\n",
            "\n",
            "\n",
            "  [[[-2.43970938e-03  1.86692842e-03  1.62296975e-03 ...\n",
            "     -4.70553664e-03 -6.75440859e-03  7.52133783e-03]\n",
            "    [ 4.93538985e-03 -1.66932459e-03 -1.49505888e-03 ...\n",
            "     -1.49072148e-03 -6.12308155e-04  5.44935977e-03]\n",
            "    [ 7.54296896e-04 -1.80931436e-03 -1.87995844e-03 ...\n",
            "      4.59202612e-03  6.18091039e-03 -6.45897258e-03]\n",
            "    ...\n",
            "    [ 1.56284345e-03 -1.02117214e-04 -4.24050028e-04 ...\n",
            "      7.14290282e-03  1.74845895e-03 -5.40437270e-03]\n",
            "    [-8.49845540e-03  3.93395458e-05  3.56603327e-04 ...\n",
            "      6.05748640e-03 -2.17248942e-03 -6.49121730e-03]\n",
            "    [-2.59230821e-03  2.30863946e-03 -5.73520141e-04 ...\n",
            "      2.65354174e-03  1.30136684e-03 -2.83834361e-03]]\n",
            "\n",
            "   [[-5.21745998e-04  5.57747344e-03  6.58973726e-03 ...\n",
            "     -3.32286349e-03  5.50591201e-03 -9.84590617e-04]\n",
            "    [ 8.76165740e-03  5.49249444e-03 -2.77184357e-04 ...\n",
            "      4.83098993e-04 -6.56809611e-03 -5.54534514e-03]\n",
            "    [-3.28804110e-03 -6.64515654e-03 -3.82726942e-03 ...\n",
            "      4.04869346e-03 -2.67960178e-03 -2.08485173e-03]\n",
            "    ...\n",
            "    [ 1.50222832e-03 -9.00744461e-03 -4.20384016e-03 ...\n",
            "      4.66717989e-04  2.38366285e-03  1.77868491e-03]\n",
            "    [-7.02596689e-03 -1.22043509e-02 -6.81218691e-03 ...\n",
            "     -6.26805937e-03  8.04877188e-03  3.10778362e-03]\n",
            "    [-5.12675848e-03 -8.45062640e-03 -7.37190852e-03 ...\n",
            "     -8.66575574e-04  2.61633121e-03  9.25947097e-04]]\n",
            "\n",
            "   [[ 4.64710360e-03  4.18186653e-03 -1.21532856e-02 ...\n",
            "      7.43413484e-03  7.16629252e-03 -1.56145846e-03]\n",
            "    [ 3.87922372e-03  4.10792604e-03 -1.40968477e-02 ...\n",
            "      2.62500695e-03  6.06903387e-03 -1.17196178e-03]\n",
            "    [-5.94212348e-03 -5.12515195e-03  1.37152784e-02 ...\n",
            "     -8.16644449e-03 -2.91108014e-03  8.92789685e-04]\n",
            "    ...\n",
            "    [-7.36480113e-03 -2.04536109e-03  1.25354873e-02 ...\n",
            "     -5.30055864e-03 -7.45392463e-04  3.88342026e-03]\n",
            "    [-9.96062532e-04 -5.60300425e-03  1.42487381e-02 ...\n",
            "     -1.93817046e-04 -1.73146557e-03 -5.02645416e-05]\n",
            "    [-3.36818118e-03 -1.25155004e-03  1.18749253e-02 ...\n",
            "     -5.85373864e-03 -6.44617667e-03 -1.69903086e-03]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-5.32081258e-03  1.05254976e-02  5.66933537e-03 ...\n",
            "     -5.20002889e-03 -1.31147141e-02 -7.66659109e-03]\n",
            "    [-5.58978738e-03  8.44442379e-03  2.99867895e-03 ...\n",
            "      7.37445836e-04 -1.24367317e-02 -3.61055881e-03]\n",
            "    [ 1.20628560e-02 -4.85242577e-03 -7.24800583e-03 ...\n",
            "      5.46672614e-03  1.39359040e-02  5.90089522e-03]\n",
            "    ...\n",
            "    [ 7.71266408e-03 -6.18384546e-03 -8.28534365e-03 ...\n",
            "      3.65139078e-03  1.20261880e-02  6.51732367e-03]\n",
            "    [ 1.31849525e-02 -4.80678631e-03 -3.28639825e-03 ...\n",
            "     -2.62642768e-03  1.56569630e-02  3.77926347e-03]\n",
            "    [ 9.58021171e-03 -5.04984614e-03 -6.41322089e-03 ...\n",
            "      2.45996891e-03  1.15509294e-02  1.84880220e-03]]\n",
            "\n",
            "   [[ 1.55666117e-02  2.21038610e-02  3.42094116e-02 ...\n",
            "      1.99988745e-02  3.66813913e-02  4.75564487e-02]\n",
            "    [ 9.78249405e-03  1.77266207e-02  2.85746437e-02 ...\n",
            "      2.82323267e-02  6.23240545e-02  2.93337908e-02]\n",
            "    [-2.01221760e-02 -2.33967807e-02 -3.10773477e-02 ...\n",
            "     -2.59260051e-02 -4.86564450e-02 -4.58604284e-02]\n",
            "    ...\n",
            "    [-1.28380144e-02 -1.95518993e-02 -2.79004946e-02 ...\n",
            "     -1.89179182e-02 -4.32145596e-02 -3.84674855e-02]\n",
            "    [-1.45305479e-02 -1.31682716e-02 -3.11483368e-02 ...\n",
            "     -2.33762339e-02 -7.15787038e-02 -3.44623849e-02]\n",
            "    [-1.86186153e-02 -1.82389282e-02 -3.23880948e-02 ...\n",
            "     -2.34479699e-02 -5.70169874e-02 -4.22012694e-02]]\n",
            "\n",
            "   [[-1.01461364e-02  4.18799510e-03 -9.22420248e-03 ...\n",
            "      6.39484776e-03 -5.47795417e-03 -2.22534081e-03]\n",
            "    [-6.22228999e-03  5.10310335e-03 -8.76399409e-03 ...\n",
            "      6.11414155e-03 -5.09725930e-03 -1.31921039e-03]\n",
            "    [ 8.96775909e-03 -5.31181553e-03  1.02934567e-02 ...\n",
            "     -5.40021667e-03  6.15673373e-03  7.21684715e-04]\n",
            "    ...\n",
            "    [ 9.51712299e-03 -4.12457390e-03  6.98291091e-03 ...\n",
            "     -7.12893950e-03  5.68847731e-03 -2.86747847e-04]\n",
            "    [ 9.92874056e-03 -8.50951206e-03  9.54600703e-03 ...\n",
            "     -1.15493196e-03  5.80481207e-03  2.26199656e-04]\n",
            "    [ 7.35261431e-03 -2.71721371e-03  5.13041019e-03 ...\n",
            "     -8.60111229e-03  5.85861644e-03  3.07806651e-04]]]]]\n"
          ]
        }
      ],
      "source": [
        "# Extracting weights from the CapsuleLayer named 'digitcaps'\n",
        "capsule_layer = model.get_layer('digitcaps')\n",
        "capsule_weights = capsule_layer.get_weights()\n",
        "capsule_weights = np.array(capsule_weights)\n",
        "\n",
        "print(\"Capsule Weights:\", capsule_weights)\n",
        "#print(capsule_weights.shape)\n",
        "# Extracting weights from the final Dense layer of the decoder\n",
        "#decoder_final_dense_layer = decoder.layers[-2]  # The second last layer is the final Dense layer\n",
        "#decoder_weights = decoder_final_dense_layer.get_weights()\n",
        "#print(\"Decoder Weights:\", decoder_weights)\n",
        "#print(decoder_weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bJVNCZKmm51U"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeykGEf2poCV",
        "outputId": "35a9c42f-36e1-4943-e779-bec4156a1589"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 2, 16128, 8, 8)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "capsule_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5iFWshOqgNd",
        "outputId": "80c5ab56-0742-4df4-fd67-8f0d49599843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reshaped shape of capsule_weights: (16, 129024)\n"
          ]
        }
      ],
      "source": [
        "reshaped_capsule_weights = capsule_weights.reshape(-1, capsule_weights.shape[-1] * capsule_weights.shape[-2] * capsule_weights.shape[-3])\n",
        "\n",
        "print(\"Reshaped shape of capsule_weights:\", reshaped_capsule_weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "7Kp-aLsJp3w4",
        "outputId": "8975c9d2-ff11-46f5-9be4-4c339981a3c8"
      },
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__Min_device_/job:localhost/replica:0/task:0/device:CPU:0}} Invalid reduction dimension (1 for input with 0 dimension(s) [Op:Min]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-5cfb4beb80c6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperplexity_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshaped_capsule_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m   2779\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2780\u001b[0m     \"\"\"\n\u001b[0;32m-> 2781\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Min_device_/job:localhost/replica:0/task:0/device:CPU:0}} Invalid reduction dimension (1 for input with 0 dimension(s) [Op:Min]"
          ]
        }
      ],
      "source": [
        "perplexity_value = min(30, reshaped_capsule_weights.shape[0] - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVJAoze4ohli"
      },
      "outputs": [],
      "source": [
        "if isinstance(capsule_weights, list):\n",
        "    capsule_weights = np.array(capsule_weights)\n",
        "\n",
        "if capsule_weights.size == 0:\n",
        "    raise ValueError(\"capsule_weights is empty. Please provide valid data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "RvIj3X5pop7W",
        "outputId": "c3763a36-ae2b-40c8-cd12-28ef246c22be"
      },
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__Min_device_/job:localhost/replica:0/task:0/device:CPU:0}} Invalid reduction dimension (0 for input with 0 dimension(s) [Op:Min]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-3c67711fb93b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperplexity_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsule_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m   2779\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mminimum\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2780\u001b[0m     \"\"\"\n\u001b[0;32m-> 2781\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Min_device_/job:localhost/replica:0/task:0/device:CPU:0}} Invalid reduction dimension (0 for input with 0 dimension(s) [Op:Min]"
          ]
        }
      ],
      "source": [
        "perplexity_value = min(30, len(capsule_weights) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "UBJ9AXvRmyVo",
        "outputId": "8d7d171e-1467-49c0-eb7f-d8d9ec0853d0"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Length of values (16) does not match length of index (5670)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-f266f43e9976>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtsne_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_capsule_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dimension-1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dimension-2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m14.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"(b)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3948\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3950\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3952\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4141\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4142\u001b[0m         \"\"\"\n\u001b[0;32m-> 4143\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4870\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4871\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (16) does not match length of index (5670)"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame()\n",
        "df['Target'] = training_labels\n",
        "df['Target'] = df['Target'].map({0: 'Non-Halophilic', 1: 'Halophilic'})\n",
        "\n",
        "m = TSNE(n_components=2, perplexity=1,learning_rate = 10)\n",
        "tsne_features = m.fit_transform(reshaped_capsule_weights)\n",
        "\n",
        "df['Dimension-1'] = tsne_features[:,0]\n",
        "df['Dimension-2'] = tsne_features[:,1]\n",
        "plt.text(-14.5, 5,\"(b)\", fontsize=15)\n",
        "sns.scatterplot(x=\"Dimension-1\",y=\"Dimension-2\",hue='Target',data=df)\n",
        "plt.tick_params(top=False,\n",
        "               bottom=False,\n",
        "               left=False,\n",
        "               right=False,\n",
        "               labelleft=False,\n",
        "               labelbottom=False)\n",
        "\n",
        "# plt.axis('off')\n",
        "# plt.set_xlabel('Subplot 1')\n",
        "plt.legend().set_visible(True)\n",
        "filename = \"TSNE_Embedding_After_Training.png\"\n",
        "#plt.savefig(filename,dpi=1600,bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WRyDacQjm0X2"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df['Target'] = labels\n",
        "df['Target'] = df['Target'].map({1: 'Halophilic', 0: 'Non-Halophilic'})\n",
        "\n",
        "m = TSNE(n_components=2, perplexity=1000, learning_rate = 10)\n",
        "tsne_features = m.fit_transform(decoder_weights)\n",
        "m = TSNE(perplexity=3, learning_rate = 10)\n",
        "df['Dimension-1'] = tsne_features[:,0]\n",
        "df['Dimension-2'] = tsne_features[:,1]\n",
        "plt.text(-10.5, 7,\"(b)\", fontsize=15)\n",
        "sns.scatterplot(x=\"Dimension-1\",y=\"Dimension-2\",hue='Target',data=df)\n",
        "plt.tick_params(top=False,\n",
        "               bottom=False,\n",
        "               left=False,\n",
        "               right=False,\n",
        "               labelleft=False,\n",
        "               labelbottom=False)\n",
        "\n",
        "# plt.axis('off')\n",
        "# plt.set_xlabel('Subplot 1')\n",
        "plt.legend().set_visible(False)\n",
        "filename = \"TSNE_Embedding_After_Training.png\"\n",
        "plt.savefig(filename,dpi=1600,bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9cT3BRxJFes-"
      },
      "outputs": [],
      "source": [
        "caps_predict = model.predict(data_test).round()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "017ztgtQDSJf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A_giAOsQDYAj"
      },
      "outputs": [],
      "source": [
        "# print(caps_predict)\n",
        "accuracy = accuracy_score(y_test, caps_predict)\n",
        "f1 = f1_score(y_test, caps_predict, average='macro')  # or average='weighted' for multiclass\n",
        "mcc = matthews_correlation_coefficient(y_test, caps_predict)\n",
        "precision = precision_score(y_test, caps_predict, average='macro')\n",
        "recall = recall_score(y_test, caps_predict, average='macro')\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test.ravel(), caps_predict.ravel())\n",
        "\n",
        "# Calculate sensitivity and specificity for each label\n",
        "sensitivity_per_class = recall_score(y_test, caps_predict, average=None)\n",
        "specificity_per_class = []\n",
        "for i in range(y_test.shape[1]):\n",
        "    tn = conf_matrix[i, i]  # True negatives are the diagonal elements\n",
        "    fp = conf_matrix[:, i].sum() - tn\n",
        "    fn = conf_matrix[i, :].sum() - tn\n",
        "    specificity = tn / (tn + fp)\n",
        "    specificity_per_class.append(specificity)\n",
        "\n",
        "# Bootstrapping function to calculate errors\n",
        "def bootstrap_metrics(y_true, predictions, n_bootstrap=1000):\n",
        "    metrics = {\n",
        "        \"accuracy\": [],\n",
        "        \"f1\": [],\n",
        "        \"mcc\": [],\n",
        "        \"precision\": [],\n",
        "        \"recall\": [],\n",
        "        \"sensitivity\": [],\n",
        "        \"specificity\": []\n",
        "    }\n",
        "    n = len(y_true)\n",
        "    for _ in range(n_bootstrap):\n",
        "        indices = np.random.choice(n, n, replace=True)\n",
        "        y_true_sample = y_true[indices]\n",
        "        predictions_sample = predictions[indices]\n",
        "\n",
        "        metrics[\"accuracy\"].append(accuracy_score(y_true_sample, predictions_sample))\n",
        "        metrics[\"f1\"].append(f1_score(y_true_sample, predictions_sample, average='macro'))\n",
        "        mcc = matthews_corrcoef(y_true_sample.ravel(), predictions_sample.ravel())\n",
        "        metrics[\"mcc\"].append(mcc)\n",
        "        metrics[\"precision\"].append(precision_score(y_true_sample, predictions_sample, average='macro'))\n",
        "        metrics[\"recall\"].append(recall_score(y_true_sample, predictions_sample, average='macro'))\n",
        "\n",
        "        # Calculate confusion matrix for multilabel classification\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true_sample.ravel(), predictions_sample.ravel()).ravel()\n",
        "        metrics[\"sensitivity\"].append(recall_score(y_true_sample, predictions_sample, average='macro'))\n",
        "        specificity = tn / (tn + fp)\n",
        "        metrics[\"specificity\"].append(specificity)\n",
        "\n",
        "    errors = {k: np.std(v) for k, v in metrics.items()}\n",
        "    return errors\n",
        "\n",
        "\n",
        "# Calculate errors\n",
        "errors = bootstrap_metrics(y_test, caps_predict)\n",
        "\n",
        "# Print metrics with errors\n",
        "print(f\"Accuracy: {accuracy:.4f} ± {errors['accuracy']:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f} ± {errors['f1']:.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient: {mcc:.4f} ± {errors['mcc']:.4f}\")\n",
        "print(f\"Precision: {precision:.4f} ± {errors['precision']:.4f}\")\n",
        "print(f\"Recall: {recall:.4f} ± {errors['recall']:.4f}\")\n",
        "print(f\"Sensitivity: {np.mean(sensitivity_per_class):.4f} ± {errors['sensitivity']:.4f}\")\n",
        "print(f\"Specificity: {np.mean(specificity_per_class):.4f} ± {errors['specificity']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtphsPC2EBke"
      },
      "source": [
        "# TCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0gEd8DuEl07",
        "outputId": "8a2f6fcc-3f9e-422a-e47e-100b081f7331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision scikit-learn tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU8qqFDgIdjd",
        "outputId": "3769a1df-8617-4445-d792-0b3c7c8508d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting skorch\n",
            "  Downloading skorch-1.0.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-1.0.0\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install torch scikit-learn skorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6Qp1PaWEDG6"
      },
      "source": [
        "## Define TCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMk5xAW4EFAM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score, matthews_corrcoef\n",
        "from skorch import NeuralNetClassifier\n",
        "#from skorch.dataset import CVSplit\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class TCNModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_channels, kernel_size, dropout):\n",
        "        super(TCNModel, self).__init__()\n",
        "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout)\n",
        "        self.linear = nn.Linear(num_channels[-1], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.tcn(x)\n",
        "        o = self.linear(y1[:, :, -1])\n",
        "        return F.log_softmax(o, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-xKxgpSEKFd"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RlrCN1REaWE"
      },
      "outputs": [],
      "source": [
        "class TCNModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_channels, kernel_size, dropout):\n",
        "        super(TCNModel, self).__init__()\n",
        "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout)\n",
        "        self.linear = nn.Linear(num_channels[-1], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.tcn(x)\n",
        "        o = self.linear(y1[:, :, -1])\n",
        "        return F.log_softmax(o, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwAYlW33E1Vp"
      },
      "source": [
        "## Define the Training and Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFye1MEJEwTZ"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    return accuracy, test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62fI3yIfGTef"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3CCP7YJGUg0"
      },
      "outputs": [],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.tensor(train_dataset)\n",
        "X_test = torch.tensor(test_dataset)\n",
        "y_train = torch.tensor(training_labels, dtype=torch.long)\n",
        "y_test = torch.tensor(testing_labels, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0mJnsKKNCx_",
        "outputId": "50b4dc39-fc30-433e-d3e0-8bb55c139e4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5670, 1024])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_xVxn50NFrY",
        "outputId": "9aee9d37-afd7-4352-e3b5-5274a1984431"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5670])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNM8yfPHEbSS"
      },
      "source": [
        "## Define Custom Scoring Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA_-3cH3Fgy_"
      },
      "outputs": [],
      "source": [
        "def combined_score(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='binary')\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "    return (accuracy + f1 + mcc) / 3\n",
        "\n",
        "scorer = make_scorer(combined_score, greater_is_better=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRkAAPRvFinJ"
      },
      "source": [
        "## Wrap the Model and Perform GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "7jWUFMIsFl2L",
        "outputId": "615e535c-c900-4da3-e6f6-4f1e859d31b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "\nAll the 96 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n96 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/skorch/classifier.py\", line 165, in fit\n    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 1317, in fit\n    self.initialize()\n  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 905, in initialize\n    self._initialize_optimizer()\n  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 876, in _initialize_optimizer\n    self.initialize_optimizer()\n  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 642, in initialize_optimizer\n    self.optimizer_ = self.optimizer(*args, **kwargs)\nTypeError: 'str' object is not callable\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-2778dc47e499>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best parameters found: {gs.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 96 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n96 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/skorch/classifier.py\", line 165, in fit\n    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 1317, in fit\n    self.initialize()\n  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 905, in initialize\n    self._initialize_optimizer()\n  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 876, in _initialize_optimizer\n    self.initialize_optimizer()\n  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 642, in initialize_optimizer\n    self.optimizer_ = self.optimizer(*args, **kwargs)\nTypeError: 'str' object is not callable\n"
          ]
        }
      ],
      "source": [
        "net = NeuralNetClassifier(\n",
        "    TCNModel,\n",
        "    module__input_size=1024,\n",
        "    module__num_classes=2,\n",
        "    max_epochs=10,\n",
        "    lr=0.1,\n",
        "    iterator_train__shuffle=True,\n",
        ")\n",
        "\n",
        "params = {\n",
        "    'module__num_channels': [[25, 25, 25], [50, 50, 50]],\n",
        "    'module__kernel_size': [2, 3],\n",
        "    'module__dropout': [0.2, 0.5],\n",
        "    'optimizer': ['adam', 'sgd'],\n",
        "    'lr': [0.01, 0.001],\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(net, params, refit=False, cv=10, scoring=scorer, verbose=2, n_jobs=-1)\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters found: {gs.best_params_}\")\n",
        "print(f\"Best cross-validation score: {gs.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EoxGqapFn17"
      },
      "source": [
        "## Train and Evaluate the Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKWCZsUvFrWx"
      },
      "outputs": [],
      "source": [
        "best_params = gs.best_params_\n",
        "net.set_params(**best_params)\n",
        "net.fit(X_train, y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
        "\n",
        "# Get predictions\n",
        "y_pred = net.predict(X_test)\n",
        "\n",
        "# Calculate and print the metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='binary')\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test F1-score: {f1:.4f}\")\n",
        "print(f\"Test MCC: {mcc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTKB8te6MJ_g",
        "outputId": "90efd42e-39a7-431b-f122-c8f234ca8817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting skorch\n",
            "  Downloading skorch-1.0.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/239.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, skorch, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 skorch-1.0.0\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install necessary libraries\n",
        "!pip install torch scikit-learn skorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 2: Define the TCN architecture\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class TCNModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_channels, kernel_size, dropout):\n",
        "        super(TCNModel, self).__init__()\n",
        "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout)\n",
        "        self.linear = nn.Linear(num_channels[-1], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.tcn(x)\n",
        "        o = self.linear(y1[:, :, -1])\n",
        "        return F.log_softmax(o, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR6u6U-UdcQu",
        "outputId": "fee903d9-dfdc-4daf-d712-0501394c4a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMtGo-pHRswW",
        "outputId": "ae98b27f-09fb-4e00-e9cf-91edd0d67220"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-06-17 13:49:58,959] A new study created in memory with name: no-name-25170f9a-2b41-4ad5-8816-963579d34aae\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [25, 25] which is of type list.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [50, 50] which is of type list.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [25, 50] which is of type list.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-3-ff3a15bd6dc9>:108: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "[I 2024-06-17 13:50:05,597] Trial 0 finished with value: 0.46 and parameters: {'num_channels': [25, 50], 'kernel_size': 4, 'dropout': 0.44242258715818017, 'lr': 0.005684514857801972, 'batch_size': 78, 'num_epochs': 35}. Best is trial 0 with value: 0.46.\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [25, 25] which is of type list.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [50, 50] which is of type list.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [25, 50] which is of type list.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-3-ff3a15bd6dc9>:108: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
            "[I 2024-06-17 13:50:11,604] Trial 1 finished with value: 0.55 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.16051036164387958, 'lr': 0.00023215164995033112, 'batch_size': 95, 'num_epochs': 50}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:14,796] Trial 2 finished with value: 0.54 and parameters: {'num_channels': [25, 25], 'kernel_size': 3, 'dropout': 0.3487437988046993, 'lr': 0.0022699530890905617, 'batch_size': 92, 'num_epochs': 42}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:15,666] Trial 3 finished with value: 0.485 and parameters: {'num_channels': [25, 25], 'kernel_size': 4, 'dropout': 0.18803427163147096, 'lr': 0.00010377680936421187, 'batch_size': 98, 'num_epochs': 10}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:19,411] Trial 4 finished with value: 0.52 and parameters: {'num_channels': [25, 50], 'kernel_size': 5, 'dropout': 0.10026518165866, 'lr': 0.0052152921452132475, 'batch_size': 28, 'num_epochs': 17}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:24,979] Trial 5 finished with value: 0.46 and parameters: {'num_channels': [25, 50], 'kernel_size': 2, 'dropout': 0.13357642738379472, 'lr': 0.00028226793492348265, 'batch_size': 27, 'num_epochs': 27}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:26,652] Trial 6 finished with value: 0.5 and parameters: {'num_channels': [25, 50], 'kernel_size': 5, 'dropout': 0.26910519590033743, 'lr': 0.0013883230743173428, 'batch_size': 72, 'num_epochs': 15}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:29,628] Trial 7 finished with value: 0.455 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.19379465824069989, 'lr': 0.004400399478120582, 'batch_size': 44, 'num_epochs': 24}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:32,413] Trial 8 finished with value: 0.46 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.2618540232998754, 'lr': 0.006854289117065991, 'batch_size': 81, 'num_epochs': 29}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:37,394] Trial 9 finished with value: 0.525 and parameters: {'num_channels': [25, 25], 'kernel_size': 3, 'dropout': 0.3576729649478022, 'lr': 0.0012496671623112355, 'batch_size': 29, 'num_epochs': 29}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:40,708] Trial 10 finished with value: 0.48 and parameters: {'num_channels': [50, 50], 'kernel_size': 2, 'dropout': 0.49632031719906766, 'lr': 0.00039295830595329037, 'batch_size': 123, 'num_epochs': 49}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:44,668] Trial 11 finished with value: 0.535 and parameters: {'num_channels': [50, 50], 'kernel_size': 3, 'dropout': 0.34355821081418275, 'lr': 0.0005351725355383331, 'batch_size': 105, 'num_epochs': 50}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:47,555] Trial 12 finished with value: 0.48 and parameters: {'num_channels': [25, 25], 'kernel_size': 3, 'dropout': 0.39053477872582065, 'lr': 0.002306640049598265, 'batch_size': 99, 'num_epochs': 40}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:53,224] Trial 13 finished with value: 0.475 and parameters: {'num_channels': [50, 50], 'kernel_size': 3, 'dropout': 0.29821396284662116, 'lr': 0.00013022895115954265, 'batch_size': 59, 'num_epochs': 43}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:56,552] Trial 14 finished with value: 0.535 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.2351023628892964, 'lr': 0.0006845973695709705, 'batch_size': 123, 'num_epochs': 43}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:50:58,918] Trial 15 finished with value: 0.5 and parameters: {'num_channels': [25, 25], 'kernel_size': 2, 'dropout': 0.4002370608775728, 'lr': 0.0022505540045888108, 'batch_size': 89, 'num_epochs': 35}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:51:02,211] Trial 16 finished with value: 0.53 and parameters: {'num_channels': [25, 25], 'kernel_size': 4, 'dropout': 0.3253444158453683, 'lr': 0.00025499551840537374, 'batch_size': 111, 'num_epochs': 46}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:51:06,341] Trial 17 finished with value: 0.54 and parameters: {'num_channels': [50, 50], 'kernel_size': 3, 'dropout': 0.18974475920159395, 'lr': 0.003085136807973955, 'batch_size': 62, 'num_epochs': 37}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:51:09,832] Trial 18 finished with value: 0.495 and parameters: {'num_channels': [25, 25], 'kernel_size': 4, 'dropout': 0.437629537869752, 'lr': 0.0009052728449056795, 'batch_size': 88, 'num_epochs': 45}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:51:14,829] Trial 19 finished with value: 0.545 and parameters: {'num_channels': [50, 50], 'kernel_size': 3, 'dropout': 0.13745613379312374, 'lr': 0.00021887181626778875, 'batch_size': 58, 'num_epochs': 39}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:51:19,590] Trial 20 finished with value: 0.47 and parameters: {'num_channels': [50, 50], 'kernel_size': 2, 'dropout': 0.1419818802626856, 'lr': 0.0001862675999964602, 'batch_size': 49, 'num_epochs': 38}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:51:24,305] Trial 21 finished with value: 0.52 and parameters: {'num_channels': [50, 50], 'kernel_size': 3, 'dropout': 0.15427163389966153, 'lr': 0.0003891178978025466, 'batch_size': 65, 'num_epochs': 41}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:51:30,552] Trial 22 finished with value: 0.48 and parameters: {'num_channels': [50, 50], 'kernel_size': 3, 'dropout': 0.10133579738404619, 'lr': 0.00016787474366529112, 'batch_size': 47, 'num_epochs': 47}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:51:33,051] Trial 23 finished with value: 0.54 and parameters: {'num_channels': [50, 50], 'kernel_size': 3, 'dropout': 0.223769039222084, 'lr': 0.0016782005870470368, 'batch_size': 113, 'num_epochs': 32}. Best is trial 1 with value: 0.55.\n",
            "[I 2024-06-17 13:51:38,218] Trial 24 finished with value: 0.575 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.27650824033070887, 'lr': 0.000753376832268, 'batch_size': 87, 'num_epochs': 50}. Best is trial 24 with value: 0.575.\n",
            "[I 2024-06-17 13:51:43,337] Trial 25 finished with value: 0.545 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.15875013744038977, 'lr': 0.00025260831134647473, 'batch_size': 79, 'num_epochs': 50}. Best is trial 24 with value: 0.575.\n",
            "[I 2024-06-17 13:51:50,244] Trial 26 finished with value: 0.545 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.21901679479821828, 'lr': 0.0005008752180398596, 'batch_size': 55, 'num_epochs': 46}. Best is trial 24 with value: 0.575.\n",
            "[I 2024-06-17 13:51:52,590] Trial 27 finished with value: 0.5 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.2656912318602248, 'lr': 0.000803703037086264, 'batch_size': 73, 'num_epochs': 23}. Best is trial 24 with value: 0.575.\n",
            "[I 2024-06-17 13:52:00,484] Trial 28 finished with value: 0.45 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.11895812830826588, 'lr': 0.009359830076665252, 'batch_size': 38, 'num_epochs': 48}. Best is trial 24 with value: 0.575.\n",
            "[I 2024-06-17 13:52:03,940] Trial 29 finished with value: 0.515 and parameters: {'num_channels': [25, 50], 'kernel_size': 4, 'dropout': 0.1724443629579266, 'lr': 0.00018637035229501173, 'batch_size': 82, 'num_epochs': 34}. Best is trial 24 with value: 0.575.\n",
            "[I 2024-06-17 13:52:15,411] Trial 30 finished with value: 0.58 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.29601780361898666, 'lr': 0.0003536369913087768, 'batch_size': 19, 'num_epochs': 39}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:52:27,674] Trial 31 finished with value: 0.54 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.3127675817854144, 'lr': 0.00033023680572707634, 'batch_size': 17, 'num_epochs': 38}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:52:31,804] Trial 32 finished with value: 0.535 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.29117654242312974, 'lr': 0.0005161088468980475, 'batch_size': 100, 'num_epochs': 44}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:52:35,914] Trial 33 finished with value: 0.49 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.20894388776338357, 'lr': 0.00010061154090630387, 'batch_size': 93, 'num_epochs': 40}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:52:41,749] Trial 34 finished with value: 0.515 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.23432335984382335, 'lr': 0.00014654902329815228, 'batch_size': 35, 'num_epochs': 33}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:52:54,053] Trial 35 finished with value: 0.52 and parameters: {'num_channels': [25, 50], 'kernel_size': 5, 'dropout': 0.3849339857319353, 'lr': 0.0002374896998509693, 'batch_size': 17, 'num_epochs': 37}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:52:59,091] Trial 36 finished with value: 0.56 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.24977664948387232, 'lr': 0.0003888764360871722, 'batch_size': 69, 'num_epochs': 47}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:04,475] Trial 37 finished with value: 0.54 and parameters: {'num_channels': [25, 50], 'kernel_size': 4, 'dropout': 0.2788370297567145, 'lr': 0.0006349835810652473, 'batch_size': 70, 'num_epochs': 48}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:08,377] Trial 38 finished with value: 0.555 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.2504803248483822, 'lr': 0.00035580787008012484, 'batch_size': 108, 'num_epochs': 42}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:12,074] Trial 39 finished with value: 0.55 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.24819867108417437, 'lr': 0.00038411616704009545, 'batch_size': 116, 'num_epochs': 42}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:17,088] Trial 40 finished with value: 0.53 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.3255650446326666, 'lr': 0.0012808093098690611, 'batch_size': 105, 'num_epochs': 45}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:22,126] Trial 41 finished with value: 0.565 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.2538316987857642, 'lr': 0.00032260016250685366, 'batch_size': 94, 'num_epochs': 50}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:27,804] Trial 42 finished with value: 0.545 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.2504148699038388, 'lr': 0.00031026632027345464, 'batch_size': 86, 'num_epochs': 48}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:32,227] Trial 43 finished with value: 0.57 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.28102310078012027, 'lr': 0.000462446869743003, 'batch_size': 128, 'num_epochs': 50}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:36,657] Trial 44 finished with value: 0.55 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.28344895921067703, 'lr': 0.0005068338686805369, 'batch_size': 117, 'num_epochs': 50}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:41,763] Trial 45 finished with value: 0.575 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.3115925651382623, 'lr': 0.0010178800483428385, 'batch_size': 127, 'num_epochs': 50}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:45,854] Trial 46 finished with value: 0.53 and parameters: {'num_channels': [25, 50], 'kernel_size': 5, 'dropout': 0.34678426730698786, 'lr': 0.0010179636588623522, 'batch_size': 124, 'num_epochs': 50}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:46,789] Trial 47 finished with value: 0.51 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.3045325735341581, 'lr': 0.0006476058189934092, 'batch_size': 127, 'num_epochs': 10}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:50,828] Trial 48 finished with value: 0.535 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.36675284903108774, 'lr': 0.0010921847464708994, 'batch_size': 128, 'num_epochs': 44}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:52,490] Trial 49 finished with value: 0.46 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.3274028988882453, 'lr': 0.0008477994150184155, 'batch_size': 121, 'num_epochs': 13}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:54,360] Trial 50 finished with value: 0.495 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.2724437286930165, 'lr': 0.000745853502842454, 'batch_size': 96, 'num_epochs': 24}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:53:59,737] Trial 51 finished with value: 0.54 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.302932551435587, 'lr': 0.0004559071071515353, 'batch_size': 74, 'num_epochs': 48}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:54:03,984] Trial 52 finished with value: 0.55 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.20329709385676697, 'lr': 0.0006107655314376588, 'batch_size': 102, 'num_epochs': 46}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:54:07,947] Trial 53 finished with value: 0.53 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.25591859912925957, 'lr': 0.0004396240639204882, 'batch_size': 118, 'num_epochs': 47}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:54:13,232] Trial 54 finished with value: 0.52 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.3174335674027617, 'lr': 0.0016542300843885229, 'batch_size': 84, 'num_epochs': 49}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:54:18,426] Trial 55 finished with value: 0.525 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.2814741670477776, 'lr': 0.0002874170635336308, 'batch_size': 91, 'num_epochs': 50}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:54:29,303] Trial 56 finished with value: 0.535 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.23221942463789003, 'lr': 0.0004290469499149048, 'batch_size': 24, 'num_epochs': 44}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:54:33,338] Trial 57 finished with value: 0.575 and parameters: {'num_channels': [25, 25], 'kernel_size': 4, 'dropout': 0.33436927824982776, 'lr': 0.0005747130240040294, 'batch_size': 67, 'num_epochs': 47}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:54:37,245] Trial 58 finished with value: 0.51 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.3686178399263369, 'lr': 0.0005647281943946399, 'batch_size': 77, 'num_epochs': 46}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:54:40,606] Trial 59 finished with value: 0.545 and parameters: {'num_channels': [25, 25], 'kernel_size': 4, 'dropout': 0.3304182762825598, 'lr': 0.0015877967513639975, 'batch_size': 111, 'num_epochs': 49}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:54:46,719] Trial 60 finished with value: 0.565 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.33977407316132285, 'lr': 0.0007573818670476814, 'batch_size': 39, 'num_epochs': 45}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:54:56,278] Trial 61 finished with value: 0.55 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.34335825792015295, 'lr': 0.0009340898875365704, 'batch_size': 23, 'num_epochs': 45}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:01,653] Trial 62 finished with value: 0.525 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.4186438813696409, 'lr': 0.0011089290374971638, 'batch_size': 50, 'num_epochs': 48}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:07,940] Trial 63 finished with value: 0.525 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.3007267670084124, 'lr': 0.0006868921951795119, 'batch_size': 38, 'num_epochs': 43}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:12,131] Trial 64 finished with value: 0.535 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.288867337974456, 'lr': 0.0007289128379848436, 'batch_size': 32, 'num_epochs': 27}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:18,648] Trial 65 finished with value: 0.535 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.33566133804958675, 'lr': 0.002118519767176066, 'batch_size': 43, 'num_epochs': 49}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:23,562] Trial 66 finished with value: 0.535 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.3597192892142523, 'lr': 0.0008765145052144702, 'batch_size': 55, 'num_epochs': 47}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:25,395] Trial 67 finished with value: 0.51 and parameters: {'num_channels': [25, 25], 'kernel_size': 4, 'dropout': 0.3195696888719721, 'lr': 0.000575050565705068, 'batch_size': 67, 'num_epochs': 21}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:30,815] Trial 68 finished with value: 0.535 and parameters: {'num_channels': [25, 50], 'kernel_size': 5, 'dropout': 0.38060208835883413, 'lr': 0.00027869744955793147, 'batch_size': 64, 'num_epochs': 41}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:39,226] Trial 69 finished with value: 0.475 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.47487111967641027, 'lr': 0.0013550100694288236, 'batch_size': 27, 'num_epochs': 46}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:46,135] Trial 70 finished with value: 0.485 and parameters: {'num_channels': [50, 50], 'kernel_size': 2, 'dropout': 0.26544262491252657, 'lr': 0.00021501118837810088, 'batch_size': 44, 'num_epochs': 49}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:51,203] Trial 71 finished with value: 0.525 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.292369781863438, 'lr': 0.0003701589989056139, 'batch_size': 70, 'num_epochs': 47}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:55:56,858] Trial 72 finished with value: 0.54 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.3072852861185274, 'lr': 0.0004769723985843508, 'batch_size': 77, 'num_epochs': 50}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:02,327] Trial 73 finished with value: 0.56 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.24047414498700073, 'lr': 0.0003301203010789369, 'batch_size': 59, 'num_epochs': 44}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:06,623] Trial 74 finished with value: 0.55 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.2168809849918638, 'lr': 0.0007836892099602413, 'batch_size': 125, 'num_epochs': 47}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:10,749] Trial 75 finished with value: 0.53 and parameters: {'num_channels': [50, 50], 'kernel_size': 3, 'dropout': 0.26681208360290654, 'lr': 0.0005402901005450798, 'batch_size': 81, 'num_epochs': 45}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:17,496] Trial 76 finished with value: 0.545 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.27751892567271813, 'lr': 0.00042004428904936735, 'batch_size': 53, 'num_epochs': 49}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:20,904] Trial 77 finished with value: 0.485 and parameters: {'num_channels': [25, 50], 'kernel_size': 5, 'dropout': 0.3373519167618334, 'lr': 0.0002960825253707847, 'batch_size': 88, 'num_epochs': 31}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:25,579] Trial 78 finished with value: 0.535 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.2581021342205343, 'lr': 0.0011142949221947984, 'batch_size': 68, 'num_epochs': 43}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:28,512] Trial 79 finished with value: 0.555 and parameters: {'num_channels': [25, 25], 'kernel_size': 3, 'dropout': 0.29598257117845883, 'lr': 0.000371362464265334, 'batch_size': 120, 'num_epochs': 48}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:33,747] Trial 80 finished with value: 0.48 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.35310074665174496, 'lr': 0.003435639535156345, 'batch_size': 61, 'num_epochs': 36}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:38,758] Trial 81 finished with value: 0.555 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.24196366739361072, 'lr': 0.00031503819173609316, 'batch_size': 58, 'num_epochs': 41}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:44,437] Trial 82 finished with value: 0.525 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.31625382874465796, 'lr': 0.00034894491016628903, 'batch_size': 64, 'num_epochs': 45}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:48,913] Trial 83 finished with value: 0.5 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.23997006213086952, 'lr': 0.00020309300113334263, 'batch_size': 75, 'num_epochs': 44}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:56:55,492] Trial 84 finished with value: 0.545 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.17293443963480884, 'lr': 0.00026799638695685913, 'batch_size': 60, 'num_epochs': 50}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:57:04,134] Trial 85 finished with value: 0.54 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.22457637673646325, 'lr': 0.0006149786245548103, 'batch_size': 31, 'num_epochs': 46}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:57:10,350] Trial 86 finished with value: 0.515 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.25830420721928227, 'lr': 0.0002459781488975148, 'batch_size': 70, 'num_epochs': 47}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:57:16,944] Trial 87 finished with value: 0.555 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.27517967570240315, 'lr': 0.0004884668875248586, 'batch_size': 41, 'num_epochs': 39}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:57:29,912] Trial 88 finished with value: 0.555 and parameters: {'num_channels': [50, 50], 'kernel_size': 4, 'dropout': 0.3092916703892701, 'lr': 0.0003336298570496615, 'batch_size': 20, 'num_epochs': 48}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:57:37,946] Trial 89 finished with value: 0.525 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.28580932684067695, 'lr': 0.00041386753639917334, 'batch_size': 49, 'num_epochs': 50}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:57:41,357] Trial 90 finished with value: 0.515 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.24161316385266549, 'lr': 0.0001576475680757002, 'batch_size': 80, 'num_epochs': 42}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:57:45,929] Trial 91 finished with value: 0.54 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.2479770272908272, 'lr': 0.0009593061428358901, 'batch_size': 103, 'num_epochs': 42}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:57:50,151] Trial 92 finished with value: 0.515 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.2278844772856361, 'lr': 0.00034906968784321514, 'batch_size': 114, 'num_epochs': 44}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:57:54,489] Trial 93 finished with value: 0.515 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.19722293216328088, 'lr': 0.00044455658155341884, 'batch_size': 122, 'num_epochs': 48}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:57:59,690] Trial 94 finished with value: 0.535 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.27081011347477363, 'lr': 0.0006631126203186853, 'batch_size': 96, 'num_epochs': 46}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:58:03,592] Trial 95 finished with value: 0.55 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.2573869334288953, 'lr': 0.0004936018619023418, 'batch_size': 110, 'num_epochs': 40}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:58:08,473] Trial 96 finished with value: 0.54 and parameters: {'num_channels': [25, 50], 'kernel_size': 4, 'dropout': 0.29712235330515363, 'lr': 0.0005628710317118581, 'batch_size': 85, 'num_epochs': 49}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:58:13,137] Trial 97 finished with value: 0.515 and parameters: {'num_channels': [50, 50], 'kernel_size': 5, 'dropout': 0.21537516638791346, 'lr': 0.0003883158088803127, 'batch_size': 92, 'num_epochs': 43}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:58:16,165] Trial 98 finished with value: 0.505 and parameters: {'num_channels': [25, 25], 'kernel_size': 5, 'dropout': 0.3227960472913607, 'lr': 0.0007862913897381354, 'batch_size': 125, 'num_epochs': 45}. Best is trial 30 with value: 0.58.\n",
            "[I 2024-06-17 13:58:20,018] Trial 99 finished with value: 0.545 and parameters: {'num_channels': [50, 50], 'kernel_size': 3, 'dropout': 0.24750187343862703, 'lr': 0.00023131788518215076, 'batch_size': 108, 'num_epochs': 47}. Best is trial 30 with value: 0.58.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "  Accuracy: 0.58\n",
            "  Params: \n",
            "    num_channels: [50, 50]\n",
            "    kernel_size: 5\n",
            "    dropout: 0.29601780361898666\n",
            "    lr: 0.0003536369913087768\n",
            "    batch_size: 19\n",
            "    num_epochs: 39\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "class TCNModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_channels, kernel_size, dropout):\n",
        "        super(TCNModel, self).__init__()\n",
        "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout)\n",
        "        self.linear = nn.Linear(num_channels[-1], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.tcn(x)\n",
        "        o = self.linear(y1[:, :, -1])\n",
        "        return F.log_softmax(o, dim=1)\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    return accuracy, test_loss\n",
        "\n",
        "# Define the Optuna objective function\n",
        "def objective(trial):\n",
        "    # Hyperparameters to tune\n",
        "    num_channels = trial.suggest_categorical('num_channels', [[25, 25], [50, 50], [25, 50]])\n",
        "    kernel_size = trial.suggest_int('kernel_size', 2, 5)\n",
        "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
        "    lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
        "    batch_size = trial.suggest_int('batch_size', 16, 128)\n",
        "    num_epochs = trial.suggest_int('num_epochs', 10, 50)\n",
        "\n",
        "    # Create the model\n",
        "    model = TCNModel(input_size=8, num_classes=2, num_channels=num_channels, kernel_size=kernel_size, dropout=dropout)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Train the model\n",
        "    model = train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, test_loss = evaluate_model(model, test_loader, criterion)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Example data preparation\n",
        "# Replace this with your actual data\n",
        "X = np.random.rand(1000, 8, 10).astype(np.float32)  # (samples, features, sequence_length)\n",
        "y = np.random.randint(0, 2, 1000).astype(np.int64)  # Binary classification\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train)\n",
        "X_test = torch.tensor(X_test)\n",
        "y_train = torch.tensor(y_train)\n",
        "y_test = torch.tensor(y_test)\n",
        "\n",
        "# Create Optuna study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Print best trial\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(f\"  Accuracy: {trial.value}\")\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPRGIUtVj2lm"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny--FohoMVv-",
        "outputId": "26a1bc50-67e1-4db0-9314-3e5675ba3bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1           nan  8.8732\n",
            "      2           nan  8.9471\n",
            "      3           nan  8.7001\n",
            "      4           nan  8.6113\n",
            "      5           nan  8.9404\n",
            "      6           nan  8.7870\n",
            "      7           nan  9.2962\n",
            "      8           nan  9.2843\n",
            "      9           nan  9.1291\n",
            "     10           nan  8.9689\n",
            "     11           nan  9.1427\n",
            "     12           nan  8.4416\n",
            "     13           nan  9.3126\n",
            "     14           nan  8.9970\n",
            "     15           nan  8.3409\n",
            "     16           nan  9.2183\n",
            "     17           nan  8.9686\n",
            "     18           nan  8.2498\n",
            "     19           nan  9.1991\n",
            "     20           nan  8.7335\n",
            "Test Accuracy: 0.1379\n",
            "Test F1-score: 0.0000\n",
            "Test MCC: 0.0000\n"
          ]
        }
      ],
      "source": [
        "X_train = torch.tensor(train_dataset, dtype=torch.float32).unsqueeze(1)\n",
        "X_test = torch.tensor(test_dataset, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "y_train = torch.tensor(training_labels, dtype=torch.long)\n",
        "y_test = torch.tensor(testing_labels, dtype=torch.long)\n",
        "\n",
        "# Step 4: Train the model\n",
        "# Define the model parameters\n",
        "input_size = 1  # Number of input channels\n",
        "num_classes = 2  # Binary classification\n",
        "num_channels = [25, 25, 25]  # Number of filters for each TCN layer\n",
        "kernel_size = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Create the TCN model\n",
        "model = NeuralNetClassifier(\n",
        "    TCNModel,\n",
        "    module__input_size=input_size,\n",
        "    module__num_classes=num_classes,\n",
        "    module__num_channels=num_channels,\n",
        "    module__kernel_size=kernel_size,\n",
        "    module__dropout=dropout,\n",
        "    max_epochs=20,\n",
        "    lr=0.001,\n",
        "    iterator_train__shuffle=True,\n",
        "    train_split=None,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "# Get predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='binary')\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test F1-score: {f1:.4f}\")\n",
        "print(f\"Test MCC: {mcc:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Bvh1CAmlSd82",
        "ydyh-KnUWTNV",
        "xWEHw1DOYWmX",
        "-tgM9DaT4iGC",
        "08-efAVMAMpe",
        "E76ef8-KUQkP"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}