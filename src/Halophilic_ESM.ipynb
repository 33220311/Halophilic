{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QAqZ7e1w3Bu2",
        "outputId": "709041e7-2ccd-4b13-f79c-197209278bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.12\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.26)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.37.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.43.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.11.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.12.0 numpy-1.23.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "580a4316acd9419290fd27effa6513a3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install tensorflow==2.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WPNiAieUpmU"
      },
      "source": [
        "## Prerequisite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqvolxWQx8uC",
        "outputId": "b8d0bdcc-3272-4f48-b5bf-f801b54a912d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/159.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m153.6/159.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71NgultbyHY3",
        "outputId": "8b794c81-0e8b-46cc-dd4c-ab40708e8cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-evaluation\n",
            "  Downloading sklearn_evaluation-0.12.1-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.2/111.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ploomber-core>=0.2.6 (from sklearn-evaluation)\n",
            "  Downloading ploomber_core-0.2.25-py3-none-any.whl (22 kB)\n",
            "Collecting ploomber-extension (from sklearn-evaluation)\n",
            "  Downloading ploomber_extension-0.1.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (3.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (4.4.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (0.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (3.1.4)\n",
            "Requirement already satisfied: mistune in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (0.8.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (2.0.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (5.10.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (7.34.0)\n",
            "Collecting black (from sklearn-evaluation)\n",
            "  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso in /usr/local/lib/python3.10/dist-packages (from sklearn-evaluation) (0.8.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ploomber-core>=0.2.6->sklearn-evaluation) (6.0.1)\n",
            "Collecting posthog (from ploomber-core>=0.2.6->sklearn-evaluation)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->sklearn-evaluation)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (24.1)\n",
            "Collecting pathspec>=0.9.0 (from black->sklearn-evaluation)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->sklearn-evaluation) (4.12.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->sklearn-evaluation)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->sklearn-evaluation) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->sklearn-evaluation) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (1.23.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->sklearn-evaluation) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->sklearn-evaluation) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->sklearn-evaluation) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->sklearn-evaluation) (5.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sklearn-evaluation) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sklearn-evaluation) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-evaluation) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-evaluation) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-evaluation) (3.5.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->sklearn-evaluation) (0.18.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->sklearn-evaluation) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->sklearn-evaluation) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->sklearn-evaluation) (1.16.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from posthog->ploomber-core>=0.2.6->sklearn-evaluation) (2.31.0)\n",
            "Collecting monotonic>=1.5 (from posthog->ploomber-core>=0.2.6->sklearn-evaluation)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->ploomber-core>=0.2.6->sklearn-evaluation)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.6->sklearn-evaluation) (2024.6.2)\n",
            "Installing collected packages: monotonic, pathspec, mypy-extensions, jedi, backoff, posthog, black, ploomber-core, ploomber-extension, sklearn-evaluation\n",
            "Successfully installed backoff-2.2.1 black-24.4.2 jedi-0.19.1 monotonic-1.6 mypy-extensions-1.0.0 pathspec-0.12.1 ploomber-core-0.2.25 ploomber-extension-0.1.1 posthog-3.5.0 sklearn-evaluation-0.12.1\n"
          ]
        }
      ],
      "source": [
        "pip install sklearn-evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoTuyH3VsxAI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data utilities\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "import torch\n",
        "import h5py\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, make_scorer, f1_score, recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za3QBj3Z-UpS"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFMl0ZAH-UpT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOHIvuD4ZMKw",
        "outputId": "7120aabd-b902-4167-8a19-a471e187a60c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-17 01:18:38--  https://raw.githubusercontent.com/33220311/halophilic/main/dataset/haloAdd.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1362849 (1.3M) [text/plain]\n",
            "Saving to: ‘haloAdd.csv’\n",
            "\n",
            "haloAdd.csv         100%[===================>]   1.30M  6.12MB/s    in 0.2s    \n",
            "\n",
            "2024-06-17 01:18:38 (6.12 MB/s) - ‘haloAdd.csv’ saved [1362849/1362849]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/33220311/halophilic/main/dataset/haloAdd.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P966jTOzoA-W",
        "outputId": "3d95bca2-a182-4c44-a666-1f0b0185b9eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydyh-KnUWTNV"
      },
      "source": [
        "## Utility Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MIcQL7TV7AE"
      },
      "outputs": [],
      "source": [
        "# Utility function: plot model's accuracy and loss\n",
        "\n",
        "# https://realpython.com/python-keras-text-classification/\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  x = range(1, len(acc) + 1)\n",
        "\n",
        "  plt.figure(figsize=(12, 5))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(x, acc, 'b', label='Training acc')\n",
        "  plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(x, loss, 'b', label='Training loss')\n",
        "  plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1miZbCjfWcl3"
      },
      "outputs": [],
      "source": [
        "# Utility function: Display model score(Loss & Accuracy) across all sets.\n",
        "\n",
        "def display_model_score(model, train, val, test, batch_size):\n",
        "\n",
        "  train_score = model.evaluate(train[0], train[1], batch_size=batch_size, verbose=1)\n",
        "  print('Train loss: ', train_score[0])\n",
        "  print('Train accuracy: ', train_score[1])\n",
        "  print('-'*70)\n",
        "\n",
        "  val_score = model.evaluate(val[0], val[1], batch_size=batch_size, verbose=1)\n",
        "  print('Val loss: ', val_score[0])\n",
        "  print('Val accuracy: ', val_score[1])\n",
        "  print('-'*70)\n",
        "\n",
        "  test_score = model.evaluate(test[0], test[1], batch_size=batch_size, verbose=1)\n",
        "  print('Test loss: ', test_score[0])\n",
        "  print('Test accuracy: ', test_score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1We_4nA3VGCl"
      },
      "outputs": [],
      "source": [
        "def equal_error_rate(y_true, y_pred):\n",
        "    n_imp = tf.count_nonzero(tf.equal(y_true, 0), dtype=tf.float32) + tf.constant(K.epsilon())\n",
        "    n_gen = tf.count_nonzero(tf.equal(y_true, 1), dtype=tf.float32) + tf.constant(K.epsilon())\n",
        "\n",
        "    scores_imp = tf.boolean_mask(y_pred, tf.equal(y_true, 0))\n",
        "    scores_gen = tf.boolean_mask(y_pred, tf.equal(y_true, 1))\n",
        "\n",
        "    loop_vars = (tf.constant(0.0), tf.constant(1.0), tf.constant(0.0))\n",
        "    cond = lambda t, fpr, fnr: tf.greater_equal(fpr, fnr)\n",
        "    body = lambda t, fpr, fnr: (\n",
        "        t + 0.001,\n",
        "        tf.divide(tf.count_nonzero(tf.greater_equal(scores_imp, t), dtype=tf.float32), n_imp),\n",
        "        tf.divide(tf.count_nonzero(tf.less(scores_gen, t), dtype=tf.float32), n_gen)\n",
        "    )\n",
        "    t, fpr, fnr = tf.while_loop(cond, body, loop_vars, back_prop=False)\n",
        "    eer = (fpr + fnr) / 2\n",
        "\n",
        "    return eer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)"
      ],
      "metadata": {
        "id": "WVYm4alJwGDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsbWeA0qjBvb"
      },
      "outputs": [],
      "source": [
        "def error_rate(testing_labels, predicted_testing_labels):\n",
        "    from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score, classification_report, recall_score, confusion_matrix\n",
        "    import numpy as np\n",
        "\n",
        "    bootstrap_performances = list()\n",
        "    performances = list()\n",
        "    f1_performances = list()\n",
        "    sn = list()\n",
        "    sp = list()\n",
        "    Y = np.array(testing_labels)  # convert list of groundtruths to numpy\n",
        "    Yhat = np.array(predicted_testing_labels)  # same same for predictions\n",
        "    n_samples = len(Y)  # get number of samples\n",
        "    n_bootstrap = 1000  # number of bootstrap iterations\n",
        "\n",
        "    for i in range(n_bootstrap):  # for each bootstrap draw\n",
        "        subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        # create a random subset of your predictions/targets with replacement\n",
        "        Y_subset = Y[subset]\n",
        "        Yhat_subset = Yhat[subset]\n",
        "\n",
        "        bootstrap_performances.append(matthews_corrcoef(Y_subset, Yhat_subset))\n",
        "        performances.append(accuracy_score(Y_subset, Yhat_subset))\n",
        "        f1_performances.append(f1_score(Y_subset, Yhat_subset))\n",
        "        sn.append(recall_score(Y_subset, Yhat_subset))\n",
        "\n",
        "        tn, fp, fn, tp = confusion_matrix(Y_subset, Yhat_subset).ravel()\n",
        "        sp.append(tn / (tn + fp))\n",
        "\n",
        "    sd_mcc = np.std(bootstrap_performances)  # compute std deviation over the bootstrapped performances\n",
        "    sd_acc = np.std(performances)\n",
        "    sd_f1 = np.std(f1_performances)\n",
        "    sd_sn = np.std(sn)\n",
        "    sd_sp = np.std(sp)\n",
        "\n",
        "    print('acc:', accuracy_score(testing_labels, predicted_testing_labels))\n",
        "    print('f1:', f1_score(testing_labels, predicted_testing_labels))\n",
        "    print('mcc:', matthews_corrcoef(testing_labels, predicted_testing_labels))\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(testing_labels, predicted_testing_labels).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    print('sn:', recall_score(testing_labels, predicted_testing_labels))\n",
        "    print('sp:', specificity)\n",
        "    print('sd_acc:', sd_acc)\n",
        "    print('sd_f1:', sd_f1)\n",
        "    print('sd_mcc:', sd_mcc)\n",
        "    print('sd_sn:', sd_sn)\n",
        "    print('sd_sp:', sd_sp)\n",
        "    print(classification_report(testing_labels, predicted_testing_labels))\n",
        "\n",
        "    return (sd_acc, sd_mcc, sd_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqLP-ppCjBzo"
      },
      "outputs": [],
      "source": [
        "def conf_matrix(confusion_matrix_data):\n",
        "  from mlxtend.plotting import plot_confusion_matrix\n",
        "  fig, ax = plot_confusion_matrix(conf_mat =confusion_matrix_data,\n",
        "                                show_absolute=True,\n",
        "                                show_normed=True,\n",
        "                                #display_labels=class_dict.values(),\n",
        "                                colorbar=True)\n",
        "  labels = ['Non-halophilic', 'Halophilic']\n",
        "  ax.set_xticklabels([''] + labels)\n",
        "  ax.set_yticklabels([''] + labels)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XavwyLrcdU4U"
      },
      "outputs": [],
      "source": [
        "def mcc(clf,X,y):\n",
        "  y_pred = clf.predict(X)\n",
        "  mcc = matthews_corrcoef(y, y_pred)\n",
        "  return mcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc5nx-ieqhNl"
      },
      "outputs": [],
      "source": [
        "def matthews_correlation_coefficient(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
        "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
        "\n",
        "    num = tp * tn - fp * fn\n",
        "    den = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
        "    return num / K.sqrt(den + K.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSzDAX6FdU5Y"
      },
      "outputs": [],
      "source": [
        "def std_acc(clf,X,y):\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  import numpy as np\n",
        "\n",
        "  bootstrap_performances = list()\n",
        "  performances = list()\n",
        "  y_pred = clf.predict(X)\n",
        "  Y = np.array(y) # convert list of groundtruths to numpy\n",
        "  Yhat = np.array(y_pred) # same same for predictions\n",
        "  n_samples = len(Y) # get number of samples\n",
        "  n_bootstrap = 1000 # number of bootstrap iterations\n",
        "  for i in range(n_bootstrap): # for each bootstrap draw\n",
        "    subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    # create a random subset of your predictions/targets with replacement (this line will only generate the indices for list elements and the line below will grab the random subset with replacement\n",
        "    bootstrap_performances.append( accuracy_score(y[subset], y_pred[subset]) )\n",
        "  sd_acc = np.std(bootstrap_performances)*1.96\n",
        "  return sd_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ9ZtjhDdU-H"
      },
      "outputs": [],
      "source": [
        "def std_f1(clf,X,y):\n",
        "  from sklearn.metrics import f1_score\n",
        "  import numpy as np\n",
        "\n",
        "  bootstrap_performances = list()\n",
        "  performances = list()\n",
        "  y_pred = clf.predict(X)\n",
        "  Y = np.array(y) # convert list of groundtruths to numpy\n",
        "  Yhat = np.array(y_pred) # same same for predictions\n",
        "  n_samples = len(Y) # get number of samples\n",
        "  n_bootstrap = 1000 # number of bootstrap iterations\n",
        "  for i in range(n_bootstrap): # for each bootstrap draw\n",
        "    subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    # create a random subset of your predictions/targets with replacement (this line will only generate the indices for list elements and the line below will grab the random subset with replacement\n",
        "    bootstrap_performances.append(f1_score(y[subset], y_pred[subset]) )\n",
        "  sd_f1 = np.std(bootstrap_performances)*1.96\n",
        "  return sd_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-S1nxizddNL"
      },
      "outputs": [],
      "source": [
        "def std_mcc(clf,X,y):\n",
        "  from sklearn.metrics import matthews_corrcoef\n",
        "  import numpy as np\n",
        "\n",
        "  bootstrap_performances = list()\n",
        "  performances = list()\n",
        "  y_pred = clf.predict(X)\n",
        "  Y = np.array(y) # convert list of groundtruths to numpy\n",
        "  Yhat = np.array(y_pred) # same same for predictions\n",
        "  n_samples = len(Y) # get number of samples\n",
        "  n_bootstrap = 1000 # number of bootstrap iterations\n",
        "  for i in range(n_bootstrap): # for each bootstrap draw\n",
        "    subset = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    # create a random subset of your predictions/targets with replacement (this line will only generate the indices for list elements and the line below will grab the random subset with replacement\n",
        "    bootstrap_performances.append(matthews_corrcoef(y[subset], y_pred[subset]) )\n",
        "  sd_mcc = np.std(bootstrap_performances)*1.96\n",
        "  return sd_mcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uwtmn_rzkoKW"
      },
      "outputs": [],
      "source": [
        "def sp():\n",
        "  TP = confusion_matrix_data[1,1]\n",
        "  TN = confusion_matrix_data[0,0]\n",
        "  FP = confusion_matrix_data[0,1]\n",
        "  FN = confusion_matrix_data[1,0]\n",
        "\n",
        "  print(TP,TN, FP, FN)\n",
        "\n",
        "  sn = TP / float(TP + FN)\n",
        "  print(sn)\n",
        "  sp = TN / float(TN + FP)\n",
        "  print(sp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrEQOWRAufE"
      },
      "source": [
        "## Open embedding file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn6qNd85C6bx"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Halophilic/ESM2_3B_HaloAdd' #/content/drive/MyDrive/Halophilic/ESM2_650M' #'/content/drive/MyDrive/Halophilic/ESM2_3B/' #'/content/drive/MyDrive/HalophilicESM2'\n",
        "suffix = '.pt'\n",
        "delete = []\n",
        "embeddings = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8A4aZOotEMQ"
      },
      "outputs": [],
      "source": [
        "proteins = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbmWbEHi3_gX"
      },
      "outputs": [],
      "source": [
        "#!rsync -av /content/drive/MyDrive/Halophilic/ESM2_3B_HaloAdd/ /content/drive/MyDrive/Multiclass/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRk2F-gOiKFn",
        "outputId": "e37e9764-9ec4-48d5-82e3-55f5b4a9e43f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-17 01:20:38--  https://raw.githubusercontent.com/33220311/halophilic/main/dataset/Halo80.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 933288 (911K) [text/plain]\n",
            "Saving to: ‘Halo80.csv’\n",
            "\n",
            "Halo80.csv          100%[===================>] 911.41K  4.77MB/s    in 0.2s    \n",
            "\n",
            "2024-06-17 01:20:39 (4.77 MB/s) - ‘Halo80.csv’ saved [933288/933288]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/33220311/halophilic/main/dataset/Halo80.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is49LNrGi6HP",
        "outputId": "58b1bb31-c6d4-4252-d9a1-ae53fac297e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-17 01:20:40--  https://raw.githubusercontent.com/33220311/halophilic/main/dataset/Halo60.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 794406 (776K) [text/plain]\n",
            "Saving to: ‘Halo60.csv’\n",
            "\n",
            "Halo60.csv          100%[===================>] 775.79K  4.20MB/s    in 0.2s    \n",
            "\n",
            "2024-06-17 01:20:40 (4.20 MB/s) - ‘Halo60.csv’ saved [794406/794406]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/33220311/halophilic/main/dataset/Halo60.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go1azOLBkaPM",
        "outputId": "3fd6b5e3-f666-49c3-9493-b61788bb5f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-17 01:20:40--  https://raw.githubusercontent.com/33220311/halophilic/main/dataset/Halo40.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 686703 (671K) [text/plain]\n",
            "Saving to: ‘Halo40.csv’\n",
            "\n",
            "Halo40.csv          100%[===================>] 670.61K  3.72MB/s    in 0.2s    \n",
            "\n",
            "2024-06-17 01:20:41 (3.72 MB/s) - ‘Halo40.csv’ saved [686703/686703]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/33220311/halophilic/main/dataset/Halo40.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LMbmybnlBwh",
        "outputId": "44af4799-5eab-4e65-e1f2-2591bc69c905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-17 01:20:41--  https://raw.githubusercontent.com/33220311/halophilic/main/dataset/Halo20.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 601036 (587K) [text/plain]\n",
            "Saving to: ‘Halo20.csv’\n",
            "\n",
            "Halo20.csv          100%[===================>] 586.95K  3.57MB/s    in 0.2s    \n",
            "\n",
            "2024-06-17 01:20:42 (3.57 MB/s) - ‘Halo20.csv’ saved [601036/601036]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/33220311/halophilic/main/dataset/Halo20.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfNnO9qltX6v",
        "outputId": "59da4477-1138-4aba-b77d-6d178af8249f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-17 01:20:42--  https://raw.githubusercontent.com/33220311/halophilic/main/dataset/haloAdd.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1362849 (1.3M) [text/plain]\n",
            "Saving to: ‘haloAdd.csv.1’\n",
            "\n",
            "haloAdd.csv.1       100%[===================>]   1.30M  6.07MB/s    in 0.2s    \n",
            "\n",
            "2024-06-17 01:20:42 (6.07 MB/s) - ‘haloAdd.csv.1’ saved [1362849/1362849]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Basic Protocol 3 — Step 5\n",
        "!wget https://raw.githubusercontent.com/33220311/halophilic/main/dataset/haloAdd.csv\n",
        "#!wget https://raw.githubusercontent.com/33220311/halophilic/main/haloNath.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgarygHFHd4J",
        "outputId": "284a2b04-4417-4392-b968-669780d6bde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-17 01:20:42--  https://raw.githubusercontent.com/33220311/halophilic/main/dataset/Halo-Hidrofob.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46407 (45K) [text/plain]\n",
            "Saving to: ‘Halo-Hidrofob.csv’\n",
            "\n",
            "Halo-Hidrofob.csv   100%[===================>]  45.32K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-06-17 01:20:43 (1.03 MB/s) - ‘Halo-Hidrofob.csv’ saved [46407/46407]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/33220311/halophilic/main/dataset/Halo-Hidrofob.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBRdJZbcnZ7Y"
      },
      "outputs": [],
      "source": [
        "annotations = read_csv('haloAdd.csv')#('haloAdd.csv')#('uniqueAnnotations1024.csv')\n",
        "#annotations = read_csv('annotationsUnique.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "t36iDvOQti9m",
        "outputId": "63a47b0a-fadd-4e76-c028-135e51129de5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  identifier                                           sequence  label    set\n",
              "0   QSG09462  MRFFDRLAERIDAVDSVVSVGLDPDPDRLPESVADADLPRFQFNRR...      1  train\n",
              "1   QSG11440  MTRVIHTGDTHLGYQQYHEPARREDFLSAFRQVIEDAVAEDVDAVV...      1  train\n",
              "2   BCB06597  MLRVAITERPQWRELAHQLGFHFHTIEGEPYWTEDAYYQFTLTQIE...      1  train"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71fb2d08-e9d2-4a46-b888-4202e1ba6bcd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>identifier</th>\n",
              "      <th>sequence</th>\n",
              "      <th>label</th>\n",
              "      <th>set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>QSG09462</td>\n",
              "      <td>MRFFDRLAERIDAVDSVVSVGLDPDPDRLPESVADADLPRFQFNRR...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>QSG11440</td>\n",
              "      <td>MTRVIHTGDTHLGYQQYHEPARREDFLSAFRQVIEDAVAEDVDAVV...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BCB06597</td>\n",
              "      <td>MLRVAITERPQWRELAHQLGFHFHTIEGEPYWTEDAYYQFTLTQIE...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71fb2d08-e9d2-4a46-b888-4202e1ba6bcd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71fb2d08-e9d2-4a46-b888-4202e1ba6bcd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71fb2d08-e9d2-4a46-b888-4202e1ba6bcd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1cc1010-58d7-4b1c-ad99-4ba229b39c38\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1cc1010-58d7-4b1c-ad99-4ba229b39c38')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1cc1010-58d7-4b1c-ad99-4ba229b39c38 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"annotations[:3]\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"identifier\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"QSG09462\",\n          \"QSG11440\",\n          \"BCB06597\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"MRFFDRLAERIDAVDSVVSVGLDPDPDRLPESVADADLPRFQFNRRIIDATHEHAACYKPNAAFYEGPDGWAALEETIAYAHGKGVPVLLDAKRGDIGNTARQYASALDPDGLDADAITVNPYLGRDSLEPFLQREDNGVFVLGRTSNPGGADLQDLELATGEPLYERVAALADLWNDNDNVGLVVGATNLDELQSIREAVPDLPFLVPGVGAQGGDAEAAVEHGLVEWDGPEASGLDVGLVNSSRGIIFAGEEARGDADAYFGAAGQAARQLAARLEQFR\",\n          \"MTRVIHTGDTHLGYQQYHEPARREDFLSAFRQVIEDAVAEDVDAVVHAGDLFHDRRPGLADIMGTLSVLRTLEDASIPFLAIVGNHETKRDAQWLDLFESLGLATRLGAEPVTIDGTAFYGLDYVPKSQRSSLAYDFEPNDADHAALVAHGLFQPFDHGDWDAEAVLAESPVDFDAMLLGDDHTPKRAEVGDTWLTYCGSTERTSGSERDDRGYNLVTFDEGVDIRRRGLPTREFVFVDVALEAGEGYGRVRDRVLQHDLEDAVVIVTIEGDGEPITPAEVETVALEDGALVARVNDRREIEPDEEVSVSFADPDDAVRERIRELGLSPAARDIDETVRASKVADSNVADRVQQRVAGIVEQADPGAFEAAEGEPDAASSDDASDTGSAEVAQSDGDGQATMEEYL\",\n          \"MLRVAITERPQWRELAHQLGFHFHTIEGEPYWTEDAYYQFTLTQIEQDIEDPTEALHEMCMDAVDRVCQSDALLHQLNIPAQMWGVIRASWRNGQPHLYGRMDFAYSGNGPAKLLELNYDTPTSIYEAGFFQWLWLEQVIEQRLLPAHADQYNSIQERMIAALAHIGQRLERDPPASPALHFASIKAHEEDRATVAYLQDCALQAGLNAPFIHIEDIGYQPNTGHGCFVDLENRPIRALFKLYPWEEMSDDLFGELLPMMQTHWFEPPWKAILSNKGILPLLWQWHEGHPNLLPAYFDTSDGTSLTPGWVRKPFFSREGSNIELMTTSGQYEAVDGPYTDNPRILQAYHPLPRFGERHALIGSWVVGDKACGIGIREDVGKITKDSSCFVPHAIV\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "annotations[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eScyOlMFtGjH"
      },
      "outputs": [],
      "source": [
        "for filename in annotations.identifier:\n",
        "    file = os.path.join(path, filename + suffix)\n",
        "    if (os.path.exists(file)):\n",
        "      result = torch.load(file)\n",
        "      rep = result.get('mean_representations')\n",
        "      val = rep.values()\n",
        "      val = list(val)\n",
        "      val = np.array(val[0])\n",
        "      val = np.reshape(val,(-1,1280))\n",
        "      proteins.append((filename,val))\n",
        "    else:\n",
        "      delete.append(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZdiQLZSDs8A"
      },
      "outputs": [],
      "source": [
        "#proteins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdwva6fUtkxW"
      },
      "outputs": [],
      "source": [
        "# Basic Protocol 3 — Step 6\n",
        "train_set = annotations[annotations.set == \"train\"]\n",
        "test_set = annotations[annotations.set == \"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsPlLP3utmt0",
        "outputId": "7e1e2c65-4249-44c3-da21-e690c9f2dcdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The train set contains 5670 samples, and we will test on 1356 samples.\n"
          ]
        }
      ],
      "source": [
        "print(f\"The train set contains {len(train_set)} samples, and we will test on {len(test_set)} samples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN1PpTc3tw-o",
        "outputId": "44757cfc-28d2-4e9f-c629-13a6eb53c27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5670\n",
            "5670\n"
          ]
        }
      ],
      "source": [
        "# Basic Protocol 3 — Step 7\n",
        "\n",
        "training_identifiers = train_set.identifier.values\n",
        "training_labels = train_set.label.values\n",
        "print(len(training_identifiers))\n",
        "print(len(training_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfK4RZisuE63",
        "outputId": "bffca60d-b199-4efe-ef84-47bdff03a63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1356\n",
            "1356\n"
          ]
        }
      ],
      "source": [
        "testing_identifiers = test_set.identifier.values\n",
        "testing_labels = test_set.label.values\n",
        "print(len(testing_identifiers))\n",
        "print(len(testing_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeo0RsDewH6e"
      },
      "outputs": [],
      "source": [
        "seq = dict(proteins)\n",
        "delete = list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw7Gs-Ovu1gR"
      },
      "outputs": [],
      "source": [
        "training_embeddings = list()\n",
        "for identifier in training_identifiers:\n",
        "        if identifier in seq:\n",
        "            embedding = seq[identifier]\n",
        "            training_embeddings.append(embedding)\n",
        "        else:\n",
        "          delete.append(identifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu95EwOVxceu"
      },
      "outputs": [],
      "source": [
        "testing_embeddings = list()\n",
        "for identifier in testing_identifiers:\n",
        "        if identifier in seq:\n",
        "            embedding = seq[identifier]\n",
        "            testing_embeddings.append(embedding)\n",
        "        else:\n",
        "          delete.append(identifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBgbhAESPht-",
        "outputId": "087652a4-39ce-4f19-a1af-22b1d2ca41e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64),)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "np.where(training_identifiers=='Mes206')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdfBRxkLQytb"
      },
      "outputs": [],
      "source": [
        "#training_identifiers = np.delete(training_identifiers,4728)\n",
        "#training_labels = np.delete(training_labels,4728)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVpB7hTIPlG8",
        "outputId": "fc0c299a-ca28-490b-96d5-4173c3798fc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5670"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "len(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLHzaARbS5wx",
        "outputId": "6f910e17-fde9-4e77-9edb-69d5a356ccf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5670"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "len(training_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq2HsFdtxkpE"
      },
      "outputs": [],
      "source": [
        "1024# A sanity check: make sure that the numbers are equal!\n",
        "assert(len(training_identifiers) == len(training_embeddings))\n",
        "assert(len(testing_identifiers) == len(testing_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJsKdxddnhMO",
        "outputId": "740bd154-b690-456b-9e1c-84f35b9446f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5670"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "len(training_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K3zQYOh3xiC",
        "outputId": "4bd9697e-6e74-45b7-eae1-11eccce659be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "delete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZOHJFqNvNsJ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RjStFxt_YIq",
        "outputId": "f6a62f48-8691-4474-b6ce-26eddb98cfa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5670, 2560)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "arr_train = np.array(training_embeddings)\n",
        "nsample, nx, ny = arr_train.shape\n",
        "train_dataset = arr_train.reshape((nsample, nx*ny))\n",
        "train_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwtSoASGAPK8",
        "outputId": "cb8a1930-c152-4ca7-91a3-9013486ec203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1356, 2560)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "arr_test = np.array(testing_embeddings)\n",
        "nsample, nx, ny = arr_test.shape\n",
        "test_dataset = arr_test.reshape((nsample, nx*ny))\n",
        "test_dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eEXVSpeI8Un"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6VLSupfI-mW"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPuwO3lT6h93"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7cjQl3Y6h9_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVSgV_nzJAGf",
        "outputId": "c1269847-8c50-4f42-e990-17851ac9050e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.911504424778761"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "lr = LogisticRegression()\n",
        "lr_history = lr.fit(train_dataset, training_labels)\n",
        "lr.score(test_dataset,testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBU9Ctc7diSv"
      },
      "outputs": [],
      "source": [
        "#grid_scorer = {'accuracy':make_scorer(accuracy_score),'f1':make_scorer(f1_score),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}\n",
        "grid_scorer = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'f1': make_scorer(f1_score),\n",
        "    'mcc': make_scorer(matthews_corrcoef, greater_is_better=True),\n",
        "    'sensitivity': make_scorer(recall_score, greater_is_better=True),\n",
        "    'specificity': make_scorer(specificity_score, greater_is_better=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QyODNLQAPaz",
        "outputId": "0a14d9fa-023e-4aa0-ca65-6df77dff71af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([1.87491012, 1.63103771, 1.47561836, 1.58759141, 1.50165629,\n",
              "        1.50874567, 1.45145917, 1.50145268, 1.73859954, 2.130126  ]),\n",
              " 'score_time': array([0.02675605, 0.01243687, 0.00918317, 0.01271272, 0.01479506,\n",
              "        0.0170505 , 0.00919056, 0.01037455, 0.01911163, 0.02816081]),\n",
              " 'test_accuracy': array([0.8377425 , 0.85890653, 0.95943563, 0.93650794, 0.93650794,\n",
              "        0.96825397, 0.89417989, 0.90123457, 0.8712522 , 0.92239859]),\n",
              " 'test_f1': array([0.87894737, 0.89924433, 0.96953642, 0.952     , 0.952     ,\n",
              "        0.97650131, 0.925     , 0.93120393, 0.90604891, 0.94527363]),\n",
              " 'test_mcc': array([0.63359123, 0.66805479, 0.91052971, 0.86111345, 0.86111345,\n",
              "        0.92771248, 0.75229534, 0.7720879 , 0.70190718, 0.82255421]),\n",
              " 'test_sensitivity': array([0.86753247, 0.92727273, 0.95064935, 0.92727273, 0.92727273,\n",
              "        0.97142857, 0.96103896, 0.98441558, 0.91428571, 0.98958333]),\n",
              " 'test_specificity': array([0.77472527, 0.71428571, 0.97802198, 0.95604396, 0.95604396,\n",
              "        0.96153846, 0.75274725, 0.72527473, 0.78021978, 0.78142077])}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "scores = cross_validate(lr, train_dataset, training_labels, scoring= grid_scorer, cv=10)\n",
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ54HJvRSYxi"
      },
      "source": [
        "source https://www.kaggle.com/code/jnikhilsai/cross-validation-with-linear-regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQH-wkUTdo9S",
        "outputId": "feb8c0ee-2952-4843-e6cb-273cb503627a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: 0.9589065255731922\n",
            "f1: 0.9699703570047686\n",
            "mcc: 0.9051979647211783\n",
            "sn: 0.9776565341647181\n",
            "sp: 0.9192751235584844\n",
            "sd_acc: 0.002527210705383344\n",
            "sd_f1: 0.001876249617416053\n",
            "sd_mcc: 0.005847063383575142\n",
            "sd_sn: 0.0022490624154456263\n",
            "sd_sp: 0.006158646957328016\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.93      1821\n",
            "           1       0.96      0.98      0.97      3849\n",
            "\n",
            "    accuracy                           0.96      5670\n",
            "   macro avg       0.96      0.95      0.95      5670\n",
            "weighted avg       0.96      0.96      0.96      5670\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.002527210705383344, 0.005847063383575142, 0.001876249617416053)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "predicted_training_labels = lr.predict(train_dataset)\n",
        "error_rate(training_labels, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JguNQ4f6SuiR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjQLJMtyJNtD",
        "outputId": "4570f061-4128-4336-cfd8-82c50270bd83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: 0.911504424778761\n",
            "f1: 0.9480968858131488\n",
            "mcc: 0.6502439800240276\n",
            "sn: 0.9375534644995723\n",
            "sp: 0.7486631016042781\n",
            "sd_acc: 0.007312496353402619\n",
            "sd_f1: 0.004462908891728077\n",
            "sd_mcc: 0.02907261244637941\n",
            "sd_sn: 0.007047897749271824\n",
            "sd_sp: 0.03163483302845615\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.75      0.70       187\n",
            "           1       0.96      0.94      0.95      1169\n",
            "\n",
            "    accuracy                           0.91      1356\n",
            "   macro avg       0.81      0.84      0.82      1356\n",
            "weighted avg       0.92      0.91      0.91      1356\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.007312496353402619, 0.02907261244637941, 0.004462908891728077)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "predicted_lr = lr.predict(test_dataset)\n",
        "accuracy = accuracy_score(testing_labels, predicted_lr)\n",
        "error_rate(testing_labels, predicted_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxjhmdcwJXsD"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(train_dataset)\n",
        "df.to_excel('/content/lr_train_dataset.xlsx')\n",
        "df =pd.DataFrame(training_labels)\n",
        "df.to_excel('/content/lr_training_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_training_labels)\n",
        "df.to_excel('/content/lr_pred_train_labels.xlsx')\n",
        "\n",
        "df =pd.DataFrame(test_dataset)\n",
        "df.to_excel('/content/lr_test_dataset.xlsx')\n",
        "df =pd.DataFrame(testing_labels)\n",
        "df.to_excel('/content/lr_testing_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_lr)\n",
        "df.to_excel('/content/lr_pred_test_labels.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPUQwR-eKR38"
      },
      "outputs": [],
      "source": [
        "classes = np.unique(testing_labels)\n",
        "\n",
        "confusion_matrix_data = confusion_matrix(testing_labels, predicted_lr, labels=classes)\n",
        "conf_matrix(confusion_matrix_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq2RkIo-1Jdb"
      },
      "outputs": [],
      "source": [
        "TP = confusion_matrix_data[1,1]\n",
        "TN = confusion_matrix_data[0,0]\n",
        "FP = confusion_matrix_data[0,1]\n",
        "FN = confusion_matrix_data[1,0]\n",
        "\n",
        "print(TP,TN, FP, FN)\n",
        "\n",
        "sn = TP / float(TP + FN)\n",
        "print(sn)\n",
        "sp = TN / float(TN + FP)\n",
        "print(sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwjJoJZiOqqC"
      },
      "outputs": [],
      "source": [
        "#lr.save_weights('/result/LR.h5')\n",
        "print(lr.coef_.shape)\n",
        "lr_weights = lr.coef_\n",
        "print(lr_weights)\n",
        "print(np.max(lr_weights))\n",
        "print(np.min(lr_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpez8nyOvPOF"
      },
      "source": [
        "### MLP with Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVg8VB-J0AXe"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqBy5Mh50AXe"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vug_DpuSylO-"
      },
      "outputs": [],
      "source": [
        "# Basic Protocol 3 — Step 8\n",
        "\n",
        "multilayerperceptron = MLPClassifier(solver='lbfgs', random_state=10, max_iter=1000)\n",
        "\n",
        "parameters = {\n",
        "    'hidden_layer_sizes': [(2056,1024),(2056,),(1024,)],\n",
        "    #'learning_rate_init': [0.001, 0.0001, 0.01],\n",
        "    #'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
        "    'solver':['adam'],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt_H5F3yOVsC"
      },
      "outputs": [],
      "source": [
        "grid_scorer ={'accuracy':make_scorer(accuracy_score),'f1':make_scorer(f1_score),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlth5o02yn-d"
      },
      "outputs": [],
      "source": [
        "# Basic Protocol 3 — Step 9\n",
        "\n",
        "classifiers = GridSearchCV(multilayerperceptron, parameters, cv=10, scoring=grid_scorer, refit='mcc')\n",
        "history = classifiers.fit(train_dataset, training_labels)\n",
        "classifier = classifiers.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMv8_JC0WcSQ",
        "outputId": "6c93a30f-f5ed-49e0-ad9b-3fbf75a7f670"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'alpha': 0.0001,\n",
              " 'batch_size': 'auto',\n",
              " 'beta_1': 0.9,\n",
              " 'beta_2': 0.999,\n",
              " 'early_stopping': False,\n",
              " 'epsilon': 1e-08,\n",
              " 'hidden_layer_sizes': (2056, 1024),\n",
              " 'learning_rate': 'constant',\n",
              " 'learning_rate_init': 0.001,\n",
              " 'max_fun': 15000,\n",
              " 'max_iter': 1000,\n",
              " 'momentum': 0.9,\n",
              " 'n_iter_no_change': 10,\n",
              " 'nesterovs_momentum': True,\n",
              " 'power_t': 0.5,\n",
              " 'random_state': 10,\n",
              " 'shuffle': True,\n",
              " 'solver': 'adam',\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': False,\n",
              " 'warm_start': False}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "iULOvdVBX3kv",
        "outputId": "c62935b7-cac3-4cd1-af28-9f5b2ec023cb"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-1084483b94bc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Save the best model's architecture to a JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Halophilic/MLPESM_best_model.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_result' is not defined"
          ]
        }
      ],
      "source": [
        "#from keras.models import model_from_json\n",
        "\n",
        "# Save the best model's architecture to a JSON file\n",
        "#model_json = grid_result.best_estimator_.model.to_json()\n",
        "#with open(\"/content/drive/MyDrive/Halophilic/MLPESM_best_model.json\", \"w\") as json_file:\n",
        "#    json_file.write(model_json)\n",
        "\n",
        "# Save the best model's weights to an HDF5 file\n",
        "#grid_result.best_estimator_.model.save_weights(\"/content/drive/MyDrive/Halophilic/MLPESM_best_model_weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkLigimLWROf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "kMYQTWrF_05C",
        "outputId": "94be11ef-0047-455c-c4fa-0d4a0f1ca3f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-12f03d65-92fd-4c61-b2e7-c6f834e88f03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_hidden_layer_sizes</th>\n",
              "      <th>param_solver</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_accuracy</th>\n",
              "      <th>split1_test_accuracy</th>\n",
              "      <th>split2_test_accuracy</th>\n",
              "      <th>...</th>\n",
              "      <th>split3_test_mcc</th>\n",
              "      <th>split4_test_mcc</th>\n",
              "      <th>split5_test_mcc</th>\n",
              "      <th>split6_test_mcc</th>\n",
              "      <th>split7_test_mcc</th>\n",
              "      <th>split8_test_mcc</th>\n",
              "      <th>split9_test_mcc</th>\n",
              "      <th>mean_test_mcc</th>\n",
              "      <th>std_test_mcc</th>\n",
              "      <th>rank_test_mcc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>184.813537</td>\n",
              "      <td>25.161848</td>\n",
              "      <td>0.053326</td>\n",
              "      <td>0.010312</td>\n",
              "      <td>(2056, 1024)</td>\n",
              "      <td>adam</td>\n",
              "      <td>{'hidden_layer_sizes': (2056, 1024), 'solver':...</td>\n",
              "      <td>0.827160</td>\n",
              "      <td>0.855379</td>\n",
              "      <td>0.971781</td>\n",
              "      <td>...</td>\n",
              "      <td>0.896197</td>\n",
              "      <td>0.870773</td>\n",
              "      <td>0.929476</td>\n",
              "      <td>0.824579</td>\n",
              "      <td>0.808279</td>\n",
              "      <td>0.752410</td>\n",
              "      <td>0.804864</td>\n",
              "      <td>0.808134</td>\n",
              "      <td>0.105952</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163.099791</td>\n",
              "      <td>12.781107</td>\n",
              "      <td>0.043167</td>\n",
              "      <td>0.011069</td>\n",
              "      <td>(2056,)</td>\n",
              "      <td>adam</td>\n",
              "      <td>{'hidden_layer_sizes': (2056,), 'solver': 'adam'}</td>\n",
              "      <td>0.816578</td>\n",
              "      <td>0.853616</td>\n",
              "      <td>0.954145</td>\n",
              "      <td>...</td>\n",
              "      <td>0.872989</td>\n",
              "      <td>0.911235</td>\n",
              "      <td>0.917829</td>\n",
              "      <td>0.805631</td>\n",
              "      <td>0.811196</td>\n",
              "      <td>0.758739</td>\n",
              "      <td>0.765492</td>\n",
              "      <td>0.797705</td>\n",
              "      <td>0.107002</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>135.653790</td>\n",
              "      <td>20.399292</td>\n",
              "      <td>0.083915</td>\n",
              "      <td>0.044345</td>\n",
              "      <td>(1024,)</td>\n",
              "      <td>adam</td>\n",
              "      <td>{'hidden_layer_sizes': (1024,), 'solver': 'adam'}</td>\n",
              "      <td>0.811287</td>\n",
              "      <td>0.850088</td>\n",
              "      <td>0.943563</td>\n",
              "      <td>...</td>\n",
              "      <td>0.876365</td>\n",
              "      <td>0.890067</td>\n",
              "      <td>0.928483</td>\n",
              "      <td>0.803340</td>\n",
              "      <td>0.791941</td>\n",
              "      <td>0.756348</td>\n",
              "      <td>0.792661</td>\n",
              "      <td>0.793652</td>\n",
              "      <td>0.107022</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 46 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12f03d65-92fd-4c61-b2e7-c6f834e88f03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12f03d65-92fd-4c61-b2e7-c6f834e88f03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12f03d65-92fd-4c61-b2e7-c6f834e88f03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7fa74a4d-52cc-4133-993c-963aed890ad1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fa74a4d-52cc-4133-993c-963aed890ad1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7fa74a4d-52cc-4133-993c-963aed890ad1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0     184.813537     25.161848         0.053326        0.010312   \n",
              "1     163.099791     12.781107         0.043167        0.011069   \n",
              "2     135.653790     20.399292         0.083915        0.044345   \n",
              "\n",
              "  param_hidden_layer_sizes param_solver  \\\n",
              "0             (2056, 1024)         adam   \n",
              "1                  (2056,)         adam   \n",
              "2                  (1024,)         adam   \n",
              "\n",
              "                                              params  split0_test_accuracy  \\\n",
              "0  {'hidden_layer_sizes': (2056, 1024), 'solver':...              0.827160   \n",
              "1  {'hidden_layer_sizes': (2056,), 'solver': 'adam'}              0.816578   \n",
              "2  {'hidden_layer_sizes': (1024,), 'solver': 'adam'}              0.811287   \n",
              "\n",
              "   split1_test_accuracy  split2_test_accuracy  ...  split3_test_mcc  \\\n",
              "0              0.855379              0.971781  ...         0.896197   \n",
              "1              0.853616              0.954145  ...         0.872989   \n",
              "2              0.850088              0.943563  ...         0.876365   \n",
              "\n",
              "   split4_test_mcc  split5_test_mcc  split6_test_mcc  split7_test_mcc  \\\n",
              "0         0.870773         0.929476         0.824579         0.808279   \n",
              "1         0.911235         0.917829         0.805631         0.811196   \n",
              "2         0.890067         0.928483         0.803340         0.791941   \n",
              "\n",
              "   split8_test_mcc  split9_test_mcc  mean_test_mcc  std_test_mcc  \\\n",
              "0         0.752410         0.804864       0.808134      0.105952   \n",
              "1         0.758739         0.765492       0.797705      0.107002   \n",
              "2         0.756348         0.792661       0.793652      0.107022   \n",
              "\n",
              "   rank_test_mcc  \n",
              "0              1  \n",
              "1              2  \n",
              "2              3  \n",
              "\n",
              "[3 rows x 46 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DataFrame(classifiers.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vFSrlejaAc5"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(classifiers.cv_results_)\n",
        "new_path = '/content/test.xls'\n",
        "writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/ESM23BMLP20.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5Efby3KSn5j",
        "outputId": "08f30a4f-862b-4b79-ff5d-e2f12d633ea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc: 0.9998236331569665\n",
            "f1: 0.9998700792516564\n",
            "mcc: 0.9995956619714399\n",
            "sn: [1.0, 0.9997362869198312, 1.0, 0.9997400571874188, 0.9997384937238494, 0.9994814622763806, 0.9997386987196237, 0.9997391077484998, 0.9994753410283316, 0.9992262058292494, 1.0, 0.9992201715622563, 0.999741468459152, 1.0, 1.0, 0.9992130115424974, 0.9997398543184183, 1.0, 0.9997419354838709, 0.9994821336095288, 0.9994814622763806, 0.999739989599584, 1.0, 1.0, 1.0, 1.0, 0.9992221934145709, 1.0, 1.0, 0.9994697773064687, 0.9994850669412977, 0.9997354497354497, 1.0, 1.0, 0.9997390396659708, 0.9994769874476988, 0.9997419354838709, 1.0, 1.0, 0.9997446373850868, 1.0, 0.9994756161510225, 0.9997360781208762, 0.9992084432717678, 1.0, 0.9997379454926625, 0.9997396511325176, 0.9997380141472361, 1.0, 0.9997407311381903, 0.9997392438070404, 0.9994869163673679, 1.0, 0.9997393117831074, 1.0, 1.0, 0.999213630406291, 1.0, 1.0, 0.9997403946002077, 0.9997437211686314, 1.0, 1.0, 0.9997424008243173, 0.9997387669801463, 1.0, 1.0, 0.9994855967078189, 0.9997385620915032, 0.9997403946002077, 0.9997349589186324, 1.0, 1.0, 0.9997408655091993, 0.9997386987196237, 0.999479979199168, 0.9994776704100288, 1.0, 1.0, 1.0, 0.9997387669801463, 1.0, 0.9994807892004154, 1.0, 0.9992209815632304, 0.99974140160331, 1.0, 1.0, 0.9997394476289734, 0.9994821336095288, 0.9994807892004154, 0.9994802494802495, 0.9992071881606766, 0.9997402597402597, 1.0, 1.0, 1.0, 0.9997419354838709, 0.9997413347128815, 0.999482936918304, 1.0, 0.9997376016793492, 1.0, 1.0, 0.9997427321842037, 0.999482936918304, 0.9997363564460849, 0.9997392438070404, 0.9994875736612862, 0.9992307692307693, 1.0, 0.999479843953186, 0.9994711792702274, 0.999485728979172, 0.9997412677878396, 0.9997362869198312, 0.999738356881214, 0.9997396511325176, 0.9997387669801463, 0.9994761655316919, 0.9994780793319415, 1.0, 1.0, 0.9997405966277562, 1.0, 0.9997387669801463, 1.0, 1.0, 1.0, 0.9997429966589566, 1.0, 0.9994850669412977, 0.9992358634742741, 1.0, 0.9997398543184183, 1.0, 1.0, 1.0, 0.999738425320429, 0.9997418022205009, 1.0, 0.9994824016563147, 0.999737739312877, 1.0, 0.9992179353493222, 0.9997398543184183, 0.9989759344598055, 1.0, 0.9997386987196237, 1.0, 0.9997409997409997, 0.9994773974392475, 1.0, 0.9997419354838709, 0.9994871794871795, 1.0, 1.0, 1.0, 0.9997443762781186, 0.9992179353493222, 1.0, 0.999739989599584, 0.9992201715622563, 0.9994803845154585, 1.0, 0.99974140160331, 0.9997363564460849, 0.9994844031967002, 0.9997401247401247, 1.0, 0.9992209815632304, 0.9997409997409997, 0.9994772608468374, 0.9997441800972116, 0.999741468459152, 0.9994786235662148, 0.9994879672299027, 0.9997405293201869, 0.9997410668047644, 0.9994809239553595, 1.0, 1.0, 1.0, 0.9997435897435898, 0.9997401247401247, 0.9997437211686314, 1.0, 1.0, 1.0, 0.9992240041386445, 1.0, 0.999737739312877, 0.999741468459152, 1.0, 1.0, 0.9994821336095288, 1.0, 1.0, 1.0, 0.9994825355756791, 1.0, 1.0, 0.9997397866250325, 0.9994801143748375, 0.9994900560938297, 1.0, 0.9994838709677419, 0.9994783515910276, 0.9997376016793492, 0.9997413347128815, 1.0, 1.0, 1.0, 0.9997389715478987, 0.9997402597402597, 1.0, 0.9992221934145709, 0.9997401922577293, 1.0, 0.999737739312877, 1.0, 0.9994689325544344, 0.9997373259784608, 0.9992215879605605, 0.9997336884154461, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997415352804342, 0.9992183428869202, 0.9997397188964081, 0.9994790309976557, 1.0, 0.999737876802097, 1.0, 0.9992250064582795, 0.999484270242393, 1.0, 0.9997402597402597, 0.9992297817715019, 1.0, 1.0, 1.0, 0.9997385620915032, 0.9994810586403736, 0.9989473684210526, 1.0, 0.999483204134367, 0.9994779430957974, 0.9992152759612869, 1.0, 0.9994824016563147, 1.0, 0.9994814622763806, 0.9997393117831074, 1.0, 0.9997351694915254, 0.9997384937238494, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9992154811715481, 0.9992209815632304, 0.9994757536041939, 0.9994821336095288, 0.9997393797237425, 0.9997387669801463, 0.9997385620915032, 0.9992189533975527, 0.999476850640858, 1.0, 1.0, 0.9992205767731879, 0.999478759447485, 0.9997410668047644, 0.9997376016793492, 1.0, 0.9994830705608685, 0.9994805194805195, 1.0, 0.9994750656167979, 0.9997424671645635, 1.0, 1.0, 1.0, 0.9994728518713759, 1.0, 1.0, 0.9997386987196237, 1.0, 0.9997374639012864, 0.9992211838006231, 0.9994753410283316, 0.9997412677878396, 0.99974173553719, 1.0, 0.9997345367666578, 1.0, 0.9997412677878396, 0.9994779430957974, 1.0, 1.0, 0.9994830705608685, 1.0, 0.9992183428869202, 0.9994786235662148, 1.0, 1.0, 0.9997361477572559, 1.0, 0.999741468459152, 0.9997444416049067, 0.9994784876140809, 0.9997393797237425, 1.0, 1.0, 1.0, 1.0, 0.9997409326424871, 0.9994767137624281, 0.999485728979172, 0.9997412677878396, 1.0, 0.9997369805365597, 1.0, 1.0, 1.0, 0.999219968798752, 0.9989875980764363, 1.0, 0.9997394476289734, 0.9997416020671834, 0.9994897959183674, 0.9997393117831074, 0.9994722955145119, 0.9997432605905007, 0.9997409326424871, 0.9994769874476988, 0.9997416688194265, 1.0, 0.999475890985325, 0.9997413347128815, 0.9997425334706488, 0.9994888832098134, 0.9994783515910276, 0.9997395833333333, 1.0, 0.9997397866250325, 0.9997357992073976, 1.0, 0.9997416020671834, 0.9997411338338079, 0.9997421351211965, 1.0, 0.9997390396659708, 0.9992197659297789, 0.9997369805365597, 0.9997353797300873, 0.999742334449884, 0.9997368421052631, 0.9997403271877434, 0.9994882292732856, 0.9994815966822188, 0.9997407311381903, 0.999738082765846, 0.9994837377387713, 1.0, 0.9994769874476988, 1.0, 0.9992293860775752, 0.9994700582935877, 1.0, 0.9997420020639834, 1.0, 1.0, 0.999474513925381, 1.0, 0.9997408655091993, 0.9992221934145709, 1.0, 1.0, 0.9994788952579469, 0.9997360084477297, 0.9997407983411094, 1.0, 0.9997394476289734, 1.0, 0.9997386987196237, 0.9989596879063719, 1.0, 0.9997384937238494, 0.9994683678894205, 1.0, 0.9992260061919505, 1.0, 0.9997424671645635, 0.9997374639012864, 0.9994932860400304, 0.9997451580020388, 0.9994896657310538, 0.999484270242393, 0.9997406639004149, 0.9997425334706488, 0.9994844031967002, 0.9997360084477297, 0.9994940551479888, 0.9994793022650351, 1.0, 0.9997386987196237, 0.9997391757955139, 0.9994813278008299, 0.9997397188964081, 1.0, 1.0, 0.999485728979172, 0.998960228749675, 0.9997396511325176, 0.9994828032066201, 1.0, 0.9997405293201869, 0.9994775339602926, 0.9994822676676158, 0.9997373259784608, 1.0, 0.9994776704100288, 0.9994803845154585, 1.0, 1.0, 0.9997348183505701, 0.9994813278008299, 0.9997395154988278, 0.9997418022205009, 1.0, 0.9992242048099301, 1.0, 0.9997389715478987, 0.9994894051570079, 0.9997409326424871, 0.9997408655091993, 0.999475478625754, 0.9997395154988278, 1.0, 1.0, 1.0, 0.9997389033942559, 1.0, 0.9992242048099301, 0.9997375328083989, 0.9997353096876654, 1.0, 1.0, 1.0, 0.9997391757955139, 0.9997413347128815, 0.9994753410283316, 1.0, 0.999742334449884, 1.0, 0.9994877049180327, 0.9994802494802495, 0.99974140160331, 0.999738425320429, 0.9997390396659708, 0.9992270033496522, 1.0, 0.999483204134367, 1.0, 0.9997409997409997, 0.999741468459152, 0.9992158912702561, 0.9992217898832685, 0.9997391077484998, 1.0, 0.9997416020671834, 0.999738082765846, 0.9994757536041939, 1.0, 0.9997443762781186, 0.9997389033942559, 0.9994834710743802, 1.0, 0.9994844031967002, 0.9994803845154585, 0.9994828032066201, 0.999468085106383, 0.9997372569626904, 0.999475890985325, 1.0, 0.9997394476289734, 0.9994782154969998, 1.0, 0.9997401922577293, 1.0, 0.9994734070563455, 0.9997425997425997, 1.0, 1.0, 1.0, 0.9997360781208762, 0.9997387669801463, 0.9994763026970411, 0.9992295839753467, 1.0, 0.9994794377928162, 0.9997393117831074, 1.0, 1.0, 0.9994795732500651, 0.9997358689910195, 0.9997429305912596, 1.0, 1.0, 1.0, 1.0, 0.9997391077484998, 0.9994824016563147, 0.9997411338338079, 1.0, 1.0, 0.9997393117831074, 0.999738082765846, 0.9997389715478987, 1.0, 0.9997393797237425, 1.0, 0.9997433923530922, 1.0, 0.9997395833333333, 1.0, 0.9992128050380478, 0.9992154811715481, 0.9997386304234187, 0.9997419354838709, 0.9997406639004149, 0.9992189533975527, 1.0, 1.0, 1.0, 1.0, 0.99974509304104, 1.0, 0.9994841372194996, 1.0, 1.0, 0.9997366341848828, 1.0, 1.0, 0.999482936918304, 0.9992236024844721, 0.9997360084477297, 1.0, 0.9997415352804342, 0.999742334449884, 0.999738219895288, 1.0, 1.0, 0.9997434581836839, 0.999743062692703, 0.9997389033942559, 0.9994790309976557, 1.0, 0.9997391077484998, 0.9997405293201869, 0.9997427983539094, 0.9997419354838709, 0.9994836044410018, 1.0, 0.999739921976593, 1.0, 0.9997425997425997, 0.9997403271877434, 1.0, 0.9997402597402597, 0.9997416020671834, 1.0, 1.0, 0.9997397866250325, 0.9997371188222923, 1.0, 1.0, 0.9997406639004149, 0.9997392438070404, 1.0, 0.9997400571874188, 1.0, 0.9992209815632304, 0.9994866529774127, 0.9997403271877434, 0.9997389033942559, 1.0, 0.9997424008243173, 0.9997396511325176, 0.9997397866250325, 1.0, 0.9997392438070404, 0.999227202472952, 1.0, 0.99948625738505, 0.9994773974392475, 0.9994761655316919, 1.0, 0.9992221934145709, 0.999738425320429, 0.9997401922577293, 0.9994724347137959, 0.9997409326424871, 0.9997407983411094, 0.9992213859330392, 0.9997401922577293, 1.0, 0.9994807892004154, 0.999742334449884, 0.9997418688693857, 0.9994817310183985, 0.9994897959183674, 0.9997410668047644, 0.9997405966277562, 0.9997420686097498, 0.9997369805365597, 0.9994824016563147, 1.0, 1.0, 0.9997439180537772, 0.999741468459152, 1.0, 1.0, 1.0, 1.0, 0.9994954591321897, 0.9997389715478987, 0.999739921976593, 0.9989594172736732, 0.9997382884061764, 0.9997424671645635, 1.0, 0.9994805194805195, 0.9994802494802495, 1.0, 0.9997375328083989, 1.0, 1.0, 0.9997406639004149, 0.9997375328083989, 0.9992140424417082, 0.9994930291508238, 0.9997395833333333, 0.9997348183505701, 1.0, 1.0, 1.0, 0.9994882292732856, 1.0, 1.0, 0.9997398543184183, 0.9997396511325176, 1.0, 0.9997433264887063, 1.0, 1.0, 0.9994863893168978, 0.9994793022650351, 0.9997375328083989, 0.999474513925381, 0.9992191566892243, 0.9992173232454996, 0.9994801143748375, 0.9997426659804426, 1.0, 0.9994822676676158, 0.999739989599584, 0.9997405293201869, 0.9997396511325176, 1.0, 1.0, 0.9997416688194265, 0.9997393117831074, 1.0, 0.999483337638853, 0.9994806543754868, 1.0, 0.9997401247401247, 0.9992207792207792, 0.9997420020639834, 0.9997386304234187, 0.9997405293201869, 1.0, 0.9997397188964081, 1.0, 0.9997373949579832, 0.9994813278008299, 0.9997435897435898, 1.0, 0.9997373259784608, 0.9994665244065084, 0.9994769874476988, 0.9994780793319415, 0.9994836044410018, 0.9997392438070404, 1.0, 0.9987080103359173, 1.0, 0.9994729907773386, 1.0, 0.9997420020639834, 0.9994846688997681, 0.9992201715622563, 0.9992092778070638, 0.9994861253854059, 1.0, 0.9997436554729556, 1.0, 0.9997355896351137, 0.999739989599584, 1.0, 0.9997445068983137, 0.9997438524590164, 1.0, 1.0, 0.9997403271877434, 0.9997364259356879, 0.9997382884061764, 1.0, 0.9997371879106439, 1.0, 0.99974140160331, 0.9994807892004154, 0.9997407983411094, 0.9992234015014237, 0.9994858611825193, 0.9997385620915032, 0.9994776704100288, 0.9994780793319415, 0.999228593468758, 1.0, 0.9997405966277562, 0.999468791500664, 0.9994813278008299, 0.9997358689910195, 0.9997350993377483, 1.0, 0.9997363564460849, 0.9994746519569214, 0.9997395154988278, 1.0, 0.9997364953886693, 0.9997415352804342, 0.9994776704100288, 1.0, 1.0, 1.0, 0.9997387669801463, 0.9997389715478987, 1.0, 0.9997389033942559, 1.0, 0.9997366341848828, 1.0, 0.9994802494802495, 0.9997392438070404, 0.9997400571874188, 0.999739921976593, 0.9994810586403736, 0.9997431946584489, 0.9997391757955139, 1.0, 1.0, 1.0, 1.0, 0.9997402597402597, 0.9994806543754868, 1.0, 1.0, 1.0, 1.0, 0.9997375328083989, 0.9994828032066201, 0.9997409326424871, 1.0, 0.9994764397905759, 1.0, 0.9997389033942559, 0.9994813278008299, 0.9994884910485934, 0.9994703389830508, 1.0, 0.9994794377928162, 0.9997397188964081, 0.9997379454926625, 1.0, 0.9994778067885117, 1.0, 0.9992025518341308, 0.9997418022205009, 0.9994844031967002, 0.9997459349593496, 0.9997386987196237, 1.0, 0.9994838709677419, 0.9997376705141658, 0.9997416688194265, 1.0, 0.9997401247401247, 1.0, 0.9997395154988278, 1.0, 0.9997404619776797, 0.9997389033942559, 0.9994773974392475, 0.9997429305912596, 0.9997421351211965, 0.9994828032066201, 1.0, 0.9994814622763806, 1.0, 0.9994848016486347, 0.9994706193753309, 0.9997391077484998, 0.9994869163673679, 0.999483337638853, 0.9994883601944231, 0.9997408655091993, 0.9994773974392475, 1.0, 0.9997391077484998, 0.9997403271877434, 0.99974140160331, 1.0, 0.9989648033126294, 0.999214248297538, 0.9997420020639834, 0.9997416688194265, 0.9994883601944231, 0.9994821336095288, 0.9997458057956279, 1.0, 1.0, 1.0, 0.9989567031820553, 1.0, 0.9992238033635188, 1.0, 1.0, 1.0, 0.9994822676676158, 0.9997407983411094, 0.9994819994819995, 1.0, 1.0, 1.0, 1.0, 0.9994747899159664, 1.0, 1.0, 0.9997393117831074, 0.9992213859330392, 1.0, 0.99974140160331, 0.9994875736612862, 0.9997422015983501, 1.0, 0.9997346776333245, 0.9997401247401247, 0.9994807892004154, 0.9994721562417525, 0.9997389715478987, 0.9992138364779874, 1.0, 1.0, 0.9992191566892243, 1.0, 0.9997422015983501, 1.0, 0.9997395154988278, 0.9994809239553595, 1.0, 0.9994764397905759, 0.9997371188222923, 1.0, 1.0, 1.0, 0.9997405293201869, 0.9994805194805195, 0.9997425334706488, 1.0, 0.9997378080755113, 1.0, 0.9989613087509738, 0.9997408655091993, 0.9997393797237425, 0.9997434581836839, 1.0, 1.0, 0.999742864489586, 1.0, 0.9997382884061764, 1.0, 0.9997442455242966, 0.9994790309976557, 1.0, 0.9994805194805195, 1.0, 0.999482936918304, 0.9997427983539094, 0.9997413347128815, 0.9994775339602926, 0.9992260061919505, 1.0, 0.9992173232454996, 0.9997415352804342, 0.9997429966589566, 0.9997397866250325, 0.9994742376445847, 0.999741468459152, 0.9997393797237425, 1.0, 0.9997366341848828, 1.0, 0.9997413347128815, 1.0, 1.0, 0.999483204134367, 0.9989558861915949, 1.0, 1.0, 0.9992207792207792, 1.0, 0.9997324772605671, 0.9997375328083989, 1.0, 1.0, 0.9994830705608685, 1.0, 0.9994834710743802, 1.0, 0.9997369805365597, 0.9997412677878396, 0.9994694960212201, 0.999746835443038, 1.0, 1.0, 0.9997408655091993, 0.9994786235662148, 0.9989553408200574, 0.9997408655091993, 1.0, 1.0, 0.9989623865110246, 0.9994760282944721, 0.9994731296101159, 1.0, 0.9994825355756791, 1.0, 1.0, 0.9989481987904286, 1.0, 0.9992339121552605, 0.9997400571874188, 1.0, 0.9994890137966275, 0.9997416688194265, 0.9994794377928162, 0.999739921976593, 1.0, 0.999227202472952, 0.9994794377928162, 0.9992313604919293, 0.9997392438070404, 0.9994836044410018, 1.0, 0.9997364953886693, 0.9997364953886693, 1.0, 0.9994791666666667, 0.9997366341848828, 0.9994848016486347, 1.0, 1.0, 0.9994803845154585, 1.0, 1.0, 1.0, 0.9994824016563147, 0.9997412008281573, 0.9997422015983501, 0.9997341839447103, 0.9994783515910276, 0.9997398543184183, 0.9997418022205009, 0.9994803845154585, 1.0, 1.0, 1.0, 0.9994747899159664, 0.9994791666666667]\n",
            "sp: [1.0, 0.9997362869198312, 1.0, 0.9997400571874188, 0.9997384937238494, 0.9994814622763806, 0.9997386987196237, 0.9997391077484998, 0.9994753410283316, 0.9992262058292494, 1.0, 0.9992201715622563, 0.999741468459152, 1.0, 1.0, 0.9992130115424974, 0.9997398543184183, 1.0, 0.9997419354838709, 0.9994821336095288, 0.9994814622763806, 0.999739989599584, 1.0, 1.0, 1.0, 1.0, 0.9992221934145709, 1.0, 1.0, 0.9994697773064687, 0.9994850669412977, 0.9997354497354497, 1.0, 1.0, 0.9997390396659708, 0.9994769874476988, 0.9997419354838709, 1.0, 1.0, 0.9997446373850868, 1.0, 0.9994756161510225, 0.9997360781208762, 0.9992084432717678, 1.0, 0.9997379454926625, 0.9997396511325176, 0.9997380141472361, 1.0, 0.9997407311381903, 0.9997392438070404, 0.9994869163673679, 1.0, 0.9997393117831074, 1.0, 1.0, 0.999213630406291, 1.0, 1.0, 0.9997403946002077, 0.9997437211686314, 1.0, 1.0, 0.9997424008243173, 0.9997387669801463, 1.0, 1.0, 0.9994855967078189, 0.9997385620915032, 0.9997403946002077, 0.9997349589186324, 1.0, 1.0, 0.9997408655091993, 0.9997386987196237, 0.999479979199168, 0.9994776704100288, 1.0, 1.0, 1.0, 0.9997387669801463, 1.0, 0.9994807892004154, 1.0, 0.9992209815632304, 0.99974140160331, 1.0, 1.0, 0.9997394476289734, 0.9994821336095288, 0.9994807892004154, 0.9994802494802495, 0.9992071881606766, 0.9997402597402597, 1.0, 1.0, 1.0, 0.9997419354838709, 0.9997413347128815, 0.999482936918304, 1.0, 0.9997376016793492, 1.0, 1.0, 0.9997427321842037, 0.999482936918304, 0.9997363564460849, 0.9997392438070404, 0.9994875736612862, 0.9992307692307693, 1.0, 0.999479843953186, 0.9994711792702274, 0.999485728979172, 0.9997412677878396, 0.9997362869198312, 0.999738356881214, 0.9997396511325176, 0.9997387669801463, 0.9994761655316919, 0.9994780793319415, 1.0, 1.0, 0.9997405966277562, 1.0, 0.9997387669801463, 1.0, 1.0, 1.0, 0.9997429966589566, 1.0, 0.9994850669412977, 0.9992358634742741, 1.0, 0.9997398543184183, 1.0, 1.0, 1.0, 0.999738425320429, 0.9997418022205009, 1.0, 0.9994824016563147, 0.999737739312877, 1.0, 0.9992179353493222, 0.9997398543184183, 0.9989759344598055, 1.0, 0.9997386987196237, 1.0, 0.9997409997409997, 0.9994773974392475, 1.0, 0.9997419354838709, 0.9994871794871795, 1.0, 1.0, 1.0, 0.9997443762781186, 0.9992179353493222, 1.0, 0.999739989599584, 0.9992201715622563, 0.9994803845154585, 1.0, 0.99974140160331, 0.9997363564460849, 0.9994844031967002, 0.9997401247401247, 1.0, 0.9992209815632304, 0.9997409997409997, 0.9994772608468374, 0.9997441800972116, 0.999741468459152, 0.9994786235662148, 0.9994879672299027, 0.9997405293201869, 0.9997410668047644, 0.9994809239553595, 1.0, 1.0, 1.0, 0.9997435897435898, 0.9997401247401247, 0.9997437211686314, 1.0, 1.0, 1.0, 0.9992240041386445, 1.0, 0.999737739312877, 0.999741468459152, 1.0, 1.0, 0.9994821336095288, 1.0, 1.0, 1.0, 0.9994825355756791, 1.0, 1.0, 0.9997397866250325, 0.9994801143748375, 0.9994900560938297, 1.0, 0.9994838709677419, 0.9994783515910276, 0.9997376016793492, 0.9997413347128815, 1.0, 1.0, 1.0, 0.9997389715478987, 0.9997402597402597, 1.0, 0.9992221934145709, 0.9997401922577293, 1.0, 0.999737739312877, 1.0, 0.9994689325544344, 0.9997373259784608, 0.9992215879605605, 0.9997336884154461, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997415352804342, 0.9992183428869202, 0.9997397188964081, 0.9994790309976557, 1.0, 0.999737876802097, 1.0, 0.9992250064582795, 0.999484270242393, 1.0, 0.9997402597402597, 0.9992297817715019, 1.0, 1.0, 1.0, 0.9997385620915032, 0.9994810586403736, 0.9989473684210526, 1.0, 0.999483204134367, 0.9994779430957974, 0.9992152759612869, 1.0, 0.9994824016563147, 1.0, 0.9994814622763806, 0.9997393117831074, 1.0, 0.9997351694915254, 0.9997384937238494, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9992154811715481, 0.9992209815632304, 0.9994757536041939, 0.9994821336095288, 0.9997393797237425, 0.9997387669801463, 0.9997385620915032, 0.9992189533975527, 0.999476850640858, 1.0, 1.0, 0.9992205767731879, 0.999478759447485, 0.9997410668047644, 0.9997376016793492, 1.0, 0.9994830705608685, 0.9994805194805195, 1.0, 0.9994750656167979, 0.9997424671645635, 1.0, 1.0, 1.0, 0.9994728518713759, 1.0, 1.0, 0.9997386987196237, 1.0, 0.9997374639012864, 0.9992211838006231, 0.9994753410283316, 0.9997412677878396, 0.99974173553719, 1.0, 0.9997345367666578, 1.0, 0.9997412677878396, 0.9994779430957974, 1.0, 1.0, 0.9994830705608685, 1.0, 0.9992183428869202, 0.9994786235662148, 1.0, 1.0, 0.9997361477572559, 1.0, 0.999741468459152, 0.9997444416049067, 0.9994784876140809, 0.9997393797237425, 1.0, 1.0, 1.0, 1.0, 0.9997409326424871, 0.9994767137624281, 0.999485728979172, 0.9997412677878396, 1.0, 0.9997369805365597, 1.0, 1.0, 1.0, 0.999219968798752, 0.9989875980764363, 1.0, 0.9997394476289734, 0.9997416020671834, 0.9994897959183674, 0.9997393117831074, 0.9994722955145119, 0.9997432605905007, 0.9997409326424871, 0.9994769874476988, 0.9997416688194265, 1.0, 0.999475890985325, 0.9997413347128815, 0.9997425334706488, 0.9994888832098134, 0.9994783515910276, 0.9997395833333333, 1.0, 0.9997397866250325, 0.9997357992073976, 1.0, 0.9997416020671834, 0.9997411338338079, 0.9997421351211965, 1.0, 0.9997390396659708, 0.9992197659297789, 0.9997369805365597, 0.9997353797300873, 0.999742334449884, 0.9997368421052631, 0.9997403271877434, 0.9994882292732856, 0.9994815966822188, 0.9997407311381903, 0.999738082765846, 0.9994837377387713, 1.0, 0.9994769874476988, 1.0, 0.9992293860775752, 0.9994700582935877, 1.0, 0.9997420020639834, 1.0, 1.0, 0.999474513925381, 1.0, 0.9997408655091993, 0.9992221934145709, 1.0, 1.0, 0.9994788952579469, 0.9997360084477297, 0.9997407983411094, 1.0, 0.9997394476289734, 1.0, 0.9997386987196237, 0.9989596879063719, 1.0, 0.9997384937238494, 0.9994683678894205, 1.0, 0.9992260061919505, 1.0, 0.9997424671645635, 0.9997374639012864, 0.9994932860400304, 0.9997451580020388, 0.9994896657310538, 0.999484270242393, 0.9997406639004149, 0.9997425334706488, 0.9994844031967002, 0.9997360084477297, 0.9994940551479888, 0.9994793022650351, 1.0, 0.9997386987196237, 0.9997391757955139, 0.9994813278008299, 0.9997397188964081, 1.0, 1.0, 0.999485728979172, 0.998960228749675, 0.9997396511325176, 0.9994828032066201, 1.0, 0.9997405293201869, 0.9994775339602926, 0.9994822676676158, 0.9997373259784608, 1.0, 0.9994776704100288, 0.9994803845154585, 1.0, 1.0, 0.9997348183505701, 0.9994813278008299, 0.9997395154988278, 0.9997418022205009, 1.0, 0.9992242048099301, 1.0, 0.9997389715478987, 0.9994894051570079, 0.9997409326424871, 0.9997408655091993, 0.999475478625754, 0.9997395154988278, 1.0, 1.0, 1.0, 0.9997389033942559, 1.0, 0.9992242048099301, 0.9997375328083989, 0.9997353096876654, 1.0, 1.0, 1.0, 0.9997391757955139, 0.9997413347128815, 0.9994753410283316, 1.0, 0.999742334449884, 1.0, 0.9994877049180327, 0.9994802494802495, 0.99974140160331, 0.999738425320429, 0.9997390396659708, 0.9992270033496522, 1.0, 0.999483204134367, 1.0, 0.9997409997409997, 0.999741468459152, 0.9992158912702561, 0.9992217898832685, 0.9997391077484998, 1.0, 0.9997416020671834, 0.999738082765846, 0.9994757536041939, 1.0, 0.9997443762781186, 0.9997389033942559, 0.9994834710743802, 1.0, 0.9994844031967002, 0.9994803845154585, 0.9994828032066201, 0.999468085106383, 0.9997372569626904, 0.999475890985325, 1.0, 0.9997394476289734, 0.9994782154969998, 1.0, 0.9997401922577293, 1.0, 0.9994734070563455, 0.9997425997425997, 1.0, 1.0, 1.0, 0.9997360781208762, 0.9997387669801463, 0.9994763026970411, 0.9992295839753467, 1.0, 0.9994794377928162, 0.9997393117831074, 1.0, 1.0, 0.9994795732500651, 0.9997358689910195, 0.9997429305912596, 1.0, 1.0, 1.0, 1.0, 0.9997391077484998, 0.9994824016563147, 0.9997411338338079, 1.0, 1.0, 0.9997393117831074, 0.999738082765846, 0.9997389715478987, 1.0, 0.9997393797237425, 1.0, 0.9997433923530922, 1.0, 0.9997395833333333, 1.0, 0.9992128050380478, 0.9992154811715481, 0.9997386304234187, 0.9997419354838709, 0.9997406639004149, 0.9992189533975527, 1.0, 1.0, 1.0, 1.0, 0.99974509304104, 1.0, 0.9994841372194996, 1.0, 1.0, 0.9997366341848828, 1.0, 1.0, 0.999482936918304, 0.9992236024844721, 0.9997360084477297, 1.0, 0.9997415352804342, 0.999742334449884, 0.999738219895288, 1.0, 1.0, 0.9997434581836839, 0.999743062692703, 0.9997389033942559, 0.9994790309976557, 1.0, 0.9997391077484998, 0.9997405293201869, 0.9997427983539094, 0.9997419354838709, 0.9994836044410018, 1.0, 0.999739921976593, 1.0, 0.9997425997425997, 0.9997403271877434, 1.0, 0.9997402597402597, 0.9997416020671834, 1.0, 1.0, 0.9997397866250325, 0.9997371188222923, 1.0, 1.0, 0.9997406639004149, 0.9997392438070404, 1.0, 0.9997400571874188, 1.0, 0.9992209815632304, 0.9994866529774127, 0.9997403271877434, 0.9997389033942559, 1.0, 0.9997424008243173, 0.9997396511325176, 0.9997397866250325, 1.0, 0.9997392438070404, 0.999227202472952, 1.0, 0.99948625738505, 0.9994773974392475, 0.9994761655316919, 1.0, 0.9992221934145709, 0.999738425320429, 0.9997401922577293, 0.9994724347137959, 0.9997409326424871, 0.9997407983411094, 0.9992213859330392, 0.9997401922577293, 1.0, 0.9994807892004154, 0.999742334449884, 0.9997418688693857, 0.9994817310183985, 0.9994897959183674, 0.9997410668047644, 0.9997405966277562, 0.9997420686097498, 0.9997369805365597, 0.9994824016563147, 1.0, 1.0, 0.9997439180537772, 0.999741468459152, 1.0, 1.0, 1.0, 1.0, 0.9994954591321897, 0.9997389715478987, 0.999739921976593, 0.9989594172736732, 0.9997382884061764, 0.9997424671645635, 1.0, 0.9994805194805195, 0.9994802494802495, 1.0, 0.9997375328083989, 1.0, 1.0, 0.9997406639004149, 0.9997375328083989, 0.9992140424417082, 0.9994930291508238, 0.9997395833333333, 0.9997348183505701, 1.0, 1.0, 1.0, 0.9994882292732856, 1.0, 1.0, 0.9997398543184183, 0.9997396511325176, 1.0, 0.9997433264887063, 1.0, 1.0, 0.9994863893168978, 0.9994793022650351, 0.9997375328083989, 0.999474513925381, 0.9992191566892243, 0.9992173232454996, 0.9994801143748375, 0.9997426659804426, 1.0, 0.9994822676676158, 0.999739989599584, 0.9997405293201869, 0.9997396511325176, 1.0, 1.0, 0.9997416688194265, 0.9997393117831074, 1.0, 0.999483337638853, 0.9994806543754868, 1.0, 0.9997401247401247, 0.9992207792207792, 0.9997420020639834, 0.9997386304234187, 0.9997405293201869, 1.0, 0.9997397188964081, 1.0, 0.9997373949579832, 0.9994813278008299, 0.9997435897435898, 1.0, 0.9997373259784608, 0.9994665244065084, 0.9994769874476988, 0.9994780793319415, 0.9994836044410018, 0.9997392438070404, 1.0, 0.9987080103359173, 1.0, 0.9994729907773386, 1.0, 0.9997420020639834, 0.9994846688997681, 0.9992201715622563, 0.9992092778070638, 0.9994861253854059, 1.0, 0.9997436554729556, 1.0, 0.9997355896351137, 0.999739989599584, 1.0, 0.9997445068983137, 0.9997438524590164, 1.0, 1.0, 0.9997403271877434, 0.9997364259356879, 0.9997382884061764, 1.0, 0.9997371879106439, 1.0, 0.99974140160331, 0.9994807892004154, 0.9997407983411094, 0.9992234015014237, 0.9994858611825193, 0.9997385620915032, 0.9994776704100288, 0.9994780793319415, 0.999228593468758, 1.0, 0.9997405966277562, 0.999468791500664, 0.9994813278008299, 0.9997358689910195, 0.9997350993377483, 1.0, 0.9997363564460849, 0.9994746519569214, 0.9997395154988278, 1.0, 0.9997364953886693, 0.9997415352804342, 0.9994776704100288, 1.0, 1.0, 1.0, 0.9997387669801463, 0.9997389715478987, 1.0, 0.9997389033942559, 1.0, 0.9997366341848828, 1.0, 0.9994802494802495, 0.9997392438070404, 0.9997400571874188, 0.999739921976593, 0.9994810586403736, 0.9997431946584489, 0.9997391757955139, 1.0, 1.0, 1.0, 1.0, 0.9997402597402597, 0.9994806543754868, 1.0, 1.0, 1.0, 1.0, 0.9997375328083989, 0.9994828032066201, 0.9997409326424871, 1.0, 0.9994764397905759, 1.0, 0.9997389033942559, 0.9994813278008299, 0.9994884910485934, 0.9994703389830508, 1.0, 0.9994794377928162, 0.9997397188964081, 0.9997379454926625, 1.0, 0.9994778067885117, 1.0, 0.9992025518341308, 0.9997418022205009, 0.9994844031967002, 0.9997459349593496, 0.9997386987196237, 1.0, 0.9994838709677419, 0.9997376705141658, 0.9997416688194265, 1.0, 0.9997401247401247, 1.0, 0.9997395154988278, 1.0, 0.9997404619776797, 0.9997389033942559, 0.9994773974392475, 0.9997429305912596, 0.9997421351211965, 0.9994828032066201, 1.0, 0.9994814622763806, 1.0, 0.9994848016486347, 0.9994706193753309, 0.9997391077484998, 0.9994869163673679, 0.999483337638853, 0.9994883601944231, 0.9997408655091993, 0.9994773974392475, 1.0, 0.9997391077484998, 0.9997403271877434, 0.99974140160331, 1.0, 0.9989648033126294, 0.999214248297538, 0.9997420020639834, 0.9997416688194265, 0.9994883601944231, 0.9994821336095288, 0.9997458057956279, 1.0, 1.0, 1.0, 0.9989567031820553, 1.0, 0.9992238033635188, 1.0, 1.0, 1.0, 0.9994822676676158, 0.9997407983411094, 0.9994819994819995, 1.0, 1.0, 1.0, 1.0, 0.9994747899159664, 1.0, 1.0, 0.9997393117831074, 0.9992213859330392, 1.0, 0.99974140160331, 0.9994875736612862, 0.9997422015983501, 1.0, 0.9997346776333245, 0.9997401247401247, 0.9994807892004154, 0.9994721562417525, 0.9997389715478987, 0.9992138364779874, 1.0, 1.0, 0.9992191566892243, 1.0, 0.9997422015983501, 1.0, 0.9997395154988278, 0.9994809239553595, 1.0, 0.9994764397905759, 0.9997371188222923, 1.0, 1.0, 1.0, 0.9997405293201869, 0.9994805194805195, 0.9997425334706488, 1.0, 0.9997378080755113, 1.0, 0.9989613087509738, 0.9997408655091993, 0.9997393797237425, 0.9997434581836839, 1.0, 1.0, 0.999742864489586, 1.0, 0.9997382884061764, 1.0, 0.9997442455242966, 0.9994790309976557, 1.0, 0.9994805194805195, 1.0, 0.999482936918304, 0.9997427983539094, 0.9997413347128815, 0.9994775339602926, 0.9992260061919505, 1.0, 0.9992173232454996, 0.9997415352804342, 0.9997429966589566, 0.9997397866250325, 0.9994742376445847, 0.999741468459152, 0.9997393797237425, 1.0, 0.9997366341848828, 1.0, 0.9997413347128815, 1.0, 1.0, 0.999483204134367, 0.9989558861915949, 1.0, 1.0, 0.9992207792207792, 1.0, 0.9997324772605671, 0.9997375328083989, 1.0, 1.0, 0.9994830705608685, 1.0, 0.9994834710743802, 1.0, 0.9997369805365597, 0.9997412677878396, 0.9994694960212201, 0.999746835443038, 1.0, 1.0, 0.9997408655091993, 0.9994786235662148, 0.9989553408200574, 0.9997408655091993, 1.0, 1.0, 0.9989623865110246, 0.9994760282944721, 0.9994731296101159, 1.0, 0.9994825355756791, 1.0, 1.0, 0.9989481987904286, 1.0, 0.9992339121552605, 0.9997400571874188, 1.0, 0.9994890137966275, 0.9997416688194265, 0.9994794377928162, 0.999739921976593, 1.0, 0.999227202472952, 0.9994794377928162, 0.9992313604919293, 0.9997392438070404, 0.9994836044410018, 1.0, 0.9997364953886693, 0.9997364953886693, 1.0, 0.9994791666666667, 0.9997366341848828, 0.9994848016486347, 1.0, 1.0, 0.9994803845154585, 1.0, 1.0, 1.0, 0.9994824016563147, 0.9997412008281573, 0.9997422015983501, 0.9997341839447103, 0.9994783515910276, 0.9997398543184183, 0.9997418022205009, 0.9994803845154585, 1.0, 1.0, 1.0, 0.9994747899159664, 0.9994791666666667]\n",
            "sd_acc: 0.00017235074686758426\n",
            "sd_f1: 0.00012694378021800782\n",
            "sd_mcc: 0.0003952747433627781\n",
            "sd_sn: 0.0002537950856724022\n",
            "sd_sp: 0.0002537950856724022\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1821\n",
            "           1       1.00      1.00      1.00      3849\n",
            "\n",
            "    accuracy                           1.00      5670\n",
            "   macro avg       1.00      1.00      1.00      5670\n",
            "weighted avg       1.00      1.00      1.00      5670\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.00017235074686758426, 0.0003952747433627781, 0.00012694378021800782)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_training_labels = classifier.predict(train_dataset)\n",
        "error_rate(training_labels, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6XZ9vilAJoD",
        "outputId": "dface014-ea64-4c6d-e24f-87a10bcd25d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc: 0.9092920353982301\n",
            "f1: 0.9467762873215058\n",
            "mcc: 0.6423311893792609\n",
            "sn: [0.9341216216216216, 0.9283276450511946, 0.9436379163108455, 0.9370689655172414, 0.9428571428571428, 0.9459227467811159, 0.9308600337268128, 0.9327659574468085, 0.9458762886597938, 0.946551724137931, 0.9376601195559351, 0.9429051217464316, 0.9440619621342513, 0.9459915611814346, 0.9317988064791134, 0.9299743808710503, 0.9416809605488851, 0.9438687392055267, 0.9328743545611016, 0.9388458225667528, 0.9457167090754877, 0.924114671163575, 0.9384088964927289, 0.9421140939597316, 0.9349871685201027, 0.9351535836177475, 0.9417721518987342, 0.9382924767540152, 0.9383033419023136, 0.9378723404255319, 0.9316823228010248, 0.9319148936170213, 0.9343986543313709, 0.941025641025641, 0.9298986486486487, 0.9385281385281385, 0.93071000855432, 0.9317988064791134, 0.9394205443371378, 0.937984496124031, 0.9448685326547922, 0.9346517626827171, 0.9333902647309992, 0.9444444444444444, 0.9397071490094746, 0.9378238341968912, 0.927461139896373, 0.9299743808710503, 0.9458762886597938, 0.9339542760372566, 0.9384615384615385, 0.9330508474576271, 0.9272260273972602, 0.9357021996615905, 0.9485861182519281, 0.9376623376623376, 0.9335038363171355, 0.9448751076658053, 0.9403862300587741, 0.9316017316017317, 0.9365482233502538, 0.9388646288209607, 0.9325938566552902, 0.9364016736401674, 0.9343003412969283, 0.9398814563928873, 0.9371772805507745, 0.9337248322147651, 0.9428571428571428, 0.9445887445887445, 0.9411764705882353, 0.9446808510638298, 0.9236773633998265, 0.9338422391857506, 0.922945205479452, 0.9222408026755853, 0.9334470989761092, 0.9177377892030848, 0.9378238341968912, 0.9366554054054054, 0.9315068493150684, 0.927461139896373, 0.937984496124031, 0.9392361111111112, 0.931239388794567, 0.9335038363171355, 0.9365768896611643, 0.9313559322033899, 0.9340753424657534, 0.9356477561388654, 0.9305084745762712, 0.9297343616109683, 0.9351211072664359, 0.946218487394958, 0.9424892703862661, 0.9336206896551724, 0.933786078098472, 0.9392643284858854, 0.9411764705882353, 0.9345955249569707, 0.9390557939914163, 0.9331103678929766, 0.9322916666666666, 0.9248704663212435, 0.934634974533107, 0.9416809605488851, 0.923469387755102, 0.9319148936170213, 0.9452861952861953, 0.9188034188034188, 0.9438202247191011, 0.9394987035436474, 0.9417391304347826, 0.9357565511411665, 0.9355670103092784, 0.9426860564585116, 0.9431239388794567, 0.921165381319623, 0.9303313508920985, 0.9375527426160337, 0.946218487394958, 0.9375, 0.9367521367521368, 0.9351305812973884, 0.9380234505862647, 0.9322607959356477, 0.9366554054054054, 0.9432684165961049, 0.9279050042408821, 0.9366438356164384, 0.9424398625429553, 0.9321739130434783, 0.9384615384615385, 0.9372349448685326, 0.9439252336448598, 0.9378238341968912, 0.9383680555555556, 0.9244482173174873, 0.938207136640557, 0.9299307958477508, 0.9269521410579346, 0.9348757497857755, 0.9386189258312021, 0.9265822784810127, 0.9340949033391915, 0.9421915444348576, 0.9478632478632478, 0.9334485738980121, 0.9458762886597938, 0.9267461669505963, 0.9437819420783645, 0.932420872540633, 0.934634974533107, 0.9341991341991343, 0.9457627118644067, 0.9345955249569707, 0.9312123817712812, 0.9397379912663756, 0.9320722269991402, 0.9352088661551577, 0.9388984509466437, 0.9385281385281385, 0.9412265758091993, 0.9232067510548523, 0.9342327150084317, 0.9432989690721649, 0.9356223175965666, 0.9406196213425129, 0.9344262295081968, 0.9337298215802888, 0.9376083188908145, 0.9367521367521368, 0.9423407917383821, 0.9345391903531438, 0.9354005167958657, 0.9361702127659575, 0.9496221662468514, 0.9373390557939915, 0.9305084745762712, 0.9219554030874786, 0.9405074365704287, 0.9354005167958657, 0.943650126156434, 0.9382608695652174, 0.9386873920552677, 0.9429787234042554, 0.9394205443371378, 0.9187339606501284, 0.9427609427609428, 0.9420783645655877, 0.9273356401384083, 0.9223468507333908, 0.9390862944162437, 0.9257045260461144, 0.9386189258312021, 0.9378774805867127, 0.9430543572044866, 0.9359521776259607, 0.939810834049871, 0.9373927958833619, 0.9358523725834798, 0.9320469798657718, 0.9418907198612315, 0.9227467811158798, 0.9387755102040817, 0.9397379912663756, 0.9300937766410913, 0.9431034482758621, 0.9377700950734659, 0.9435273675065161, 0.9300937766410913, 0.9270199826238054, 0.9329940627650551, 0.9505862646566164, 0.9459915611814346, 0.9407783417935702, 0.9348561759729273, 0.9213197969543148, 0.9397794741306191, 0.9407783417935702, 0.928082191780822, 0.9434447300771208, 0.9363327674023769, 0.9357565511411665, 0.9411255411255411, 0.9374464438731791, 0.9403747870528109, 0.9380378657487092, 0.9309462915601023, 0.9529616724738676, 0.9230118443316413, 0.934801016088061, 0.932937181663837, 0.9305555555555556, 0.9375, 0.9308283518360376, 0.9166666666666666, 0.9392643284858854, 0.944110060189166, 0.9352941176470588, 0.9340753424657534, 0.9442538593481989, 0.9420916162489196, 0.929553264604811, 0.938091143594153, 0.9289991445680068, 0.9323181049069373, 0.9274124679760888, 0.9515717926932881, 0.9324894514767933, 0.9322469982847341, 0.9284497444633731, 0.9448217317487266, 0.9411764705882353, 0.9361158432708688, 0.9388458225667528, 0.9368512110726643, 0.928082191780822, 0.9459691252144082, 0.9381974248927039, 0.935429056924384, 0.9305317324185248, 0.9373368146214099, 0.9279050042408821, 0.9478632478632478, 0.9297343616109683, 0.9257679180887372, 0.9373412362404742, 0.9462457337883959, 0.9343003412969283, 0.9383033419023136, 0.9299743808710503, 0.9405267629566695, 0.9233390119250426, 0.9278260869565217, 0.9343434343434344, 0.9355932203389831, 0.9397590361445783, 0.9048020219039595, 0.9309153713298791, 0.9353448275862069, 0.9377133105802048, 0.9304721030042918, 0.9420289855072463, 0.9327586206896552, 0.9477674810446504, 0.9401197604790419, 0.9427350427350427, 0.9467455621301775, 0.9474576271186441, 0.9335060449050087, 0.9351771823681936, 0.9277824978759558, 0.946199829205807, 0.934412265758092, 0.9211864406779661, 0.9362068965517242, 0.9372822299651568, 0.9235447437011295, 0.9480851063829787, 0.9202081526452732, 0.9486510008703221, 0.9350210970464135, 0.9407216494845361, 0.9511568123393316, 0.9310344827586207, 0.9383561643835616, 0.9469565217391305, 0.9488291413703382, 0.939625850340136, 0.9371772805507745, 0.939810834049871, 0.9354005167958657, 0.9409246575342466, 0.9300937766410913, 0.9395744680851064, 0.9331641285956007, 0.9511986301369864, 0.9374456993918332, 0.9339704604691572, 0.9318568994889267, 0.9330472103004291, 0.9424703891708968, 0.9301934398654331, 0.9417897480451781, 0.9428090832632464, 0.939932318104907, 0.9374464438731791, 0.9254498714652957, 0.9363714531384351, 0.934018851756641, 0.9453458582408198, 0.9391377852916315, 0.9291736930860034, 0.9502145922746781, 0.9365482233502538, 0.9369138959931799, 0.932420872540633, 0.9297800338409475, 0.9318568994889267, 0.9414298018949182, 0.9301346801346801, 0.9392405063291139, 0.9317988064791134, 0.9242424242424242, 0.929004329004329, 0.9384485666104553, 0.9413793103448276, 0.9335604770017035, 0.927038626609442, 0.9258312020460358, 0.938671209540034, 0.9423240033927057, 0.9363166953528399, 0.9183848797250859, 0.932937181663837, 0.9300937766410913, 0.9398814563928873, 0.9242928452579035, 0.9506065857885615, 0.9321888412017167, 0.943650126156434, 0.9349871685201027, 0.941929974380871, 0.9399656946826758, 0.9241379310344827, 0.9394714407502132, 0.9432989690721649, 0.9417897480451781, 0.9232736572890026, 0.9368421052631579, 0.9419191919191919, 0.9335604770017035, 0.9430756159728122, 0.9439171699741156, 0.9316239316239316, 0.9381443298969072, 0.9381974248927039, 0.9291270527225584, 0.9481292517006803, 0.9391602399314481, 0.9380831212892281, 0.9432203389830508, 0.934819897084048, 0.9214346712211785, 0.9441624365482234, 0.9217021276595745, 0.9304347826086956, 0.9324894514767933, 0.9415749364944962, 0.9385665529010239, 0.9318377911993098, 0.9341317365269461, 0.9386343993085566, 0.9457627118644067, 0.9327086882453152, 0.9341880341880342, 0.9221453287197232, 0.9388111888111889, 0.9509043927648578, 0.926208651399491, 0.9515151515151515, 0.9291808873720137, 0.9475494411006019, 0.9372852233676976, 0.9305084745762712, 0.9393428812131424, 0.9321305841924399, 0.931740614334471, 0.9373412362404742, 0.938671209540034, 0.9451585261353899, 0.9381974248927039, 0.9273504273504274, 0.927536231884058, 0.9387234042553192, 0.9341772151898734, 0.9434121621621622, 0.9280762564991335, 0.9282051282051282, 0.9332161687170475, 0.9443507588532883, 0.9361158432708688, 0.9312123817712812, 0.9331016507384883, 0.9409246575342466, 0.9134125636672326, 0.9175347222222222, 0.9304274937133278, 0.9425675675675675, 0.925476603119584, 0.9402220324508966, 0.9206212251941329, 0.9460370994940978, 0.9355116079105761, 0.9277824978759558, 0.9338487972508591, 0.916030534351145, 0.924831081081081, 0.9407345575959933, 0.9446808510638298, 0.9420289855072463, 0.9431321084864392, 0.930976430976431, 0.9314481576692374, 0.9439655172413793, 0.9328231292517006, 0.9237435008665511, 0.9363327674023769, 0.9414758269720102, 0.9413265306122449, 0.9284497444633731, 0.9382504288164666, 0.9217171717171717, 0.9451585261353899, 0.9347457627118644, 0.9252971137521222, 0.9366554054054054, 0.9260533104041273, 0.9404761904761905, 0.9274124679760888, 0.9408695652173913, 0.9405172413793104, 0.9437340153452686, 0.9390034364261168, 0.9398814563928873, 0.944206008583691, 0.9359649122807018, 0.9370146678170836, 0.9273984442523768, 0.9373412362404742, 0.931239388794567, 0.9271636675235647, 0.9460616438356164, 0.9503849443969205, 0.9465056082830026, 0.9301121656600517, 0.924831081081081, 0.9283276450511946, 0.936411149825784, 0.9281437125748503, 0.9431034482758621, 0.9241786015164279, 0.9304495335029687, 0.9336099585062241, 0.9372881355932203, 0.9333910034602076, 0.9421915444348576, 0.9307432432432432, 0.9299743808710503, 0.9408284023668639, 0.9533106960950763, 0.9305912596401028, 0.939034716342083, 0.9413763806287171, 0.9294217687074829, 0.9433962264150944, 0.9248945147679325, 0.9370689655172414, 0.9252823631624674, 0.9393162393162393, 0.9405172413793104, 0.9385140905209223, 0.9457567804024497, 0.9444444444444444, 0.9305555555555556, 0.944206008583691, 0.9432989690721649, 0.9418907198612315, 0.9381879762912786, 0.9421276595744681, 0.9317988064791134, 0.9472340425531914, 0.935429056924384, 0.9401197604790419, 0.9421915444348576, 0.9273504273504274, 0.9366438356164384, 0.9321148825065274, 0.9201009251471826, 0.9447278911564626, 0.9482612383375743, 0.9462457337883959, 0.944206008583691, 0.9306506849315068, 0.944110060189166, 0.94331641285956, 0.9287553648068669, 0.9440734557595993, 0.9203084832904884, 0.9323050556983719, 0.9324786324786325, 0.9370212765957446, 0.9291808873720137, 0.9393428812131424, 0.9425878320479862, 0.9294926913155632, 0.9439655172413793, 0.9381974248927039, 0.9411262798634812, 0.9186147186147187, 0.938135593220339, 0.9397071490094746, 0.9433643279797126, 0.9369602763385146, 0.9181585677749361, 0.9255499153976311, 0.9426585577758471, 0.9457364341085271, 0.9269328802039083, 0.9292412617220801, 0.9406196213425129, 0.9314720812182741, 0.9447799827437446, 0.932937181663837, 0.9432684165961049, 0.9446808510638298, 0.9141886151231946, 0.9393939393939394, 0.9308283518360376, 0.9399141630901288, 0.9335038363171355, 0.9388984509466437, 0.9326424870466321, 0.9407783417935702, 0.9431034482758621, 0.9229422066549913, 0.9363714531384351, 0.9384088964927289, 0.9421768707482994, 0.9435075885328836, 0.934018851756641, 0.9427350427350427, 0.9399830938292477, 0.9419795221843004, 0.9316455696202531, 0.9471919530595139, 0.9412780656303973, 0.9341880341880342, 0.9339622641509434, 0.9377192982456141, 0.9384615384615385, 0.9251934651762683, 0.9250645994832042, 0.9381879762912786, 0.9376068376068376, 0.942390369733448, 0.9362786745964317, 0.9424892703862661, 0.924190800681431, 0.9318181818181818, 0.9307432432432432, 0.9333902647309992, 0.9283246977547496, 0.941586748038361, 0.9395017793594306, 0.9420916162489196, 0.9437819420783645, 0.9440203562340967, 0.930976430976431, 0.9511986301369864, 0.9249374478732277, 0.9345955249569707, 0.9412780656303973, 0.9368421052631579, 0.9237435008665511, 0.9388794567062818, 0.9326424870466321, 0.947502116850127, 0.9246575342465754, 0.9353448275862069, 0.9356775300171527, 0.9313640312771503, 0.9384088964927289, 0.9262792714657415, 0.9396771452846219, 0.9328802039082413, 0.9388984509466437, 0.9275979557069847, 0.9409209383145091, 0.9326513213981245, 0.931063829787234, 0.9404761904761905, 0.943250214961307, 0.9377664109121909, 0.9380378657487092, 0.9373412362404742, 0.9332755632582322, 0.9329896907216495, 0.9291270527225584, 0.9457627118644067, 0.9279588336192109, 0.9521739130434783, 0.9539930555555556, 0.9383145091225021, 0.9343986543313709, 0.9316666666666666, 0.9383561643835616, 0.934634974533107, 0.9275237273511648, 0.935064935064935, 0.9548167092924126, 0.9375, 0.9389830508474576, 0.9340753424657534, 0.9376623376623376, 0.9432989690721649, 0.9404761904761905, 0.929481733220051, 0.9299743808710503, 0.9334456613310868, 0.9420783645655877, 0.9381879762912786, 0.9363327674023769, 0.9380453752181501, 0.9354026845637584, 0.9278887923544744, 0.9380831212892281, 0.9308873720136519, 0.9228813559322034, 0.9387402933563417, 0.9317032040472175, 0.9277730008598453, 0.9265975820379966, 0.9321888412017167, 0.9417721518987342, 0.9462915601023018, 0.9383680555555556, 0.9278969957081545, 0.933786078098472, 0.9277824978759558, 0.9464740866610025, 0.933786078098472, 0.9349112426035503, 0.9408740359897172, 0.9413763806287171, 0.9366018596787827, 0.9405772495755518, 0.9336823734729494, 0.9457364341085271, 0.934819897084048, 0.9383033419023136, 0.9418907198612315, 0.95, 0.9347457627118644, 0.9265341400172861, 0.9377104377104377, 0.9464131374243734, 0.934931506849315, 0.9401349072512648, 0.9394957983193277, 0.9308016877637131, 0.929481733220051, 0.9391833188531712, 0.9349871685201027, 0.9303525365434222, 0.9271186440677966, 0.9375542064180399, 0.9377664109121909, 0.9227467811158798, 0.9325938566552902, 0.9263067694944301, 0.9385665529010239, 0.9451114922813036, 0.9301346801346801, 0.9413763806287171, 0.9518581081081081, 0.9350877192982456, 0.9533106960950763, 0.9414298018949182, 0.9303135888501742, 0.9357876712328768, 0.9352088661551577, 0.9409209383145091, 0.9458086367485182, 0.9493996569468267, 0.9388275276125744, 0.9326424870466321, 0.9283305227655987, 0.9430543572044866, 0.939932318104907, 0.9307359307359307, 0.9370748299319728, 0.935042735042735, 0.939625850340136, 0.9406113537117904, 0.9210977701543739, 0.9384871155444722, 0.9463986599664992, 0.9328802039082413, 0.931740614334471, 0.946551724137931, 0.9453125, 0.9453125, 0.9377133105802048, 0.9292493528904228, 0.9208510638297872, 0.9437819420783645, 0.9328231292517006, 0.9347079037800687, 0.9309462915601023, 0.932937181663837, 0.9296137339055794, 0.9219554030874786, 0.938671209540034, 0.9403747870528109, 0.9384885764499121, 0.939034716342083, 0.9270568278201866, 0.9335634167385677, 0.9457567804024497, 0.9330508474576271, 0.9319327731092437, 0.9323050556983719, 0.9394714407502132, 0.9286926994906621, 0.9283305227655987, 0.9385665529010239, 0.9427839453458582, 0.9341991341991343, 0.9409317803660566, 0.9463373083475298, 0.9277730008598453, 0.9420783645655877, 0.93071000855432, 0.9371231696813093, 0.9283333333333333, 0.9396771452846219, 0.94275802254987, 0.9445392491467577, 0.9314830875975716, 0.9349871685201027, 0.9282006920415224, 0.9333902647309992, 0.9361158432708688, 0.9405857740585774, 0.9419795221843004, 0.9432013769363167, 0.9312445604873804, 0.9374456993918332, 0.9349871685201027, 0.9389830508474576, 0.9175965665236051, 0.9303904923599321, 0.9370212765957446, 0.9506802721088435, 0.9472340425531914, 0.9299145299145299, 0.9413763806287171, 0.9462555066079296, 0.9370146678170836, 0.9335060449050087, 0.9355932203389831, 0.9404659188955996, 0.9219015280135824, 0.9328743545611016, 0.929004329004329, 0.9428822495606327, 0.9367521367521368, 0.9462636439966414, 0.9383145091225021, 0.9443016281062554, 0.9198635976129582, 0.944633730834753, 0.928448275862069, 0.9319727891156463, 0.9289383561643836, 0.9366554054054054, 0.929957805907173, 0.9385813148788927, 0.9357326478149101, 0.9215686274509803, 0.93025283347864, 0.919104991394148, 0.9283246977547496, 0.9404761904761905, 0.9303525365434222, 0.9426860564585116, 0.9341317365269461, 0.9286328460877042, 0.9368061485909479, 0.9331075359864521, 0.9302127659574468, 0.9301724137931034, 0.9392123287671232, 0.9349112426035503, 0.9380234505862647, 0.9432203389830508, 0.9405857740585774, 0.9421915444348576, 0.9411255411255411, 0.9368061485909479, 0.9471861471861471, 0.939810834049871, 0.9336691855583543, 0.9406113537117904, 0.9338912133891213, 0.9313559322033899, 0.9358196010407632, 0.9443016281062554, 0.9337298215802888, 0.9457167090754877, 0.9492691315563199, 0.9467713787085514, 0.9421768707482994, 0.9279588336192109, 0.9375549692172384, 0.9322916666666666, 0.9374464438731791, 0.9319552110249785, 0.9410760034158838, 0.9272419627749577, 0.9463537300922046, 0.925, 0.9329268292682927, 0.9446808510638298, 0.9346904156064462, 0.9387755102040817, 0.9416243654822335, 0.9421416234887737, 0.9348561759729273, 0.945518453427065, 0.9329940627650551, 0.9468802698145026, 0.9304123711340206, 0.9356223175965666, 0.9250841750841751, 0.9247038917089678, 0.9266211604095563, 0.9424398625429553, 0.9351535836177475, 0.9340753424657534, 0.9388458225667528, 0.9414802065404475, 0.9289383561643836, 0.947502116850127, 0.9295652173913044, 0.9443507588532883, 0.9426160337552743, 0.9314481576692374, 0.9300758213984835, 0.9362445414847161, 0.9263067694944301, 0.9361158432708688, 0.9392643284858854, 0.9386189258312021, 0.9473237043330501, 0.9399830938292477, 0.9396551724137931, 0.9323630136986302, 0.9210754553339116, 0.9327086882453152, 0.9300758213984835, 0.9353191489361702, 0.9212924606462303, 0.9297205757832345, 0.9251934651762683, 0.9448685326547922, 0.9398998330550918, 0.9445407279029463, 0.9391377852916315, 0.9340659340659341, 0.9312123817712812, 0.9341421143847487, 0.9416809605488851, 0.9264705882352942, 0.949486301369863, 0.9387931034482758, 0.938207136640557, 0.9395509499136442, 0.9332191780821918, 0.9402460456942003, 0.9321458863443596, 0.9458762886597938, 0.9283276450511946, 0.9349112426035503, 0.9298545765611634, 0.9379310344827586, 0.9336170212765957, 0.9291882556131261, 0.9258943781942078, 0.9285714285714286, 0.9274261603375528, 0.9263959390862944, 0.9356477561388654, 0.9343128781331028, 0.923785594639866, 0.9424398625429553, 0.9476351351351351, 0.9316239316239316, 0.9343003412969283, 0.9371772805507745, 0.9297343616109683, 0.9421416234887737, 0.9309153713298791, 0.9347079037800687, 0.9455017301038062, 0.9462738301559792, 0.933277027027027, 0.9335038363171355, 0.9337919174548581, 0.9393939393939394, 0.9283305227655987, 0.941991341991342, 0.9357326478149101, 0.9293617021276596, 0.9361702127659575, 0.9238665526090676, 0.926829268292683, 0.9325938566552902, 0.9316608996539792, 0.934468085106383, 0.9303691275167785, 0.9280138768430182, 0.9282051282051282, 0.9411764705882353, 0.9260226283724978, 0.9541984732824428, 0.9344978165938864, 0.9354026845637584, 0.9420289855072463, 0.9448751076658053, 0.9227504244482173, 0.9298545765611634, 0.944110060189166, 0.9343003412969283, 0.9375542064180399, 0.9276485788113695, 0.9242424242424242, 0.941830624465355, 0.9344262295081968, 0.9419410745233969, 0.9343128781331028, 0.9321888412017167, 0.9364944961896697, 0.9299474605954466, 0.9492691315563199, 0.9283865401207938, 0.9288164665523156, 0.9384615384615385, 0.9434931506849316, 0.9381879762912786, 0.9264705882352942, 0.9195596951735817, 0.9307359307359307, 0.940068493150685, 0.9331046312178388, 0.925513698630137, 0.9190800681431005, 0.9393680614859095, 0.9455488331892826, 0.9279661016949152, 0.9398625429553265, 0.9323050556983719, 0.9378723404255319, 0.9447748513169074, 0.934931506849315, 0.937231298366294, 0.9422413793103448, 0.928448275862069]\n",
            "sp: [0.9341216216216216, 0.9283276450511946, 0.9436379163108455, 0.9370689655172414, 0.9428571428571428, 0.9459227467811159, 0.9308600337268128, 0.9327659574468085, 0.9458762886597938, 0.946551724137931, 0.9376601195559351, 0.9429051217464316, 0.9440619621342513, 0.9459915611814346, 0.9317988064791134, 0.9299743808710503, 0.9416809605488851, 0.9438687392055267, 0.9328743545611016, 0.9388458225667528, 0.9457167090754877, 0.924114671163575, 0.9384088964927289, 0.9421140939597316, 0.9349871685201027, 0.9351535836177475, 0.9417721518987342, 0.9382924767540152, 0.9383033419023136, 0.9378723404255319, 0.9316823228010248, 0.9319148936170213, 0.9343986543313709, 0.941025641025641, 0.9298986486486487, 0.9385281385281385, 0.93071000855432, 0.9317988064791134, 0.9394205443371378, 0.937984496124031, 0.9448685326547922, 0.9346517626827171, 0.9333902647309992, 0.9444444444444444, 0.9397071490094746, 0.9378238341968912, 0.927461139896373, 0.9299743808710503, 0.9458762886597938, 0.9339542760372566, 0.9384615384615385, 0.9330508474576271, 0.9272260273972602, 0.9357021996615905, 0.9485861182519281, 0.9376623376623376, 0.9335038363171355, 0.9448751076658053, 0.9403862300587741, 0.9316017316017317, 0.9365482233502538, 0.9388646288209607, 0.9325938566552902, 0.9364016736401674, 0.9343003412969283, 0.9398814563928873, 0.9371772805507745, 0.9337248322147651, 0.9428571428571428, 0.9445887445887445, 0.9411764705882353, 0.9446808510638298, 0.9236773633998265, 0.9338422391857506, 0.922945205479452, 0.9222408026755853, 0.9334470989761092, 0.9177377892030848, 0.9378238341968912, 0.9366554054054054, 0.9315068493150684, 0.927461139896373, 0.937984496124031, 0.9392361111111112, 0.931239388794567, 0.9335038363171355, 0.9365768896611643, 0.9313559322033899, 0.9340753424657534, 0.9356477561388654, 0.9305084745762712, 0.9297343616109683, 0.9351211072664359, 0.946218487394958, 0.9424892703862661, 0.9336206896551724, 0.933786078098472, 0.9392643284858854, 0.9411764705882353, 0.9345955249569707, 0.9390557939914163, 0.9331103678929766, 0.9322916666666666, 0.9248704663212435, 0.934634974533107, 0.9416809605488851, 0.923469387755102, 0.9319148936170213, 0.9452861952861953, 0.9188034188034188, 0.9438202247191011, 0.9394987035436474, 0.9417391304347826, 0.9357565511411665, 0.9355670103092784, 0.9426860564585116, 0.9431239388794567, 0.921165381319623, 0.9303313508920985, 0.9375527426160337, 0.946218487394958, 0.9375, 0.9367521367521368, 0.9351305812973884, 0.9380234505862647, 0.9322607959356477, 0.9366554054054054, 0.9432684165961049, 0.9279050042408821, 0.9366438356164384, 0.9424398625429553, 0.9321739130434783, 0.9384615384615385, 0.9372349448685326, 0.9439252336448598, 0.9378238341968912, 0.9383680555555556, 0.9244482173174873, 0.938207136640557, 0.9299307958477508, 0.9269521410579346, 0.9348757497857755, 0.9386189258312021, 0.9265822784810127, 0.9340949033391915, 0.9421915444348576, 0.9478632478632478, 0.9334485738980121, 0.9458762886597938, 0.9267461669505963, 0.9437819420783645, 0.932420872540633, 0.934634974533107, 0.9341991341991343, 0.9457627118644067, 0.9345955249569707, 0.9312123817712812, 0.9397379912663756, 0.9320722269991402, 0.9352088661551577, 0.9388984509466437, 0.9385281385281385, 0.9412265758091993, 0.9232067510548523, 0.9342327150084317, 0.9432989690721649, 0.9356223175965666, 0.9406196213425129, 0.9344262295081968, 0.9337298215802888, 0.9376083188908145, 0.9367521367521368, 0.9423407917383821, 0.9345391903531438, 0.9354005167958657, 0.9361702127659575, 0.9496221662468514, 0.9373390557939915, 0.9305084745762712, 0.9219554030874786, 0.9405074365704287, 0.9354005167958657, 0.943650126156434, 0.9382608695652174, 0.9386873920552677, 0.9429787234042554, 0.9394205443371378, 0.9187339606501284, 0.9427609427609428, 0.9420783645655877, 0.9273356401384083, 0.9223468507333908, 0.9390862944162437, 0.9257045260461144, 0.9386189258312021, 0.9378774805867127, 0.9430543572044866, 0.9359521776259607, 0.939810834049871, 0.9373927958833619, 0.9358523725834798, 0.9320469798657718, 0.9418907198612315, 0.9227467811158798, 0.9387755102040817, 0.9397379912663756, 0.9300937766410913, 0.9431034482758621, 0.9377700950734659, 0.9435273675065161, 0.9300937766410913, 0.9270199826238054, 0.9329940627650551, 0.9505862646566164, 0.9459915611814346, 0.9407783417935702, 0.9348561759729273, 0.9213197969543148, 0.9397794741306191, 0.9407783417935702, 0.928082191780822, 0.9434447300771208, 0.9363327674023769, 0.9357565511411665, 0.9411255411255411, 0.9374464438731791, 0.9403747870528109, 0.9380378657487092, 0.9309462915601023, 0.9529616724738676, 0.9230118443316413, 0.934801016088061, 0.932937181663837, 0.9305555555555556, 0.9375, 0.9308283518360376, 0.9166666666666666, 0.9392643284858854, 0.944110060189166, 0.9352941176470588, 0.9340753424657534, 0.9442538593481989, 0.9420916162489196, 0.929553264604811, 0.938091143594153, 0.9289991445680068, 0.9323181049069373, 0.9274124679760888, 0.9515717926932881, 0.9324894514767933, 0.9322469982847341, 0.9284497444633731, 0.9448217317487266, 0.9411764705882353, 0.9361158432708688, 0.9388458225667528, 0.9368512110726643, 0.928082191780822, 0.9459691252144082, 0.9381974248927039, 0.935429056924384, 0.9305317324185248, 0.9373368146214099, 0.9279050042408821, 0.9478632478632478, 0.9297343616109683, 0.9257679180887372, 0.9373412362404742, 0.9462457337883959, 0.9343003412969283, 0.9383033419023136, 0.9299743808710503, 0.9405267629566695, 0.9233390119250426, 0.9278260869565217, 0.9343434343434344, 0.9355932203389831, 0.9397590361445783, 0.9048020219039595, 0.9309153713298791, 0.9353448275862069, 0.9377133105802048, 0.9304721030042918, 0.9420289855072463, 0.9327586206896552, 0.9477674810446504, 0.9401197604790419, 0.9427350427350427, 0.9467455621301775, 0.9474576271186441, 0.9335060449050087, 0.9351771823681936, 0.9277824978759558, 0.946199829205807, 0.934412265758092, 0.9211864406779661, 0.9362068965517242, 0.9372822299651568, 0.9235447437011295, 0.9480851063829787, 0.9202081526452732, 0.9486510008703221, 0.9350210970464135, 0.9407216494845361, 0.9511568123393316, 0.9310344827586207, 0.9383561643835616, 0.9469565217391305, 0.9488291413703382, 0.939625850340136, 0.9371772805507745, 0.939810834049871, 0.9354005167958657, 0.9409246575342466, 0.9300937766410913, 0.9395744680851064, 0.9331641285956007, 0.9511986301369864, 0.9374456993918332, 0.9339704604691572, 0.9318568994889267, 0.9330472103004291, 0.9424703891708968, 0.9301934398654331, 0.9417897480451781, 0.9428090832632464, 0.939932318104907, 0.9374464438731791, 0.9254498714652957, 0.9363714531384351, 0.934018851756641, 0.9453458582408198, 0.9391377852916315, 0.9291736930860034, 0.9502145922746781, 0.9365482233502538, 0.9369138959931799, 0.932420872540633, 0.9297800338409475, 0.9318568994889267, 0.9414298018949182, 0.9301346801346801, 0.9392405063291139, 0.9317988064791134, 0.9242424242424242, 0.929004329004329, 0.9384485666104553, 0.9413793103448276, 0.9335604770017035, 0.927038626609442, 0.9258312020460358, 0.938671209540034, 0.9423240033927057, 0.9363166953528399, 0.9183848797250859, 0.932937181663837, 0.9300937766410913, 0.9398814563928873, 0.9242928452579035, 0.9506065857885615, 0.9321888412017167, 0.943650126156434, 0.9349871685201027, 0.941929974380871, 0.9399656946826758, 0.9241379310344827, 0.9394714407502132, 0.9432989690721649, 0.9417897480451781, 0.9232736572890026, 0.9368421052631579, 0.9419191919191919, 0.9335604770017035, 0.9430756159728122, 0.9439171699741156, 0.9316239316239316, 0.9381443298969072, 0.9381974248927039, 0.9291270527225584, 0.9481292517006803, 0.9391602399314481, 0.9380831212892281, 0.9432203389830508, 0.934819897084048, 0.9214346712211785, 0.9441624365482234, 0.9217021276595745, 0.9304347826086956, 0.9324894514767933, 0.9415749364944962, 0.9385665529010239, 0.9318377911993098, 0.9341317365269461, 0.9386343993085566, 0.9457627118644067, 0.9327086882453152, 0.9341880341880342, 0.9221453287197232, 0.9388111888111889, 0.9509043927648578, 0.926208651399491, 0.9515151515151515, 0.9291808873720137, 0.9475494411006019, 0.9372852233676976, 0.9305084745762712, 0.9393428812131424, 0.9321305841924399, 0.931740614334471, 0.9373412362404742, 0.938671209540034, 0.9451585261353899, 0.9381974248927039, 0.9273504273504274, 0.927536231884058, 0.9387234042553192, 0.9341772151898734, 0.9434121621621622, 0.9280762564991335, 0.9282051282051282, 0.9332161687170475, 0.9443507588532883, 0.9361158432708688, 0.9312123817712812, 0.9331016507384883, 0.9409246575342466, 0.9134125636672326, 0.9175347222222222, 0.9304274937133278, 0.9425675675675675, 0.925476603119584, 0.9402220324508966, 0.9206212251941329, 0.9460370994940978, 0.9355116079105761, 0.9277824978759558, 0.9338487972508591, 0.916030534351145, 0.924831081081081, 0.9407345575959933, 0.9446808510638298, 0.9420289855072463, 0.9431321084864392, 0.930976430976431, 0.9314481576692374, 0.9439655172413793, 0.9328231292517006, 0.9237435008665511, 0.9363327674023769, 0.9414758269720102, 0.9413265306122449, 0.9284497444633731, 0.9382504288164666, 0.9217171717171717, 0.9451585261353899, 0.9347457627118644, 0.9252971137521222, 0.9366554054054054, 0.9260533104041273, 0.9404761904761905, 0.9274124679760888, 0.9408695652173913, 0.9405172413793104, 0.9437340153452686, 0.9390034364261168, 0.9398814563928873, 0.944206008583691, 0.9359649122807018, 0.9370146678170836, 0.9273984442523768, 0.9373412362404742, 0.931239388794567, 0.9271636675235647, 0.9460616438356164, 0.9503849443969205, 0.9465056082830026, 0.9301121656600517, 0.924831081081081, 0.9283276450511946, 0.936411149825784, 0.9281437125748503, 0.9431034482758621, 0.9241786015164279, 0.9304495335029687, 0.9336099585062241, 0.9372881355932203, 0.9333910034602076, 0.9421915444348576, 0.9307432432432432, 0.9299743808710503, 0.9408284023668639, 0.9533106960950763, 0.9305912596401028, 0.939034716342083, 0.9413763806287171, 0.9294217687074829, 0.9433962264150944, 0.9248945147679325, 0.9370689655172414, 0.9252823631624674, 0.9393162393162393, 0.9405172413793104, 0.9385140905209223, 0.9457567804024497, 0.9444444444444444, 0.9305555555555556, 0.944206008583691, 0.9432989690721649, 0.9418907198612315, 0.9381879762912786, 0.9421276595744681, 0.9317988064791134, 0.9472340425531914, 0.935429056924384, 0.9401197604790419, 0.9421915444348576, 0.9273504273504274, 0.9366438356164384, 0.9321148825065274, 0.9201009251471826, 0.9447278911564626, 0.9482612383375743, 0.9462457337883959, 0.944206008583691, 0.9306506849315068, 0.944110060189166, 0.94331641285956, 0.9287553648068669, 0.9440734557595993, 0.9203084832904884, 0.9323050556983719, 0.9324786324786325, 0.9370212765957446, 0.9291808873720137, 0.9393428812131424, 0.9425878320479862, 0.9294926913155632, 0.9439655172413793, 0.9381974248927039, 0.9411262798634812, 0.9186147186147187, 0.938135593220339, 0.9397071490094746, 0.9433643279797126, 0.9369602763385146, 0.9181585677749361, 0.9255499153976311, 0.9426585577758471, 0.9457364341085271, 0.9269328802039083, 0.9292412617220801, 0.9406196213425129, 0.9314720812182741, 0.9447799827437446, 0.932937181663837, 0.9432684165961049, 0.9446808510638298, 0.9141886151231946, 0.9393939393939394, 0.9308283518360376, 0.9399141630901288, 0.9335038363171355, 0.9388984509466437, 0.9326424870466321, 0.9407783417935702, 0.9431034482758621, 0.9229422066549913, 0.9363714531384351, 0.9384088964927289, 0.9421768707482994, 0.9435075885328836, 0.934018851756641, 0.9427350427350427, 0.9399830938292477, 0.9419795221843004, 0.9316455696202531, 0.9471919530595139, 0.9412780656303973, 0.9341880341880342, 0.9339622641509434, 0.9377192982456141, 0.9384615384615385, 0.9251934651762683, 0.9250645994832042, 0.9381879762912786, 0.9376068376068376, 0.942390369733448, 0.9362786745964317, 0.9424892703862661, 0.924190800681431, 0.9318181818181818, 0.9307432432432432, 0.9333902647309992, 0.9283246977547496, 0.941586748038361, 0.9395017793594306, 0.9420916162489196, 0.9437819420783645, 0.9440203562340967, 0.930976430976431, 0.9511986301369864, 0.9249374478732277, 0.9345955249569707, 0.9412780656303973, 0.9368421052631579, 0.9237435008665511, 0.9388794567062818, 0.9326424870466321, 0.947502116850127, 0.9246575342465754, 0.9353448275862069, 0.9356775300171527, 0.9313640312771503, 0.9384088964927289, 0.9262792714657415, 0.9396771452846219, 0.9328802039082413, 0.9388984509466437, 0.9275979557069847, 0.9409209383145091, 0.9326513213981245, 0.931063829787234, 0.9404761904761905, 0.943250214961307, 0.9377664109121909, 0.9380378657487092, 0.9373412362404742, 0.9332755632582322, 0.9329896907216495, 0.9291270527225584, 0.9457627118644067, 0.9279588336192109, 0.9521739130434783, 0.9539930555555556, 0.9383145091225021, 0.9343986543313709, 0.9316666666666666, 0.9383561643835616, 0.934634974533107, 0.9275237273511648, 0.935064935064935, 0.9548167092924126, 0.9375, 0.9389830508474576, 0.9340753424657534, 0.9376623376623376, 0.9432989690721649, 0.9404761904761905, 0.929481733220051, 0.9299743808710503, 0.9334456613310868, 0.9420783645655877, 0.9381879762912786, 0.9363327674023769, 0.9380453752181501, 0.9354026845637584, 0.9278887923544744, 0.9380831212892281, 0.9308873720136519, 0.9228813559322034, 0.9387402933563417, 0.9317032040472175, 0.9277730008598453, 0.9265975820379966, 0.9321888412017167, 0.9417721518987342, 0.9462915601023018, 0.9383680555555556, 0.9278969957081545, 0.933786078098472, 0.9277824978759558, 0.9464740866610025, 0.933786078098472, 0.9349112426035503, 0.9408740359897172, 0.9413763806287171, 0.9366018596787827, 0.9405772495755518, 0.9336823734729494, 0.9457364341085271, 0.934819897084048, 0.9383033419023136, 0.9418907198612315, 0.95, 0.9347457627118644, 0.9265341400172861, 0.9377104377104377, 0.9464131374243734, 0.934931506849315, 0.9401349072512648, 0.9394957983193277, 0.9308016877637131, 0.929481733220051, 0.9391833188531712, 0.9349871685201027, 0.9303525365434222, 0.9271186440677966, 0.9375542064180399, 0.9377664109121909, 0.9227467811158798, 0.9325938566552902, 0.9263067694944301, 0.9385665529010239, 0.9451114922813036, 0.9301346801346801, 0.9413763806287171, 0.9518581081081081, 0.9350877192982456, 0.9533106960950763, 0.9414298018949182, 0.9303135888501742, 0.9357876712328768, 0.9352088661551577, 0.9409209383145091, 0.9458086367485182, 0.9493996569468267, 0.9388275276125744, 0.9326424870466321, 0.9283305227655987, 0.9430543572044866, 0.939932318104907, 0.9307359307359307, 0.9370748299319728, 0.935042735042735, 0.939625850340136, 0.9406113537117904, 0.9210977701543739, 0.9384871155444722, 0.9463986599664992, 0.9328802039082413, 0.931740614334471, 0.946551724137931, 0.9453125, 0.9453125, 0.9377133105802048, 0.9292493528904228, 0.9208510638297872, 0.9437819420783645, 0.9328231292517006, 0.9347079037800687, 0.9309462915601023, 0.932937181663837, 0.9296137339055794, 0.9219554030874786, 0.938671209540034, 0.9403747870528109, 0.9384885764499121, 0.939034716342083, 0.9270568278201866, 0.9335634167385677, 0.9457567804024497, 0.9330508474576271, 0.9319327731092437, 0.9323050556983719, 0.9394714407502132, 0.9286926994906621, 0.9283305227655987, 0.9385665529010239, 0.9427839453458582, 0.9341991341991343, 0.9409317803660566, 0.9463373083475298, 0.9277730008598453, 0.9420783645655877, 0.93071000855432, 0.9371231696813093, 0.9283333333333333, 0.9396771452846219, 0.94275802254987, 0.9445392491467577, 0.9314830875975716, 0.9349871685201027, 0.9282006920415224, 0.9333902647309992, 0.9361158432708688, 0.9405857740585774, 0.9419795221843004, 0.9432013769363167, 0.9312445604873804, 0.9374456993918332, 0.9349871685201027, 0.9389830508474576, 0.9175965665236051, 0.9303904923599321, 0.9370212765957446, 0.9506802721088435, 0.9472340425531914, 0.9299145299145299, 0.9413763806287171, 0.9462555066079296, 0.9370146678170836, 0.9335060449050087, 0.9355932203389831, 0.9404659188955996, 0.9219015280135824, 0.9328743545611016, 0.929004329004329, 0.9428822495606327, 0.9367521367521368, 0.9462636439966414, 0.9383145091225021, 0.9443016281062554, 0.9198635976129582, 0.944633730834753, 0.928448275862069, 0.9319727891156463, 0.9289383561643836, 0.9366554054054054, 0.929957805907173, 0.9385813148788927, 0.9357326478149101, 0.9215686274509803, 0.93025283347864, 0.919104991394148, 0.9283246977547496, 0.9404761904761905, 0.9303525365434222, 0.9426860564585116, 0.9341317365269461, 0.9286328460877042, 0.9368061485909479, 0.9331075359864521, 0.9302127659574468, 0.9301724137931034, 0.9392123287671232, 0.9349112426035503, 0.9380234505862647, 0.9432203389830508, 0.9405857740585774, 0.9421915444348576, 0.9411255411255411, 0.9368061485909479, 0.9471861471861471, 0.939810834049871, 0.9336691855583543, 0.9406113537117904, 0.9338912133891213, 0.9313559322033899, 0.9358196010407632, 0.9443016281062554, 0.9337298215802888, 0.9457167090754877, 0.9492691315563199, 0.9467713787085514, 0.9421768707482994, 0.9279588336192109, 0.9375549692172384, 0.9322916666666666, 0.9374464438731791, 0.9319552110249785, 0.9410760034158838, 0.9272419627749577, 0.9463537300922046, 0.925, 0.9329268292682927, 0.9446808510638298, 0.9346904156064462, 0.9387755102040817, 0.9416243654822335, 0.9421416234887737, 0.9348561759729273, 0.945518453427065, 0.9329940627650551, 0.9468802698145026, 0.9304123711340206, 0.9356223175965666, 0.9250841750841751, 0.9247038917089678, 0.9266211604095563, 0.9424398625429553, 0.9351535836177475, 0.9340753424657534, 0.9388458225667528, 0.9414802065404475, 0.9289383561643836, 0.947502116850127, 0.9295652173913044, 0.9443507588532883, 0.9426160337552743, 0.9314481576692374, 0.9300758213984835, 0.9362445414847161, 0.9263067694944301, 0.9361158432708688, 0.9392643284858854, 0.9386189258312021, 0.9473237043330501, 0.9399830938292477, 0.9396551724137931, 0.9323630136986302, 0.9210754553339116, 0.9327086882453152, 0.9300758213984835, 0.9353191489361702, 0.9212924606462303, 0.9297205757832345, 0.9251934651762683, 0.9448685326547922, 0.9398998330550918, 0.9445407279029463, 0.9391377852916315, 0.9340659340659341, 0.9312123817712812, 0.9341421143847487, 0.9416809605488851, 0.9264705882352942, 0.949486301369863, 0.9387931034482758, 0.938207136640557, 0.9395509499136442, 0.9332191780821918, 0.9402460456942003, 0.9321458863443596, 0.9458762886597938, 0.9283276450511946, 0.9349112426035503, 0.9298545765611634, 0.9379310344827586, 0.9336170212765957, 0.9291882556131261, 0.9258943781942078, 0.9285714285714286, 0.9274261603375528, 0.9263959390862944, 0.9356477561388654, 0.9343128781331028, 0.923785594639866, 0.9424398625429553, 0.9476351351351351, 0.9316239316239316, 0.9343003412969283, 0.9371772805507745, 0.9297343616109683, 0.9421416234887737, 0.9309153713298791, 0.9347079037800687, 0.9455017301038062, 0.9462738301559792, 0.933277027027027, 0.9335038363171355, 0.9337919174548581, 0.9393939393939394, 0.9283305227655987, 0.941991341991342, 0.9357326478149101, 0.9293617021276596, 0.9361702127659575, 0.9238665526090676, 0.926829268292683, 0.9325938566552902, 0.9316608996539792, 0.934468085106383, 0.9303691275167785, 0.9280138768430182, 0.9282051282051282, 0.9411764705882353, 0.9260226283724978, 0.9541984732824428, 0.9344978165938864, 0.9354026845637584, 0.9420289855072463, 0.9448751076658053, 0.9227504244482173, 0.9298545765611634, 0.944110060189166, 0.9343003412969283, 0.9375542064180399, 0.9276485788113695, 0.9242424242424242, 0.941830624465355, 0.9344262295081968, 0.9419410745233969, 0.9343128781331028, 0.9321888412017167, 0.9364944961896697, 0.9299474605954466, 0.9492691315563199, 0.9283865401207938, 0.9288164665523156, 0.9384615384615385, 0.9434931506849316, 0.9381879762912786, 0.9264705882352942, 0.9195596951735817, 0.9307359307359307, 0.940068493150685, 0.9331046312178388, 0.925513698630137, 0.9190800681431005, 0.9393680614859095, 0.9455488331892826, 0.9279661016949152, 0.9398625429553265, 0.9323050556983719, 0.9378723404255319, 0.9447748513169074, 0.934931506849315, 0.937231298366294, 0.9422413793103448, 0.928448275862069]\n",
            "sd_acc: 0.007717964245438891\n",
            "sd_f1: 0.0046979580186572245\n",
            "sd_mcc: 0.030770667245480488\n",
            "sd_sn: 0.007151156287979007\n",
            "sd_sp: 0.007151156287979007\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.74      0.69       187\n",
            "           1       0.96      0.94      0.95      1169\n",
            "\n",
            "    accuracy                           0.91      1356\n",
            "   macro avg       0.80      0.84      0.82      1356\n",
            "weighted avg       0.92      0.91      0.91      1356\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.007717964245438891, 0.030770667245480488, 0.0046979580186572245)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Basic Protocol 3 — Step 10\n",
        "\n",
        "predicted_mlp = classifier.predict(test_dataset)\n",
        "accuracy = accuracy_score(testing_labels, predicted_mlp)\n",
        "error_rate(testing_labels, predicted_mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzHq6kceTcLo"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(train_dataset)\n",
        "df.to_excel('/content/mlp_train_dataset.xlsx')\n",
        "df =pd.DataFrame(training_labels)\n",
        "df.to_excel('/content/mlp_training_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_training_labels)\n",
        "df.to_excel('/content/mlp_pred_train_labels.xlsx')\n",
        "\n",
        "df =pd.DataFrame(test_dataset)\n",
        "df.to_excel('/content/mlp_test_dataset.xlsx')\n",
        "df =pd.DataFrame(testing_labels)\n",
        "df.to_excel('/content/mlp_testing_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_mlp)\n",
        "df.to_excel('/content/mlp_pred_test_labels.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeG8NDvGBeYM"
      },
      "outputs": [],
      "source": [
        "from pandas import DataFrame\n",
        "cv_results = DataFrame(classifiers.cv_results_)\n",
        "print(cv_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViDDElvGBnf6"
      },
      "outputs": [],
      "source": [
        "# Further metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Data visualization\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqKqqPfoBvZ7"
      },
      "outputs": [],
      "source": [
        "classes = np.unique(testing_labels)\n",
        "\n",
        "confusion_matrix_data = confusion_matrix(testing_labels, predicted_mlp, labels=classes)\n",
        "conf_matrix(confusion_matrix_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azx1iNma1Lyc"
      },
      "outputs": [],
      "source": [
        "TP = confusion_matrix_data[1,1]\n",
        "TN = confusion_matrix_data[0,0]\n",
        "FP = confusion_matrix_data[0,1]\n",
        "FN = confusion_matrix_data[1,0]\n",
        "\n",
        "print(TP,TN, FP, FN)\n",
        "\n",
        "sn = TP / float(TP + FN)\n",
        "print(sn)\n",
        "sp = TN / float(TN + FP)\n",
        "print(sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBR_WxhhOg81"
      },
      "outputs": [],
      "source": [
        "#classifier.save_weights('/result/MLP.h5')\n",
        "\n",
        "#fig, axes = plt.subplots(4, 4)\n",
        "# use global min / max to ensure all weights are shown on the same scale\n",
        "vmin, vmax = classifier.coefs_[0].min(), classifier.coefs_[0].max()\n",
        "#for coef, ax in zip(classifier.coefs_[0].T, axes.ravel()):\n",
        "#    ax.matshow(coef.reshape(1024, ), cmap=plt.cm.gray, vmin=0.5 * vmin, vmax=0.5 * vmax)\n",
        "#    ax.set_xticks(())\n",
        "#    ax.set_yticks(())\n",
        "\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FudCxEtRT-SY"
      },
      "outputs": [],
      "source": [
        "vmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icNm5SrdoKTv"
      },
      "outputs": [],
      "source": [
        "weights = classifier.coefs_\n",
        "print(len(weights))\n",
        "print(\"shape\",weights[0].shape,\"content\",weights[0])\n",
        "print(\"shape\",weights[1].shape,\"content\",weights[1])\n",
        "#print(\"shape\",weights[2].shape,\"content\",weights[2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC6sZ0D_kgZj"
      },
      "source": [
        "### CNN with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8S7uiM5ykoYz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Dropout, Activation\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GycVI1SWkoY0"
      },
      "outputs": [],
      "source": [
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D, AveragePooling1D\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-SW6lCZkuvLH"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "od56RcTJuvLH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g2wBaT28koY0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jJcrkuiokoY0"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jHoLG0YFkoY0"
      },
      "outputs": [],
      "source": [
        "n_timesteps, n_features, n_outputs =train_dataset.shape[0], train_dataset.shape[1], Y_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cpfyojPuYKtg"
      },
      "outputs": [],
      "source": [
        "n_epochs = 30 # 30\n",
        "n_epochs_cv = 10 # 10  # reduce number of epochs for cross validation for performance reason\n",
        "\n",
        "n_cv = 10\n",
        "validation_ratio = 0.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lavUwJEZPC9T"
      },
      "outputs": [],
      "source": [
        "def create_cnn_model(pool_type='max', conv_activation='tanh', dropout_rate=0.1, kernel=3, optimizer='adam'):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # first layer: convolution\n",
        "    #model.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(Conv1D(filters=128, kernel_size=kernel, activation=conv_activation,input_shape=(n_features,1)))\n",
        "    # second series of layers: convolution, pooling, and dropout\n",
        "    model.add(Conv1D(32, kernel_size=kernel, activation=conv_activation))\n",
        "    if pool_type == 'max':\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "    if pool_type == 'average':\n",
        "        model.add(AveragePooling1D(pool_size=2))\n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    # third series of layers: convolution, pooling, and dropout\n",
        "    model.add(Conv1D(64, kernel_size=kernel, activation=conv_activation))   # 32   10\n",
        "    if pool_type == 'max':\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "    if pool_type == 'average':\n",
        "        model.add(AveragePooling1D(pool_size=2))\n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Conv1D(64, kernel_size=kernel, activation=conv_activation))   # 32   10\n",
        "    if pool_type == 'max':\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "    if pool_type == 'average':\n",
        "        model.add(AveragePooling1D(pool_size=2))\n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    # fourth series\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='sigmoid')) # 64\n",
        "    # add a dropout layer if rate is not null\n",
        "    if dropout_rate != 0:\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer= optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'],\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VLA3JilNT1UC"
      },
      "outputs": [],
      "source": [
        "cnn = create_cnn_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gGjva7x6T7mx",
        "outputId": "607f9ced-cada-4453-951b-71da059ede32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 2558, 128)         512       \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 2556, 32)          12320     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 1278, 32)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1278, 32)          0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 1276, 64)          6208      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 638, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 638, 64)           0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 636, 64)           12352     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 318, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 318, 64)           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 20352)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1302592   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,334,049\n",
            "Trainable params: 1,334,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AhtyDVo3-kk6"
      },
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor='val_loss', patience=150, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2Yf-Lgae-n4_",
        "outputId": "20fb8125-884b-4693-c097-ee3eb6987a60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "178/178 [==============================] - 41s 209ms/step - loss: 0.2990 - accuracy: 0.8644 - recall: 0.9348 - precision: 0.8741 - true_positives: 3598.0000 - true_negatives: 1303.0000 - false_positives: 518.0000 - false_negatives: 251.0000 - val_loss: 0.2537 - val_accuracy: 0.8791 - val_recall: 0.8973 - val_precision: 0.9597 - val_true_positives: 1049.0000 - val_true_negatives: 143.0000 - val_false_positives: 44.0000 - val_false_negatives: 120.0000\n",
            "Epoch 2/10\n",
            "178/178 [==============================] - 52s 290ms/step - loss: 0.1929 - accuracy: 0.9206 - recall: 0.9499 - precision: 0.9343 - true_positives: 3656.0000 - true_negatives: 1564.0000 - false_positives: 257.0000 - false_negatives: 193.0000 - val_loss: 0.2439 - val_accuracy: 0.8923 - val_recall: 0.9068 - val_precision: 0.9663 - val_true_positives: 1060.0000 - val_true_negatives: 150.0000 - val_false_positives: 37.0000 - val_false_negatives: 109.0000\n",
            "Epoch 3/10\n",
            "178/178 [==============================] - 40s 224ms/step - loss: 0.1562 - accuracy: 0.9330 - recall: 0.9564 - precision: 0.9455 - true_positives: 3681.0000 - true_negatives: 1609.0000 - false_positives: 212.0000 - false_negatives: 168.0000 - val_loss: 0.2486 - val_accuracy: 0.9004 - val_recall: 0.9196 - val_precision: 0.9633 - val_true_positives: 1075.0000 - val_true_negatives: 146.0000 - val_false_positives: 41.0000 - val_false_negatives: 94.0000\n",
            "Epoch 4/10\n",
            "178/178 [==============================] - 36s 200ms/step - loss: 0.1305 - accuracy: 0.9489 - recall: 0.9649 - precision: 0.9599 - true_positives: 3714.0000 - true_negatives: 1666.0000 - false_positives: 155.0000 - false_negatives: 135.0000 - val_loss: 0.2625 - val_accuracy: 0.8923 - val_recall: 0.9068 - val_precision: 0.9663 - val_true_positives: 1060.0000 - val_true_negatives: 150.0000 - val_false_positives: 37.0000 - val_false_negatives: 109.0000\n",
            "Epoch 5/10\n",
            "178/178 [==============================] - 37s 207ms/step - loss: 0.1097 - accuracy: 0.9549 - recall: 0.9706 - precision: 0.9631 - true_positives: 3736.0000 - true_negatives: 1678.0000 - false_positives: 143.0000 - false_negatives: 113.0000 - val_loss: 0.2415 - val_accuracy: 0.9056 - val_recall: 0.9470 - val_precision: 0.9437 - val_true_positives: 1107.0000 - val_true_negatives: 121.0000 - val_false_positives: 66.0000 - val_false_negatives: 62.0000\n",
            "Epoch 6/10\n",
            "178/178 [==============================] - 35s 199ms/step - loss: 0.0883 - accuracy: 0.9663 - recall: 0.9787 - precision: 0.9719 - true_positives: 3767.0000 - true_negatives: 1712.0000 - false_positives: 109.0000 - false_negatives: 82.0000 - val_loss: 0.2323 - val_accuracy: 0.9115 - val_recall: 0.9461 - val_precision: 0.9510 - val_true_positives: 1106.0000 - val_true_negatives: 130.0000 - val_false_positives: 57.0000 - val_false_negatives: 63.0000\n",
            "Epoch 7/10\n",
            "178/178 [==============================] - 36s 205ms/step - loss: 0.0736 - accuracy: 0.9741 - recall: 0.9842 - precision: 0.9778 - true_positives: 3788.0000 - true_negatives: 1735.0000 - false_positives: 86.0000 - false_negatives: 61.0000 - val_loss: 0.3013 - val_accuracy: 0.8857 - val_recall: 0.8965 - val_precision: 0.9686 - val_true_positives: 1048.0000 - val_true_negatives: 153.0000 - val_false_positives: 34.0000 - val_false_negatives: 121.0000\n",
            "Epoch 8/10\n",
            "178/178 [==============================] - 36s 201ms/step - loss: 0.0594 - accuracy: 0.9806 - recall: 0.9883 - precision: 0.9832 - true_positives: 3804.0000 - true_negatives: 1756.0000 - false_positives: 65.0000 - false_negatives: 45.0000 - val_loss: 0.2939 - val_accuracy: 0.8901 - val_recall: 0.9076 - val_precision: 0.9628 - val_true_positives: 1061.0000 - val_true_negatives: 146.0000 - val_false_positives: 41.0000 - val_false_negatives: 108.0000\n",
            "Epoch 9/10\n",
            "178/178 [==============================] - 36s 202ms/step - loss: 0.0501 - accuracy: 0.9838 - recall: 0.9904 - precision: 0.9858 - true_positives: 3812.0000 - true_negatives: 1766.0000 - false_positives: 55.0000 - false_negatives: 37.0000 - val_loss: 0.2724 - val_accuracy: 0.9108 - val_recall: 0.9358 - val_precision: 0.9596 - val_true_positives: 1094.0000 - val_true_negatives: 141.0000 - val_false_positives: 46.0000 - val_false_negatives: 75.0000\n",
            "Epoch 10/10\n",
            "178/178 [==============================] - 36s 202ms/step - loss: 0.0410 - accuracy: 0.9869 - recall: 0.9891 - precision: 0.9917 - true_positives: 3807.0000 - true_negatives: 1789.0000 - false_positives: 32.0000 - false_negatives: 42.0000 - val_loss: 0.2846 - val_accuracy: 0.9071 - val_recall: 0.9444 - val_precision: 0.9476 - val_true_positives: 1104.0000 - val_true_negatives: 126.0000 - val_false_positives: 61.0000 - val_false_negatives: 65.0000\n"
          ]
        }
      ],
      "source": [
        "# fit network\n",
        "history = cnn.fit(train_dataset, Y_train,\n",
        "                        validation_data=(test_dataset, Y_test),\n",
        "                        callbacks=[es],\n",
        "                        epochs=10, verbose=1\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ByEiiFAnO6v5",
        "outputId": "9ec0ca21-9dd8-488d-ab47-cbc40dba1c38"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-61-d21e2dc07263>:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_cnn_model, verbose=1)\n"
          ]
        }
      ],
      "source": [
        "# optimize model\n",
        "start = time()\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_cnn_model, verbose=1)\n",
        "# define parameters and values for grid search\n",
        "param_grid = {\n",
        "    'pool_type': ['max','average'], #max\n",
        "    'conv_activation': ['relu', 'tanh'],#relu\n",
        "    'epochs': [10],\n",
        "    'kernel':[1,2,3,4], #2\n",
        "    'optimizer':['adam','sgd'] #adam\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lY9VpwzjPqNw"
      },
      "outputs": [],
      "source": [
        "grid_scorer = {'accuracy':make_scorer(accuracy_score),'f1':make_scorer(f1_score),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4AjzaBaZDkC",
        "outputId": "0689ec0c-0a71-452e-fdd5-e4948f0dd2e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=10, scoring=grid_scorer, refit='mcc')\n",
        "grid_result = grid.fit(train_dataset, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rITE0rSjYKz7"
      },
      "outputs": [],
      "source": [
        "classifier = grid.best_estimator_\n",
        "\n",
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "liIHz72BjYDh"
      },
      "outputs": [],
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# Save the best model's architecture to a JSON file\n",
        "model_json = grid_result.best_estimator_.model.to_json()\n",
        "with open(\"/content/drive/MyDrive/Halophilic/CNNESM_best_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Save the best model's weights to an HDF5 file\n",
        "grid_result.best_estimator_.model.save_weights(\"/content/drive/MyDrive/Halophilic/CNNESM_best_model_weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YXH7b_VacCie"
      },
      "outputs": [],
      "source": [
        "predicted_training_labels = classifier.predict(train_dataset)\n",
        "error_rate(training_labels, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ilgVWiL4cGtR"
      },
      "outputs": [],
      "source": [
        "predicted_cnn = classifier.predict(test_dataset)\n",
        "error_rate(testing_labels, predicted_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GvU3yNNhgdFO"
      },
      "outputs": [],
      "source": [
        "def display_cv_results(search_results):\n",
        "    print('Best score = {:.4f} using {}'.format(search_results.best_score_, search_results.best_params_))\n",
        "    means = search_results.cv_results_['mean_test_score']\n",
        "    stds = search_results.cv_results_['std_test_score']\n",
        "    params = search_results.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "        print('mean test accuracy +/- std = {:.4f} +/- {:.4f} with: {}'.format(mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pdc9syuZgPDy"
      },
      "outputs": [],
      "source": [
        "# summarize results\n",
        "#print('time for grid search = {:.0f} sec'.format(time()-start))\n",
        "#display_cv_results(grid_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Tn8hczYMdLy5"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(grid.cv_results_)\n",
        "#new_path = '/content/test.xls'\n",
        "#writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/ESM23BCNN2.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45PkomX_j9dy"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(train_dataset)\n",
        "df.to_excel('/content/cnn_train_dataset.xlsx')\n",
        "df =pd.DataFrame(training_labels)\n",
        "df.to_excel('/content/cnn_training_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_training_labels)\n",
        "df.to_excel('/content/cnn_pred_train_labels.xlsx')\n",
        "\n",
        "df =pd.DataFrame(test_dataset)\n",
        "df.to_excel('/content/cnn_test_dataset.xlsx')\n",
        "df =pd.DataFrame(testing_labels)\n",
        "df.to_excel('/content/cnn_testing_labels.xlsx')\n",
        "df =pd.DataFrame(predicted_cnn)\n",
        "df.to_excel('/content/cnn_pred_test_labels.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e7ei0hoj9dy"
      },
      "outputs": [],
      "source": [
        "#from pandas import DataFrame\n",
        "#cv_results = DataFrame(grid.cv_results_)\n",
        "\n",
        "#cv_results[['param_conv_activation','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1Ut3Y2ej9dy"
      },
      "outputs": [],
      "source": [
        "# Further metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Data visualization\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvD7KRaBj9dy"
      },
      "outputs": [],
      "source": [
        "classes = np.unique(testing_labels)\n",
        "\n",
        "confusion_matrix_data = confusion_matrix(testing_labels, predicted_cnn, labels=classes)\n",
        "conf_matrix(confusion_matrix_data)\n",
        "confusion_matrix_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guHyXf_vj9dy"
      },
      "outputs": [],
      "source": [
        "TP = confusion_matrix_data[1,1]\n",
        "TN = confusion_matrix_data[0,0]\n",
        "FP = confusion_matrix_data[0,1]\n",
        "FN = confusion_matrix_data[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpqxYh-7j9dy"
      },
      "outputs": [],
      "source": [
        "sn = TP / float(TP + FN)\n",
        "print(sn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPGTyFCcj9dy"
      },
      "outputs": [],
      "source": [
        "sp = TN / float(TN + FP)\n",
        "print(sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJyR0W1cj9dy"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_figure = px.imshow(\n",
        "    confusion_matrix_data,\n",
        "    labels=dict(x=\"True label\", y=\"Predicted label\", color=\"# of samples\"),\n",
        "    x=classes,\n",
        "    y=classes,\n",
        "    color_continuous_scale='Gray_r'\n",
        ")\n",
        "confusion_matrix_figure.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ1xEprBX6JG"
      },
      "source": [
        "### CNN using Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJgYYpSr6Ru9"
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slw0eCEoYp2B"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJKldHjqYp2C"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzbRNMgKYp2D"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset[:5632], test_dataset[:1280]\n",
        "y_train, y_test = training_labels[:5632], testing_labels[:1280]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PPG3ur4Yp2D"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLsSXtROY86V"
      },
      "outputs": [],
      "source": [
        "X_train = torch.from_numpy(X_train)\n",
        "y_train = torch.from_numpy(y_train).type(torch.FloatTensor) # data type is long\n",
        "\n",
        "X_test = torch.from_numpy(X_test)\n",
        "y_test = torch.from_numpy(y_test).type(torch.FloatTensor) # data type is long\n",
        "\n",
        "batch_size = 128\n",
        "num_epochs = 100\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "test = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UseRZXGZYrt9"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=1, stride=1)\n",
        "        self.tanh1 = nn.Tanh()\n",
        "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=32, kernel_size=1)\n",
        "        self.tanh2 = nn.Tanh()\n",
        "        self.maxpool1 = nn.MaxPool1d(kernel_size=2)\n",
        "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=1)\n",
        "        self.tanh3 = nn.Tanh()\n",
        "        self.maxpool2 = nn.MaxPool1d(kernel_size=2)\n",
        "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=1)\n",
        "        self.tanh4 = nn.Tanh()\n",
        "        self.maxpool3 = nn.MaxPool1d(kernel_size=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(320, 128)\n",
        "        self.sigmoid1 = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.sigmoid2 = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.tanh1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.tanh2(out)\n",
        "        out = self.maxpool1(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.tanh3(out)\n",
        "        out = self.maxpool2(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.tanh4(out)\n",
        "        out = self.maxpool3(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.sigmoid1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid2(out)\n",
        "        return out\n",
        "\n",
        "# Create CNN\n",
        "model = CNNModel()\n",
        "\n",
        "# Cross Entropy Loss\n",
        "error = nn.BCELoss()\n",
        "\n",
        "# Adam Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1azCptlYwkw",
        "outputId": "a3d6d663-17c3-4487-b47c-736ec805ac86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 500  Loss: 0.00020486551511567086  Accuracy: 8.671875 %\n",
            "Iteration: 1000  Loss: 0.0003513967676553875  Accuracy: 8.671875 %\n",
            "Iteration: 1500  Loss: 8.751754648983479e-05  Accuracy: 8.671875 %\n",
            "Iteration: 2000  Loss: 8.642775355838239e-05  Accuracy: 8.671875 %\n",
            "Iteration: 2500  Loss: 0.00010572530300123617  Accuracy: 8.671875 %\n",
            "Iteration: 3000  Loss: 3.788506001001224e-05  Accuracy: 8.671875 %\n",
            "Iteration: 3500  Loss: 2.9513119443436153e-05  Accuracy: 8.671875 %\n",
            "Iteration: 4000  Loss: 5.871677058166824e-05  Accuracy: 8.671875 %\n"
          ]
        }
      ],
      "source": [
        "# CNN model training\n",
        "count = 0\n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (embeddings, labels) in enumerate(train_loader):\n",
        "        train = embeddings\n",
        "        labels = labels.view(-1, 1)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad() # Clear gradients\n",
        "        outputs = model(train) # Forward propagation\n",
        "        loss = error(outputs, labels) # Calculate softmax and cross entropy loss\n",
        "        loss.backward() # Calculating gradients\n",
        "        optimizer.step() # Update parameters\n",
        "\n",
        "        count += 1\n",
        "\n",
        "        if count % 50 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            # Predict test dataset\n",
        "            for embeddings, labels in test_loader:\n",
        "                test = embeddings\n",
        "                outputs = model(test) # Forward propagation\n",
        "                predicted = torch.max(outputs.data, 1)[1] # Get predictions from the maximum value\n",
        "                total += len(labels) # Total number of labels\n",
        "                correct += (predicted == labels).sum() # Total correct predictions\n",
        "\n",
        "            accuracy = 100.0 * correct.item() / total\n",
        "\n",
        "            # store loss and iteration\n",
        "            loss_list.append(loss.data.item())\n",
        "            iteration_list.append(count)\n",
        "            accuracy_list.append(accuracy)\n",
        "            if count % 500 == 0:\n",
        "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWrjbaEbPL8J"
      },
      "source": [
        "### LR with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ur7Rs3yPKpr"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "rwyF5b1wPTOH",
        "outputId": "33d92e3b-0cef-4228-a96a-070ad7df2716"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(train_dataset, training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRe-fKacPyVH"
      },
      "outputs": [],
      "source": [
        "hyper_params = [{'n_features_to_select': list(range(1, 1024))}]\n",
        "rfe = RFE(lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeyDjPkYPwir"
      },
      "outputs": [],
      "source": [
        "model_cv = GridSearchCV(estimator = rfe,\n",
        "                        param_grid = hyper_params,\n",
        "                        scoring= 'r2',\n",
        "                        cv = 10,\n",
        "                        verbose = 1,\n",
        "                        return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT54Q2SFQSQ-",
        "outputId": "fcd6da79-319f-4638-8bfe-73a2d21319e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 1023 candidates, totalling 10230 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "model_cv.fit(train_dataset, training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2rVcpSHQnj6"
      },
      "outputs": [],
      "source": [
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UejYIxeXLxAO"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(model_cv.cv_results_)\n",
        "#new_path = '/content/test.xls'\n",
        "#writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/SOM/LRESM1bMerged.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlJMkOX4QqfX"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
        "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
        "plt.xlabel('number of features')\n",
        "plt.ylabel('r-squared')\n",
        "plt.title(\"Optimal Number of Features\")\n",
        "plt.legend(['test score', 'train score'], loc='upper left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pOz5dr8Q3hU"
      },
      "outputs": [],
      "source": [
        "# final model\n",
        "n_features_optimal = 10\n",
        "\n",
        "lm = LinearRegression()\n",
        "lm.fit(X_train, y_train)\n",
        "\n",
        "rfe = RFE(lm, n_features_to_select=n_features_optimal)\n",
        "rfe = rfe.fit(X_train, y_train)\n",
        "\n",
        "# predict prices of X_test\n",
        "y_pred = lm.predict(X_test)\n",
        "r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
        "print(r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as02wxoCAjGs"
      },
      "source": [
        "### Capsnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrgQBwJaAxln"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras import initializers, models\n",
        "from keras.layers import LSTM, Bidirectional, BatchNormalization, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tD3XFCo-7C20"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZDiRGv_DbMZ"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5joLEQ6EqfI"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LbIoqNBEfbX"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train[1,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_G9SNF6A52h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "outputId": "ccafadb7-d927-4e7a-9ef3-1e9acb36c209"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Exception encountered when calling layer \"lambda_16\" (type Lambda).\n\nCapsNet_Binary.<locals>.<lambda>() missing 1 required positional argument: 'digit_caps_hat'\n\nCall arguments received by layer \"lambda_16\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 1, 8), dtype=float32)', 'tf.Tensor(shape=(None, 1, 1, 8), dtype=float32)']\n  • mask=None\n  • training=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-731875a80f20>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mroutings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCapsNet_Binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_capsule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_capsule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroutings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Compile the model (binary cross-entropy loss for binary classification)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-731875a80f20>\u001b[0m in \u001b[0;36mCapsNet_Binary\u001b[0;34m(input_shape, num_capsule, dim_capsule, routings)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdigit_caps_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_capsule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_capsule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigit_caps_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Ensure both squashed and digit_caps_hat are passed as arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0magreement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msquashed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigit_caps_hat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquashed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigit_caps_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msquashed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigit_caps_hat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0magreement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magreement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdigit_caps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msquashed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magreement\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magreement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquashed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msquashed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magreement\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/core/lambda_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mwatch_accessed_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         ) as tape, tf.variable_creator_scope(_variable_creator):\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"lambda_16\" (type Lambda).\n\nCapsNet_Binary.<locals>.<lambda>() missing 1 required positional argument: 'digit_caps_hat'\n\nCall arguments received by layer \"lambda_16\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 1, 8), dtype=float32)', 'tf.Tensor(shape=(None, 1, 1, 8), dtype=float32)']\n  • mask=None\n  • training=None"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "def CapsNet_Binary(input_shape, num_capsule, dim_capsule, routings=2):\n",
        "  \"\"\"\n",
        "  Creates a CapsNet model architecture for binary classification.\n",
        "\n",
        "  Args:\n",
        "      input_shape: Shape of the input data (e.g., (None, 1024, 1)).\n",
        "      num_capsule: Number of digit capsules (set to 1 for binary classification).\n",
        "      dim_capsule: Dimension of each capsule vector.\n",
        "      routings: Number of routing iterations between DigitCaps and PrimaryCaps.\n",
        "\n",
        "  Returns:\n",
        "      A Keras model representing the CapsNet architecture.\n",
        "  \"\"\"\n",
        "  # Input layer\n",
        "  inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "  # Convolution layer\n",
        "  conv1 = layers.Conv1D(filters=256, kernel_size=9, activation='relu')(inputs)\n",
        "\n",
        "  # Primary capsule layer\n",
        "  primary_capsule = layers.Conv1D(filters=num_capsule * dim_capsule, kernel_size=1)(conv1)\n",
        "  reshaped = layers.Reshape((num_capsule, dim_capsule))(primary_capsule)\n",
        "\n",
        "  # Squashing function (modified for numerical stability)\n",
        "  def squash(x):\n",
        "    norm = tf.sqrt(tf.reduce_sum(tf.square(x), axis=-1, keepdims=True))\n",
        "    squash_factor = (norm + 1) / (norm ** 2 + 1)\n",
        "    return squash_factor * x\n",
        "\n",
        "  squashed = layers.Lambda(squash)(reshaped)\n",
        "\n",
        "  # Digit capsule layer\n",
        "  digit_caps = squashed\n",
        "  for _ in range(routings):\n",
        "    digit_caps_hat = layers.Dense(num_capsule * dim_capsule, activation='relu')(digit_caps)\n",
        "    digit_caps_hat = layers.Reshape((num_capsule, 1, dim_capsule))(digit_caps_hat)\n",
        "    # Ensure both squashed and digit_caps_hat are passed as arguments\n",
        "    agreement = layers.Lambda(lambda squashed, digit_caps_hat: tf.keras.backend.batch_dot(squashed, digit_caps_hat, axes=[1, 1]))([squashed, digit_caps_hat])\n",
        "    agreement = layers.Activation('softmax')(agreement)\n",
        "    digit_caps = layers.Lambda(lambda squashed, agreement: tf.keras.backend.batch_dot(agreement, squashed, axes=[1, 1]))([squashed, agreement])\n",
        "\n",
        "  # Output layer (sigmoid activation for binary classification)\n",
        "  outputs = layers.Dense(1, activation='sigmoid')(digit_caps)\n",
        "\n",
        "  # Model definition\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return model\n",
        "\n",
        "\n",
        "# Example usage (replace with your actual input shape)\n",
        "input_shape = (None, 1024, 1)\n",
        "num_capsule = 1  # Set to 1 for binary classification\n",
        "dim_capsule = 8\n",
        "routings = 2\n",
        "\n",
        "model = CapsNet_Binary(input_shape, num_capsule, dim_capsule, routings)\n",
        "\n",
        "# Compile the model (binary cross-entropy loss for binary classification)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Load your training data (X_train, y_train) - binary labels (0 or 1)\n",
        "# ...\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Save the model (optional)\n",
        "model.save('capsnet_binary_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "def CapsNet(input_shape, num_capsule, dim_capsule, routings=3):\n",
        "    \"\"\"\n",
        "    Creates a CapsNet model architecture.\n",
        "\n",
        "    Args:\n",
        "        input_shape: Shape of the input data (e.g., (1024, 1)).\n",
        "        num_capsule: Number of digit capsules.\n",
        "        dim_capsule: Dimension of each capsule vector.\n",
        "        routings: Number of routing iterations between DigitCaps and PrimaryCaps.\n",
        "\n",
        "    Returns:\n",
        "        A Keras model representing the CapsNet architecture.\n",
        "    \"\"\"\n",
        "    # Input layer\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Convolution layer\n",
        "    conv1 = layers.Conv1D(filters=256, kernel_size=9, activation='relu')(inputs)\n",
        "\n",
        "    # Primary capsule layer\n",
        "    primary_capsule = layers.Conv1D(filters=num_capsule * dim_capsule, kernel_size=9, strides=2, padding='valid')(conv1)\n",
        "\n",
        "    # Calculate the primary capsule output shape dynamically\n",
        "    primary_capsule_output_shape = primary_capsule.shape\n",
        "    reshaped = layers.Reshape((primary_capsule_output_shape[1] * primary_capsule_output_shape[2] // dim_capsule, dim_capsule))(primary_capsule)\n",
        "\n",
        "    # Squashing function (modified for numerical stability)\n",
        "    def squash(x):\n",
        "        norm = tf.sqrt(tf.reduce_sum(tf.square(x), axis=-1, keepdims=True))\n",
        "        squash_factor = (norm ** 2) / (1 + norm ** 2)\n",
        "        return squash_factor * x / norm\n",
        "\n",
        "    squashed = layers.Lambda(squash)(reshaped)\n",
        "\n",
        "    # Digit capsule layer\n",
        "    digit_caps = squashed\n",
        "    for _ in range(routings):\n",
        "        digit_caps_hat = layers.Dense(num_capsule * dim_capsule, activation='relu')(digit_caps)\n",
        "        digit_caps_hat = layers.Reshape((num_capsule, dim_capsule))(digit_caps_hat)\n",
        "        agreement = layers.Lambda(lambda caps: tf.keras.backend.batch_dot(caps, digit_caps, axes=[2, 1]))([squashed, digit_caps_hat])\n",
        "        agreement = layers.Activation('softmax')(agreement)\n",
        "        digit_caps = layers.Lambda(lambda x: tf.keras.backend.batch_dot(agreement, x, axes=[2, 1]))([digit_caps_hat, squashed])\n",
        "\n",
        "    # Flatten the digit capsules output\n",
        "    digit_caps_flat = layers.Flatten()(digit_caps)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Dense(2, activation='softmax')(digit_caps_flat)\n",
        "\n",
        "    # Model definition\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_shape = (1024, 1)  # Replace with your actual input shape\n",
        "num_capsule = 32\n",
        "dim_capsule = 8\n",
        "routings = 3\n",
        "\n",
        "model = CapsNet(input_shape, num_capsule, dim_capsule, routings)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Load your training data (X_train, y_train)\n",
        "# ...\n",
        "\n",
        "# Example training data\n",
        "import numpy as np\n",
        "X_train = np.random.rand(100, 1024, 1)  # Dummy data, replace with actual data\n",
        "Y_train = keras.utils.to_categorical(np.random.randint(2, size=(100, 1)), num_classes=2)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, epochs=10)\n",
        "\n",
        "# Save the model (optional)\n",
        "model.save('capsnet_model.h5')\n"
      ],
      "metadata": {
        "id": "E9a69yOY_YU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg1gq_D_vy7B"
      },
      "outputs": [],
      "source": [
        "predicted_training_labels = classifier.predict(X_train)\n",
        "predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "error_rate(Y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L31Nfq_Rv2wD"
      },
      "outputs": [],
      "source": [
        "# Basic Protocol 3 — Step 10\n",
        "predicted_testing_labels = model.predict(X_test)\n",
        "predicted_testing_labels = np.where(predicted_testing_labels > 0.5, 1, 0)\n",
        "error_rate(Y_test, predicted_testing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tgM9DaT4iGC"
      },
      "source": [
        "### RNN with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK16axrl4iGE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Bidirectional, Input, Embedding, LSTM, Dropout, Dense, InputLayer, GRU\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from time import time\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1GErIWQWyRF"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtwPIv02WyRH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUc3tuPW4iGE"
      },
      "outputs": [],
      "source": [
        "max_length = 1280"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE7qx0Ef4iGF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omdigfpk4iGF"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og6-h7Hl4iGF"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train[1,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY61j3y24iGG"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vibk8C8t4iGG"
      },
      "outputs": [],
      "source": [
        "def create_rnn_model(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam'):\n",
        "    x_input = layers.Input(input_shape)\n",
        "    #emb = Embedding(21, units, input_length=max_length)(x_input)\n",
        "    rnn = SimpleRNN(units, activity_regularizer=l2(regularizer), return_sequences = True)(x_input) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x = Dropout(dropout_rate)(rnn)\n",
        "    rnn2 =SimpleRNN(units, activity_regularizer=l2(dropout_rate))(x) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x2 = Dropout(dropout_rate)(rnn2)\n",
        "    # softmax classifier\n",
        "    x_output = Dense(1, activation='sigmoid')(x2)\n",
        "\n",
        "    model = Model(inputs=x_input, outputs=x_output)\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_init),#solver,#\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fx-WbXR4iGG",
        "outputId": "8fa27cc5-7a83-4753-b962-a70d920c9b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 2560, 1)]         0         \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 2560, 50)          2600      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2560, 50)          0         \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,701\n",
            "Trainable params: 7,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "rnn_model = create_rnn_model()\n",
        "rnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ8aG71e4iGH",
        "outputId": "3316ef3a-d812-4830-ab96-6c42465b8742"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-58-d4d62c73a518>:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_rnn_model, verbose=1, epochs=5)\n"
          ]
        }
      ],
      "source": [
        "start = time()\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_rnn_model, verbose=1, epochs=5)\n",
        "# define parameters and values for grid search\n",
        "\n",
        "parameters = {\n",
        "    'units':[50], # 1024\n",
        "    #'learning_rate_init': [0.001, 0.01],\n",
        "    'solver':['sgd', 'adam'],\n",
        "    'epochs':[2,3,5,10]\n",
        "    #'dropout_rate':[0.0,0.05, 0.1], #0.05\n",
        "    #'regularizer':[0.0,0.05, 0.1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0Us0Bmf4iGH"
      },
      "outputs": [],
      "source": [
        "metrics = {'accuracy':make_scorer(accuracy_score,greater_is_better=True),'f1':make_scorer(f1_score,greater_is_better=True),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VId_Vtu64iGI",
        "outputId": "a3461c5d-da89-447f-eaa5-f0ea50bce837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "178/178 [==============================] - 283s 2s/step - loss: 0.4835 - accuracy: 0.7690\n",
            "Epoch 2/3\n",
            "178/178 [==============================] - 283s 2s/step - loss: 0.4084 - accuracy: 0.8162\n",
            "Epoch 3/3\n",
            "178/178 [==============================] - 281s 2s/step - loss: 0.3693 - accuracy: 0.8347\n"
          ]
        }
      ],
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=parameters, n_jobs=-1, cv=10, scoring=metrics, refit='mcc')\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6V4U-0E4iGI"
      },
      "outputs": [],
      "source": [
        "classifier = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxZTjoZX4iGJ",
        "outputId": "acc13b08-767b-4353-90cc-ba20bf80ae4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbose': 1,\n",
              " 'epochs': 3,\n",
              " 'solver': 'sgd',\n",
              " 'units': 50,\n",
              " 'build_fn': <function __main__.create_rnn_model(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam')>}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU7pc4Fz4iGJ"
      },
      "outputs": [],
      "source": [
        "#cv_results = DataFrame(grid.cv_results_)\n",
        "\n",
        "#cv_results[['param_units','param_dropout_rate','param_regularizer','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGc8apIR4iGJ"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(grid.cv_results_)\n",
        "new_path = '/content/test.xls'\n",
        "writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/ESM23BRNN2.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtA2NV_z4iGK",
        "outputId": "19fb5eb6-f691-4a7a-daec-66f610cdab61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "178/178 [==============================] - 49s 276ms/step\n",
            "acc: 0.8359788359788359\n",
            "f1: 0.8831658291457287\n",
            "mcc: 0.612743893963337\n",
            "sn: [0.9175176747839748, 0.9179852320675106, 0.9206598586017282, 0.9136989862230309, 0.9228556485355649, 0.9105522426756546, 0.9111575646720669, 0.9089486042264545, 0.9121196222455404, 0.9102398761929327, 0.9131101456682852, 0.9048609305952691, 0.9146845915201655, 0.9174406604747162, 0.9151843258571797, 0.9089716684155299, 0.9177939646201873, 0.9113760041461518, 0.9055483870967742, 0.9124805800103574, 0.9134042001555613, 0.9092563702548102, 0.9202211690363349, 0.922875131164743, 0.9160747171796896, 0.9155776267642446, 0.9074410163339383, 0.9108860759493671, 0.9126775381378222, 0.9209968186638389, 0.9150360453141092, 0.917989417989418, 0.9191157347204161, 0.9124675324675324, 0.9086638830897703, 0.9181485355648535, 0.9130322580645162, 0.9137355584082156, 0.9129866736347008, 0.9159856996935649, 0.913545407901488, 0.916885159937074, 0.9173924518342571, 0.9145118733509234, 0.9136881122584062, 0.9140461215932913, 0.9122624316584222, 0.9077809798270894, 0.9163254861821903, 0.9154783510500389, 0.921251629726206, 0.9171369933299128, 0.9144686299615877, 0.916058394160584, 0.9211209133367929, 0.9080429656798533, 0.9150720838794233, 0.9165816326530613, 0.9118954248366014, 0.9169262720664589, 0.9095335725269093, 0.9119266055045872, 0.9077404222048475, 0.9211746522411128, 0.9106583072100314, 0.9111918982082576, 0.9177657098525989, 0.9151234567901234, 0.9113725490196078, 0.9145898234683282, 0.9178372647760403, 0.9228418640183346, 0.9210665258711721, 0.9137082145633584, 0.9056702377841651, 0.9118564742589703, 0.9054583442151998, 0.9219638242894057, 0.9184095016782856, 0.915010460251046, 0.9132706374085684, 0.9048863339430363, 0.9145898234683282, 0.9189748899818794, 0.9117112438327707, 0.9138867339022498, 0.922237017310253, 0.9199151418721825, 0.9192287649817613, 0.9091144484722942, 0.920301142263759, 0.9134615384615384, 0.9101479915433404, 0.9098701298701298, 0.9126840609661586, 0.9100156494522692, 0.9157785287236808, 0.9076129032258065, 0.913347128815313, 0.9069286452947259, 0.9107652399481193, 0.9155077407504592, 0.9183032207384132, 0.909233586188857, 0.9133007460766658, 0.9157187176835574, 0.9053519641444767, 0.913168187744459, 0.9100691775557264, 0.9082051282051282, 0.9193673839771843, 0.905591677503251, 0.9169751454257007, 0.9076883517613783, 0.9146183699870634, 0.9063818565400844, 0.9188906331763474, 0.9109606873210101, 0.9150992685475444, 0.9164484023048717, 0.9125782881002088, 0.9170591313448456, 0.9208354822073234, 0.9115434500648508, 0.912839248434238, 0.9096133751306165, 0.913375796178344, 0.9147993746743095, 0.9153246753246753, 0.9133898740683629, 0.9150275373721479, 0.9150360453141092, 0.9169638308711157, 0.9096841555729575, 0.9149323621227887, 0.9113236814891417, 0.9091389329107237, 0.9184258535314047, 0.9155113784985613, 0.9176349083397882, 0.9197402597402597, 0.910455486542443, 0.921584054550223, 0.9137709137709138, 0.9142335766423357, 0.9175338189386056, 0.9147465437788018, 0.909446764091858, 0.9095897569898093, 0.9120649044752682, 0.905982905982906, 0.9098510582701855, 0.9201962809917356, 0.9135483870967742, 0.9146153846153846, 0.9098467134320603, 0.9035921817221342, 0.9114188659524431, 0.911042944785276, 0.9126694473409802, 0.9103210400636774, 0.9160166406656266, 0.9147387574733559, 0.910106521174331, 0.9107700312174818, 0.9221618825963279, 0.9087793303453731, 0.9131219386439804, 0.9142411642411642, 0.9132007233273056, 0.9122305894572839, 0.9127169127169127, 0.9184526921066388, 0.9127654131491431, 0.9022750775594622, 0.9152763295099061, 0.916794674859191, 0.9133367929423976, 0.9176592439150699, 0.9218790552815987, 0.913111342351717, 0.9169024954978132, 0.9173319598248777, 0.9184615384615384, 0.9215176715176715, 0.9144028703229113, 0.9071611253196931, 0.9069527009563194, 0.9172912897389507, 0.9187790998448008, 0.9112592972557066, 0.917912404930501, 0.9185625646328852, 0.9146277980218636, 0.9244641923680084, 0.9106680476437079, 0.9130546955624355, 0.9125416773531675, 0.9121372031662269, 0.913065976714101, 0.9145165493875423, 0.9147652766850249, 0.9045016913869373, 0.9149987002859371, 0.9168791432942376, 0.9160384715362621, 0.9107096774193548, 0.915753781950965, 0.9136709525059039, 0.91722710812209, 0.9119035133717881, 0.923967377006051, 0.9104046242774566, 0.9172539806838945, 0.9145454545454546, 0.9170769629437678, 0.9032927145449832, 0.9077682514938945, 0.9130548988705017, 0.9210595331759769, 0.9202674897119342, 0.9110462028677642, 0.9078014184397163, 0.9102231447846393, 0.9115845539280959, 0.9102895553257497, 0.9109838625715773, 0.9105088212733317, 0.9117647058823529, 0.9044668215853343, 0.9131558542258982, 0.9119332985930172, 0.911504424778761, 0.9153425371190415, 0.9161939143888602, 0.9121887287024901, 0.9149870801033592, 0.9289589253422889, 0.9115523465703971, 0.9120370370370371, 0.9127272727272727, 0.9109114249037227, 0.923921568627451, 0.9072004159085001, 0.9130434782608695, 0.9090196078431373, 0.911261027503892, 0.9139473684210526, 0.9151530877010898, 0.9108527131782945, 0.9028974158183242, 0.9081872874705729, 0.9138606108065779, 0.9070910973084886, 0.9069828722002635, 0.9118485869847032, 0.9155370177267987, 0.9142632406921867, 0.916843220338983, 0.9116108786610879, 0.9050883205905615, 0.9106635682933126, 0.9171990799897777, 0.9124805800103574, 0.921736869474779, 0.9173767105602891, 0.9183303085299456, 0.9155334728033473, 0.915086990392106, 0.908781127129751, 0.914810978767478, 0.91060724524368, 0.9093521421107628, 0.9220915032679738, 0.9093985941161156, 0.9040020925974366, 0.9161323416260579, 0.917885552989479, 0.9098467134320603, 0.9113891060724524, 0.9122216468151217, 0.9047494096037786, 0.9107515657620042, 0.9165158955802533, 0.918961038961039, 0.9155578300921188, 0.9136482939632546, 0.9062580479011074, 0.914574165156614, 0.899897066392177, 0.9151016207872396, 0.9127569847127043, 0.9122257053291536, 0.9182829066459788, 0.9114188659524431, 0.9103699843668578, 0.9149383040168023, 0.9171858774662512, 0.907922350472193, 0.908150064683053, 0.9145144628099173, 0.9151657530670844, 0.9195646402973188, 0.9136799596163554, 0.9228978007761967, 0.9156878099712868, 0.9173187271778821, 0.9184149184149184, 0.9165158955802533, 0.9183514774494557, 0.9088066701406983, 0.9139728884254432, 0.9079819676478388, 0.9183410613086038, 0.9153034300791557, 0.9060190073917634, 0.8981385729058945, 0.9210324559161769, 0.9134289439374185, 0.9212926765702372, 0.9057104913678619, 0.9114857744994731, 0.9178258629572386, 0.9138731304796287, 0.916580310880829, 0.902407116692831, 0.914116739521728, 0.9135834411384217, 0.9091614906832298, 0.9147816938453446, 0.9102998696219036, 0.9071409887522888, 0.9124544033350703, 0.9154966198647946, 0.9109086307263984, 0.9201361612987693, 0.9116727462219906, 0.9198966408268734, 0.9168367346938775, 0.9139728884254432, 0.9160949868073879, 0.9139922978177151, 0.9160621761658031, 0.9113493723849372, 0.9108757427021441, 0.9176439927026323, 0.914832285115304, 0.9195550957061562, 0.9196704428424305, 0.9118323536928188, 0.9181011997913406, 0.9169270833333333, 0.911911648698396, 0.9182930002602133, 0.9096433289299868, 0.9101966873706004, 0.913953488372093, 0.9150918974889982, 0.9190304280556988, 0.9172558261324955, 0.9149269311064718, 0.9105331599479844, 0.9132035770647028, 0.9124106906589045, 0.9198660139139397, 0.916578947368421, 0.9171643728901584, 0.9094165813715456, 0.9193882840850182, 0.9157376199118485, 0.9122577265584075, 0.9117191533298916, 0.9135357694287185, 0.9121338912133892, 0.9172359432475039, 0.9100950423837657, 0.9146793852676206, 0.9145344236349249, 0.9089267285861713, 0.9104995992519369, 0.9118400820092261, 0.9104046242774566, 0.9071521456436931, 0.909302928219746, 0.916256157635468, 0.9127725856697819, 0.9207094418362024, 0.907764460656592, 0.9157866948257656, 0.9038361845515811, 0.9067840497151735, 0.9069828035435122, 0.9161864850707176, 0.9135092761954534, 0.9123537061118335, 0.910057024364956, 0.9110878661087866, 0.911217437533227, 0.9117043121149897, 0.9220846233230134, 0.9155996864384636, 0.9132114344578934, 0.912050406930953, 0.9120851279452749, 0.9164118246687054, 0.9117121714723143, 0.9172253739040742, 0.9131224066390041, 0.914778578784758, 0.9035833977829337, 0.9099788806758183, 0.9170250442701745, 0.9164280135381411, 0.9144050104384134, 0.9103736608309381, 0.9115805946791862, 0.9120850622406639, 0.9133263925039042, 0.9183410613086038, 0.9104865990111892, 0.91231679094883, 0.9118793865349623, 0.9166883624056236, 0.9177657098525989, 0.9166021172217919, 0.9141152049818371, 0.9153605015673981, 0.9150918974889982, 0.9217231415812976, 0.9176592439150699, 0.9046748498302429, 0.9155624837620161, 0.9155002592016589, 0.9133385539023754, 0.9154070538318748, 0.9141597510373444, 0.9103933315967699, 0.9202168861347793, 0.9146820204135043, 0.9081975691750711, 0.9161273621537666, 0.9070738710519447, 0.910645902476385, 0.9147668393782383, 0.9087846592381446, 0.911093627065303, 0.9114352696014587, 0.9113660062565172, 0.902101486417222, 0.909257802255442, 0.9203655352480418, 0.9184313725490196, 0.9141453322989398, 0.9139107611548556, 0.9182106934886183, 0.9091379756665804, 0.9051094890510949, 0.9134020618556701, 0.9139280125195618, 0.9125711329539575, 0.9105456453305352, 0.9063146997929606, 0.9074980675083741, 0.9125065685759327, 0.9080430327868853, 0.9139812889812889, 0.908714765968451, 0.9076641381114308, 0.9024008350730689, 0.9105900541097656, 0.9118335500650195, 0.917312661498708, 0.9134187810619931, 0.912975912975913, 0.9167528438469493, 0.9108729743857815, 0.9169909208819714, 0.9076441429689538, 0.9154203197524498, 0.9093023255813953, 0.9146149816657936, 0.9103538663171691, 0.9018740239458616, 0.9066973415132924, 0.9120104438642298, 0.912448347107438, 0.909020618556701, 0.9154421242588296, 0.9127045985970382, 0.9136281355055599, 0.9101063829787234, 0.9127693116132423, 0.9090670859538784, 0.913303827128352, 0.9147993746743095, 0.9154709105139577, 0.9127413127413128, 0.9062094050402703, 0.9108446298227321, 0.9146919431279621, 0.9117117117117117, 0.916796267496112, 0.9109660574412533, 0.9164287568128731, 0.9147532330430193, 0.9164054336468129, 0.9183032207384132, 0.9093477144324602, 0.9172056921086675, 0.911504424778761, 0.9165797705943691, 0.9117037804246504, 0.9137042761463163, 0.9112672391360916, 0.9167987321711569, 0.9190231362467867, 0.9114745586708204, 0.9145165493875423, 0.9078471863706763, 0.9145124136165856, 0.9149491260109575, 0.9187370600414079, 0.9042195185089309, 0.9145165493875423, 0.9092088197146563, 0.9186652763295099, 0.9106862231534835, 0.9091620986687549, 0.9186949766960124, 0.9145165493875423, 0.9145520455722423, 0.9191685912240185, 0.9166224110462029, 0.9106770833333333, 0.9149491260109575, 0.9155077407504592, 0.9131799163179917, 0.9079979090433874, 0.904258064516129, 0.9128630705394191, 0.9067951054412914, 0.9166228300894266, 0.9109907120743034, 0.909784324039979, 0.9078709677419354, 0.9046647973489677, 0.9051971794202142, 0.9151405726076863, 0.9068550497121926, 0.9097491595552107, 0.9194100605741374, 0.9161849710982659, 0.9085413929040735, 0.9154601861427094, 0.9189958592132506, 0.9155227032734953, 0.9118942731277533, 0.9172912897389507, 0.9072404019582582, 0.9146596858638744, 0.9028947368421053, 0.9127725856697819, 0.9155977424320164, 0.9095580678314491, 0.9091383812010444, 0.9109143005991144, 0.9164511122607346, 0.9050352204539526, 0.9156720290607161, 0.918724279835391, 0.911741935483871, 0.9142783372063, 0.9076367389060888, 0.9118335500650195, 0.9159555210757694, 0.9045045045045045, 0.9184627369514412, 0.9080430327868853, 0.911948051948052, 0.917312661498708, 0.9157566302652106, 0.9151888974556669, 0.9117876658860266, 0.9116719242902208, 0.9150447133087849, 0.9106635682933126, 0.9089730290456431, 0.9110821382007823, 0.9158805031446541, 0.9139589290356122, 0.9133919338159255, 0.9114515710205141, 0.9145277207392197, 0.910932225396001, 0.9130548302872062, 0.9108396152846374, 0.9070066975785678, 0.9067951054412914, 0.9110070257611241, 0.9185508735868448, 0.9222946544980444, 0.9162802679031428, 0.9132932880647688, 0.9231954790649884, 0.9106349621113143, 0.9125196437925616, 0.9093484419263456, 0.9193673839771843, 0.9079257127910019, 0.9142634450506625, 0.9140068583487206, 0.9113989637305699, 0.9110938310005184, 0.915390604723592, 0.9121849831124967, 0.9232790331056226, 0.9138110072689511, 0.9149703684617366, 0.9122354155911203, 0.915003887017362, 0.9076530612244897, 0.9145520455722423, 0.9162127107652399, 0.9135929842661852, 0.9174118884797475, 0.9091614906832298, 0.9135416666666667, 0.9101449275362319, 0.917797695262484, 0.9123578076525336, 0.9148273175798494, 0.915851775604735, 0.9204070981210856, 0.9136186770428015, 0.9157416750756812, 0.9128164969981728, 0.9092327698309493, 0.9053069719042663, 0.9225333682282125, 0.9126963687870203, 0.9081580297588507, 0.9212987012987013, 0.91008316008316, 0.9129644063393089, 0.9081364829396326, 0.9107005388760585, 0.9146055714657642, 0.9136410788381742, 0.9188976377952756, 0.9138066544406602, 0.9173637515842838, 0.9057291666666667, 0.916998143728454, 0.9101094319958312, 0.9133611691022965, 0.9068371607515657, 0.9163254861821903, 0.9104633003643935, 0.9113007499353504, 0.918054110301769, 0.9127831293933871, 0.9073208722741433, 0.9042607802874744, 0.9197930142302717, 0.9044438736193168, 0.9049820236260914, 0.9151262692007289, 0.9123359580052494, 0.9098791382028376, 0.911504424778761, 0.9183407252804592, 0.9165583571614245, 0.9122490993309316, 0.9204787234042553, 0.9070670463370437, 0.9173166926677067, 0.9081473793461339, 0.9166883624056236, 0.9085051546391752, 0.9146820204135043, 0.9183673469387755, 0.9124087591240876, 0.9052713987473904, 0.917075691035908, 0.9143079719553363, 0.9138020833333333, 0.9119022869022869, 0.9179220779220779, 0.9135706914344686, 0.9184526921066388, 0.9117799688635184, 0.9155221559989635, 0.9135866736074961, 0.9106546854942233, 0.9115021008403361, 0.9066390041493776, 0.9128205128205128, 0.9183194154488518, 0.9125295508274232, 0.9157108562283276, 0.9097803347280334, 0.9151878914405011, 0.9111799638523108, 0.9152542372881356, 0.9134289439374185, 0.9020671834625323, 0.9110533159947984, 0.9104084321475626, 0.9061203319502075, 0.9081527347781218, 0.9154856995619686, 0.9136989862230309, 0.9095940959409594, 0.9149537512846866, 0.9133385539023754, 0.9110484491156113, 0.9136125654450262, 0.9116869381279746, 0.9227769110764431, 0.9103197296594749, 0.9095554420030659, 0.9121413934426229, 0.9123764950598023, 0.9122577265584075, 0.9088548428979486, 0.9148655772272009, 0.9131117508505627, 0.9160526315789473, 0.9124835742444153, 0.9206594538897476, 0.9097491595552107, 0.9156282450674974, 0.9095386210471748, 0.9037017861765467, 0.9154241645244215, 0.908235294117647, 0.9085923217550275, 0.9151878914405011, 0.91231679094883, 0.9145610836155249, 0.9125810635538262, 0.9107569721115538, 0.9133817427385892, 0.9170628631801373, 0.9149668874172185, 0.9119644723092999, 0.9169522805167414, 0.9101654846335697, 0.9077884865850482, 0.916731923779692, 0.9085638998682477, 0.9229775135693977, 0.911726299294855, 0.906266318537859, 0.9145321484579195, 0.9119170984455959, 0.9184952978056427, 0.91020621247716, 0.9219273383148673, 0.9193211488250653, 0.9061192468619247, 0.9115090861206215, 0.9124315871774824, 0.9093035343035343, 0.9121251629726206, 0.9043410449701066, 0.9157347204161248, 0.911261027503892, 0.9026707755521315, 0.9144496609285342, 0.9175257731958762, 0.9160602910602911, 0.911254851228978, 0.9120429557657888, 0.9093506493506494, 0.9130096078940535, 0.9233341908927193, 0.9192660550458716, 0.9144702842377261, 0.9109090909090909, 0.910761154855643, 0.9177657098525989, 0.9158031088082902, 0.9129634499079674, 0.9107329842931937, 0.9072517078297425, 0.9245430809399477, 0.9196058091286307, 0.9125319693094629, 0.9176377118644068, 0.9190964013659049, 0.907339927121291, 0.9086413326392504, 0.9185010482180294, 0.8985395849346657, 0.9117493472584857, 0.9098723625944256, 0.9082934609250398, 0.9178931061192874, 0.9187935034802784, 0.9194613821138211, 0.9116801672328194, 0.9222280609563847, 0.9011612903225806, 0.9118572927597062, 0.9085507620769827, 0.91795139796185, 0.9150207900207901, 0.9200622891253568, 0.9098723625944256, 0.9173360974345686, 0.9159096807682325, 0.9198433420365535, 0.9166448915599686, 0.9161953727506427, 0.9136152656008252, 0.9141453322989398, 0.908714765968451, 0.9097744360902256, 0.9167313162658391, 0.9039155074703761, 0.9203282159872949, 0.9089486042264545, 0.9102103642893792, 0.9090674244381297, 0.9140445126630852, 0.915003887017362, 0.9166448915599686, 0.9191685912240185, 0.9183407252804592, 0.9215788106985199, 0.9154383242823895, 0.9068550497121926, 0.9177018633540373, 0.9075432163436354, 0.9081527347781218, 0.9119090674244381, 0.9173701713993349, 0.916882444329363, 0.9097610574478902, 0.9157594608605495, 0.9136375354472802, 0.9176195426195426, 0.9136671883150757, 0.9121887287024901, 0.9104786545924968, 0.91285234031549, 0.9139175257731958, 0.9066598097197223, 0.9127621019932695, 0.9108346293416277, 0.9098679098679099, 0.9122257053291536, 0.9106770833333333, 0.9110301768990635, 0.9079530638852673, 0.9086134453781513, 0.9164294954721863, 0.9144190871369294, 0.9084984358706987, 0.9089021541655853, 0.9119627136198861, 0.9200930954228084, 0.9144248014347938, 0.9138953338489302, 0.9105882352941177, 0.9140355531971345, 0.9194386694386695, 0.9091381100726895, 0.9287410926365796, 0.9091620986687549, 0.9182389937106918, 0.9200207738249805, 0.9071949947862357, 0.9112441436751691, 0.9104946349123266, 0.9108017530291312, 0.9179778179004385, 0.9090909090909091, 0.9127952245003893, 0.9241071428571429, 0.9143979057591624, 0.9103575184016824, 0.9146500130106687, 0.9108396152846374, 0.9114583333333334, 0.9159314997405293, 0.912987012987013, 0.9127188465499485, 0.9142264835449598, 0.911116937598322, 0.9142403388035998, 0.9187224097636978, 0.9108577351645504, 0.9129528277299974, 0.9186762442278091, 0.9035733053074093, 0.9160677618069816, 0.9105168423759321, 0.9190736403851157, 0.9125883276629154, 0.9138461538461539, 0.9186700767263427, 0.9187288356342798, 0.9209908735332464, 0.911948051948052, 0.9088090932575562, 0.906670113753878, 0.911522633744856, 0.9120538023797207, 0.9200626959247649, 0.9125386996904025, 0.9152498038189903, 0.9076441429689538, 0.9105712070302404, 0.9154459007967104, 0.9042414780119699, 0.9132492113564669, 0.9131334022750776, 0.9179046129788898, 0.9125455491931286, 0.9051883065578088, 0.9118652986056301, 0.91722710812209, 0.9162961025372743, 0.9090674244381297, 0.9118863049095607, 0.9112503262855651, 0.9138655462184874, 0.9189754312598014, 0.9135064935064935, 0.9078604893284747, 0.9138576779026217, 0.910761154855643, 0.9153945666235447, 0.9055097837281153, 0.918066683897648, 0.9124049305009179, 0.9127066115702479, 0.9178655506147005, 0.9095213045765387, 0.9148771021992238, 0.9177718832891246, 0.9070886075949367, 0.9089971642175818, 0.9148051948051948, 0.9144856180357606, 0.9124087591240876, 0.9179942543745103, 0.9087846592381446, 0.9141752577319587, 0.9128956317028512, 0.9094682230869001, 0.9077809798270894, 0.9183350895679663, 0.911070780399274, 0.9089262613195342, 0.9209908735332464, 0.9126716766001555, 0.9108598474888246, 0.9116266944734098, 0.9118998978549541, 0.919417728099818, 0.9087863952589539, 0.9138988247317322, 0.9046757943683803, 0.9141072358146799, 0.9120936280884265, 0.9159905783826223, 0.9116434827408553, 0.911504424778761, 0.9185242121445042, 0.9168187744458931, 0.9197004905757811, 0.9194665298794563, 0.9061923583662714, 0.9175230566534914, 0.917424045702415, 0.91484375, 0.9122991835659732, 0.9142194744976816, 0.915390604723592, 0.9092084842214175, 0.9030917121330215, 0.910106521174331, 0.9118863049095607, 0.905903583397783, 0.9169254658385093, 0.9112318840579711, 0.9126063418406806, 0.9125465178096757, 0.9188836724047992, 0.9027055150884495, 0.9153111283242964, 0.9064692127825409, 0.9105564222568903, 0.9154024170737979, 0.9133230452674898, 0.9193802521008403, 0.9138020833333333]\n",
            "sp: [0.9175176747839748, 0.9179852320675106, 0.9206598586017282, 0.9136989862230309, 0.9228556485355649, 0.9105522426756546, 0.9111575646720669, 0.9089486042264545, 0.9121196222455404, 0.9102398761929327, 0.9131101456682852, 0.9048609305952691, 0.9146845915201655, 0.9174406604747162, 0.9151843258571797, 0.9089716684155299, 0.9177939646201873, 0.9113760041461518, 0.9055483870967742, 0.9124805800103574, 0.9134042001555613, 0.9092563702548102, 0.9202211690363349, 0.922875131164743, 0.9160747171796896, 0.9155776267642446, 0.9074410163339383, 0.9108860759493671, 0.9126775381378222, 0.9209968186638389, 0.9150360453141092, 0.917989417989418, 0.9191157347204161, 0.9124675324675324, 0.9086638830897703, 0.9181485355648535, 0.9130322580645162, 0.9137355584082156, 0.9129866736347008, 0.9159856996935649, 0.913545407901488, 0.916885159937074, 0.9173924518342571, 0.9145118733509234, 0.9136881122584062, 0.9140461215932913, 0.9122624316584222, 0.9077809798270894, 0.9163254861821903, 0.9154783510500389, 0.921251629726206, 0.9171369933299128, 0.9144686299615877, 0.916058394160584, 0.9211209133367929, 0.9080429656798533, 0.9150720838794233, 0.9165816326530613, 0.9118954248366014, 0.9169262720664589, 0.9095335725269093, 0.9119266055045872, 0.9077404222048475, 0.9211746522411128, 0.9106583072100314, 0.9111918982082576, 0.9177657098525989, 0.9151234567901234, 0.9113725490196078, 0.9145898234683282, 0.9178372647760403, 0.9228418640183346, 0.9210665258711721, 0.9137082145633584, 0.9056702377841651, 0.9118564742589703, 0.9054583442151998, 0.9219638242894057, 0.9184095016782856, 0.915010460251046, 0.9132706374085684, 0.9048863339430363, 0.9145898234683282, 0.9189748899818794, 0.9117112438327707, 0.9138867339022498, 0.922237017310253, 0.9199151418721825, 0.9192287649817613, 0.9091144484722942, 0.920301142263759, 0.9134615384615384, 0.9101479915433404, 0.9098701298701298, 0.9126840609661586, 0.9100156494522692, 0.9157785287236808, 0.9076129032258065, 0.913347128815313, 0.9069286452947259, 0.9107652399481193, 0.9155077407504592, 0.9183032207384132, 0.909233586188857, 0.9133007460766658, 0.9157187176835574, 0.9053519641444767, 0.913168187744459, 0.9100691775557264, 0.9082051282051282, 0.9193673839771843, 0.905591677503251, 0.9169751454257007, 0.9076883517613783, 0.9146183699870634, 0.9063818565400844, 0.9188906331763474, 0.9109606873210101, 0.9150992685475444, 0.9164484023048717, 0.9125782881002088, 0.9170591313448456, 0.9208354822073234, 0.9115434500648508, 0.912839248434238, 0.9096133751306165, 0.913375796178344, 0.9147993746743095, 0.9153246753246753, 0.9133898740683629, 0.9150275373721479, 0.9150360453141092, 0.9169638308711157, 0.9096841555729575, 0.9149323621227887, 0.9113236814891417, 0.9091389329107237, 0.9184258535314047, 0.9155113784985613, 0.9176349083397882, 0.9197402597402597, 0.910455486542443, 0.921584054550223, 0.9137709137709138, 0.9142335766423357, 0.9175338189386056, 0.9147465437788018, 0.909446764091858, 0.9095897569898093, 0.9120649044752682, 0.905982905982906, 0.9098510582701855, 0.9201962809917356, 0.9135483870967742, 0.9146153846153846, 0.9098467134320603, 0.9035921817221342, 0.9114188659524431, 0.911042944785276, 0.9126694473409802, 0.9103210400636774, 0.9160166406656266, 0.9147387574733559, 0.910106521174331, 0.9107700312174818, 0.9221618825963279, 0.9087793303453731, 0.9131219386439804, 0.9142411642411642, 0.9132007233273056, 0.9122305894572839, 0.9127169127169127, 0.9184526921066388, 0.9127654131491431, 0.9022750775594622, 0.9152763295099061, 0.916794674859191, 0.9133367929423976, 0.9176592439150699, 0.9218790552815987, 0.913111342351717, 0.9169024954978132, 0.9173319598248777, 0.9184615384615384, 0.9215176715176715, 0.9144028703229113, 0.9071611253196931, 0.9069527009563194, 0.9172912897389507, 0.9187790998448008, 0.9112592972557066, 0.917912404930501, 0.9185625646328852, 0.9146277980218636, 0.9244641923680084, 0.9106680476437079, 0.9130546955624355, 0.9125416773531675, 0.9121372031662269, 0.913065976714101, 0.9145165493875423, 0.9147652766850249, 0.9045016913869373, 0.9149987002859371, 0.9168791432942376, 0.9160384715362621, 0.9107096774193548, 0.915753781950965, 0.9136709525059039, 0.91722710812209, 0.9119035133717881, 0.923967377006051, 0.9104046242774566, 0.9172539806838945, 0.9145454545454546, 0.9170769629437678, 0.9032927145449832, 0.9077682514938945, 0.9130548988705017, 0.9210595331759769, 0.9202674897119342, 0.9110462028677642, 0.9078014184397163, 0.9102231447846393, 0.9115845539280959, 0.9102895553257497, 0.9109838625715773, 0.9105088212733317, 0.9117647058823529, 0.9044668215853343, 0.9131558542258982, 0.9119332985930172, 0.911504424778761, 0.9153425371190415, 0.9161939143888602, 0.9121887287024901, 0.9149870801033592, 0.9289589253422889, 0.9115523465703971, 0.9120370370370371, 0.9127272727272727, 0.9109114249037227, 0.923921568627451, 0.9072004159085001, 0.9130434782608695, 0.9090196078431373, 0.911261027503892, 0.9139473684210526, 0.9151530877010898, 0.9108527131782945, 0.9028974158183242, 0.9081872874705729, 0.9138606108065779, 0.9070910973084886, 0.9069828722002635, 0.9118485869847032, 0.9155370177267987, 0.9142632406921867, 0.916843220338983, 0.9116108786610879, 0.9050883205905615, 0.9106635682933126, 0.9171990799897777, 0.9124805800103574, 0.921736869474779, 0.9173767105602891, 0.9183303085299456, 0.9155334728033473, 0.915086990392106, 0.908781127129751, 0.914810978767478, 0.91060724524368, 0.9093521421107628, 0.9220915032679738, 0.9093985941161156, 0.9040020925974366, 0.9161323416260579, 0.917885552989479, 0.9098467134320603, 0.9113891060724524, 0.9122216468151217, 0.9047494096037786, 0.9107515657620042, 0.9165158955802533, 0.918961038961039, 0.9155578300921188, 0.9136482939632546, 0.9062580479011074, 0.914574165156614, 0.899897066392177, 0.9151016207872396, 0.9127569847127043, 0.9122257053291536, 0.9182829066459788, 0.9114188659524431, 0.9103699843668578, 0.9149383040168023, 0.9171858774662512, 0.907922350472193, 0.908150064683053, 0.9145144628099173, 0.9151657530670844, 0.9195646402973188, 0.9136799596163554, 0.9228978007761967, 0.9156878099712868, 0.9173187271778821, 0.9184149184149184, 0.9165158955802533, 0.9183514774494557, 0.9088066701406983, 0.9139728884254432, 0.9079819676478388, 0.9183410613086038, 0.9153034300791557, 0.9060190073917634, 0.8981385729058945, 0.9210324559161769, 0.9134289439374185, 0.9212926765702372, 0.9057104913678619, 0.9114857744994731, 0.9178258629572386, 0.9138731304796287, 0.916580310880829, 0.902407116692831, 0.914116739521728, 0.9135834411384217, 0.9091614906832298, 0.9147816938453446, 0.9102998696219036, 0.9071409887522888, 0.9124544033350703, 0.9154966198647946, 0.9109086307263984, 0.9201361612987693, 0.9116727462219906, 0.9198966408268734, 0.9168367346938775, 0.9139728884254432, 0.9160949868073879, 0.9139922978177151, 0.9160621761658031, 0.9113493723849372, 0.9108757427021441, 0.9176439927026323, 0.914832285115304, 0.9195550957061562, 0.9196704428424305, 0.9118323536928188, 0.9181011997913406, 0.9169270833333333, 0.911911648698396, 0.9182930002602133, 0.9096433289299868, 0.9101966873706004, 0.913953488372093, 0.9150918974889982, 0.9190304280556988, 0.9172558261324955, 0.9149269311064718, 0.9105331599479844, 0.9132035770647028, 0.9124106906589045, 0.9198660139139397, 0.916578947368421, 0.9171643728901584, 0.9094165813715456, 0.9193882840850182, 0.9157376199118485, 0.9122577265584075, 0.9117191533298916, 0.9135357694287185, 0.9121338912133892, 0.9172359432475039, 0.9100950423837657, 0.9146793852676206, 0.9145344236349249, 0.9089267285861713, 0.9104995992519369, 0.9118400820092261, 0.9104046242774566, 0.9071521456436931, 0.909302928219746, 0.916256157635468, 0.9127725856697819, 0.9207094418362024, 0.907764460656592, 0.9157866948257656, 0.9038361845515811, 0.9067840497151735, 0.9069828035435122, 0.9161864850707176, 0.9135092761954534, 0.9123537061118335, 0.910057024364956, 0.9110878661087866, 0.911217437533227, 0.9117043121149897, 0.9220846233230134, 0.9155996864384636, 0.9132114344578934, 0.912050406930953, 0.9120851279452749, 0.9164118246687054, 0.9117121714723143, 0.9172253739040742, 0.9131224066390041, 0.914778578784758, 0.9035833977829337, 0.9099788806758183, 0.9170250442701745, 0.9164280135381411, 0.9144050104384134, 0.9103736608309381, 0.9115805946791862, 0.9120850622406639, 0.9133263925039042, 0.9183410613086038, 0.9104865990111892, 0.91231679094883, 0.9118793865349623, 0.9166883624056236, 0.9177657098525989, 0.9166021172217919, 0.9141152049818371, 0.9153605015673981, 0.9150918974889982, 0.9217231415812976, 0.9176592439150699, 0.9046748498302429, 0.9155624837620161, 0.9155002592016589, 0.9133385539023754, 0.9154070538318748, 0.9141597510373444, 0.9103933315967699, 0.9202168861347793, 0.9146820204135043, 0.9081975691750711, 0.9161273621537666, 0.9070738710519447, 0.910645902476385, 0.9147668393782383, 0.9087846592381446, 0.911093627065303, 0.9114352696014587, 0.9113660062565172, 0.902101486417222, 0.909257802255442, 0.9203655352480418, 0.9184313725490196, 0.9141453322989398, 0.9139107611548556, 0.9182106934886183, 0.9091379756665804, 0.9051094890510949, 0.9134020618556701, 0.9139280125195618, 0.9125711329539575, 0.9105456453305352, 0.9063146997929606, 0.9074980675083741, 0.9125065685759327, 0.9080430327868853, 0.9139812889812889, 0.908714765968451, 0.9076641381114308, 0.9024008350730689, 0.9105900541097656, 0.9118335500650195, 0.917312661498708, 0.9134187810619931, 0.912975912975913, 0.9167528438469493, 0.9108729743857815, 0.9169909208819714, 0.9076441429689538, 0.9154203197524498, 0.9093023255813953, 0.9146149816657936, 0.9103538663171691, 0.9018740239458616, 0.9066973415132924, 0.9120104438642298, 0.912448347107438, 0.909020618556701, 0.9154421242588296, 0.9127045985970382, 0.9136281355055599, 0.9101063829787234, 0.9127693116132423, 0.9090670859538784, 0.913303827128352, 0.9147993746743095, 0.9154709105139577, 0.9127413127413128, 0.9062094050402703, 0.9108446298227321, 0.9146919431279621, 0.9117117117117117, 0.916796267496112, 0.9109660574412533, 0.9164287568128731, 0.9147532330430193, 0.9164054336468129, 0.9183032207384132, 0.9093477144324602, 0.9172056921086675, 0.911504424778761, 0.9165797705943691, 0.9117037804246504, 0.9137042761463163, 0.9112672391360916, 0.9167987321711569, 0.9190231362467867, 0.9114745586708204, 0.9145165493875423, 0.9078471863706763, 0.9145124136165856, 0.9149491260109575, 0.9187370600414079, 0.9042195185089309, 0.9145165493875423, 0.9092088197146563, 0.9186652763295099, 0.9106862231534835, 0.9091620986687549, 0.9186949766960124, 0.9145165493875423, 0.9145520455722423, 0.9191685912240185, 0.9166224110462029, 0.9106770833333333, 0.9149491260109575, 0.9155077407504592, 0.9131799163179917, 0.9079979090433874, 0.904258064516129, 0.9128630705394191, 0.9067951054412914, 0.9166228300894266, 0.9109907120743034, 0.909784324039979, 0.9078709677419354, 0.9046647973489677, 0.9051971794202142, 0.9151405726076863, 0.9068550497121926, 0.9097491595552107, 0.9194100605741374, 0.9161849710982659, 0.9085413929040735, 0.9154601861427094, 0.9189958592132506, 0.9155227032734953, 0.9118942731277533, 0.9172912897389507, 0.9072404019582582, 0.9146596858638744, 0.9028947368421053, 0.9127725856697819, 0.9155977424320164, 0.9095580678314491, 0.9091383812010444, 0.9109143005991144, 0.9164511122607346, 0.9050352204539526, 0.9156720290607161, 0.918724279835391, 0.911741935483871, 0.9142783372063, 0.9076367389060888, 0.9118335500650195, 0.9159555210757694, 0.9045045045045045, 0.9184627369514412, 0.9080430327868853, 0.911948051948052, 0.917312661498708, 0.9157566302652106, 0.9151888974556669, 0.9117876658860266, 0.9116719242902208, 0.9150447133087849, 0.9106635682933126, 0.9089730290456431, 0.9110821382007823, 0.9158805031446541, 0.9139589290356122, 0.9133919338159255, 0.9114515710205141, 0.9145277207392197, 0.910932225396001, 0.9130548302872062, 0.9108396152846374, 0.9070066975785678, 0.9067951054412914, 0.9110070257611241, 0.9185508735868448, 0.9222946544980444, 0.9162802679031428, 0.9132932880647688, 0.9231954790649884, 0.9106349621113143, 0.9125196437925616, 0.9093484419263456, 0.9193673839771843, 0.9079257127910019, 0.9142634450506625, 0.9140068583487206, 0.9113989637305699, 0.9110938310005184, 0.915390604723592, 0.9121849831124967, 0.9232790331056226, 0.9138110072689511, 0.9149703684617366, 0.9122354155911203, 0.915003887017362, 0.9076530612244897, 0.9145520455722423, 0.9162127107652399, 0.9135929842661852, 0.9174118884797475, 0.9091614906832298, 0.9135416666666667, 0.9101449275362319, 0.917797695262484, 0.9123578076525336, 0.9148273175798494, 0.915851775604735, 0.9204070981210856, 0.9136186770428015, 0.9157416750756812, 0.9128164969981728, 0.9092327698309493, 0.9053069719042663, 0.9225333682282125, 0.9126963687870203, 0.9081580297588507, 0.9212987012987013, 0.91008316008316, 0.9129644063393089, 0.9081364829396326, 0.9107005388760585, 0.9146055714657642, 0.9136410788381742, 0.9188976377952756, 0.9138066544406602, 0.9173637515842838, 0.9057291666666667, 0.916998143728454, 0.9101094319958312, 0.9133611691022965, 0.9068371607515657, 0.9163254861821903, 0.9104633003643935, 0.9113007499353504, 0.918054110301769, 0.9127831293933871, 0.9073208722741433, 0.9042607802874744, 0.9197930142302717, 0.9044438736193168, 0.9049820236260914, 0.9151262692007289, 0.9123359580052494, 0.9098791382028376, 0.911504424778761, 0.9183407252804592, 0.9165583571614245, 0.9122490993309316, 0.9204787234042553, 0.9070670463370437, 0.9173166926677067, 0.9081473793461339, 0.9166883624056236, 0.9085051546391752, 0.9146820204135043, 0.9183673469387755, 0.9124087591240876, 0.9052713987473904, 0.917075691035908, 0.9143079719553363, 0.9138020833333333, 0.9119022869022869, 0.9179220779220779, 0.9135706914344686, 0.9184526921066388, 0.9117799688635184, 0.9155221559989635, 0.9135866736074961, 0.9106546854942233, 0.9115021008403361, 0.9066390041493776, 0.9128205128205128, 0.9183194154488518, 0.9125295508274232, 0.9157108562283276, 0.9097803347280334, 0.9151878914405011, 0.9111799638523108, 0.9152542372881356, 0.9134289439374185, 0.9020671834625323, 0.9110533159947984, 0.9104084321475626, 0.9061203319502075, 0.9081527347781218, 0.9154856995619686, 0.9136989862230309, 0.9095940959409594, 0.9149537512846866, 0.9133385539023754, 0.9110484491156113, 0.9136125654450262, 0.9116869381279746, 0.9227769110764431, 0.9103197296594749, 0.9095554420030659, 0.9121413934426229, 0.9123764950598023, 0.9122577265584075, 0.9088548428979486, 0.9148655772272009, 0.9131117508505627, 0.9160526315789473, 0.9124835742444153, 0.9206594538897476, 0.9097491595552107, 0.9156282450674974, 0.9095386210471748, 0.9037017861765467, 0.9154241645244215, 0.908235294117647, 0.9085923217550275, 0.9151878914405011, 0.91231679094883, 0.9145610836155249, 0.9125810635538262, 0.9107569721115538, 0.9133817427385892, 0.9170628631801373, 0.9149668874172185, 0.9119644723092999, 0.9169522805167414, 0.9101654846335697, 0.9077884865850482, 0.916731923779692, 0.9085638998682477, 0.9229775135693977, 0.911726299294855, 0.906266318537859, 0.9145321484579195, 0.9119170984455959, 0.9184952978056427, 0.91020621247716, 0.9219273383148673, 0.9193211488250653, 0.9061192468619247, 0.9115090861206215, 0.9124315871774824, 0.9093035343035343, 0.9121251629726206, 0.9043410449701066, 0.9157347204161248, 0.911261027503892, 0.9026707755521315, 0.9144496609285342, 0.9175257731958762, 0.9160602910602911, 0.911254851228978, 0.9120429557657888, 0.9093506493506494, 0.9130096078940535, 0.9233341908927193, 0.9192660550458716, 0.9144702842377261, 0.9109090909090909, 0.910761154855643, 0.9177657098525989, 0.9158031088082902, 0.9129634499079674, 0.9107329842931937, 0.9072517078297425, 0.9245430809399477, 0.9196058091286307, 0.9125319693094629, 0.9176377118644068, 0.9190964013659049, 0.907339927121291, 0.9086413326392504, 0.9185010482180294, 0.8985395849346657, 0.9117493472584857, 0.9098723625944256, 0.9082934609250398, 0.9178931061192874, 0.9187935034802784, 0.9194613821138211, 0.9116801672328194, 0.9222280609563847, 0.9011612903225806, 0.9118572927597062, 0.9085507620769827, 0.91795139796185, 0.9150207900207901, 0.9200622891253568, 0.9098723625944256, 0.9173360974345686, 0.9159096807682325, 0.9198433420365535, 0.9166448915599686, 0.9161953727506427, 0.9136152656008252, 0.9141453322989398, 0.908714765968451, 0.9097744360902256, 0.9167313162658391, 0.9039155074703761, 0.9203282159872949, 0.9089486042264545, 0.9102103642893792, 0.9090674244381297, 0.9140445126630852, 0.915003887017362, 0.9166448915599686, 0.9191685912240185, 0.9183407252804592, 0.9215788106985199, 0.9154383242823895, 0.9068550497121926, 0.9177018633540373, 0.9075432163436354, 0.9081527347781218, 0.9119090674244381, 0.9173701713993349, 0.916882444329363, 0.9097610574478902, 0.9157594608605495, 0.9136375354472802, 0.9176195426195426, 0.9136671883150757, 0.9121887287024901, 0.9104786545924968, 0.91285234031549, 0.9139175257731958, 0.9066598097197223, 0.9127621019932695, 0.9108346293416277, 0.9098679098679099, 0.9122257053291536, 0.9106770833333333, 0.9110301768990635, 0.9079530638852673, 0.9086134453781513, 0.9164294954721863, 0.9144190871369294, 0.9084984358706987, 0.9089021541655853, 0.9119627136198861, 0.9200930954228084, 0.9144248014347938, 0.9138953338489302, 0.9105882352941177, 0.9140355531971345, 0.9194386694386695, 0.9091381100726895, 0.9287410926365796, 0.9091620986687549, 0.9182389937106918, 0.9200207738249805, 0.9071949947862357, 0.9112441436751691, 0.9104946349123266, 0.9108017530291312, 0.9179778179004385, 0.9090909090909091, 0.9127952245003893, 0.9241071428571429, 0.9143979057591624, 0.9103575184016824, 0.9146500130106687, 0.9108396152846374, 0.9114583333333334, 0.9159314997405293, 0.912987012987013, 0.9127188465499485, 0.9142264835449598, 0.911116937598322, 0.9142403388035998, 0.9187224097636978, 0.9108577351645504, 0.9129528277299974, 0.9186762442278091, 0.9035733053074093, 0.9160677618069816, 0.9105168423759321, 0.9190736403851157, 0.9125883276629154, 0.9138461538461539, 0.9186700767263427, 0.9187288356342798, 0.9209908735332464, 0.911948051948052, 0.9088090932575562, 0.906670113753878, 0.911522633744856, 0.9120538023797207, 0.9200626959247649, 0.9125386996904025, 0.9152498038189903, 0.9076441429689538, 0.9105712070302404, 0.9154459007967104, 0.9042414780119699, 0.9132492113564669, 0.9131334022750776, 0.9179046129788898, 0.9125455491931286, 0.9051883065578088, 0.9118652986056301, 0.91722710812209, 0.9162961025372743, 0.9090674244381297, 0.9118863049095607, 0.9112503262855651, 0.9138655462184874, 0.9189754312598014, 0.9135064935064935, 0.9078604893284747, 0.9138576779026217, 0.910761154855643, 0.9153945666235447, 0.9055097837281153, 0.918066683897648, 0.9124049305009179, 0.9127066115702479, 0.9178655506147005, 0.9095213045765387, 0.9148771021992238, 0.9177718832891246, 0.9070886075949367, 0.9089971642175818, 0.9148051948051948, 0.9144856180357606, 0.9124087591240876, 0.9179942543745103, 0.9087846592381446, 0.9141752577319587, 0.9128956317028512, 0.9094682230869001, 0.9077809798270894, 0.9183350895679663, 0.911070780399274, 0.9089262613195342, 0.9209908735332464, 0.9126716766001555, 0.9108598474888246, 0.9116266944734098, 0.9118998978549541, 0.919417728099818, 0.9087863952589539, 0.9138988247317322, 0.9046757943683803, 0.9141072358146799, 0.9120936280884265, 0.9159905783826223, 0.9116434827408553, 0.911504424778761, 0.9185242121445042, 0.9168187744458931, 0.9197004905757811, 0.9194665298794563, 0.9061923583662714, 0.9175230566534914, 0.917424045702415, 0.91484375, 0.9122991835659732, 0.9142194744976816, 0.915390604723592, 0.9092084842214175, 0.9030917121330215, 0.910106521174331, 0.9118863049095607, 0.905903583397783, 0.9169254658385093, 0.9112318840579711, 0.9126063418406806, 0.9125465178096757, 0.9188836724047992, 0.9027055150884495, 0.9153111283242964, 0.9064692127825409, 0.9105564222568903, 0.9154024170737979, 0.9133230452674898, 0.9193802521008403, 0.9138020833333333]\n",
            "sd_acc: 0.004921827799755303\n",
            "sd_f1: 0.003812693844120401\n",
            "sd_mcc: 0.011220447861780957\n",
            "sd_sn: 0.00442648908545797\n",
            "sd_sp: 0.00442648908545797\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.67      0.72      1821\n",
            "           1       0.86      0.91      0.88      3849\n",
            "\n",
            "    accuracy                           0.84      5670\n",
            "   macro avg       0.82      0.79      0.80      5670\n",
            "weighted avg       0.83      0.84      0.83      5670\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.004921827799755303, 0.011220447861780957, 0.003812693844120401)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_training_labels = classifier.predict(X_train)\n",
        "predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "predicted_training_labels = np.reshape(predicted_training_labels,(len(predicted_training_labels),)).astype(int)\n",
        "error_rate(Y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZNsQYdJ4iGL",
        "outputId": "6b95fc87-1785-49e3-96d0-dbe9ce71e30f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 17s 398ms/step\n",
            "acc: 0.8296460176991151\n",
            "f1: 0.9004739336492891\n",
            "mcc: 0.31030129304726994\n",
            "sn: [0.9028716216216216, 0.893344709897611, 0.8812980358667806, 0.8939655172413793, 0.8831932773109243, 0.9081545064377683, 0.8929173693086003, 0.8919148936170213, 0.9080756013745704, 0.8991379310344828, 0.9077711357813835, 0.887489504617968, 0.8907056798623064, 0.9122362869198313, 0.875532821824382, 0.8975234842015372, 0.8962264150943396, 0.9075993091537133, 0.9053356282271945, 0.9104220499569337, 0.9050042408821035, 0.8853288364249579, 0.8810949529512404, 0.8934563758389261, 0.88366124893071, 0.893344709897611, 0.8827004219409282, 0.8951817413355875, 0.8946015424164524, 0.8970212765957447, 0.89666951323655, 0.9012765957446809, 0.8999158957106812, 0.8940170940170941, 0.9054054054054054, 0.8909090909090909, 0.8956372968349017, 0.8951406649616368, 0.8762071992976295, 0.8854435831180018, 0.8888888888888888, 0.8856405846947549, 0.8855678906917165, 0.9017094017094017, 0.8811369509043928, 0.8816925734024179, 0.8842832469775475, 0.9043552519214346, 0.897766323024055, 0.8992379339542761, 0.882051282051282, 0.902542372881356, 0.877568493150685, 0.8976311336717429, 0.8988860325621251, 0.9004329004329005, 0.8687127024722933, 0.9026701119724375, 0.8958858102434929, 0.8831168831168831, 0.8967851099830795, 0.896943231441048, 0.9010238907849829, 0.895397489539749, 0.8831058020477816, 0.882303132938188, 0.9010327022375215, 0.8926174496644296, 0.9090909090909091, 0.8874458874458875, 0.8873949579831932, 0.9029787234042553, 0.8881179531656548, 0.8939779474130619, 0.901541095890411, 0.8996655518394648, 0.9061433447098977, 0.8903170522707797, 0.8989637305699482, 0.8952702702702703, 0.8955479452054794, 0.8825561312607945, 0.9061154177433247, 0.9053819444444444, 0.8981324278438031, 0.8695652173913043, 0.8887923544743701, 0.9033898305084745, 0.8938356164383562, 0.8873835732430144, 0.885593220338983, 0.8928877463581834, 0.893598615916955, 0.892436974789916, 0.8884120171673819, 0.903448275862069, 0.9057724957555179, 0.8939264328485885, 0.889273356401384, 0.8950086058519794, 0.8824034334763948, 0.903010033444816, 0.890625, 0.8860103626943006, 0.8938879456706282, 0.8979416809605489, 0.8809523809523809, 0.8740425531914894, 0.8897306397306397, 0.8760683760683761, 0.8997407087294728, 0.888504753673293, 0.8939130434782608, 0.8960270498732037, 0.8848797250859106, 0.8990590248075278, 0.8972835314091681, 0.8757497857754927, 0.8819031435853866, 0.8886075949367088, 0.9008403361344538, 0.8998287671232876, 0.8786324786324786, 0.8972198820556023, 0.8969849246231156, 0.8941574936494496, 0.9113175675675675, 0.8975444538526672, 0.8905852417302799, 0.9023972602739726, 0.8788659793814433, 0.8843478260869565, 0.8931623931623932, 0.8948261238337574, 0.8997451146983857, 0.8877374784110535, 0.9010416666666666, 0.8879456706281834, 0.8894691035683203, 0.9013840830449827, 0.889168765743073, 0.897172236503856, 0.887468030690537, 0.8852320675105485, 0.8954305799648506, 0.8912855910267472, 0.8957264957264958, 0.9075194468452895, 0.8986254295532646, 0.889267461669506, 0.8943781942078365, 0.9016253207869974, 0.8896434634974533, 0.8848484848484849, 0.8974576271186441, 0.8975903614457831, 0.8968185726569218, 0.8960698689956332, 0.8959587274290628, 0.8985507246376812, 0.9053356282271945, 0.896969696969697, 0.8781942078364565, 0.8911392405063291, 0.8920741989881956, 0.904639175257732, 0.8832618025751073, 0.8993115318416524, 0.8835202761000863, 0.8895497026338148, 0.9090121317157712, 0.888034188034188, 0.8846815834767642, 0.892334194659776, 0.8940568475452196, 0.908936170212766, 0.8942065491183879, 0.8987124463519314, 0.8983050847457628, 0.8756432246998285, 0.9090113735783028, 0.8992248062015504, 0.904121110176619, 0.8991304347826087, 0.886873920552677, 0.9055319148936171, 0.8832309043020193, 0.8982035928143712, 0.9023569023569024, 0.8875638841567292, 0.8910034602076125, 0.8930112165660051, 0.8815566835871405, 0.8701964133219471, 0.8832054560954816, 0.9007765314926661, 0.9016393442622951, 0.892399658411614, 0.883920894239037, 0.9099485420240138, 0.9007029876977153, 0.8909395973154363, 0.8855160450997398, 0.8952789699570816, 0.8996598639455783, 0.9013100436681223, 0.9036658141517476, 0.8931034482758621, 0.8867761452031115, 0.894874022589053, 0.907928388746803, 0.8774978279756733, 0.8939779474130619, 0.9036850921273032, 0.9037974683544304, 0.8976311336717429, 0.9086294416243654, 0.8925549915397631, 0.8871925360474979, 0.8917089678510999, 0.8946917808219178, 0.8988860325621251, 0.8887945670628183, 0.8926458157227388, 0.8978354978354979, 0.9005998286203942, 0.8926746166950597, 0.8881239242685026, 0.8917306052855924, 0.8972125435540069, 0.8697123519458545, 0.8890770533446232, 0.8769100169779287, 0.8871527777777778, 0.898972602739726, 0.8847139197267293, 0.8921052631578947, 0.893071000855432, 0.8916595012897678, 0.9100840336134454, 0.898972602739726, 0.8987993138936535, 0.8980121002592912, 0.8865979381443299, 0.8899398108340498, 0.9127459366980325, 0.8883248730964467, 0.9009393680614859, 0.9158878504672897, 0.8911392405063291, 0.9082332761578045, 0.8850085178875639, 0.8904923599320883, 0.8900255754475703, 0.8867120954003407, 0.8863049095607235, 0.884083044982699, 0.8946917808219178, 0.8962264150943396, 0.903862660944206, 0.8853016142735769, 0.8910806174957119, 0.9077458659704091, 0.8922815945716709, 0.8982905982905983, 0.8886032562125107, 0.8993174061433447, 0.8831498729889924, 0.909556313993174, 0.908703071672355, 0.9057412167952014, 0.8778821520068317, 0.8954970263381479, 0.8747870528109029, 0.8852173913043478, 0.8930976430976431, 0.9008474576271186, 0.9079173838209983, 0.8879528222409435, 0.8929188255613126, 0.9094827586206896, 0.9010238907849829, 0.9055793991416309, 0.8815004262574595, 0.8913793103448275, 0.9073294018534119, 0.8845166809238666, 0.8965811965811966, 0.8960270498732037, 0.8847457627118644, 0.8955094991364422, 0.888504753673293, 0.9022939677145284, 0.89666951323655, 0.9003407155025553, 0.885593220338983, 0.8991379310344828, 0.912020905923345, 0.8757602085143353, 0.8995744680851064, 0.9019947961838681, 0.9060052219321149, 0.8953586497890296, 0.9123711340206185, 0.897172236503856, 0.8810344827586207, 0.8758561643835616, 0.8904347826086957, 0.8941890719861232, 0.9141156462585034, 0.9018932874354562, 0.9071367153912295, 0.8880275624461671, 0.9066780821917808, 0.8806479113384484, 0.908936170212766, 0.8984771573604061, 0.8912671232876712, 0.9061685490877498, 0.895742832319722, 0.8943781942078365, 0.8875536480686695, 0.9103214890016921, 0.8898233809924306, 0.9044309296264118, 0.8898233809924306, 0.8993231810490694, 0.8937446443873179, 0.884318766066838, 0.88134135855546, 0.8980291345329906, 0.8915456874466268, 0.8926458157227388, 0.8811129848229342, 0.8858369098712446, 0.8967851099830795, 0.8959931798806479, 0.8896492728828058, 0.883248730964467, 0.8884156729131175, 0.8992248062015504, 0.882996632996633, 0.8936708860759494, 0.8959931798806479, 0.8914141414141414, 0.8917748917748918, 0.8988195615514334, 0.8913793103448275, 0.8943781942078365, 0.8978540772532189, 0.8934356351236147, 0.9011925042589438, 0.8939779474130619, 0.9104991394148021, 0.8823024054982818, 0.8904923599320883, 0.8772378516624041, 0.882303132938188, 0.8818635607321131, 0.9003466204506065, 0.9004291845493563, 0.9024390243902439, 0.8828058169375534, 0.8983774551665243, 0.8765008576329331, 0.8810344827586207, 0.9019607843137255, 0.8891752577319587, 0.8844483058210252, 0.8925831202046036, 0.8771929824561403, 0.8804713804713805, 0.8773424190800682, 0.9039932030586236, 0.8817946505608283, 0.8931623931623932, 0.9029209621993127, 0.9124463519313305, 0.9040622299049266, 0.9030612244897959, 0.9108826049700086, 0.8982188295165394, 0.8991525423728813, 0.8782161234991424, 0.8889837745516652, 0.9001692047377327, 0.8817021276595745, 0.8965217391304348, 0.8751054852320675, 0.903471634208298, 0.886518771331058, 0.8930112165660051, 0.8896492728828058, 0.8928262748487468, 0.8889830508474577, 0.9122657580919932, 0.8957264957264958, 0.903114186851211, 0.8942307692307693, 0.8931955211024979, 0.8863443596268024, 0.8943722943722944, 0.8813993174061433, 0.8907996560619088, 0.884020618556701, 0.888135593220339, 0.8989048020219039, 0.8926116838487973, 0.8907849829351536, 0.8941574936494496, 0.8560477001703578, 0.9065981148243359, 0.8918454935622318, 0.8897435897435897, 0.8994032395566922, 0.8885106382978724, 0.8962025316455696, 0.8969594594594594, 0.8890814558058926, 0.8829059829059829, 0.8760984182776801, 0.8929173693086003, 0.8909710391822828, 0.8865004299226139, 0.8818418766290183, 0.884417808219178, 0.8981324278438031, 0.8871527777777778, 0.8935456831517183, 0.902027027027027, 0.8908145580589255, 0.8898377455166524, 0.9016393442622951, 0.897133220910624, 0.8985382631126397, 0.892948173322005, 0.9020618556701031, 0.8922815945716709, 0.8918918918918919, 0.8973288814691152, 0.894468085106383, 0.8883205456095482, 0.9020122484689413, 0.8930976430976431, 0.8791773778920309, 0.8982758620689655, 0.891156462585034, 0.8804159445407279, 0.900679117147708, 0.897370653095844, 0.8860544217687075, 0.8858603066439523, 0.888507718696398, 0.8981481481481481, 0.8997429305912596, 0.8822033898305085, 0.9015280135823429, 0.9003378378378378, 0.8907996560619088, 0.8954081632653061, 0.8778821520068317, 0.8826086956521739, 0.8810344827586207, 0.9028132992327366, 0.897766323024055, 0.8966977138018628, 0.886695278969957, 0.9052631578947369, 0.8904227782571182, 0.88504753673293, 0.8890770533446232, 0.9066213921901528, 0.8946015424164524, 0.8878424657534246, 0.9007698887938409, 0.907679033649698, 0.8861087144089732, 0.8885135135135135, 0.9035836177474402, 0.9085365853658537, 0.8964927288280582, 0.8767241379310344, 0.8946925021061499, 0.8999151823579304, 0.9012448132780083, 0.9084745762711864, 0.8875432525951558, 0.905090595340811, 0.9003378378378378, 0.8975234842015372, 0.8960270498732037, 0.8930390492359932, 0.8937446443873179, 0.8941574936494496, 0.9022939677145284, 0.8894557823129252, 0.8945111492281304, 0.8835443037974684, 0.8939655172413793, 0.9000868809730669, 0.9008547008547009, 0.8948275862068965, 0.892399658411614, 0.905511811023622, 0.8810763888888888, 0.890625, 0.9012875536480687, 0.8994845360824743, 0.9115351257588898, 0.9009314140558848, 0.8995744680851064, 0.8942881500426257, 0.8961702127659574, 0.8946474086661003, 0.8956372968349017, 0.8973252804141502, 0.8914529914529915, 0.898972602739726, 0.896431679721497, 0.8898233809924306, 0.8792517006802721, 0.8770144189991518, 0.8779863481228669, 0.9004291845493563, 0.9049657534246576, 0.8950988822012038, 0.9010152284263959, 0.8841201716738197, 0.8931552587646077, 0.8946015424164524, 0.8911739502999143, 0.8948717948717949, 0.8987234042553192, 0.8984641638225256, 0.8980623420387531, 0.9117395029991431, 0.9002579535683577, 0.8974137931034483, 0.8815450643776824, 0.8924914675767918, 0.8891774891774892, 0.8906779661016949, 0.9078380706287683, 0.8909551986475064, 0.9015544041450777, 0.8917306052855924, 0.8917089678510999, 0.8922675933970461, 0.9043927648578811, 0.8793542905692439, 0.8883205456095482, 0.887263339070568, 0.8984771573604061, 0.8895599654874892, 0.8845500848896435, 0.9009314140558848, 0.8859574468085106, 0.887000849617672, 0.8952380952380953, 0.8983774551665243, 0.8909871244635194, 0.8849104859335039, 0.8941480206540448, 0.886873920552677, 0.9010152284263959, 0.8905172413793103, 0.8940455341506129, 0.8993981083404987, 0.8870829769033362, 0.8894557823129252, 0.9072512647554806, 0.8963153384747216, 0.8957264957264958, 0.8909551986475064, 0.9078498293515358, 0.8970464135021097, 0.9052808046940486, 0.8911917098445595, 0.888034188034188, 0.8970840480274442, 0.8921052631578947, 0.8923076923076924, 0.8761822871883062, 0.8751076658053403, 0.9060118543607113, 0.9094017094017094, 0.8890799656061908, 0.8802039082412915, 0.894420600858369, 0.8926746166950597, 0.9064685314685315, 0.8969594594594594, 0.8949615713065756, 0.8946459412780656, 0.8945074106364429, 0.9092526690391459, 0.8936905790838375, 0.903747870528109, 0.8837998303647159, 0.8838383838383839, 0.8955479452054794, 0.8815679733110926, 0.8967297762478486, 0.8860103626943006, 0.8868421052631579, 0.8760831889081456, 0.8862478777589134, 0.8998272884283247, 0.9009314140558848, 0.8690068493150684, 0.8801724137931034, 0.8910806174957119, 0.8992180712423979, 0.8982035928143712, 0.9080659150043365, 0.8937977909940527, 0.8997451146983857, 0.8907056798623064, 0.8722316865417377, 0.896611642050391, 0.8849104859335039, 0.8740425531914894, 0.8877551020408163, 0.9200343938091143, 0.8891730605285593, 0.9053356282271945, 0.8882303132938189, 0.8838821490467937, 0.8737113402061856, 0.8997407087294728, 0.902542372881356, 0.8970840480274442, 0.9182608695652174, 0.9105902777777778, 0.9009556907037359, 0.8873002523128679, 0.8841666666666667, 0.8792808219178082, 0.8828522920203735, 0.8895599654874892, 0.8995670995670996, 0.8883205456095482, 0.8955479452054794, 0.902542372881356, 0.8886986301369864, 0.8917748917748918, 0.8805841924398625, 0.9081632653061225, 0.913338997451147, 0.8855678906917165, 0.9022746419545071, 0.903747870528109, 0.903471634208298, 0.8913412563667232, 0.8848167539267016, 0.9001677852348994, 0.895742832319722, 0.904156064461408, 0.8779863481228669, 0.8805084745762712, 0.8955996548748921, 0.9080944350758853, 0.8959587274290628, 0.9041450777202072, 0.8969957081545065, 0.8962025316455696, 0.9062233589087809, 0.8923611111111112, 0.878969957081545, 0.8887945670628183, 0.9082412914188616, 0.8844519966015293, 0.8828522920203735, 0.8850380388841927, 0.8946015424164524, 0.8954970263381479, 0.885883347421809, 0.8938879456706282, 0.8795811518324608, 0.9095607235142119, 0.8807890222984562, 0.8928877463581834, 0.8985255854293148, 0.9051724137931034, 0.8932203389830509, 0.8945548833189283, 0.9023569023569024, 0.905790838375108, 0.889554794520548, 0.8903878583473862, 0.9058823529411765, 0.8827004219409282, 0.8827527612574342, 0.8792354474370113, 0.8973481608212147, 0.883061049011178, 0.8838983050847458, 0.9150043365134432, 0.8942881500426257, 0.8806866952789699, 0.8873720136518771, 0.895458440445587, 0.9112627986348123, 0.9108061749571184, 0.8939393939393939, 0.8946474086661003, 0.8893581081081081, 0.8780701754385964, 0.8930390492359932, 0.8949181739879414, 0.8893728222996515, 0.884417808219178, 0.8942881500426257, 0.889661164205039, 0.8933107535986452, 0.8996569468267581, 0.8954970263381479, 0.9032815198618307, 0.9089376053962901, 0.8852459016393442, 0.883248730964467, 0.8831168831168831, 0.8758503401360545, 0.8931623931623932, 0.891156462585034, 0.8934497816593886, 0.885934819897084, 0.9010806317539485, 0.8894472361809045, 0.8827527612574342, 0.8813993174061433, 0.8991379310344828, 0.9079861111111112, 0.9045138888888888, 0.8984641638225256, 0.910267471958585, 0.8919148936170213, 0.9088586030664395, 0.8869047619047619, 0.8926116838487973, 0.887468030690537, 0.8904923599320883, 0.9004291845493563, 0.8962264150943396, 0.903747870528109, 0.8841567291311755, 0.8848857644991213, 0.9085520745131245, 0.8965224766751484, 0.8921484037963762, 0.8880139982502188, 0.9008474576271186, 0.8983193277310925, 0.8946015424164524, 0.907928388746803, 0.8896434634974533, 0.9072512647554806, 0.9052901023890785, 0.8855678906917165, 0.9064935064935065, 0.891846921797005, 0.8969335604770017, 0.8933791917454859, 0.9020442930153322, 0.8776732249786142, 0.892334194659776, 0.8933333333333333, 0.8954970263381479, 0.8759757155247181, 0.8984641638225256, 0.8976582827406765, 0.9084687767322498, 0.8910034602076125, 0.8932536293766012, 0.8858603066439523, 0.8937238493723849, 0.9027303754266212, 0.8846815834767642, 0.8859878154917319, 0.894874022589053, 0.8999144568006844, 0.8830508474576271, 0.9030042918454936, 0.8913412563667232, 0.8851063829787233, 0.9030612244897959, 0.9029787234042553, 0.9025641025641026, 0.8776550552251486, 0.9074889867841409, 0.8938740293356342, 0.9041450777202072, 0.8889830508474577, 0.8955996548748921, 0.8964346349745331, 0.8898450946643718, 0.8822510822510823, 0.883128295254833, 0.8914529914529915, 0.890848026868178, 0.891398783666377, 0.8800342759211653, 0.8840579710144928, 0.8858603066439523, 0.8689655172413793, 0.8903061224489796, 0.8827054794520548, 0.9130067567567568, 0.8835443037974684, 0.9022491349480969, 0.9023136246786633, 0.8780903665814151, 0.8979947689625108, 0.8803786574870912, 0.883419689119171, 0.8928571428571429, 0.883920894239037, 0.8879384088964928, 0.9084687767322498, 0.8916595012897678, 0.8992314261315115, 0.9043183742591024, 0.8995744680851064, 0.896551724137931, 0.910958904109589, 0.8951817413355875, 0.8827470686767169, 0.9169491525423729, 0.902092050209205, 0.8809318377911993, 0.8865800865800866, 0.9017933390264731, 0.8935064935064935, 0.8993981083404987, 0.8967254408060453, 0.8960698689956332, 0.8903765690376569, 0.8915254237288136, 0.9011274934952298, 0.8920308483290489, 0.8954970263381479, 0.8982188295165394, 0.8933791917454859, 0.900523560209424, 0.8852040816326531, 0.8996569468267581, 0.899736147757256, 0.8871527777777778, 0.8946015424164524, 0.896640826873385, 0.9086251067463706, 0.8857868020304569, 0.9061190276613579, 0.9043103448275862, 0.8980836236933798, 0.8876595744680851, 0.8778625954198473, 0.9030612244897959, 0.88917089678511, 0.8920552677029361, 0.9035532994923858, 0.8989455184534271, 0.8753180661577609, 0.8996627318718381, 0.8891752577319587, 0.896137339055794, 0.8964646464646465, 0.8874788494077834, 0.8796928327645052, 0.9020618556701031, 0.8890784982935154, 0.9006849315068494, 0.9130060292850991, 0.8950086058519794, 0.8972602739726028, 0.90770533446232, 0.8939130434782608, 0.8979763912310287, 0.9046413502109705, 0.8911739502999143, 0.8938500421229991, 0.8759825327510917, 0.9023136246786633, 0.8713798977853492, 0.88366124893071, 0.9087809036658141, 0.9005947323704333, 0.8968723584108199, 0.9, 0.896404109589041, 0.8907198612315698, 0.899488926746167, 0.8845829823083403, 0.894468085106383, 0.8956089478044739, 0.8873835732430144, 0.9062768701633706, 0.897370653095844, 0.8873121869782972, 0.8986135181975736, 0.8884192730346576, 0.8816568047337278, 0.9028374892519346, 0.891681109185442, 0.9065180102915952, 0.8910034602076125, 0.8921232876712328, 0.896551724137931, 0.8912097476066144, 0.917098445595855, 0.913527397260274, 0.8945518453427065, 0.8787107718405428, 0.9132302405498282, 0.8856655290102389, 0.8850380388841927, 0.8922155688622755, 0.8974137931034483, 0.8859574468085106, 0.8989637305699482, 0.8841567291311755, 0.9053356282271945, 0.8607594936708861, 0.88917089678511, 0.8924640135478408, 0.8876404494382022, 0.871859296482412, 0.8943298969072165, 0.8978040540540541, 0.8811965811965812, 0.8899317406143344, 0.8898450946643718, 0.8937446443873179, 0.8963730569948186, 0.9067357512953368, 0.897766323024055, 0.8944636678200693, 0.8951473136915078, 0.8978040540540541, 0.8976982097186701, 0.8968185726569218, 0.9004329004329005, 0.8836424957841484, 0.8779220779220779, 0.8903170522707797, 0.9029787234042553, 0.9055319148936171, 0.9033361847733106, 0.896551724137931, 0.8813993174061433, 0.8918685121107266, 0.8995744680851064, 0.9035234899328859, 0.8898525585429314, 0.8854700854700854, 0.9016806722689076, 0.9042645778938208, 0.9083969465648855, 0.8943231441048035, 0.8716442953020134, 0.9028132992327366, 0.8957795004306632, 0.8828522920203735, 0.9059024807527801, 0.9045571797076526, 0.8796928327645052, 0.8837814397224631, 0.9043927648578811, 0.898989898989899, 0.8768177929854577, 0.8973252804141502, 0.9072790294627383, 0.9031979256698358, 0.8798283261802575, 0.903471634208298, 0.8817863397548161, 0.8882201203783319, 0.8938740293356342, 0.8807890222984562, 0.8923076923076924, 0.8938356164383562, 0.8983911939034717, 0.9048442906574394, 0.8899237933954276, 0.8995670995670996, 0.8835616438356164, 0.8979416809605489, 0.8955479452054794, 0.8986371379897785, 0.8838599487617421, 0.8980121002592912, 0.9, 0.8994845360824743, 0.897172236503856, 0.8936170212765957, 0.907391673746814, 0.8998287671232876, 0.8993981083404987, 0.8939655172413793, 0.8663793103448276]\n",
            "sp: [0.9028716216216216, 0.893344709897611, 0.8812980358667806, 0.8939655172413793, 0.8831932773109243, 0.9081545064377683, 0.8929173693086003, 0.8919148936170213, 0.9080756013745704, 0.8991379310344828, 0.9077711357813835, 0.887489504617968, 0.8907056798623064, 0.9122362869198313, 0.875532821824382, 0.8975234842015372, 0.8962264150943396, 0.9075993091537133, 0.9053356282271945, 0.9104220499569337, 0.9050042408821035, 0.8853288364249579, 0.8810949529512404, 0.8934563758389261, 0.88366124893071, 0.893344709897611, 0.8827004219409282, 0.8951817413355875, 0.8946015424164524, 0.8970212765957447, 0.89666951323655, 0.9012765957446809, 0.8999158957106812, 0.8940170940170941, 0.9054054054054054, 0.8909090909090909, 0.8956372968349017, 0.8951406649616368, 0.8762071992976295, 0.8854435831180018, 0.8888888888888888, 0.8856405846947549, 0.8855678906917165, 0.9017094017094017, 0.8811369509043928, 0.8816925734024179, 0.8842832469775475, 0.9043552519214346, 0.897766323024055, 0.8992379339542761, 0.882051282051282, 0.902542372881356, 0.877568493150685, 0.8976311336717429, 0.8988860325621251, 0.9004329004329005, 0.8687127024722933, 0.9026701119724375, 0.8958858102434929, 0.8831168831168831, 0.8967851099830795, 0.896943231441048, 0.9010238907849829, 0.895397489539749, 0.8831058020477816, 0.882303132938188, 0.9010327022375215, 0.8926174496644296, 0.9090909090909091, 0.8874458874458875, 0.8873949579831932, 0.9029787234042553, 0.8881179531656548, 0.8939779474130619, 0.901541095890411, 0.8996655518394648, 0.9061433447098977, 0.8903170522707797, 0.8989637305699482, 0.8952702702702703, 0.8955479452054794, 0.8825561312607945, 0.9061154177433247, 0.9053819444444444, 0.8981324278438031, 0.8695652173913043, 0.8887923544743701, 0.9033898305084745, 0.8938356164383562, 0.8873835732430144, 0.885593220338983, 0.8928877463581834, 0.893598615916955, 0.892436974789916, 0.8884120171673819, 0.903448275862069, 0.9057724957555179, 0.8939264328485885, 0.889273356401384, 0.8950086058519794, 0.8824034334763948, 0.903010033444816, 0.890625, 0.8860103626943006, 0.8938879456706282, 0.8979416809605489, 0.8809523809523809, 0.8740425531914894, 0.8897306397306397, 0.8760683760683761, 0.8997407087294728, 0.888504753673293, 0.8939130434782608, 0.8960270498732037, 0.8848797250859106, 0.8990590248075278, 0.8972835314091681, 0.8757497857754927, 0.8819031435853866, 0.8886075949367088, 0.9008403361344538, 0.8998287671232876, 0.8786324786324786, 0.8972198820556023, 0.8969849246231156, 0.8941574936494496, 0.9113175675675675, 0.8975444538526672, 0.8905852417302799, 0.9023972602739726, 0.8788659793814433, 0.8843478260869565, 0.8931623931623932, 0.8948261238337574, 0.8997451146983857, 0.8877374784110535, 0.9010416666666666, 0.8879456706281834, 0.8894691035683203, 0.9013840830449827, 0.889168765743073, 0.897172236503856, 0.887468030690537, 0.8852320675105485, 0.8954305799648506, 0.8912855910267472, 0.8957264957264958, 0.9075194468452895, 0.8986254295532646, 0.889267461669506, 0.8943781942078365, 0.9016253207869974, 0.8896434634974533, 0.8848484848484849, 0.8974576271186441, 0.8975903614457831, 0.8968185726569218, 0.8960698689956332, 0.8959587274290628, 0.8985507246376812, 0.9053356282271945, 0.896969696969697, 0.8781942078364565, 0.8911392405063291, 0.8920741989881956, 0.904639175257732, 0.8832618025751073, 0.8993115318416524, 0.8835202761000863, 0.8895497026338148, 0.9090121317157712, 0.888034188034188, 0.8846815834767642, 0.892334194659776, 0.8940568475452196, 0.908936170212766, 0.8942065491183879, 0.8987124463519314, 0.8983050847457628, 0.8756432246998285, 0.9090113735783028, 0.8992248062015504, 0.904121110176619, 0.8991304347826087, 0.886873920552677, 0.9055319148936171, 0.8832309043020193, 0.8982035928143712, 0.9023569023569024, 0.8875638841567292, 0.8910034602076125, 0.8930112165660051, 0.8815566835871405, 0.8701964133219471, 0.8832054560954816, 0.9007765314926661, 0.9016393442622951, 0.892399658411614, 0.883920894239037, 0.9099485420240138, 0.9007029876977153, 0.8909395973154363, 0.8855160450997398, 0.8952789699570816, 0.8996598639455783, 0.9013100436681223, 0.9036658141517476, 0.8931034482758621, 0.8867761452031115, 0.894874022589053, 0.907928388746803, 0.8774978279756733, 0.8939779474130619, 0.9036850921273032, 0.9037974683544304, 0.8976311336717429, 0.9086294416243654, 0.8925549915397631, 0.8871925360474979, 0.8917089678510999, 0.8946917808219178, 0.8988860325621251, 0.8887945670628183, 0.8926458157227388, 0.8978354978354979, 0.9005998286203942, 0.8926746166950597, 0.8881239242685026, 0.8917306052855924, 0.8972125435540069, 0.8697123519458545, 0.8890770533446232, 0.8769100169779287, 0.8871527777777778, 0.898972602739726, 0.8847139197267293, 0.8921052631578947, 0.893071000855432, 0.8916595012897678, 0.9100840336134454, 0.898972602739726, 0.8987993138936535, 0.8980121002592912, 0.8865979381443299, 0.8899398108340498, 0.9127459366980325, 0.8883248730964467, 0.9009393680614859, 0.9158878504672897, 0.8911392405063291, 0.9082332761578045, 0.8850085178875639, 0.8904923599320883, 0.8900255754475703, 0.8867120954003407, 0.8863049095607235, 0.884083044982699, 0.8946917808219178, 0.8962264150943396, 0.903862660944206, 0.8853016142735769, 0.8910806174957119, 0.9077458659704091, 0.8922815945716709, 0.8982905982905983, 0.8886032562125107, 0.8993174061433447, 0.8831498729889924, 0.909556313993174, 0.908703071672355, 0.9057412167952014, 0.8778821520068317, 0.8954970263381479, 0.8747870528109029, 0.8852173913043478, 0.8930976430976431, 0.9008474576271186, 0.9079173838209983, 0.8879528222409435, 0.8929188255613126, 0.9094827586206896, 0.9010238907849829, 0.9055793991416309, 0.8815004262574595, 0.8913793103448275, 0.9073294018534119, 0.8845166809238666, 0.8965811965811966, 0.8960270498732037, 0.8847457627118644, 0.8955094991364422, 0.888504753673293, 0.9022939677145284, 0.89666951323655, 0.9003407155025553, 0.885593220338983, 0.8991379310344828, 0.912020905923345, 0.8757602085143353, 0.8995744680851064, 0.9019947961838681, 0.9060052219321149, 0.8953586497890296, 0.9123711340206185, 0.897172236503856, 0.8810344827586207, 0.8758561643835616, 0.8904347826086957, 0.8941890719861232, 0.9141156462585034, 0.9018932874354562, 0.9071367153912295, 0.8880275624461671, 0.9066780821917808, 0.8806479113384484, 0.908936170212766, 0.8984771573604061, 0.8912671232876712, 0.9061685490877498, 0.895742832319722, 0.8943781942078365, 0.8875536480686695, 0.9103214890016921, 0.8898233809924306, 0.9044309296264118, 0.8898233809924306, 0.8993231810490694, 0.8937446443873179, 0.884318766066838, 0.88134135855546, 0.8980291345329906, 0.8915456874466268, 0.8926458157227388, 0.8811129848229342, 0.8858369098712446, 0.8967851099830795, 0.8959931798806479, 0.8896492728828058, 0.883248730964467, 0.8884156729131175, 0.8992248062015504, 0.882996632996633, 0.8936708860759494, 0.8959931798806479, 0.8914141414141414, 0.8917748917748918, 0.8988195615514334, 0.8913793103448275, 0.8943781942078365, 0.8978540772532189, 0.8934356351236147, 0.9011925042589438, 0.8939779474130619, 0.9104991394148021, 0.8823024054982818, 0.8904923599320883, 0.8772378516624041, 0.882303132938188, 0.8818635607321131, 0.9003466204506065, 0.9004291845493563, 0.9024390243902439, 0.8828058169375534, 0.8983774551665243, 0.8765008576329331, 0.8810344827586207, 0.9019607843137255, 0.8891752577319587, 0.8844483058210252, 0.8925831202046036, 0.8771929824561403, 0.8804713804713805, 0.8773424190800682, 0.9039932030586236, 0.8817946505608283, 0.8931623931623932, 0.9029209621993127, 0.9124463519313305, 0.9040622299049266, 0.9030612244897959, 0.9108826049700086, 0.8982188295165394, 0.8991525423728813, 0.8782161234991424, 0.8889837745516652, 0.9001692047377327, 0.8817021276595745, 0.8965217391304348, 0.8751054852320675, 0.903471634208298, 0.886518771331058, 0.8930112165660051, 0.8896492728828058, 0.8928262748487468, 0.8889830508474577, 0.9122657580919932, 0.8957264957264958, 0.903114186851211, 0.8942307692307693, 0.8931955211024979, 0.8863443596268024, 0.8943722943722944, 0.8813993174061433, 0.8907996560619088, 0.884020618556701, 0.888135593220339, 0.8989048020219039, 0.8926116838487973, 0.8907849829351536, 0.8941574936494496, 0.8560477001703578, 0.9065981148243359, 0.8918454935622318, 0.8897435897435897, 0.8994032395566922, 0.8885106382978724, 0.8962025316455696, 0.8969594594594594, 0.8890814558058926, 0.8829059829059829, 0.8760984182776801, 0.8929173693086003, 0.8909710391822828, 0.8865004299226139, 0.8818418766290183, 0.884417808219178, 0.8981324278438031, 0.8871527777777778, 0.8935456831517183, 0.902027027027027, 0.8908145580589255, 0.8898377455166524, 0.9016393442622951, 0.897133220910624, 0.8985382631126397, 0.892948173322005, 0.9020618556701031, 0.8922815945716709, 0.8918918918918919, 0.8973288814691152, 0.894468085106383, 0.8883205456095482, 0.9020122484689413, 0.8930976430976431, 0.8791773778920309, 0.8982758620689655, 0.891156462585034, 0.8804159445407279, 0.900679117147708, 0.897370653095844, 0.8860544217687075, 0.8858603066439523, 0.888507718696398, 0.8981481481481481, 0.8997429305912596, 0.8822033898305085, 0.9015280135823429, 0.9003378378378378, 0.8907996560619088, 0.8954081632653061, 0.8778821520068317, 0.8826086956521739, 0.8810344827586207, 0.9028132992327366, 0.897766323024055, 0.8966977138018628, 0.886695278969957, 0.9052631578947369, 0.8904227782571182, 0.88504753673293, 0.8890770533446232, 0.9066213921901528, 0.8946015424164524, 0.8878424657534246, 0.9007698887938409, 0.907679033649698, 0.8861087144089732, 0.8885135135135135, 0.9035836177474402, 0.9085365853658537, 0.8964927288280582, 0.8767241379310344, 0.8946925021061499, 0.8999151823579304, 0.9012448132780083, 0.9084745762711864, 0.8875432525951558, 0.905090595340811, 0.9003378378378378, 0.8975234842015372, 0.8960270498732037, 0.8930390492359932, 0.8937446443873179, 0.8941574936494496, 0.9022939677145284, 0.8894557823129252, 0.8945111492281304, 0.8835443037974684, 0.8939655172413793, 0.9000868809730669, 0.9008547008547009, 0.8948275862068965, 0.892399658411614, 0.905511811023622, 0.8810763888888888, 0.890625, 0.9012875536480687, 0.8994845360824743, 0.9115351257588898, 0.9009314140558848, 0.8995744680851064, 0.8942881500426257, 0.8961702127659574, 0.8946474086661003, 0.8956372968349017, 0.8973252804141502, 0.8914529914529915, 0.898972602739726, 0.896431679721497, 0.8898233809924306, 0.8792517006802721, 0.8770144189991518, 0.8779863481228669, 0.9004291845493563, 0.9049657534246576, 0.8950988822012038, 0.9010152284263959, 0.8841201716738197, 0.8931552587646077, 0.8946015424164524, 0.8911739502999143, 0.8948717948717949, 0.8987234042553192, 0.8984641638225256, 0.8980623420387531, 0.9117395029991431, 0.9002579535683577, 0.8974137931034483, 0.8815450643776824, 0.8924914675767918, 0.8891774891774892, 0.8906779661016949, 0.9078380706287683, 0.8909551986475064, 0.9015544041450777, 0.8917306052855924, 0.8917089678510999, 0.8922675933970461, 0.9043927648578811, 0.8793542905692439, 0.8883205456095482, 0.887263339070568, 0.8984771573604061, 0.8895599654874892, 0.8845500848896435, 0.9009314140558848, 0.8859574468085106, 0.887000849617672, 0.8952380952380953, 0.8983774551665243, 0.8909871244635194, 0.8849104859335039, 0.8941480206540448, 0.886873920552677, 0.9010152284263959, 0.8905172413793103, 0.8940455341506129, 0.8993981083404987, 0.8870829769033362, 0.8894557823129252, 0.9072512647554806, 0.8963153384747216, 0.8957264957264958, 0.8909551986475064, 0.9078498293515358, 0.8970464135021097, 0.9052808046940486, 0.8911917098445595, 0.888034188034188, 0.8970840480274442, 0.8921052631578947, 0.8923076923076924, 0.8761822871883062, 0.8751076658053403, 0.9060118543607113, 0.9094017094017094, 0.8890799656061908, 0.8802039082412915, 0.894420600858369, 0.8926746166950597, 0.9064685314685315, 0.8969594594594594, 0.8949615713065756, 0.8946459412780656, 0.8945074106364429, 0.9092526690391459, 0.8936905790838375, 0.903747870528109, 0.8837998303647159, 0.8838383838383839, 0.8955479452054794, 0.8815679733110926, 0.8967297762478486, 0.8860103626943006, 0.8868421052631579, 0.8760831889081456, 0.8862478777589134, 0.8998272884283247, 0.9009314140558848, 0.8690068493150684, 0.8801724137931034, 0.8910806174957119, 0.8992180712423979, 0.8982035928143712, 0.9080659150043365, 0.8937977909940527, 0.8997451146983857, 0.8907056798623064, 0.8722316865417377, 0.896611642050391, 0.8849104859335039, 0.8740425531914894, 0.8877551020408163, 0.9200343938091143, 0.8891730605285593, 0.9053356282271945, 0.8882303132938189, 0.8838821490467937, 0.8737113402061856, 0.8997407087294728, 0.902542372881356, 0.8970840480274442, 0.9182608695652174, 0.9105902777777778, 0.9009556907037359, 0.8873002523128679, 0.8841666666666667, 0.8792808219178082, 0.8828522920203735, 0.8895599654874892, 0.8995670995670996, 0.8883205456095482, 0.8955479452054794, 0.902542372881356, 0.8886986301369864, 0.8917748917748918, 0.8805841924398625, 0.9081632653061225, 0.913338997451147, 0.8855678906917165, 0.9022746419545071, 0.903747870528109, 0.903471634208298, 0.8913412563667232, 0.8848167539267016, 0.9001677852348994, 0.895742832319722, 0.904156064461408, 0.8779863481228669, 0.8805084745762712, 0.8955996548748921, 0.9080944350758853, 0.8959587274290628, 0.9041450777202072, 0.8969957081545065, 0.8962025316455696, 0.9062233589087809, 0.8923611111111112, 0.878969957081545, 0.8887945670628183, 0.9082412914188616, 0.8844519966015293, 0.8828522920203735, 0.8850380388841927, 0.8946015424164524, 0.8954970263381479, 0.885883347421809, 0.8938879456706282, 0.8795811518324608, 0.9095607235142119, 0.8807890222984562, 0.8928877463581834, 0.8985255854293148, 0.9051724137931034, 0.8932203389830509, 0.8945548833189283, 0.9023569023569024, 0.905790838375108, 0.889554794520548, 0.8903878583473862, 0.9058823529411765, 0.8827004219409282, 0.8827527612574342, 0.8792354474370113, 0.8973481608212147, 0.883061049011178, 0.8838983050847458, 0.9150043365134432, 0.8942881500426257, 0.8806866952789699, 0.8873720136518771, 0.895458440445587, 0.9112627986348123, 0.9108061749571184, 0.8939393939393939, 0.8946474086661003, 0.8893581081081081, 0.8780701754385964, 0.8930390492359932, 0.8949181739879414, 0.8893728222996515, 0.884417808219178, 0.8942881500426257, 0.889661164205039, 0.8933107535986452, 0.8996569468267581, 0.8954970263381479, 0.9032815198618307, 0.9089376053962901, 0.8852459016393442, 0.883248730964467, 0.8831168831168831, 0.8758503401360545, 0.8931623931623932, 0.891156462585034, 0.8934497816593886, 0.885934819897084, 0.9010806317539485, 0.8894472361809045, 0.8827527612574342, 0.8813993174061433, 0.8991379310344828, 0.9079861111111112, 0.9045138888888888, 0.8984641638225256, 0.910267471958585, 0.8919148936170213, 0.9088586030664395, 0.8869047619047619, 0.8926116838487973, 0.887468030690537, 0.8904923599320883, 0.9004291845493563, 0.8962264150943396, 0.903747870528109, 0.8841567291311755, 0.8848857644991213, 0.9085520745131245, 0.8965224766751484, 0.8921484037963762, 0.8880139982502188, 0.9008474576271186, 0.8983193277310925, 0.8946015424164524, 0.907928388746803, 0.8896434634974533, 0.9072512647554806, 0.9052901023890785, 0.8855678906917165, 0.9064935064935065, 0.891846921797005, 0.8969335604770017, 0.8933791917454859, 0.9020442930153322, 0.8776732249786142, 0.892334194659776, 0.8933333333333333, 0.8954970263381479, 0.8759757155247181, 0.8984641638225256, 0.8976582827406765, 0.9084687767322498, 0.8910034602076125, 0.8932536293766012, 0.8858603066439523, 0.8937238493723849, 0.9027303754266212, 0.8846815834767642, 0.8859878154917319, 0.894874022589053, 0.8999144568006844, 0.8830508474576271, 0.9030042918454936, 0.8913412563667232, 0.8851063829787233, 0.9030612244897959, 0.9029787234042553, 0.9025641025641026, 0.8776550552251486, 0.9074889867841409, 0.8938740293356342, 0.9041450777202072, 0.8889830508474577, 0.8955996548748921, 0.8964346349745331, 0.8898450946643718, 0.8822510822510823, 0.883128295254833, 0.8914529914529915, 0.890848026868178, 0.891398783666377, 0.8800342759211653, 0.8840579710144928, 0.8858603066439523, 0.8689655172413793, 0.8903061224489796, 0.8827054794520548, 0.9130067567567568, 0.8835443037974684, 0.9022491349480969, 0.9023136246786633, 0.8780903665814151, 0.8979947689625108, 0.8803786574870912, 0.883419689119171, 0.8928571428571429, 0.883920894239037, 0.8879384088964928, 0.9084687767322498, 0.8916595012897678, 0.8992314261315115, 0.9043183742591024, 0.8995744680851064, 0.896551724137931, 0.910958904109589, 0.8951817413355875, 0.8827470686767169, 0.9169491525423729, 0.902092050209205, 0.8809318377911993, 0.8865800865800866, 0.9017933390264731, 0.8935064935064935, 0.8993981083404987, 0.8967254408060453, 0.8960698689956332, 0.8903765690376569, 0.8915254237288136, 0.9011274934952298, 0.8920308483290489, 0.8954970263381479, 0.8982188295165394, 0.8933791917454859, 0.900523560209424, 0.8852040816326531, 0.8996569468267581, 0.899736147757256, 0.8871527777777778, 0.8946015424164524, 0.896640826873385, 0.9086251067463706, 0.8857868020304569, 0.9061190276613579, 0.9043103448275862, 0.8980836236933798, 0.8876595744680851, 0.8778625954198473, 0.9030612244897959, 0.88917089678511, 0.8920552677029361, 0.9035532994923858, 0.8989455184534271, 0.8753180661577609, 0.8996627318718381, 0.8891752577319587, 0.896137339055794, 0.8964646464646465, 0.8874788494077834, 0.8796928327645052, 0.9020618556701031, 0.8890784982935154, 0.9006849315068494, 0.9130060292850991, 0.8950086058519794, 0.8972602739726028, 0.90770533446232, 0.8939130434782608, 0.8979763912310287, 0.9046413502109705, 0.8911739502999143, 0.8938500421229991, 0.8759825327510917, 0.9023136246786633, 0.8713798977853492, 0.88366124893071, 0.9087809036658141, 0.9005947323704333, 0.8968723584108199, 0.9, 0.896404109589041, 0.8907198612315698, 0.899488926746167, 0.8845829823083403, 0.894468085106383, 0.8956089478044739, 0.8873835732430144, 0.9062768701633706, 0.897370653095844, 0.8873121869782972, 0.8986135181975736, 0.8884192730346576, 0.8816568047337278, 0.9028374892519346, 0.891681109185442, 0.9065180102915952, 0.8910034602076125, 0.8921232876712328, 0.896551724137931, 0.8912097476066144, 0.917098445595855, 0.913527397260274, 0.8945518453427065, 0.8787107718405428, 0.9132302405498282, 0.8856655290102389, 0.8850380388841927, 0.8922155688622755, 0.8974137931034483, 0.8859574468085106, 0.8989637305699482, 0.8841567291311755, 0.9053356282271945, 0.8607594936708861, 0.88917089678511, 0.8924640135478408, 0.8876404494382022, 0.871859296482412, 0.8943298969072165, 0.8978040540540541, 0.8811965811965812, 0.8899317406143344, 0.8898450946643718, 0.8937446443873179, 0.8963730569948186, 0.9067357512953368, 0.897766323024055, 0.8944636678200693, 0.8951473136915078, 0.8978040540540541, 0.8976982097186701, 0.8968185726569218, 0.9004329004329005, 0.8836424957841484, 0.8779220779220779, 0.8903170522707797, 0.9029787234042553, 0.9055319148936171, 0.9033361847733106, 0.896551724137931, 0.8813993174061433, 0.8918685121107266, 0.8995744680851064, 0.9035234899328859, 0.8898525585429314, 0.8854700854700854, 0.9016806722689076, 0.9042645778938208, 0.9083969465648855, 0.8943231441048035, 0.8716442953020134, 0.9028132992327366, 0.8957795004306632, 0.8828522920203735, 0.9059024807527801, 0.9045571797076526, 0.8796928327645052, 0.8837814397224631, 0.9043927648578811, 0.898989898989899, 0.8768177929854577, 0.8973252804141502, 0.9072790294627383, 0.9031979256698358, 0.8798283261802575, 0.903471634208298, 0.8817863397548161, 0.8882201203783319, 0.8938740293356342, 0.8807890222984562, 0.8923076923076924, 0.8938356164383562, 0.8983911939034717, 0.9048442906574394, 0.8899237933954276, 0.8995670995670996, 0.8835616438356164, 0.8979416809605489, 0.8955479452054794, 0.8986371379897785, 0.8838599487617421, 0.8980121002592912, 0.9, 0.8994845360824743, 0.897172236503856, 0.8936170212765957, 0.907391673746814, 0.8998287671232876, 0.8993981083404987, 0.8939655172413793, 0.8663793103448276]\n",
            "sd_acc: 0.010159137191586488\n",
            "sd_f1: 0.006473745669038299\n",
            "sd_mcc: 0.03519226789090742\n",
            "sd_sn: 0.009218853036425449\n",
            "sd_sp: 0.009218853036425449\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.43      0.41       187\n",
            "           1       0.91      0.89      0.90      1169\n",
            "\n",
            "    accuracy                           0.83      1356\n",
            "   macro avg       0.65      0.66      0.65      1356\n",
            "weighted avg       0.84      0.83      0.83      1356\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.010159137191586488, 0.03519226789090742, 0.006473745669038299)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_rnn = classifier.predict(X_test)\n",
        "predicted_rnn = np.where(predicted_rnn > 0.5, 1, 0)\n",
        "predicted_rnn = np.reshape(predicted_rnn,(len(predicted_rnn),)).astype(int)\n",
        "error_rate(Y_test, predicted_rnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08-efAVMAMpe"
      },
      "source": [
        "### GRU with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkFKB2K0AMpe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Bidirectional, Input, Embedding, LSTM, Dropout, Dense, InputLayer, GRU\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from time import time\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpOrZtVaUy7L"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMBmAb4dUy7L"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqOBv6FqAMpe"
      },
      "outputs": [],
      "source": [
        "max_length = 1280"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIgk3kMWAMpf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jekKhU6uAMpf"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LtStluIAMpf"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train[1,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRScf_IEAMpf"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAw2m_sEAMpf"
      },
      "outputs": [],
      "source": [
        "def create_gru_model(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam'):\n",
        "    x_input = layers.Input(input_shape)\n",
        "    #emb = Embedding(21, units, input_length=max_length)(x_input)\n",
        "    gru = GRU(units, activity_regularizer=l2(regularizer), return_sequences = True)(x_input) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x = Dropout(dropout_rate)(gru)\n",
        "    gru2 =GRU(units, activity_regularizer=l2(dropout_rate))(x) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x2 = Dropout(dropout_rate)(gru2)\n",
        "    # softmax classifier\n",
        "    x_output = Dense(1, activation='sigmoid')(x2)\n",
        "\n",
        "    model = Model(inputs=x_input, outputs=x_output)\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_init),#solver,#\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWjZhNmaAMpf",
        "outputId": "b3a60b0f-ebb6-4e1e-9348-17b80b6d63aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 2560, 1)]         0         \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 2560, 50)          7950      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2560, 50)          0         \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 50)                15300     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,301\n",
            "Trainable params: 23,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "gru_model = create_gru_model()\n",
        "gru_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEngQp4tAMpf",
        "outputId": "185fe5ee-e1af-4903-9565-9aafbefed382"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-77-c73ca1a6eab2>:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_gru_model, verbose=1, batch_size = 256, epochs=10)\n"
          ]
        }
      ],
      "source": [
        "start = time()\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_gru_model, verbose=1, batch_size = 256, epochs=10)\n",
        "# define parameters and values for grid search\n",
        "\n",
        "parameters = {\n",
        "    'units':[50], # 1024\n",
        "    #'learning_rate_init': [0.001, 0.01],\n",
        "    'solver':['adam'],\n",
        "    #'epochs':[3,5,10]\n",
        "    #'dropout_rate':[0.0,0.05, 0.1], #0.05\n",
        "    #'regularizer':[0.0,0.05, 0.1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhB4jEx8AMpg"
      },
      "outputs": [],
      "source": [
        "metrics = {'accuracy':make_scorer(accuracy_score,greater_is_better=True),'f1':make_scorer(f1_score,greater_is_better=True),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFG1wNb2AMpg",
        "outputId": "8da137c1-aa58-4611-b6aa-b4fb2d41687c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - 143s 6s/step - loss: 0.6539 - accuracy: 0.6691\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 135s 6s/step - loss: 0.6276 - accuracy: 0.6788\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 137s 6s/step - loss: 0.6246 - accuracy: 0.6788\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 135s 6s/step - loss: 0.6228 - accuracy: 0.6788\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 140s 6s/step - loss: 0.6195 - accuracy: 0.6788\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 138s 6s/step - loss: 0.6159 - accuracy: 0.6788\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 160s 7s/step - loss: 0.6131 - accuracy: 0.6776\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 135s 6s/step - loss: 0.6076 - accuracy: 0.6772\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 133s 6s/step - loss: 0.5999 - accuracy: 0.6734\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 136s 6s/step - loss: 0.5520 - accuracy: 0.7053\n"
          ]
        }
      ],
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=parameters, n_jobs=-1, cv=10, scoring=metrics, refit='mcc')\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE1zJUaAAMpg"
      },
      "outputs": [],
      "source": [
        "classifier = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL5EUnbHAMpg",
        "outputId": "7f661346-f8df-46dc-b74a-cb75d5700f09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbose': 1,\n",
              " 'batch_size': 256,\n",
              " 'epochs': 10,\n",
              " 'solver': 'adam',\n",
              " 'units': 50,\n",
              " 'build_fn': <function __main__.create_gru_model(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam')>}"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF8zMX5jAMpg"
      },
      "outputs": [],
      "source": [
        "#cv_results = DataFrame(grid.cv_results_)\n",
        "\n",
        "#cv_results[['param_units','param_dropout_rate','param_regularizer','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIC-yOznAMpg"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(grid.cv_results_)\n",
        "new_path = '/content/test.xls'\n",
        "writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/ESM23BGRU2.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyNEgPlWAMpg",
        "outputId": "436025c3-9e8b-4100-8035-05c512783230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "178/178 [==============================] - 102s 569ms/step\n",
            "acc: 0.7562610229276896\n",
            "f1: 0.8362559241706162\n",
            "mcc: 0.39689518769832893\n",
            "sn: [0.9135899450117831, 0.9156118143459916, 0.9266823775857554, 0.9279958409149986, 0.9205020920502092, 0.9183303085299456, 0.9187353018029788, 0.9149491260109575, 0.9194648478488983, 0.9184936806809388, 0.9146434960388449, 0.9152586430985183, 0.9188210961737332, 0.9182146542827657, 0.9123485434390307, 0.9202518363064008, 0.9157127991675338, 0.91785436641617, 0.9138064516129032, 0.9184360435007768, 0.925589836660617, 0.9115964638585543, 0.9175882043180621, 0.9144805876180483, 0.9171270718232044, 0.9176685833768949, 0.9183303085299456, 0.9139240506329114, 0.9082062072593372, 0.9178154825026511, 0.914778578784758, 0.9169312169312169, 0.9167750325097529, 0.92, 0.916231732776618, 0.9105648535564853, 0.9109677419354839, 0.9155327342747112, 0.9174287954010975, 0.9141981613891726, 0.9163673678809646, 0.9134766649187205, 0.9118500923726577, 0.9147757255936676, 0.9171299973523961, 0.9137840670859538, 0.9271023171049206, 0.915378569557244, 0.9222108495394064, 0.9115893181228935, 0.913168187744459, 0.9161108260646486, 0.917797695262484, 0.9066736183524504, 0.916969382459782, 0.909876866649201, 0.9129750982961992, 0.9168367346938775, 0.9226143790849674, 0.9075804776739356, 0.9177344951307022, 0.9208387942332896, 0.9145165493875423, 0.9270994332818135, 0.9117032392894462, 0.9187224097636978, 0.9164727178691492, 0.9251543209876543, 0.9160784313725491, 0.9127725856697819, 0.917307182613305, 0.917494270435447, 0.9155227032734953, 0.9295154185022027, 0.9184740005226025, 0.9170566822672906, 0.9059806738051711, 0.9116279069767442, 0.9173767105602891, 0.9197175732217573, 0.9242424242424242, 0.9184740005226025, 0.9091381100726895, 0.9163862283199585, 0.906258114775383, 0.9162141194724592, 0.9150466045272969, 0.9124900556881463, 0.9223553934340802, 0.9140341791817711, 0.9148494288681205, 0.9202182952182952, 0.912262156448203, 0.9187012987012987, 0.918625678119349, 0.9162754303599374, 0.9196776709123993, 0.9143225806451613, 0.9182617692705639, 0.9157187176835574, 0.922697795071336, 0.917869325636316, 0.9177795234354543, 0.9189118493329845, 0.9210187805505531, 0.9149431230610134, 0.9272343791194305, 0.9160365058670144, 0.916474506789649, 0.9215384615384615, 0.9141820067409904, 0.9139141742522757, 0.917239555790587, 0.9136024685009, 0.9094437257438551, 0.9156118143459916, 0.9120879120879121, 0.9146055714657642, 0.9237199582027168, 0.9182818229439497, 0.9172755741127349, 0.9167974882260597, 0.9192882929345023, 0.911284046692607, 0.9110125260960334, 0.9195402298850575, 0.9184713375796179, 0.9210526315789473, 0.918961038961039, 0.9146748907735801, 0.916338840807763, 0.9191555097837281, 0.9179826795720836, 0.9216914643696162, 0.9175338189386056, 0.9183040330920372, 0.9183835182250396, 0.9077404222048475, 0.9181271252942715, 0.9147947327652982, 0.9163636363636364, 0.9091614906832298, 0.9213217938630999, 0.9153153153153153, 0.9108446298227321, 0.9201352757544224, 0.9178187403993856, 0.9183194154488518, 0.9074993467467991, 0.9167757131640931, 0.9145299145299145, 0.9205644107656128, 0.9214876033057852, 0.9218064516129032, 0.921025641025641, 0.9217978695765133, 0.9138932910723719, 0.9203031094852365, 0.9141104294478528, 0.920490093847758, 0.9233218360307774, 0.9157566302652106, 0.917078242786587, 0.9121849831124967, 0.918054110301769, 0.9206102922161883, 0.9124703401001846, 0.9151843258571797, 0.9119022869022869, 0.9199173340222164, 0.9166450272656453, 0.9222999222999223, 0.9124411918452692, 0.9114863136352008, 0.921406411582213, 0.9152763295099061, 0.9178187403993856, 0.915412558380903, 0.9166235111341274, 0.9203218271476772, 0.9206555671175859, 0.9161306920504245, 0.9129539016224568, 0.9153846153846154, 0.9176195426195426, 0.9149154279856484, 0.9202046035805627, 0.9253036960454898, 0.9110881364693719, 0.9190377651319193, 0.9194665298794563, 0.9166011014948859, 0.9206308169596691, 0.9130661114003124, 0.9210663878724517, 0.9184360435007768, 0.9115067079463365, 0.9210053859964094, 0.9187335092348285, 0.9138421733505822, 0.9160802710450873, 0.9084710201940729, 0.9099661722612542, 0.9155185859110996, 0.9130545639979603, 0.9230569274759552, 0.9171612903225806, 0.9222743870631195, 0.9092101810548413, 0.9143817899637868, 0.9226533822758259, 0.9181794264667192, 0.918286915396742, 0.9198642652049074, 0.9168831168831169, 0.9157812904897642, 0.9178117708063261, 0.9129644063393089, 0.920147097452062, 0.912667191188041, 0.9179526748971193, 0.9187466808284652, 0.916206987128973, 0.9216398546964193, 0.9129161118508655, 0.9128748707342296, 0.913846954711088, 0.9169010483252366, 0.9141072358146799, 0.908856183836819, 0.9198759369346085, 0.9210526315789473, 0.9161894846434149, 0.9156030216202136, 0.9198040226921094, 0.9103538663171691, 0.9204134366925064, 0.9222423146473779, 0.9174832387828777, 0.904320987654321, 0.9174025974025974, 0.9209242618741977, 0.910326797385621, 0.9149987002859371, 0.9223051196295343, 0.9105882352941177, 0.9104826154644525, 0.9202631578947369, 0.9208614426569798, 0.9198966408268734, 0.9122944400939702, 0.9134187810619931, 0.9089010702166536, 0.9177018633540373, 0.916205533596838, 0.9097744360902256, 0.9173618352450469, 0.9189826953329837, 0.9197563559322034, 0.9189330543933054, 0.9140522014236752, 0.916860315001291, 0.9182213135701508, 0.9215432418436044, 0.9204368174726989, 0.9256390395042603, 0.9206637282862328, 0.9121338912133892, 0.9184627369514412, 0.9182175622542595, 0.9155877783531848, 0.9160802710450873, 0.9150992685475444, 0.9202614379084967, 0.9237177818276491, 0.9136803557415643, 0.9192100538599641, 0.918142160636387, 0.9153026760197454, 0.911128485796195, 0.9194717762817193, 0.9120965625819994, 0.9177974947807933, 0.9126389247867666, 0.9103896103896104, 0.9240020470829069, 0.920997375328084, 0.9222250836981715, 0.9184571576494952, 0.9166237776634071, 0.9192179058399794, 0.9185556141275698, 0.9250261233019854, 0.917507111455909, 0.9148157825973348, 0.9093277748827514, 0.9099501181412444, 0.9171858774662512, 0.9176285414480587, 0.921862871927555, 0.9152892561983471, 0.9193422083007048, 0.9182373241306079, 0.9129227662796567, 0.9125485122897801, 0.9245627773427304, 0.9160146061554513, 0.9166019166019166, 0.9100542775911088, 0.9204250907205807, 0.9161021365294424, 0.9194473409801877, 0.9196499602227526, 0.916795466254508, 0.9134564643799472, 0.9231784582893348, 0.922182006204757, 0.9210324559161769, 0.9189048239895697, 0.9189470940839197, 0.9237715803452855, 0.91622760800843, 0.9100978876867594, 0.907426508509541, 0.9173575129533679, 0.9147043432757719, 0.9156595525842118, 0.9197930142302717, 0.9148550724637681, 0.9163598106259864, 0.914993481095176, 0.9134187810619931, 0.9205315268368942, 0.9152366094643786, 0.914958238420653, 0.9248494370253993, 0.9132360604481501, 0.9224806201550387, 0.9107142857142857, 0.9173618352450469, 0.9226912928759895, 0.9150192554557125, 0.9233160621761658, 0.9110878661087866, 0.9225006458279514, 0.9212926765702372, 0.9255765199161425, 0.9105018106570099, 0.914778578784758, 0.9179657551750575, 0.9199269692227439, 0.9135416666666667, 0.9103339468840389, 0.9068436117616445, 0.922324966974901, 0.9166666666666666, 0.9113695090439277, 0.9187160238156873, 0.9156781846312533, 0.914637339617701, 0.9206680584551148, 0.9167750325097529, 0.9195160441872698, 0.9245832230748875, 0.9196083483638238, 0.9194736842105263, 0.9259932485068814, 0.9145342886386899, 0.9209434940383618, 0.9082188229193674, 0.9064955474070194, 0.92230252968508, 0.9163664436438497, 0.9173640167364017, 0.9248554913294798, 0.9134343693809401, 0.9194488606253313, 0.917963597995252, 0.9184726522187823, 0.9145070798824473, 0.9105586878523834, 0.9159222280609564, 0.9154746423927178, 0.9155221559989635, 0.910292973813845, 0.9187435098650052, 0.9207094418362024, 0.9189682126107348, 0.9208025343189018, 0.9155002592016589, 0.9194717762817193, 0.9210526315789473, 0.9182818229439497, 0.9119414685131957, 0.9162548764629389, 0.9123898392949715, 0.9194560669456067, 0.9141414141414141, 0.9119609856262834, 0.9115067079463365, 0.91795139796185, 0.9186196240020602, 0.9178262011026516, 0.9113250570053205, 0.9095310907237513, 0.920132686909926, 0.9254770500257865, 0.9242738589211619, 0.9132337796086509, 0.9136375354472802, 0.9149947201689546, 0.9213255755122691, 0.9153866180682114, 0.9191022964509394, 0.9187353018029788, 0.9134063641105895, 0.908454356846473, 0.9216553878188444, 0.916795466254508, 0.9167317200104085, 0.9148881460529699, 0.9149987002859371, 0.9117417339234575, 0.9182829066459788, 0.9233152594887684, 0.915412558380903, 0.9166666666666666, 0.9119855034946932, 0.9248752298397689, 0.9161056447436562, 0.9148602768346827, 0.9210184463497012, 0.9165370658372214, 0.9156878099712868, 0.9146115088835852, 0.9136410788381742, 0.9080489710862204, 0.9150529305447973, 0.9154671551949751, 0.9193173002327386, 0.9099145741651566, 0.9203863221091099, 0.9075823334184324, 0.9178756476683938, 0.9183726353977715, 0.9150275373721479, 0.9294087001823391, 0.9150156412930136, 0.9172219374679651, 0.9105691056910569, 0.9255874673629243, 0.910326797385621, 0.9156969226790794, 0.9246719160104987, 0.9240338803599788, 0.9117266373285011, 0.9194473409801877, 0.918041237113402, 0.9220135628586332, 0.9213657527159855, 0.9260230849947534, 0.9254658385093167, 0.9113630507601134, 0.9080399369416711, 0.9252049180327869, 0.9095634095634095, 0.9144039306956296, 0.9225738948469788, 0.9170146137787056, 0.9193506828137078, 0.9092327698309493, 0.9209302325581395, 0.9220507454878368, 0.911939911939912, 0.921147880041365, 0.9111343439623628, 0.9190661478599221, 0.933994260370467, 0.9234141309953584, 0.9229974160206719, 0.9143530644316396, 0.9195281782437745, 0.911504424778761, 0.9061860940695297, 0.9216710182767625, 0.9209710743801653, 0.9146907216494845, 0.9128641402423305, 0.911925175370226, 0.9182829066459788, 0.9207446808510639, 0.9111928533893852, 0.9088050314465409, 0.9195521999479302, 0.9088066701406983, 0.9139055570049569, 0.912998712998713, 0.9155624837620161, 0.9137122002085506, 0.9133754607688257, 0.9202059202059202, 0.9282011404872991, 0.9227154046997389, 0.9185050609914353, 0.9129057798891528, 0.9150992685475444, 0.9193506153443309, 0.9165382639958911, 0.9197930142302717, 0.9122852680895367, 0.9129301355578728, 0.914810978767478, 0.9234930448222566, 0.912568306010929, 0.9241944004226096, 0.9197943444730077, 0.9093977154724818, 0.9160802710450873, 0.9155911202891068, 0.9119529050422319, 0.9146882337594573, 0.9197722567287785, 0.9127621019932695, 0.9142559291112848, 0.9237354085603113, 0.9095411887382691, 0.9182818229439497, 0.9099451840250588, 0.9166235111341274, 0.9160802710450873, 0.9106680476437079, 0.9153194765204004, 0.9166224110462029, 0.9130208333333333, 0.9170362640229586, 0.9223300970873787, 0.9225941422594143, 0.9098274960794563, 0.9143225806451613, 0.9180497925311203, 0.9224160374902369, 0.9260915307732772, 0.9073787409700722, 0.9182009468700684, 0.9143225806451613, 0.9176650522559265, 0.9156437712196396, 0.913335052875935, 0.9162742019884877, 0.9182829066459788, 0.9191466947590203, 0.919863373620599, 0.9140604467805519, 0.9203722854188211, 0.9174430641821946, 0.9234424498416051, 0.9232961907229852, 0.9147066425432928, 0.9242463282659108, 0.9167539267015706, 0.9197368421052632, 0.9166666666666666, 0.922267829656234, 0.9193216855087358, 0.9240208877284596, 0.9208127116436572, 0.9200724262803932, 0.9214714322984607, 0.9224182667358588, 0.9179526748971193, 0.9158709677419354, 0.9173767105602891, 0.9195046439628483, 0.9087126137841353, 0.9188001034393587, 0.9034749034749034, 0.9298883406907297, 0.9167520491803278, 0.9163636363636364, 0.9144702842377261, 0.9160166406656266, 0.9038807504497558, 0.9253187613843351, 0.9177181913774973, 0.9216201998947923, 0.9142783372063, 0.9149377593360996, 0.9215123859191656, 0.9234800838574424, 0.9209773849753055, 0.9084798345398138, 0.9057387691508699, 0.9242813141683778, 0.908075824461179, 0.9274151436031332, 0.9160384715362621, 0.9206594538897476, 0.9140848737307993, 0.9195940671350508, 0.9321685508735869, 0.9194263363754889, 0.9165378670788253, 0.9190389135544529, 0.9175443103005394, 0.9250065325320094, 0.9216867469879518, 0.9229976822044811, 0.9240342234897588, 0.9189118493329845, 0.9189399844115355, 0.9169084674228436, 0.9160621761658031, 0.9175738724727839, 0.9179859849467947, 0.9155624837620161, 0.9240672622175512, 0.9184839044652129, 0.9170316928626643, 0.9132679401135777, 0.9209639803057788, 0.923469387755102, 0.9220611082340756, 0.9224383916990921, 0.918751612071189, 0.9192530247238295, 0.9127846790890269, 0.9135416666666667, 0.9125164690382082, 0.9113956466069142, 0.9206308169596691, 0.9137886263308231, 0.9230571281523418, 0.918580375782881, 0.9159533073929961, 0.9124621594349143, 0.916731923779692, 0.9144343302990897, 0.9190946930280958, 0.9183459827270348, 0.9173319598248777, 0.9140584915341201, 0.9168831168831169, 0.9155405405405406, 0.9116653676279554, 0.9133858267716536, 0.9171157300487555, 0.9140848737307993, 0.9107883817427386, 0.9131233595800525, 0.9245480744039822, 0.9239543726235742, 0.91640625, 0.9201803235216123, 0.9161021365294424, 0.9175365344467641, 0.9157098121085595, 0.9222108495394064, 0.913846954711088, 0.9115593483320403, 0.9216961498439126, 0.9195521999479302, 0.9114745586708204, 0.910164271047228, 0.9141009055627426, 0.9139481119958901, 0.9170518746789933, 0.9252798750325436, 0.926509186351706, 0.9201261166579086, 0.9154086413326392, 0.9186016175319593, 0.9134390434104497, 0.9166237776634071, 0.9151595744680852, 0.910950038829925, 0.9160166406656266, 0.9174883238194084, 0.9093985941161156, 0.9146907216494845, 0.9165140015702695, 0.9088090932575562, 0.9173618352450469, 0.9107515657620042, 0.9139757168690261, 0.9130096078940535, 0.91640625, 0.9134615384615384, 0.9171428571428571, 0.913312693498452, 0.9163617354939885, 0.9239750908147379, 0.9054159108577352, 0.9216553878188444, 0.9139922978177151, 0.9217436974789915, 0.9162344398340249, 0.9138461538461539, 0.9196242171189979, 0.9167323351720514, 0.9194451853827688, 0.9134414225941423, 0.9091858037578288, 0.9091143816163181, 0.9220338983050848, 0.9225554106910039, 0.9214470284237726, 0.9149544863459038, 0.9212121212121213, 0.924792531120332, 0.9063467492260062, 0.9160010306622005, 0.9222770990382116, 0.9209277807063785, 0.9193216855087358, 0.9151657530670844, 0.9184824403998975, 0.918848167539267, 0.9235854045478583, 0.907436297451898, 0.9100597868468937, 0.9179867143587123, 0.9203381147540983, 0.9193967758710349, 0.9101623886851755, 0.917943391326928, 0.922772799156563, 0.9199162522899764, 0.9113157894736842, 0.9245729303547964, 0.9170530654301906, 0.9185415050426687, 0.9065420560747663, 0.9165370658372214, 0.9140564328242299, 0.9275064267352185, 0.9050980392156863, 0.9135544528597545, 0.9170146137787056, 0.9148881460529699, 0.916123990622558, 0.9195849546044098, 0.9134130146082338, 0.91701244813278, 0.9160063391442155, 0.9131125827814569, 0.9169278996865203, 0.9143158449775903, 0.9122668768058839, 0.9111747851002865, 0.9188201513965022, 0.9198945981554677, 0.9077280951150168, 0.9174719247845391, 0.9203655352480418, 0.9140094093047569, 0.9113989637305699, 0.9114420062695925, 0.9196032367528061, 0.923473331615563, 0.9232375979112272, 0.9055962343096234, 0.9122991835659732, 0.9197289549126922, 0.9168399168399168, 0.9126466753585397, 0.9139589290356122, 0.9237971391417426, 0.9206019719771665, 0.9203903441191577, 0.9267083985393845, 0.9188144329896907, 0.9178794178794178, 0.9148771021992238, 0.9143441575044745, 0.9184415584415584, 0.9137886263308231, 0.9163879598662207, 0.9200524246395806, 0.9167958656330749, 0.9088311688311689, 0.9120734908136483, 0.9113007499353504, 0.9101036269430052, 0.9132264002103603, 0.9206806282722513, 0.9109301103520757, 0.9164490861618799, 0.9196058091286307, 0.9194373401534527, 0.923728813559322, 0.9130548988705017, 0.915929203539823, 0.9154086413326392, 0.9150943396226415, 0.9203177043300026, 0.925065274151436, 0.9135191456108361, 0.9160021265284424, 0.9202168861347793, 0.9262696571281258, 0.9148882113821138, 0.9129866736347008, 0.9117183394640042, 0.9104516129032258, 0.9084470094438615, 0.9103590803409971, 0.9218709171674941, 0.9129417879417879, 0.922138593303919, 0.921854649648346, 0.9085255247473438, 0.9203218271476772, 0.9177545691906005, 0.9158609877188398, 0.9161953727506427, 0.9203197524497163, 0.9190587018360487, 0.9247478665632273, 0.9242934923515685, 0.9203516938194983, 0.916795466254508, 0.9118581259925886, 0.9105139577354553, 0.9125192406362237, 0.9126840609661586, 0.9199283704272192, 0.9155221559989635, 0.9216096158871179, 0.9191685912240185, 0.9141664492564571, 0.9220981563230329, 0.9149211274890096, 0.9157509157509157, 0.9182194616977226, 0.9193294918805658, 0.9120227038183695, 0.9214673211056574, 0.9217191097467383, 0.9158467115484205, 0.9206914082358922, 0.9139450492483152, 0.9089971642175818, 0.9113825363825364, 0.918622848200313, 0.9163826998689384, 0.9153945666235447, 0.9172485130592191, 0.9211340206185566, 0.9125739264592441, 0.921045819311416, 0.9196474857439088, 0.9124579124579124, 0.9148380355276907, 0.9255208333333333, 0.918054110301769, 0.9129074315514993, 0.9122899159663865, 0.9151358344113842, 0.9162344398340249, 0.9137122002085506, 0.9138333765896703, 0.9104091144484723, 0.9123351435221102, 0.9149372277735076, 0.9182779066769786, 0.9173856209150327, 0.9166887768638896, 0.9163201663201663, 0.917705088265836, 0.9123779361309052, 0.9154267815191856, 0.9156184486373166, 0.9070371332121527, 0.920490093847758, 0.9151483602290473, 0.9196545406961528, 0.9193091002835783, 0.9112716017539334, 0.9241990101588955, 0.9231767453932, 0.9212184873949579, 0.9204188481675393, 0.9150893796004206, 0.9154306531355711, 0.9157785287236808, 0.9247395833333333, 0.9195640892579139, 0.9148051948051948, 0.9178681771369722, 0.9124125421093547, 0.918720503408495, 0.9126521969295924, 0.9169047000779018, 0.912153407618554, 0.9132134480062549, 0.9171369933299128, 0.9180241723594325, 0.9224845995893224, 0.9082026227822062, 0.9190736403851157, 0.9246270609788013, 0.9138461538461539, 0.9263427109974425, 0.9210731961448294, 0.9147327249022165, 0.9148051948051948, 0.919659002841643, 0.9077042399172699, 0.9117798353909465, 0.9174857734092084, 0.920846394984326, 0.9187306501547987, 0.9202197227308396, 0.9230367858074615, 0.9242698371672267, 0.911076843998972, 0.9172521467603435, 0.9148264984227129, 0.9203722854188211, 0.9176439927026323, 0.9208745445080687, 0.9091387937845667, 0.9142330965535386, 0.9146404552509053, 0.9199581480512686, 0.919659002841643, 0.9183462532299742, 0.9190811798486035, 0.9154411764705882, 0.9176685833768949, 0.9145454545454546, 0.9237376366475794, 0.9248261102193687, 0.9131233595800525, 0.9141009055627426, 0.9240473738414006, 0.9118635306280692, 0.916338840807763, 0.9137396694214877, 0.9128956317028512, 0.9129405576012625, 0.9104786545924968, 0.9153846153846154, 0.9268354430379747, 0.9162155194637793, 0.911948051948052, 0.9248509976677896, 0.9238790406673618, 0.9245233742491512, 0.9113760041461518, 0.9164948453608247, 0.9207428720899817, 0.9211413748378728, 0.9182604139376473, 0.9183350895679663, 0.919626652838994, 0.9143596377749029, 0.924380704041721, 0.9173360974345686, 0.9161188535366815, 0.9032846715328468, 0.9139427987742594, 0.917078242786587, 0.9152280340118526, 0.9072560040878896, 0.9178506845776285, 0.9187922956793336, 0.9068920676202861, 0.912850039256739, 0.9193714580113344, 0.9151483602290473, 0.9157058672815783, 0.916297262059974, 0.9160857216627937, 0.9217748140548858, 0.9183135704874835, 0.9148880105401844, 0.9192417553882108, 0.9158854166666667, 0.9233605478008955, 0.9185986604842864, 0.912535686478069, 0.9198137609932747, 0.9108859444011431, 0.914783060535204, 0.9191214470284238, 0.9177623098736788, 0.9184782608695652, 0.9133022774327122, 0.9115751482340809, 0.917331206804891, 0.9110589462702139, 0.9253381893860562, 0.9235734572682675, 0.9215380618342427, 0.9152366094643786, 0.9231164823862176, 0.918724279835391, 0.9038865546218487, 0.9145833333333333]\n",
            "sp: [0.9135899450117831, 0.9156118143459916, 0.9266823775857554, 0.9279958409149986, 0.9205020920502092, 0.9183303085299456, 0.9187353018029788, 0.9149491260109575, 0.9194648478488983, 0.9184936806809388, 0.9146434960388449, 0.9152586430985183, 0.9188210961737332, 0.9182146542827657, 0.9123485434390307, 0.9202518363064008, 0.9157127991675338, 0.91785436641617, 0.9138064516129032, 0.9184360435007768, 0.925589836660617, 0.9115964638585543, 0.9175882043180621, 0.9144805876180483, 0.9171270718232044, 0.9176685833768949, 0.9183303085299456, 0.9139240506329114, 0.9082062072593372, 0.9178154825026511, 0.914778578784758, 0.9169312169312169, 0.9167750325097529, 0.92, 0.916231732776618, 0.9105648535564853, 0.9109677419354839, 0.9155327342747112, 0.9174287954010975, 0.9141981613891726, 0.9163673678809646, 0.9134766649187205, 0.9118500923726577, 0.9147757255936676, 0.9171299973523961, 0.9137840670859538, 0.9271023171049206, 0.915378569557244, 0.9222108495394064, 0.9115893181228935, 0.913168187744459, 0.9161108260646486, 0.917797695262484, 0.9066736183524504, 0.916969382459782, 0.909876866649201, 0.9129750982961992, 0.9168367346938775, 0.9226143790849674, 0.9075804776739356, 0.9177344951307022, 0.9208387942332896, 0.9145165493875423, 0.9270994332818135, 0.9117032392894462, 0.9187224097636978, 0.9164727178691492, 0.9251543209876543, 0.9160784313725491, 0.9127725856697819, 0.917307182613305, 0.917494270435447, 0.9155227032734953, 0.9295154185022027, 0.9184740005226025, 0.9170566822672906, 0.9059806738051711, 0.9116279069767442, 0.9173767105602891, 0.9197175732217573, 0.9242424242424242, 0.9184740005226025, 0.9091381100726895, 0.9163862283199585, 0.906258114775383, 0.9162141194724592, 0.9150466045272969, 0.9124900556881463, 0.9223553934340802, 0.9140341791817711, 0.9148494288681205, 0.9202182952182952, 0.912262156448203, 0.9187012987012987, 0.918625678119349, 0.9162754303599374, 0.9196776709123993, 0.9143225806451613, 0.9182617692705639, 0.9157187176835574, 0.922697795071336, 0.917869325636316, 0.9177795234354543, 0.9189118493329845, 0.9210187805505531, 0.9149431230610134, 0.9272343791194305, 0.9160365058670144, 0.916474506789649, 0.9215384615384615, 0.9141820067409904, 0.9139141742522757, 0.917239555790587, 0.9136024685009, 0.9094437257438551, 0.9156118143459916, 0.9120879120879121, 0.9146055714657642, 0.9237199582027168, 0.9182818229439497, 0.9172755741127349, 0.9167974882260597, 0.9192882929345023, 0.911284046692607, 0.9110125260960334, 0.9195402298850575, 0.9184713375796179, 0.9210526315789473, 0.918961038961039, 0.9146748907735801, 0.916338840807763, 0.9191555097837281, 0.9179826795720836, 0.9216914643696162, 0.9175338189386056, 0.9183040330920372, 0.9183835182250396, 0.9077404222048475, 0.9181271252942715, 0.9147947327652982, 0.9163636363636364, 0.9091614906832298, 0.9213217938630999, 0.9153153153153153, 0.9108446298227321, 0.9201352757544224, 0.9178187403993856, 0.9183194154488518, 0.9074993467467991, 0.9167757131640931, 0.9145299145299145, 0.9205644107656128, 0.9214876033057852, 0.9218064516129032, 0.921025641025641, 0.9217978695765133, 0.9138932910723719, 0.9203031094852365, 0.9141104294478528, 0.920490093847758, 0.9233218360307774, 0.9157566302652106, 0.917078242786587, 0.9121849831124967, 0.918054110301769, 0.9206102922161883, 0.9124703401001846, 0.9151843258571797, 0.9119022869022869, 0.9199173340222164, 0.9166450272656453, 0.9222999222999223, 0.9124411918452692, 0.9114863136352008, 0.921406411582213, 0.9152763295099061, 0.9178187403993856, 0.915412558380903, 0.9166235111341274, 0.9203218271476772, 0.9206555671175859, 0.9161306920504245, 0.9129539016224568, 0.9153846153846154, 0.9176195426195426, 0.9149154279856484, 0.9202046035805627, 0.9253036960454898, 0.9110881364693719, 0.9190377651319193, 0.9194665298794563, 0.9166011014948859, 0.9206308169596691, 0.9130661114003124, 0.9210663878724517, 0.9184360435007768, 0.9115067079463365, 0.9210053859964094, 0.9187335092348285, 0.9138421733505822, 0.9160802710450873, 0.9084710201940729, 0.9099661722612542, 0.9155185859110996, 0.9130545639979603, 0.9230569274759552, 0.9171612903225806, 0.9222743870631195, 0.9092101810548413, 0.9143817899637868, 0.9226533822758259, 0.9181794264667192, 0.918286915396742, 0.9198642652049074, 0.9168831168831169, 0.9157812904897642, 0.9178117708063261, 0.9129644063393089, 0.920147097452062, 0.912667191188041, 0.9179526748971193, 0.9187466808284652, 0.916206987128973, 0.9216398546964193, 0.9129161118508655, 0.9128748707342296, 0.913846954711088, 0.9169010483252366, 0.9141072358146799, 0.908856183836819, 0.9198759369346085, 0.9210526315789473, 0.9161894846434149, 0.9156030216202136, 0.9198040226921094, 0.9103538663171691, 0.9204134366925064, 0.9222423146473779, 0.9174832387828777, 0.904320987654321, 0.9174025974025974, 0.9209242618741977, 0.910326797385621, 0.9149987002859371, 0.9223051196295343, 0.9105882352941177, 0.9104826154644525, 0.9202631578947369, 0.9208614426569798, 0.9198966408268734, 0.9122944400939702, 0.9134187810619931, 0.9089010702166536, 0.9177018633540373, 0.916205533596838, 0.9097744360902256, 0.9173618352450469, 0.9189826953329837, 0.9197563559322034, 0.9189330543933054, 0.9140522014236752, 0.916860315001291, 0.9182213135701508, 0.9215432418436044, 0.9204368174726989, 0.9256390395042603, 0.9206637282862328, 0.9121338912133892, 0.9184627369514412, 0.9182175622542595, 0.9155877783531848, 0.9160802710450873, 0.9150992685475444, 0.9202614379084967, 0.9237177818276491, 0.9136803557415643, 0.9192100538599641, 0.918142160636387, 0.9153026760197454, 0.911128485796195, 0.9194717762817193, 0.9120965625819994, 0.9177974947807933, 0.9126389247867666, 0.9103896103896104, 0.9240020470829069, 0.920997375328084, 0.9222250836981715, 0.9184571576494952, 0.9166237776634071, 0.9192179058399794, 0.9185556141275698, 0.9250261233019854, 0.917507111455909, 0.9148157825973348, 0.9093277748827514, 0.9099501181412444, 0.9171858774662512, 0.9176285414480587, 0.921862871927555, 0.9152892561983471, 0.9193422083007048, 0.9182373241306079, 0.9129227662796567, 0.9125485122897801, 0.9245627773427304, 0.9160146061554513, 0.9166019166019166, 0.9100542775911088, 0.9204250907205807, 0.9161021365294424, 0.9194473409801877, 0.9196499602227526, 0.916795466254508, 0.9134564643799472, 0.9231784582893348, 0.922182006204757, 0.9210324559161769, 0.9189048239895697, 0.9189470940839197, 0.9237715803452855, 0.91622760800843, 0.9100978876867594, 0.907426508509541, 0.9173575129533679, 0.9147043432757719, 0.9156595525842118, 0.9197930142302717, 0.9148550724637681, 0.9163598106259864, 0.914993481095176, 0.9134187810619931, 0.9205315268368942, 0.9152366094643786, 0.914958238420653, 0.9248494370253993, 0.9132360604481501, 0.9224806201550387, 0.9107142857142857, 0.9173618352450469, 0.9226912928759895, 0.9150192554557125, 0.9233160621761658, 0.9110878661087866, 0.9225006458279514, 0.9212926765702372, 0.9255765199161425, 0.9105018106570099, 0.914778578784758, 0.9179657551750575, 0.9199269692227439, 0.9135416666666667, 0.9103339468840389, 0.9068436117616445, 0.922324966974901, 0.9166666666666666, 0.9113695090439277, 0.9187160238156873, 0.9156781846312533, 0.914637339617701, 0.9206680584551148, 0.9167750325097529, 0.9195160441872698, 0.9245832230748875, 0.9196083483638238, 0.9194736842105263, 0.9259932485068814, 0.9145342886386899, 0.9209434940383618, 0.9082188229193674, 0.9064955474070194, 0.92230252968508, 0.9163664436438497, 0.9173640167364017, 0.9248554913294798, 0.9134343693809401, 0.9194488606253313, 0.917963597995252, 0.9184726522187823, 0.9145070798824473, 0.9105586878523834, 0.9159222280609564, 0.9154746423927178, 0.9155221559989635, 0.910292973813845, 0.9187435098650052, 0.9207094418362024, 0.9189682126107348, 0.9208025343189018, 0.9155002592016589, 0.9194717762817193, 0.9210526315789473, 0.9182818229439497, 0.9119414685131957, 0.9162548764629389, 0.9123898392949715, 0.9194560669456067, 0.9141414141414141, 0.9119609856262834, 0.9115067079463365, 0.91795139796185, 0.9186196240020602, 0.9178262011026516, 0.9113250570053205, 0.9095310907237513, 0.920132686909926, 0.9254770500257865, 0.9242738589211619, 0.9132337796086509, 0.9136375354472802, 0.9149947201689546, 0.9213255755122691, 0.9153866180682114, 0.9191022964509394, 0.9187353018029788, 0.9134063641105895, 0.908454356846473, 0.9216553878188444, 0.916795466254508, 0.9167317200104085, 0.9148881460529699, 0.9149987002859371, 0.9117417339234575, 0.9182829066459788, 0.9233152594887684, 0.915412558380903, 0.9166666666666666, 0.9119855034946932, 0.9248752298397689, 0.9161056447436562, 0.9148602768346827, 0.9210184463497012, 0.9165370658372214, 0.9156878099712868, 0.9146115088835852, 0.9136410788381742, 0.9080489710862204, 0.9150529305447973, 0.9154671551949751, 0.9193173002327386, 0.9099145741651566, 0.9203863221091099, 0.9075823334184324, 0.9178756476683938, 0.9183726353977715, 0.9150275373721479, 0.9294087001823391, 0.9150156412930136, 0.9172219374679651, 0.9105691056910569, 0.9255874673629243, 0.910326797385621, 0.9156969226790794, 0.9246719160104987, 0.9240338803599788, 0.9117266373285011, 0.9194473409801877, 0.918041237113402, 0.9220135628586332, 0.9213657527159855, 0.9260230849947534, 0.9254658385093167, 0.9113630507601134, 0.9080399369416711, 0.9252049180327869, 0.9095634095634095, 0.9144039306956296, 0.9225738948469788, 0.9170146137787056, 0.9193506828137078, 0.9092327698309493, 0.9209302325581395, 0.9220507454878368, 0.911939911939912, 0.921147880041365, 0.9111343439623628, 0.9190661478599221, 0.933994260370467, 0.9234141309953584, 0.9229974160206719, 0.9143530644316396, 0.9195281782437745, 0.911504424778761, 0.9061860940695297, 0.9216710182767625, 0.9209710743801653, 0.9146907216494845, 0.9128641402423305, 0.911925175370226, 0.9182829066459788, 0.9207446808510639, 0.9111928533893852, 0.9088050314465409, 0.9195521999479302, 0.9088066701406983, 0.9139055570049569, 0.912998712998713, 0.9155624837620161, 0.9137122002085506, 0.9133754607688257, 0.9202059202059202, 0.9282011404872991, 0.9227154046997389, 0.9185050609914353, 0.9129057798891528, 0.9150992685475444, 0.9193506153443309, 0.9165382639958911, 0.9197930142302717, 0.9122852680895367, 0.9129301355578728, 0.914810978767478, 0.9234930448222566, 0.912568306010929, 0.9241944004226096, 0.9197943444730077, 0.9093977154724818, 0.9160802710450873, 0.9155911202891068, 0.9119529050422319, 0.9146882337594573, 0.9197722567287785, 0.9127621019932695, 0.9142559291112848, 0.9237354085603113, 0.9095411887382691, 0.9182818229439497, 0.9099451840250588, 0.9166235111341274, 0.9160802710450873, 0.9106680476437079, 0.9153194765204004, 0.9166224110462029, 0.9130208333333333, 0.9170362640229586, 0.9223300970873787, 0.9225941422594143, 0.9098274960794563, 0.9143225806451613, 0.9180497925311203, 0.9224160374902369, 0.9260915307732772, 0.9073787409700722, 0.9182009468700684, 0.9143225806451613, 0.9176650522559265, 0.9156437712196396, 0.913335052875935, 0.9162742019884877, 0.9182829066459788, 0.9191466947590203, 0.919863373620599, 0.9140604467805519, 0.9203722854188211, 0.9174430641821946, 0.9234424498416051, 0.9232961907229852, 0.9147066425432928, 0.9242463282659108, 0.9167539267015706, 0.9197368421052632, 0.9166666666666666, 0.922267829656234, 0.9193216855087358, 0.9240208877284596, 0.9208127116436572, 0.9200724262803932, 0.9214714322984607, 0.9224182667358588, 0.9179526748971193, 0.9158709677419354, 0.9173767105602891, 0.9195046439628483, 0.9087126137841353, 0.9188001034393587, 0.9034749034749034, 0.9298883406907297, 0.9167520491803278, 0.9163636363636364, 0.9144702842377261, 0.9160166406656266, 0.9038807504497558, 0.9253187613843351, 0.9177181913774973, 0.9216201998947923, 0.9142783372063, 0.9149377593360996, 0.9215123859191656, 0.9234800838574424, 0.9209773849753055, 0.9084798345398138, 0.9057387691508699, 0.9242813141683778, 0.908075824461179, 0.9274151436031332, 0.9160384715362621, 0.9206594538897476, 0.9140848737307993, 0.9195940671350508, 0.9321685508735869, 0.9194263363754889, 0.9165378670788253, 0.9190389135544529, 0.9175443103005394, 0.9250065325320094, 0.9216867469879518, 0.9229976822044811, 0.9240342234897588, 0.9189118493329845, 0.9189399844115355, 0.9169084674228436, 0.9160621761658031, 0.9175738724727839, 0.9179859849467947, 0.9155624837620161, 0.9240672622175512, 0.9184839044652129, 0.9170316928626643, 0.9132679401135777, 0.9209639803057788, 0.923469387755102, 0.9220611082340756, 0.9224383916990921, 0.918751612071189, 0.9192530247238295, 0.9127846790890269, 0.9135416666666667, 0.9125164690382082, 0.9113956466069142, 0.9206308169596691, 0.9137886263308231, 0.9230571281523418, 0.918580375782881, 0.9159533073929961, 0.9124621594349143, 0.916731923779692, 0.9144343302990897, 0.9190946930280958, 0.9183459827270348, 0.9173319598248777, 0.9140584915341201, 0.9168831168831169, 0.9155405405405406, 0.9116653676279554, 0.9133858267716536, 0.9171157300487555, 0.9140848737307993, 0.9107883817427386, 0.9131233595800525, 0.9245480744039822, 0.9239543726235742, 0.91640625, 0.9201803235216123, 0.9161021365294424, 0.9175365344467641, 0.9157098121085595, 0.9222108495394064, 0.913846954711088, 0.9115593483320403, 0.9216961498439126, 0.9195521999479302, 0.9114745586708204, 0.910164271047228, 0.9141009055627426, 0.9139481119958901, 0.9170518746789933, 0.9252798750325436, 0.926509186351706, 0.9201261166579086, 0.9154086413326392, 0.9186016175319593, 0.9134390434104497, 0.9166237776634071, 0.9151595744680852, 0.910950038829925, 0.9160166406656266, 0.9174883238194084, 0.9093985941161156, 0.9146907216494845, 0.9165140015702695, 0.9088090932575562, 0.9173618352450469, 0.9107515657620042, 0.9139757168690261, 0.9130096078940535, 0.91640625, 0.9134615384615384, 0.9171428571428571, 0.913312693498452, 0.9163617354939885, 0.9239750908147379, 0.9054159108577352, 0.9216553878188444, 0.9139922978177151, 0.9217436974789915, 0.9162344398340249, 0.9138461538461539, 0.9196242171189979, 0.9167323351720514, 0.9194451853827688, 0.9134414225941423, 0.9091858037578288, 0.9091143816163181, 0.9220338983050848, 0.9225554106910039, 0.9214470284237726, 0.9149544863459038, 0.9212121212121213, 0.924792531120332, 0.9063467492260062, 0.9160010306622005, 0.9222770990382116, 0.9209277807063785, 0.9193216855087358, 0.9151657530670844, 0.9184824403998975, 0.918848167539267, 0.9235854045478583, 0.907436297451898, 0.9100597868468937, 0.9179867143587123, 0.9203381147540983, 0.9193967758710349, 0.9101623886851755, 0.917943391326928, 0.922772799156563, 0.9199162522899764, 0.9113157894736842, 0.9245729303547964, 0.9170530654301906, 0.9185415050426687, 0.9065420560747663, 0.9165370658372214, 0.9140564328242299, 0.9275064267352185, 0.9050980392156863, 0.9135544528597545, 0.9170146137787056, 0.9148881460529699, 0.916123990622558, 0.9195849546044098, 0.9134130146082338, 0.91701244813278, 0.9160063391442155, 0.9131125827814569, 0.9169278996865203, 0.9143158449775903, 0.9122668768058839, 0.9111747851002865, 0.9188201513965022, 0.9198945981554677, 0.9077280951150168, 0.9174719247845391, 0.9203655352480418, 0.9140094093047569, 0.9113989637305699, 0.9114420062695925, 0.9196032367528061, 0.923473331615563, 0.9232375979112272, 0.9055962343096234, 0.9122991835659732, 0.9197289549126922, 0.9168399168399168, 0.9126466753585397, 0.9139589290356122, 0.9237971391417426, 0.9206019719771665, 0.9203903441191577, 0.9267083985393845, 0.9188144329896907, 0.9178794178794178, 0.9148771021992238, 0.9143441575044745, 0.9184415584415584, 0.9137886263308231, 0.9163879598662207, 0.9200524246395806, 0.9167958656330749, 0.9088311688311689, 0.9120734908136483, 0.9113007499353504, 0.9101036269430052, 0.9132264002103603, 0.9206806282722513, 0.9109301103520757, 0.9164490861618799, 0.9196058091286307, 0.9194373401534527, 0.923728813559322, 0.9130548988705017, 0.915929203539823, 0.9154086413326392, 0.9150943396226415, 0.9203177043300026, 0.925065274151436, 0.9135191456108361, 0.9160021265284424, 0.9202168861347793, 0.9262696571281258, 0.9148882113821138, 0.9129866736347008, 0.9117183394640042, 0.9104516129032258, 0.9084470094438615, 0.9103590803409971, 0.9218709171674941, 0.9129417879417879, 0.922138593303919, 0.921854649648346, 0.9085255247473438, 0.9203218271476772, 0.9177545691906005, 0.9158609877188398, 0.9161953727506427, 0.9203197524497163, 0.9190587018360487, 0.9247478665632273, 0.9242934923515685, 0.9203516938194983, 0.916795466254508, 0.9118581259925886, 0.9105139577354553, 0.9125192406362237, 0.9126840609661586, 0.9199283704272192, 0.9155221559989635, 0.9216096158871179, 0.9191685912240185, 0.9141664492564571, 0.9220981563230329, 0.9149211274890096, 0.9157509157509157, 0.9182194616977226, 0.9193294918805658, 0.9120227038183695, 0.9214673211056574, 0.9217191097467383, 0.9158467115484205, 0.9206914082358922, 0.9139450492483152, 0.9089971642175818, 0.9113825363825364, 0.918622848200313, 0.9163826998689384, 0.9153945666235447, 0.9172485130592191, 0.9211340206185566, 0.9125739264592441, 0.921045819311416, 0.9196474857439088, 0.9124579124579124, 0.9148380355276907, 0.9255208333333333, 0.918054110301769, 0.9129074315514993, 0.9122899159663865, 0.9151358344113842, 0.9162344398340249, 0.9137122002085506, 0.9138333765896703, 0.9104091144484723, 0.9123351435221102, 0.9149372277735076, 0.9182779066769786, 0.9173856209150327, 0.9166887768638896, 0.9163201663201663, 0.917705088265836, 0.9123779361309052, 0.9154267815191856, 0.9156184486373166, 0.9070371332121527, 0.920490093847758, 0.9151483602290473, 0.9196545406961528, 0.9193091002835783, 0.9112716017539334, 0.9241990101588955, 0.9231767453932, 0.9212184873949579, 0.9204188481675393, 0.9150893796004206, 0.9154306531355711, 0.9157785287236808, 0.9247395833333333, 0.9195640892579139, 0.9148051948051948, 0.9178681771369722, 0.9124125421093547, 0.918720503408495, 0.9126521969295924, 0.9169047000779018, 0.912153407618554, 0.9132134480062549, 0.9171369933299128, 0.9180241723594325, 0.9224845995893224, 0.9082026227822062, 0.9190736403851157, 0.9246270609788013, 0.9138461538461539, 0.9263427109974425, 0.9210731961448294, 0.9147327249022165, 0.9148051948051948, 0.919659002841643, 0.9077042399172699, 0.9117798353909465, 0.9174857734092084, 0.920846394984326, 0.9187306501547987, 0.9202197227308396, 0.9230367858074615, 0.9242698371672267, 0.911076843998972, 0.9172521467603435, 0.9148264984227129, 0.9203722854188211, 0.9176439927026323, 0.9208745445080687, 0.9091387937845667, 0.9142330965535386, 0.9146404552509053, 0.9199581480512686, 0.919659002841643, 0.9183462532299742, 0.9190811798486035, 0.9154411764705882, 0.9176685833768949, 0.9145454545454546, 0.9237376366475794, 0.9248261102193687, 0.9131233595800525, 0.9141009055627426, 0.9240473738414006, 0.9118635306280692, 0.916338840807763, 0.9137396694214877, 0.9128956317028512, 0.9129405576012625, 0.9104786545924968, 0.9153846153846154, 0.9268354430379747, 0.9162155194637793, 0.911948051948052, 0.9248509976677896, 0.9238790406673618, 0.9245233742491512, 0.9113760041461518, 0.9164948453608247, 0.9207428720899817, 0.9211413748378728, 0.9182604139376473, 0.9183350895679663, 0.919626652838994, 0.9143596377749029, 0.924380704041721, 0.9173360974345686, 0.9161188535366815, 0.9032846715328468, 0.9139427987742594, 0.917078242786587, 0.9152280340118526, 0.9072560040878896, 0.9178506845776285, 0.9187922956793336, 0.9068920676202861, 0.912850039256739, 0.9193714580113344, 0.9151483602290473, 0.9157058672815783, 0.916297262059974, 0.9160857216627937, 0.9217748140548858, 0.9183135704874835, 0.9148880105401844, 0.9192417553882108, 0.9158854166666667, 0.9233605478008955, 0.9185986604842864, 0.912535686478069, 0.9198137609932747, 0.9108859444011431, 0.914783060535204, 0.9191214470284238, 0.9177623098736788, 0.9184782608695652, 0.9133022774327122, 0.9115751482340809, 0.917331206804891, 0.9110589462702139, 0.9253381893860562, 0.9235734572682675, 0.9215380618342427, 0.9152366094643786, 0.9231164823862176, 0.918724279835391, 0.9038865546218487, 0.9145833333333333]\n",
            "sd_acc: 0.005616736657918823\n",
            "sd_f1: 0.004279407147895261\n",
            "sd_mcc: 0.013084198147822303\n",
            "sd_sn: 0.004616823389591219\n",
            "sd_sp: 0.004616823389591219\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.42      0.52      1821\n",
            "           1       0.77      0.92      0.84      3849\n",
            "\n",
            "    accuracy                           0.76      5670\n",
            "   macro avg       0.74      0.67      0.68      5670\n",
            "weighted avg       0.75      0.76      0.74      5670\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.005616736657918823, 0.013084198147822303, 0.004279407147895261)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_training_labels = classifier.predict(X_train)\n",
        "predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "predicted_training_labels = np.reshape(predicted_training_labels,(len(predicted_training_labels),)).astype(int)\n",
        "error_rate(Y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4jGE6nUAMpg",
        "outputId": "0f8adc98-2cad-4894-a782-8c13d8f6374c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 23s 535ms/step\n",
            "acc: 0.81047197640118\n",
            "f1: 0.8926931106471816\n",
            "mcc: 0.08770083116577813\n",
            "sn: [0.9087837837837838, 0.9223549488054608, 0.9180187873612298, 0.9112068965517242, 0.9243697478991597, 0.927038626609442, 0.9038785834738617, 0.92, 0.9072164948453608, 0.9163793103448276, 0.910333048676345, 0.9135180520570949, 0.9044750430292599, 0.9105485232067511, 0.9224211423699915, 0.9146029035012809, 0.9271012006861064, 0.9231433506044905, 0.9225473321858864, 0.9302325581395349, 0.9219677692960135, 0.9080944350758853, 0.9281437125748503, 0.9186241610738255, 0.9144568006843456, 0.9172354948805461, 0.9130801687763713, 0.9222316145393068, 0.9108826049700086, 0.92, 0.918872758326217, 0.9242553191489362, 0.9184188393608074, 0.9042735042735043, 0.9273648648648649, 0.9203463203463204, 0.9204448246364414, 0.9087809036658141, 0.9086918349429324, 0.9121447028423773, 0.9236641221374046, 0.9028374892519346, 0.9146029035012809, 0.9282051282051282, 0.9069767441860465, 0.9300518134715026, 0.9024179620034543, 0.9111870196413322, 0.904639175257732, 0.9246401354784082, 0.9111111111111111, 0.9127118644067796, 0.8929794520547946, 0.9043993231810491, 0.9177377892030848, 0.9168831168831169, 0.9215686274509803, 0.9164513350559862, 0.9109991603694374, 0.8995670995670996, 0.9103214890016921, 0.9152838427947598, 0.9257679180887372, 0.9205020920502092, 0.9172354948805461, 0.8983911939034717, 0.9053356282271945, 0.8993288590604027, 0.9064935064935065, 0.9073593073593074, 0.8991596638655462, 0.9208510638297872, 0.9063313096270599, 0.9168787107718406, 0.9186643835616438, 0.9130434782608695, 0.9266211604095563, 0.9151670951156813, 0.92573402417962, 0.9087837837837838, 0.9066780821917808, 0.9231433506044905, 0.9207579672695951, 0.9027777777777778, 0.9100169779286927, 0.9104859335038363, 0.9131190269331017, 0.9084745762711864, 0.9152397260273972, 0.9178662150719729, 0.9194915254237288, 0.9177377892030848, 0.8918685121107266, 0.9142857142857143, 0.9167381974248927, 0.925, 0.9193548387096774, 0.9178785286569717, 0.907439446366782, 0.9182444061962134, 0.9184549356223176, 0.9289297658862876, 0.9123263888888888, 0.9205526770293609, 0.9168081494057725, 0.9168096054888508, 0.9030612244897959, 0.9234042553191489, 0.9267676767676768, 0.9085470085470085, 0.9031979256698358, 0.9187554019014693, 0.9095652173913044, 0.907861369399831, 0.9192439862542955, 0.9238665526090676, 0.900679117147708, 0.9143101970865467, 0.9056924384027187, 0.920675105485232, 0.9142857142857143, 0.910958904109589, 0.9222222222222223, 0.9157540016849199, 0.914572864321608, 0.9102455546147333, 0.918918918918919, 0.9119390347163421, 0.9202714164546225, 0.9152397260273972, 0.9218213058419243, 0.9121739130434783, 0.9128205128205128, 0.905852417302799, 0.91928632115548, 0.9153713298791019, 0.9201388888888888, 0.9142614601018676, 0.9077458659704091, 0.9039792387543253, 0.9051217464315701, 0.9160239931448158, 0.9019607843137255, 0.9139240506329114, 0.9156414762741653, 0.909404659188956, 0.9247863247863248, 0.9239412273120138, 0.9269759450171822, 0.9088586030664395, 0.9165247018739353, 0.9170230966638152, 0.9244482173174873, 0.9177489177489178, 0.9152542372881356, 0.9156626506024096, 0.9286328460877042, 0.9161572052401746, 0.9174548581255374, 0.896845694799659, 0.9070567986230637, 0.8874458874458875, 0.919931856899489, 0.9156118143459916, 0.9089376053962901, 0.9132302405498282, 0.9098712446351931, 0.9328743545611016, 0.9163071613459879, 0.9252336448598131, 0.9306759098786829, 0.9051282051282051, 0.9139414802065404, 0.9086993970714901, 0.9112833763996555, 0.916595744680851, 0.9135180520570949, 0.927038626609442, 0.9177966101694915, 0.9133790737564322, 0.9221347331583553, 0.9198966408268734, 0.9184188393608074, 0.9234782608695652, 0.9153713298791019, 0.9157446808510639, 0.9086918349429324, 0.9204448246364414, 0.9082491582491582, 0.8969335604770017, 0.9039792387543253, 0.905090595340811, 0.9137055837563451, 0.9069171648163963, 0.9181585677749361, 0.9266609145815358, 0.9068162208800691, 0.9086251067463706, 0.9011177987962167, 0.9262435677530018, 0.9068541300527241, 0.9001677852348994, 0.9063313096270599, 0.9064377682403434, 0.923469387755102, 0.914410480349345, 0.9053708439897699, 0.9224137931034483, 0.9196197061365601, 0.9165942658557776, 0.9190110826939472, 0.9183318853171155, 0.909245122985581, 0.9254606365159129, 0.9139240506329114, 0.9018612521150592, 0.8942470389170897, 0.9145516074450084, 0.914334181509754, 0.922165820642978, 0.9092465753424658, 0.9134532990574121, 0.9159592529711376, 0.9171597633136095, 0.9082251082251083, 0.9074550128534704, 0.9105621805792163, 0.9113597246127366, 0.9181585677749361, 0.9128919860627178, 0.9035532994923858, 0.9102455546147333, 0.9057724957555179, 0.9157986111111112, 0.9143835616438356, 0.9086251067463706, 0.9236842105263158, 0.9213002566295979, 0.8985382631126397, 0.9285714285714286, 0.9152397260273972, 0.9142367066895368, 0.9101123595505618, 0.9012027491408935, 0.9165950128976784, 0.9213002566295979, 0.9306260575296108, 0.918872758326217, 0.9269328802039083, 0.9130801687763713, 0.9219554030874786, 0.9224872231686542, 0.9202037351443124, 0.9045183290707587, 0.9224872231686542, 0.9095607235142119, 0.9134948096885813, 0.9289383561643836, 0.9202401372212693, 0.8995708154506438, 0.91928632115548, 0.9236706689536878, 0.9295039164490861, 0.916030534351145, 0.9316239316239316, 0.9331619537275064, 0.9104095563139932, 0.9119390347163421, 0.9189419795221843, 0.9129692832764505, 0.9297343616109683, 0.9120409906063194, 0.9141886151231946, 0.9131175468483816, 0.9278260869565217, 0.9015151515151515, 0.9127118644067796, 0.9199655765920827, 0.9149115417017691, 0.9050086355785838, 0.9206896551724137, 0.9291808873720137, 0.9064377682403434, 0.907075873827792, 0.928448275862069, 0.9182813816343723, 0.9084687767322498, 0.917094017094017, 0.9205409974640744, 0.9127118644067796, 0.918825561312608, 0.9144338807260155, 0.9141886151231946, 0.9069171648163963, 0.9190800681431005, 0.9093220338983051, 0.9137931034482759, 0.912020905923345, 0.9000868809730669, 0.92, 0.9297484822202949, 0.9094865100087032, 0.9147679324894514, 0.929553264604811, 0.9125964010282777, 0.9181034482758621, 0.8784246575342466, 0.9121739130434783, 0.9210754553339116, 0.9081632653061225, 0.9061962134251291, 0.9079965606190885, 0.9095607235142119, 0.9143835616438356, 0.9121909633418585, 0.902127659574468, 0.9120135363790186, 0.9220890410958904, 0.9165942658557776, 0.9157254561251086, 0.9335604770017035, 0.9072961373390558, 0.9060913705583756, 0.9142136248948697, 0.9218071242397915, 0.913372582001682, 0.9255499153976311, 0.9271636675235647, 0.919451585261354, 0.9148753224419605, 0.9263067694944301, 0.9026473099914603, 0.9036348267117498, 0.9123102866779089, 0.9278969957081545, 0.9128595600676819, 0.9173060528559249, 0.9204448246364414, 0.9086294416243654, 0.9105621805792163, 0.9164513350559862, 0.9015151515151515, 0.9147679324894514, 0.9190110826939472, 0.9175084175084175, 0.9160173160173161, 0.9139966273187183, 0.9112068965517242, 0.9173764906303237, 0.9158798283261803, 0.9190110826939472, 0.9063032367972743, 0.926208651399491, 0.9251290877796902, 0.9080756013745704, 0.9083191850594228, 0.9138959931798807, 0.90770533446232, 0.910981697171381, 0.9090121317157712, 0.9201716738197425, 0.9167367535744323, 0.9041916167664671, 0.9128949615713066, 0.9090909090909091, 0.9017241379310345, 0.9121909633418585, 0.8994845360824743, 0.9113814074717637, 0.9156010230179028, 0.9, 0.9124579124579124, 0.9045996592844975, 0.929481733220051, 0.8912855910267472, 0.9, 0.9115120274914089, 0.9175965665236051, 0.9204840103716508, 0.9226190476190477, 0.908311910882605, 0.9168787107718406, 0.9101694915254237, 0.9168096054888508, 0.9171648163962425, 0.9297800338409475, 0.9182978723404255, 0.9069565217391304, 0.919831223628692, 0.9136325148179509, 0.9189419795221843, 0.917169974115617, 0.9093242087254063, 0.9127052722558341, 0.9245762711864407, 0.9063032367972743, 0.9145299145299145, 0.9048442906574394, 0.9064685314685315, 0.921619293712317, 0.926208651399491, 0.9056277056277057, 0.9197952218430034, 0.9269131556319863, 0.9080756013745704, 0.9279661016949152, 0.9250210614995787, 0.9097938144329897, 0.9155290102389079, 0.9170194750211685, 0.9080068143100511, 0.9031705227077977, 0.911587982832618, 0.9162393162393162, 0.9104859335038363, 0.9140425531914894, 0.9274261603375528, 0.924831081081081, 0.9072790294627383, 0.9222222222222223, 0.9086115992970123, 0.9173693086003373, 0.919931856899489, 0.9122957867583835, 0.9018245004344049, 0.928082191780822, 0.9100169779286927, 0.9036458333333334, 0.9077954735959766, 0.9273648648648649, 0.9350086655112652, 0.9111870196413322, 0.9292493528904228, 0.9139966273187183, 0.9243336199484092, 0.907391673746814, 0.9063573883161512, 0.899067005937235, 0.9172297297297297, 0.9190317195325542, 0.9029787234042553, 0.9087809036658141, 0.9273840769903762, 0.9048821548821548, 0.9177377892030848, 0.903448275862069, 0.9166666666666666, 0.9194107452339688, 0.9117147707979627, 0.9312977099236641, 0.9404761904761905, 0.9156729131175468, 0.9202401372212693, 0.914983164983165, 0.9168808911739503, 0.8966101694915254, 0.9142614601018676, 0.9256756756756757, 0.9165950128976784, 0.9081632653061225, 0.9000853970964987, 0.9173913043478261, 0.9267241379310345, 0.9215686274509803, 0.9175257731958762, 0.9195596951735817, 0.9030042918454936, 0.9140350877192982, 0.9232096635030198, 0.9187554019014693, 0.9153259949195597, 0.9168081494057725, 0.9134532990574121, 0.9169520547945206, 0.913601368691189, 0.913718723037101, 0.90595340811044, 0.9028716216216216, 0.9155290102389079, 0.9181184668989547, 0.9076133447390933, 0.9215517241379311, 0.9081718618365627, 0.910941475826972, 0.9269709543568465, 0.9016949152542373, 0.9230103806228374, 0.9266609145815358, 0.9079391891891891, 0.9180187873612298, 0.9205409974640744, 0.9210526315789473, 0.9091688089117395, 0.9068585944115156, 0.9005947323704333, 0.91921768707483, 0.9073756432246999, 0.8970464135021097, 0.9086206896551724, 0.9105125977410947, 0.9145299145299145, 0.9146551724137931, 0.9086251067463706, 0.9256342957130359, 0.9192708333333334, 0.90625, 0.9133047210300429, 0.9226804123711341, 0.9262792714657415, 0.9110922946655376, 0.92, 0.9045183290707587, 0.9097872340425532, 0.9048428207306712, 0.9281437125748503, 0.9301121656600517, 0.9094017094017094, 0.9169520547945206, 0.9199303742384682, 0.896551724137931, 0.9217687074829932, 0.9016115351993215, 0.9146757679180887, 0.91931330472103, 0.9289383561643836, 0.9028374892519346, 0.922165820642978, 0.9253218884120171, 0.9131886477462438, 0.9160239931448158, 0.9117395029991431, 0.905982905982906, 0.9123404255319149, 0.9052901023890785, 0.9149115417017691, 0.9065981148243359, 0.9208942390369733, 0.9043103448275862, 0.9167381974248927, 0.9035836177474402, 0.9168831168831169, 0.8991525423728813, 0.9112833763996555, 0.9146238377007607, 0.9360967184801382, 0.9087809036658141, 0.9187817258883249, 0.9165942658557776, 0.9121447028423773, 0.9150382327952421, 0.9130434782608695, 0.9096385542168675, 0.9111675126903553, 0.917169974115617, 0.9057724957555179, 0.9204064352243861, 0.9182978723404255, 0.9039932030586236, 0.9073593073593074, 0.9060631938514091, 0.9047210300429185, 0.9181585677749361, 0.9053356282271945, 0.92573402417962, 0.9137055837563451, 0.9112068965517242, 0.9168126094570929, 0.8950988822012038, 0.9153122326775022, 0.9132653061224489, 0.9064080944350759, 0.919451585261354, 0.9188034188034188, 0.9256128486897718, 0.9104095563139932, 0.909704641350211, 0.9086336965632859, 0.9214162348877375, 0.9051282051282051, 0.9073756432246999, 0.9175438596491228, 0.9111111111111111, 0.9174548581255374, 0.9112833763996555, 0.9170194750211685, 0.905982905982906, 0.9054170249355116, 0.9116397621070518, 0.9175965665236051, 0.9165247018739353, 0.9108391608391608, 0.90625, 0.9154568744662681, 0.9153713298791019, 0.911944202266783, 0.9172597864768683, 0.9083837510803803, 0.9258943781942078, 0.8965224766751484, 0.9183501683501684, 0.922945205479452, 0.9124270225187656, 0.9122203098106713, 0.9110535405872193, 0.9087719298245615, 0.9176776429809359, 0.9057724957555179, 0.9179620034542314, 0.9170194750211685, 0.916095890410959, 0.9129310344827586, 0.9082332761578045, 0.9209383145091226, 0.9093242087254063, 0.9098005203816132, 0.9107901444350043, 0.9107901444350043, 0.9165232358003442, 0.919931856899489, 0.9035621198957429, 0.9207161125319693, 0.9106382978723404, 0.9098639455782312, 0.9148753224419605, 0.9113384484228474, 0.923407917383821, 0.9187129551227773, 0.9107452339688041, 0.9072164948453608, 0.898876404494382, 0.9110169491525424, 0.9331046312178388, 0.9217391304347826, 0.9019097222222222, 0.9044309296264118, 0.8990748528174937, 0.935, 0.9178082191780822, 0.9151103565365025, 0.9206212251941329, 0.9116883116883117, 0.928388746803069, 0.922945205479452, 0.9177966101694915, 0.9066780821917808, 0.922077922077922, 0.9115120274914089, 0.9141156462585034, 0.903143585386576, 0.9205807002561913, 0.9106992417860151, 0.9165247018739353, 0.9127857747671465, 0.9134125636672326, 0.9040139616055847, 0.9052013422818792, 0.9200695047784535, 0.9067005937234945, 0.9266211604095563, 0.9076271186440678, 0.9266609145815358, 0.9123102866779089, 0.9200343938091143, 0.9153713298791019, 0.9141630901287554, 0.9232067510548523, 0.9062233589087809, 0.9114583333333334, 0.8995708154506438, 0.8998302207130731, 0.897196261682243, 0.913338997451147, 0.9108658743633277, 0.9273034657650042, 0.9117395029991431, 0.9107901444350043, 0.9129332206255283, 0.9227504244482173, 0.9214659685863874, 0.9276485788113695, 0.9202401372212693, 0.9091688089117395, 0.9150043365134432, 0.9327586206896552, 0.9093220338983051, 0.9006050129645635, 0.9107744107744108, 0.9308556611927399, 0.9083904109589042, 0.918212478920742, 0.9142857142857143, 0.909704641350211, 0.9184367034834324, 0.9278887923544744, 0.9093242087254063, 0.9105760963026656, 0.9152542372881356, 0.9254119687771032, 0.9002557544757033, 0.9107296137339056, 0.9155290102389079, 0.9168808911739503, 0.9138225255972696, 0.9168096054888508, 0.9074074074074074, 0.9141886151231946, 0.9037162162162162, 0.8982456140350877, 0.9159592529711376, 0.905254091300603, 0.9050522648083623, 0.916095890410959, 0.9121909633418585, 0.9218071242397915, 0.9246401354784082, 0.9150943396226415, 0.9158878504672897, 0.9032815198618307, 0.9258010118043845, 0.9223468507333908, 0.9111675126903553, 0.9142857142857143, 0.8962585034013606, 0.9213675213675213, 0.9175170068027211, 0.9301310043668122, 0.9125214408233276, 0.9177057356608479, 0.9137353433835846, 0.9090909090909091, 0.9104095563139932, 0.9206896551724137, 0.9253472222222222, 0.9270833333333334, 0.9172354948805461, 0.9240724762726489, 0.9046808510638298, 0.9224872231686542, 0.9124149659863946, 0.9183848797250859, 0.9224211423699915, 0.9151103565365025, 0.9064377682403434, 0.9099485420240138, 0.9250425894378195, 0.9207836456558773, 0.9147627416520211, 0.9195596951735817, 0.9083969465648855, 0.910267471958585, 0.8967629046369204, 0.9245762711864407, 0.9176470588235294, 0.9057412167952014, 0.9326513213981245, 0.9100169779286927, 0.9139966273187183, 0.9078498293515358, 0.910333048676345, 0.9125541125541126, 0.9126455906821963, 0.9216354344122658, 0.9157351676698194, 0.9165247018739353, 0.9255774165953806, 0.9069767441860465, 0.9, 0.8963466440101954, 0.9063313096270599, 0.9061433447098977, 0.9098005203816132, 0.9298545765611634, 0.9178200692041523, 0.9231426131511529, 0.919931856899489, 0.9154811715481171, 0.9232081911262798, 0.9148020654044751, 0.9051348999129678, 0.9174630755864466, 0.9153122326775022, 0.9050847457627119, 0.91931330472103, 0.9185059422750425, 0.9174468085106383, 0.9124149659863946, 0.9157446808510639, 0.9230769230769231, 0.9167374681393373, 0.9127753303964757, 0.909404659188956, 0.9248704663212435, 0.9033898305084745, 0.911130284728214, 0.9210526315789473, 0.9337349397590361, 0.9186147186147187, 0.9059753954305799, 0.9034188034188034, 0.929471032745592, 0.9296264118158123, 0.9168808911739503, 0.9138959931798807, 0.9114139693356048, 0.9198275862068965, 0.9056122448979592, 0.8946917808219178, 0.9146959459459459, 0.9105485232067511, 0.9195501730103807, 0.922879177377892, 0.8985507246376812, 0.9084568439407149, 0.9199655765920827, 0.9214162348877375, 0.9039115646258503, 0.9097162510748066, 0.8964927288280582, 0.9298545765611634, 0.9114359415305245, 0.9154568744662681, 0.9127857747671465, 0.9208510638297872, 0.9163793103448276, 0.910958904109589, 0.907861369399831, 0.9195979899497487, 0.9288135593220339, 0.9246861924686193, 0.9214840379637619, 0.9168831168831169, 0.9180187873612298, 0.90995670995671, 0.9157351676698194, 0.9000839630562553, 0.9056768558951965, 0.9196652719665271, 0.8974576271186441, 0.9098005203816132, 0.9203084832904884, 0.9107901444350043, 0.9117896522476675, 0.9234737747205503, 0.9171029668411868, 0.9166666666666666, 0.9150943396226415, 0.920844327176781, 0.9244791666666666, 0.9031705227077977, 0.9164513350559862, 0.9308283518360376, 0.9018612521150592, 0.90360435875943, 0.9094827586206896, 0.9181184668989547, 0.9157446808510639, 0.910941475826972, 0.91921768707483, 0.9297800338409475, 0.8981001727115717, 0.9035532994923858, 0.9253075571177505, 0.9168787107718406, 0.918212478920742, 0.9175257731958762, 0.911587982832618, 0.9158249158249159, 0.9153976311336718, 0.9035836177474402, 0.9123711340206185, 0.9129692832764505, 0.8981164383561644, 0.9233419465977606, 0.9044750430292599, 0.9126712328767124, 0.9119390347163421, 0.9260869565217391, 0.9047217537942664, 0.9189873417721519, 0.9117395029991431, 0.9031171019376579, 0.9117903930131004, 0.9074550128534704, 0.9071550255536627, 0.9144568006843456, 0.9173060528559249, 0.9311809685641461, 0.9171597633136095, 0.9206896551724137, 0.9118150684931506, 0.9141370338248048, 0.9224872231686542, 0.9014321819713563, 0.9038297872340425, 0.927920463960232, 0.9093988145639289, 0.9234737747205503, 0.904156064461408, 0.9190317195325542, 0.9072790294627383, 0.8977176669484361, 0.8943364327979713, 0.9183147033533964, 0.9263431542461005, 0.9193825042881647, 0.9195501730103807, 0.9203767123287672, 0.9224137931034483, 0.8955613577023499, 0.9265975820379966, 0.9238013698630136, 0.9261862917398945, 0.9304495335029687, 0.9226804123711341, 0.9138225255972696, 0.9087066779374472, 0.9110350727117195, 0.9172413793103448, 0.931063829787234, 0.92573402417962, 0.8952299829642248, 0.923407917383821, 0.8970464135021097, 0.9196277495769881, 0.9127857747671465, 0.9187554019014693, 0.9170854271356784, 0.9226804123711341, 0.9130067567567568, 0.9102564102564102, 0.9197952218430034, 0.8924268502581756, 0.9177377892030848, 0.9067357512953368, 0.918825561312608, 0.9286941580756014, 0.9195501730103807, 0.902946273830156, 0.9324324324324325, 0.9104859335038363, 0.9174548581255374, 0.922943722943723, 0.9258010118043845, 0.9177489177489178, 0.9023136246786633, 0.9114893617021277, 0.9055319148936171, 0.9041916167664671, 0.9243061396131202, 0.9001706484641638, 0.9238754325259516, 0.9208510638297872, 0.9211409395973155, 0.8985255854293148, 0.9282051282051282, 0.9176470588235294, 0.8990426457789382, 0.9253604749787956, 0.9126637554585153, 0.9026845637583892, 0.9215686274509803, 0.9155900086132644, 0.9049235993208828, 0.9067579127459366, 0.9045571797076526, 0.9069965870307167, 0.9219427580225499, 0.9138673557278209, 0.9099326599326599, 0.9101796407185628, 0.903364969801553, 0.9150779896013865, 0.9204840103716508, 0.9090128755364807, 0.9009314140558848, 0.9159369527145359, 0.9105760963026656, 0.907679033649698, 0.9142367066895368, 0.9179487179487179, 0.9058219178082192, 0.9288738357324301, 0.9108996539792388, 0.903471634208298, 0.9056277056277057, 0.9101027397260274, 0.9210977701543739, 0.910958904109589, 0.9207836456558773, 0.9128949615713066, 0.9230769230769231, 0.9076271186440678, 0.9175257731958762, 0.9091688089117395, 0.9208510638297872, 0.9286321155480034, 0.9083904109589042, 0.9260533104041273, 0.9120689655172414, 0.9120689655172414]\n",
            "sp: [0.9087837837837838, 0.9223549488054608, 0.9180187873612298, 0.9112068965517242, 0.9243697478991597, 0.927038626609442, 0.9038785834738617, 0.92, 0.9072164948453608, 0.9163793103448276, 0.910333048676345, 0.9135180520570949, 0.9044750430292599, 0.9105485232067511, 0.9224211423699915, 0.9146029035012809, 0.9271012006861064, 0.9231433506044905, 0.9225473321858864, 0.9302325581395349, 0.9219677692960135, 0.9080944350758853, 0.9281437125748503, 0.9186241610738255, 0.9144568006843456, 0.9172354948805461, 0.9130801687763713, 0.9222316145393068, 0.9108826049700086, 0.92, 0.918872758326217, 0.9242553191489362, 0.9184188393608074, 0.9042735042735043, 0.9273648648648649, 0.9203463203463204, 0.9204448246364414, 0.9087809036658141, 0.9086918349429324, 0.9121447028423773, 0.9236641221374046, 0.9028374892519346, 0.9146029035012809, 0.9282051282051282, 0.9069767441860465, 0.9300518134715026, 0.9024179620034543, 0.9111870196413322, 0.904639175257732, 0.9246401354784082, 0.9111111111111111, 0.9127118644067796, 0.8929794520547946, 0.9043993231810491, 0.9177377892030848, 0.9168831168831169, 0.9215686274509803, 0.9164513350559862, 0.9109991603694374, 0.8995670995670996, 0.9103214890016921, 0.9152838427947598, 0.9257679180887372, 0.9205020920502092, 0.9172354948805461, 0.8983911939034717, 0.9053356282271945, 0.8993288590604027, 0.9064935064935065, 0.9073593073593074, 0.8991596638655462, 0.9208510638297872, 0.9063313096270599, 0.9168787107718406, 0.9186643835616438, 0.9130434782608695, 0.9266211604095563, 0.9151670951156813, 0.92573402417962, 0.9087837837837838, 0.9066780821917808, 0.9231433506044905, 0.9207579672695951, 0.9027777777777778, 0.9100169779286927, 0.9104859335038363, 0.9131190269331017, 0.9084745762711864, 0.9152397260273972, 0.9178662150719729, 0.9194915254237288, 0.9177377892030848, 0.8918685121107266, 0.9142857142857143, 0.9167381974248927, 0.925, 0.9193548387096774, 0.9178785286569717, 0.907439446366782, 0.9182444061962134, 0.9184549356223176, 0.9289297658862876, 0.9123263888888888, 0.9205526770293609, 0.9168081494057725, 0.9168096054888508, 0.9030612244897959, 0.9234042553191489, 0.9267676767676768, 0.9085470085470085, 0.9031979256698358, 0.9187554019014693, 0.9095652173913044, 0.907861369399831, 0.9192439862542955, 0.9238665526090676, 0.900679117147708, 0.9143101970865467, 0.9056924384027187, 0.920675105485232, 0.9142857142857143, 0.910958904109589, 0.9222222222222223, 0.9157540016849199, 0.914572864321608, 0.9102455546147333, 0.918918918918919, 0.9119390347163421, 0.9202714164546225, 0.9152397260273972, 0.9218213058419243, 0.9121739130434783, 0.9128205128205128, 0.905852417302799, 0.91928632115548, 0.9153713298791019, 0.9201388888888888, 0.9142614601018676, 0.9077458659704091, 0.9039792387543253, 0.9051217464315701, 0.9160239931448158, 0.9019607843137255, 0.9139240506329114, 0.9156414762741653, 0.909404659188956, 0.9247863247863248, 0.9239412273120138, 0.9269759450171822, 0.9088586030664395, 0.9165247018739353, 0.9170230966638152, 0.9244482173174873, 0.9177489177489178, 0.9152542372881356, 0.9156626506024096, 0.9286328460877042, 0.9161572052401746, 0.9174548581255374, 0.896845694799659, 0.9070567986230637, 0.8874458874458875, 0.919931856899489, 0.9156118143459916, 0.9089376053962901, 0.9132302405498282, 0.9098712446351931, 0.9328743545611016, 0.9163071613459879, 0.9252336448598131, 0.9306759098786829, 0.9051282051282051, 0.9139414802065404, 0.9086993970714901, 0.9112833763996555, 0.916595744680851, 0.9135180520570949, 0.927038626609442, 0.9177966101694915, 0.9133790737564322, 0.9221347331583553, 0.9198966408268734, 0.9184188393608074, 0.9234782608695652, 0.9153713298791019, 0.9157446808510639, 0.9086918349429324, 0.9204448246364414, 0.9082491582491582, 0.8969335604770017, 0.9039792387543253, 0.905090595340811, 0.9137055837563451, 0.9069171648163963, 0.9181585677749361, 0.9266609145815358, 0.9068162208800691, 0.9086251067463706, 0.9011177987962167, 0.9262435677530018, 0.9068541300527241, 0.9001677852348994, 0.9063313096270599, 0.9064377682403434, 0.923469387755102, 0.914410480349345, 0.9053708439897699, 0.9224137931034483, 0.9196197061365601, 0.9165942658557776, 0.9190110826939472, 0.9183318853171155, 0.909245122985581, 0.9254606365159129, 0.9139240506329114, 0.9018612521150592, 0.8942470389170897, 0.9145516074450084, 0.914334181509754, 0.922165820642978, 0.9092465753424658, 0.9134532990574121, 0.9159592529711376, 0.9171597633136095, 0.9082251082251083, 0.9074550128534704, 0.9105621805792163, 0.9113597246127366, 0.9181585677749361, 0.9128919860627178, 0.9035532994923858, 0.9102455546147333, 0.9057724957555179, 0.9157986111111112, 0.9143835616438356, 0.9086251067463706, 0.9236842105263158, 0.9213002566295979, 0.8985382631126397, 0.9285714285714286, 0.9152397260273972, 0.9142367066895368, 0.9101123595505618, 0.9012027491408935, 0.9165950128976784, 0.9213002566295979, 0.9306260575296108, 0.918872758326217, 0.9269328802039083, 0.9130801687763713, 0.9219554030874786, 0.9224872231686542, 0.9202037351443124, 0.9045183290707587, 0.9224872231686542, 0.9095607235142119, 0.9134948096885813, 0.9289383561643836, 0.9202401372212693, 0.8995708154506438, 0.91928632115548, 0.9236706689536878, 0.9295039164490861, 0.916030534351145, 0.9316239316239316, 0.9331619537275064, 0.9104095563139932, 0.9119390347163421, 0.9189419795221843, 0.9129692832764505, 0.9297343616109683, 0.9120409906063194, 0.9141886151231946, 0.9131175468483816, 0.9278260869565217, 0.9015151515151515, 0.9127118644067796, 0.9199655765920827, 0.9149115417017691, 0.9050086355785838, 0.9206896551724137, 0.9291808873720137, 0.9064377682403434, 0.907075873827792, 0.928448275862069, 0.9182813816343723, 0.9084687767322498, 0.917094017094017, 0.9205409974640744, 0.9127118644067796, 0.918825561312608, 0.9144338807260155, 0.9141886151231946, 0.9069171648163963, 0.9190800681431005, 0.9093220338983051, 0.9137931034482759, 0.912020905923345, 0.9000868809730669, 0.92, 0.9297484822202949, 0.9094865100087032, 0.9147679324894514, 0.929553264604811, 0.9125964010282777, 0.9181034482758621, 0.8784246575342466, 0.9121739130434783, 0.9210754553339116, 0.9081632653061225, 0.9061962134251291, 0.9079965606190885, 0.9095607235142119, 0.9143835616438356, 0.9121909633418585, 0.902127659574468, 0.9120135363790186, 0.9220890410958904, 0.9165942658557776, 0.9157254561251086, 0.9335604770017035, 0.9072961373390558, 0.9060913705583756, 0.9142136248948697, 0.9218071242397915, 0.913372582001682, 0.9255499153976311, 0.9271636675235647, 0.919451585261354, 0.9148753224419605, 0.9263067694944301, 0.9026473099914603, 0.9036348267117498, 0.9123102866779089, 0.9278969957081545, 0.9128595600676819, 0.9173060528559249, 0.9204448246364414, 0.9086294416243654, 0.9105621805792163, 0.9164513350559862, 0.9015151515151515, 0.9147679324894514, 0.9190110826939472, 0.9175084175084175, 0.9160173160173161, 0.9139966273187183, 0.9112068965517242, 0.9173764906303237, 0.9158798283261803, 0.9190110826939472, 0.9063032367972743, 0.926208651399491, 0.9251290877796902, 0.9080756013745704, 0.9083191850594228, 0.9138959931798807, 0.90770533446232, 0.910981697171381, 0.9090121317157712, 0.9201716738197425, 0.9167367535744323, 0.9041916167664671, 0.9128949615713066, 0.9090909090909091, 0.9017241379310345, 0.9121909633418585, 0.8994845360824743, 0.9113814074717637, 0.9156010230179028, 0.9, 0.9124579124579124, 0.9045996592844975, 0.929481733220051, 0.8912855910267472, 0.9, 0.9115120274914089, 0.9175965665236051, 0.9204840103716508, 0.9226190476190477, 0.908311910882605, 0.9168787107718406, 0.9101694915254237, 0.9168096054888508, 0.9171648163962425, 0.9297800338409475, 0.9182978723404255, 0.9069565217391304, 0.919831223628692, 0.9136325148179509, 0.9189419795221843, 0.917169974115617, 0.9093242087254063, 0.9127052722558341, 0.9245762711864407, 0.9063032367972743, 0.9145299145299145, 0.9048442906574394, 0.9064685314685315, 0.921619293712317, 0.926208651399491, 0.9056277056277057, 0.9197952218430034, 0.9269131556319863, 0.9080756013745704, 0.9279661016949152, 0.9250210614995787, 0.9097938144329897, 0.9155290102389079, 0.9170194750211685, 0.9080068143100511, 0.9031705227077977, 0.911587982832618, 0.9162393162393162, 0.9104859335038363, 0.9140425531914894, 0.9274261603375528, 0.924831081081081, 0.9072790294627383, 0.9222222222222223, 0.9086115992970123, 0.9173693086003373, 0.919931856899489, 0.9122957867583835, 0.9018245004344049, 0.928082191780822, 0.9100169779286927, 0.9036458333333334, 0.9077954735959766, 0.9273648648648649, 0.9350086655112652, 0.9111870196413322, 0.9292493528904228, 0.9139966273187183, 0.9243336199484092, 0.907391673746814, 0.9063573883161512, 0.899067005937235, 0.9172297297297297, 0.9190317195325542, 0.9029787234042553, 0.9087809036658141, 0.9273840769903762, 0.9048821548821548, 0.9177377892030848, 0.903448275862069, 0.9166666666666666, 0.9194107452339688, 0.9117147707979627, 0.9312977099236641, 0.9404761904761905, 0.9156729131175468, 0.9202401372212693, 0.914983164983165, 0.9168808911739503, 0.8966101694915254, 0.9142614601018676, 0.9256756756756757, 0.9165950128976784, 0.9081632653061225, 0.9000853970964987, 0.9173913043478261, 0.9267241379310345, 0.9215686274509803, 0.9175257731958762, 0.9195596951735817, 0.9030042918454936, 0.9140350877192982, 0.9232096635030198, 0.9187554019014693, 0.9153259949195597, 0.9168081494057725, 0.9134532990574121, 0.9169520547945206, 0.913601368691189, 0.913718723037101, 0.90595340811044, 0.9028716216216216, 0.9155290102389079, 0.9181184668989547, 0.9076133447390933, 0.9215517241379311, 0.9081718618365627, 0.910941475826972, 0.9269709543568465, 0.9016949152542373, 0.9230103806228374, 0.9266609145815358, 0.9079391891891891, 0.9180187873612298, 0.9205409974640744, 0.9210526315789473, 0.9091688089117395, 0.9068585944115156, 0.9005947323704333, 0.91921768707483, 0.9073756432246999, 0.8970464135021097, 0.9086206896551724, 0.9105125977410947, 0.9145299145299145, 0.9146551724137931, 0.9086251067463706, 0.9256342957130359, 0.9192708333333334, 0.90625, 0.9133047210300429, 0.9226804123711341, 0.9262792714657415, 0.9110922946655376, 0.92, 0.9045183290707587, 0.9097872340425532, 0.9048428207306712, 0.9281437125748503, 0.9301121656600517, 0.9094017094017094, 0.9169520547945206, 0.9199303742384682, 0.896551724137931, 0.9217687074829932, 0.9016115351993215, 0.9146757679180887, 0.91931330472103, 0.9289383561643836, 0.9028374892519346, 0.922165820642978, 0.9253218884120171, 0.9131886477462438, 0.9160239931448158, 0.9117395029991431, 0.905982905982906, 0.9123404255319149, 0.9052901023890785, 0.9149115417017691, 0.9065981148243359, 0.9208942390369733, 0.9043103448275862, 0.9167381974248927, 0.9035836177474402, 0.9168831168831169, 0.8991525423728813, 0.9112833763996555, 0.9146238377007607, 0.9360967184801382, 0.9087809036658141, 0.9187817258883249, 0.9165942658557776, 0.9121447028423773, 0.9150382327952421, 0.9130434782608695, 0.9096385542168675, 0.9111675126903553, 0.917169974115617, 0.9057724957555179, 0.9204064352243861, 0.9182978723404255, 0.9039932030586236, 0.9073593073593074, 0.9060631938514091, 0.9047210300429185, 0.9181585677749361, 0.9053356282271945, 0.92573402417962, 0.9137055837563451, 0.9112068965517242, 0.9168126094570929, 0.8950988822012038, 0.9153122326775022, 0.9132653061224489, 0.9064080944350759, 0.919451585261354, 0.9188034188034188, 0.9256128486897718, 0.9104095563139932, 0.909704641350211, 0.9086336965632859, 0.9214162348877375, 0.9051282051282051, 0.9073756432246999, 0.9175438596491228, 0.9111111111111111, 0.9174548581255374, 0.9112833763996555, 0.9170194750211685, 0.905982905982906, 0.9054170249355116, 0.9116397621070518, 0.9175965665236051, 0.9165247018739353, 0.9108391608391608, 0.90625, 0.9154568744662681, 0.9153713298791019, 0.911944202266783, 0.9172597864768683, 0.9083837510803803, 0.9258943781942078, 0.8965224766751484, 0.9183501683501684, 0.922945205479452, 0.9124270225187656, 0.9122203098106713, 0.9110535405872193, 0.9087719298245615, 0.9176776429809359, 0.9057724957555179, 0.9179620034542314, 0.9170194750211685, 0.916095890410959, 0.9129310344827586, 0.9082332761578045, 0.9209383145091226, 0.9093242087254063, 0.9098005203816132, 0.9107901444350043, 0.9107901444350043, 0.9165232358003442, 0.919931856899489, 0.9035621198957429, 0.9207161125319693, 0.9106382978723404, 0.9098639455782312, 0.9148753224419605, 0.9113384484228474, 0.923407917383821, 0.9187129551227773, 0.9107452339688041, 0.9072164948453608, 0.898876404494382, 0.9110169491525424, 0.9331046312178388, 0.9217391304347826, 0.9019097222222222, 0.9044309296264118, 0.8990748528174937, 0.935, 0.9178082191780822, 0.9151103565365025, 0.9206212251941329, 0.9116883116883117, 0.928388746803069, 0.922945205479452, 0.9177966101694915, 0.9066780821917808, 0.922077922077922, 0.9115120274914089, 0.9141156462585034, 0.903143585386576, 0.9205807002561913, 0.9106992417860151, 0.9165247018739353, 0.9127857747671465, 0.9134125636672326, 0.9040139616055847, 0.9052013422818792, 0.9200695047784535, 0.9067005937234945, 0.9266211604095563, 0.9076271186440678, 0.9266609145815358, 0.9123102866779089, 0.9200343938091143, 0.9153713298791019, 0.9141630901287554, 0.9232067510548523, 0.9062233589087809, 0.9114583333333334, 0.8995708154506438, 0.8998302207130731, 0.897196261682243, 0.913338997451147, 0.9108658743633277, 0.9273034657650042, 0.9117395029991431, 0.9107901444350043, 0.9129332206255283, 0.9227504244482173, 0.9214659685863874, 0.9276485788113695, 0.9202401372212693, 0.9091688089117395, 0.9150043365134432, 0.9327586206896552, 0.9093220338983051, 0.9006050129645635, 0.9107744107744108, 0.9308556611927399, 0.9083904109589042, 0.918212478920742, 0.9142857142857143, 0.909704641350211, 0.9184367034834324, 0.9278887923544744, 0.9093242087254063, 0.9105760963026656, 0.9152542372881356, 0.9254119687771032, 0.9002557544757033, 0.9107296137339056, 0.9155290102389079, 0.9168808911739503, 0.9138225255972696, 0.9168096054888508, 0.9074074074074074, 0.9141886151231946, 0.9037162162162162, 0.8982456140350877, 0.9159592529711376, 0.905254091300603, 0.9050522648083623, 0.916095890410959, 0.9121909633418585, 0.9218071242397915, 0.9246401354784082, 0.9150943396226415, 0.9158878504672897, 0.9032815198618307, 0.9258010118043845, 0.9223468507333908, 0.9111675126903553, 0.9142857142857143, 0.8962585034013606, 0.9213675213675213, 0.9175170068027211, 0.9301310043668122, 0.9125214408233276, 0.9177057356608479, 0.9137353433835846, 0.9090909090909091, 0.9104095563139932, 0.9206896551724137, 0.9253472222222222, 0.9270833333333334, 0.9172354948805461, 0.9240724762726489, 0.9046808510638298, 0.9224872231686542, 0.9124149659863946, 0.9183848797250859, 0.9224211423699915, 0.9151103565365025, 0.9064377682403434, 0.9099485420240138, 0.9250425894378195, 0.9207836456558773, 0.9147627416520211, 0.9195596951735817, 0.9083969465648855, 0.910267471958585, 0.8967629046369204, 0.9245762711864407, 0.9176470588235294, 0.9057412167952014, 0.9326513213981245, 0.9100169779286927, 0.9139966273187183, 0.9078498293515358, 0.910333048676345, 0.9125541125541126, 0.9126455906821963, 0.9216354344122658, 0.9157351676698194, 0.9165247018739353, 0.9255774165953806, 0.9069767441860465, 0.9, 0.8963466440101954, 0.9063313096270599, 0.9061433447098977, 0.9098005203816132, 0.9298545765611634, 0.9178200692041523, 0.9231426131511529, 0.919931856899489, 0.9154811715481171, 0.9232081911262798, 0.9148020654044751, 0.9051348999129678, 0.9174630755864466, 0.9153122326775022, 0.9050847457627119, 0.91931330472103, 0.9185059422750425, 0.9174468085106383, 0.9124149659863946, 0.9157446808510639, 0.9230769230769231, 0.9167374681393373, 0.9127753303964757, 0.909404659188956, 0.9248704663212435, 0.9033898305084745, 0.911130284728214, 0.9210526315789473, 0.9337349397590361, 0.9186147186147187, 0.9059753954305799, 0.9034188034188034, 0.929471032745592, 0.9296264118158123, 0.9168808911739503, 0.9138959931798807, 0.9114139693356048, 0.9198275862068965, 0.9056122448979592, 0.8946917808219178, 0.9146959459459459, 0.9105485232067511, 0.9195501730103807, 0.922879177377892, 0.8985507246376812, 0.9084568439407149, 0.9199655765920827, 0.9214162348877375, 0.9039115646258503, 0.9097162510748066, 0.8964927288280582, 0.9298545765611634, 0.9114359415305245, 0.9154568744662681, 0.9127857747671465, 0.9208510638297872, 0.9163793103448276, 0.910958904109589, 0.907861369399831, 0.9195979899497487, 0.9288135593220339, 0.9246861924686193, 0.9214840379637619, 0.9168831168831169, 0.9180187873612298, 0.90995670995671, 0.9157351676698194, 0.9000839630562553, 0.9056768558951965, 0.9196652719665271, 0.8974576271186441, 0.9098005203816132, 0.9203084832904884, 0.9107901444350043, 0.9117896522476675, 0.9234737747205503, 0.9171029668411868, 0.9166666666666666, 0.9150943396226415, 0.920844327176781, 0.9244791666666666, 0.9031705227077977, 0.9164513350559862, 0.9308283518360376, 0.9018612521150592, 0.90360435875943, 0.9094827586206896, 0.9181184668989547, 0.9157446808510639, 0.910941475826972, 0.91921768707483, 0.9297800338409475, 0.8981001727115717, 0.9035532994923858, 0.9253075571177505, 0.9168787107718406, 0.918212478920742, 0.9175257731958762, 0.911587982832618, 0.9158249158249159, 0.9153976311336718, 0.9035836177474402, 0.9123711340206185, 0.9129692832764505, 0.8981164383561644, 0.9233419465977606, 0.9044750430292599, 0.9126712328767124, 0.9119390347163421, 0.9260869565217391, 0.9047217537942664, 0.9189873417721519, 0.9117395029991431, 0.9031171019376579, 0.9117903930131004, 0.9074550128534704, 0.9071550255536627, 0.9144568006843456, 0.9173060528559249, 0.9311809685641461, 0.9171597633136095, 0.9206896551724137, 0.9118150684931506, 0.9141370338248048, 0.9224872231686542, 0.9014321819713563, 0.9038297872340425, 0.927920463960232, 0.9093988145639289, 0.9234737747205503, 0.904156064461408, 0.9190317195325542, 0.9072790294627383, 0.8977176669484361, 0.8943364327979713, 0.9183147033533964, 0.9263431542461005, 0.9193825042881647, 0.9195501730103807, 0.9203767123287672, 0.9224137931034483, 0.8955613577023499, 0.9265975820379966, 0.9238013698630136, 0.9261862917398945, 0.9304495335029687, 0.9226804123711341, 0.9138225255972696, 0.9087066779374472, 0.9110350727117195, 0.9172413793103448, 0.931063829787234, 0.92573402417962, 0.8952299829642248, 0.923407917383821, 0.8970464135021097, 0.9196277495769881, 0.9127857747671465, 0.9187554019014693, 0.9170854271356784, 0.9226804123711341, 0.9130067567567568, 0.9102564102564102, 0.9197952218430034, 0.8924268502581756, 0.9177377892030848, 0.9067357512953368, 0.918825561312608, 0.9286941580756014, 0.9195501730103807, 0.902946273830156, 0.9324324324324325, 0.9104859335038363, 0.9174548581255374, 0.922943722943723, 0.9258010118043845, 0.9177489177489178, 0.9023136246786633, 0.9114893617021277, 0.9055319148936171, 0.9041916167664671, 0.9243061396131202, 0.9001706484641638, 0.9238754325259516, 0.9208510638297872, 0.9211409395973155, 0.8985255854293148, 0.9282051282051282, 0.9176470588235294, 0.8990426457789382, 0.9253604749787956, 0.9126637554585153, 0.9026845637583892, 0.9215686274509803, 0.9155900086132644, 0.9049235993208828, 0.9067579127459366, 0.9045571797076526, 0.9069965870307167, 0.9219427580225499, 0.9138673557278209, 0.9099326599326599, 0.9101796407185628, 0.903364969801553, 0.9150779896013865, 0.9204840103716508, 0.9090128755364807, 0.9009314140558848, 0.9159369527145359, 0.9105760963026656, 0.907679033649698, 0.9142367066895368, 0.9179487179487179, 0.9058219178082192, 0.9288738357324301, 0.9108996539792388, 0.903471634208298, 0.9056277056277057, 0.9101027397260274, 0.9210977701543739, 0.910958904109589, 0.9207836456558773, 0.9128949615713066, 0.9230769230769231, 0.9076271186440678, 0.9175257731958762, 0.9091688089117395, 0.9208510638297872, 0.9286321155480034, 0.9083904109589042, 0.9260533104041273, 0.9120689655172414, 0.9120689655172414]\n",
            "sd_acc: 0.010436783873960619\n",
            "sd_f1: 0.006528000159460506\n",
            "sd_mcc: 0.03260543714441914\n",
            "sd_sn: 0.008378911506392993\n",
            "sd_sp: 0.008378911506392993\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.16      0.19       187\n",
            "           1       0.87      0.91      0.89      1169\n",
            "\n",
            "    accuracy                           0.81      1356\n",
            "   macro avg       0.55      0.54      0.54      1356\n",
            "weighted avg       0.78      0.81      0.80      1356\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.010436783873960619, 0.03260543714441914, 0.006528000159460506)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_gru = classifier.predict(X_test)\n",
        "predicted_gru = np.where(predicted_gru > 0.5, 1, 0)\n",
        "predicted_gru = np.reshape(predicted_gru,(len(predicted_gru),)).astype(int)\n",
        "error_rate(Y_test, predicted_gru)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E76ef8-KUQkP"
      },
      "source": [
        "### LSTM with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88td3Dd4UUSl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Bidirectional, Input, Embedding, LSTM, Dropout, Dense, InputLayer\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from time import time\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckcUO-v09XUY"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu3pXV8o9XUZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eByT44Fj8Mvw"
      },
      "outputs": [],
      "source": [
        "max_length = 1280"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpWikkLDVESA"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVdkEABDUKuw"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd_XYxWoJ8Uw"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train[1,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhJ5yPWsVESB"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bABscCD2UdFT"
      },
      "outputs": [],
      "source": [
        "def create_lstm_model(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam'):\n",
        "    x_input = layers.Input(input_shape)\n",
        "    #emb = Embedding(21, units, input_length=max_length)(x_input)\n",
        "    lstm = LSTM(units, activity_regularizer=l2(regularizer))(x_input) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x = Dropout(dropout_rate)(lstm)\n",
        "    #lstm2 =LSTM(units, activity_regularizer=l2(dropout_rate))(x) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    #x2 = Dropout(dropout_rate)(lstm2)\n",
        "    # softmax classifier\n",
        "    x_output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=x_input, outputs=x_output)\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=solver,#tf.keras.optimizers.Adam(learning_rate=learning_rate_init),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRwnsQ75Ue-6",
        "outputId": "f5b01b55-5640-49ac-991f-6dc6d45998e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 2560, 1)]         0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50)                10400     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "lstm_model = create_lstm_model()\n",
        "lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdZ6JgxYUg-G",
        "outputId": "91681300-04f6-45ce-a636-40c4bcc0b5c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-96-7d51c6a25297>:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_lstm_model, verbose=1, batch_size=256, epochs=5)\n"
          ]
        }
      ],
      "source": [
        "start = time()\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_lstm_model, verbose=1, batch_size=256, epochs=5)\n",
        "# define parameters and values for grid search\n",
        "\n",
        "parameters = {\n",
        "    'units':[50], # 1024\n",
        "    #'learning_rate_init': [0.001, 0.01],\n",
        "    'solver':['adam'],\n",
        "    #'epochs':[3,5,10],\n",
        "    #'dropout_rate':[0.0,0.05, 0.1], #0.05\n",
        "    #'regularizer':[0.0,0.05, 0.1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hos-hNI7UpOs"
      },
      "outputs": [],
      "source": [
        "metrics = {'accuracy':make_scorer(accuracy_score,greater_is_better=True),'f1':make_scorer(f1_score,greater_is_better=True),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Xa7AQTUqIO",
        "outputId": "ccde609c-da2c-4543-8a8d-cad0e3c90da2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 72s 3s/step - loss: 0.6609 - accuracy: 0.6781\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 70s 3s/step - loss: 0.6297 - accuracy: 0.6788\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 73s 3s/step - loss: 0.6268 - accuracy: 0.6788\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 94s 4s/step - loss: 0.6259 - accuracy: 0.6788\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 71s 3s/step - loss: 0.6165 - accuracy: 0.6794\n"
          ]
        }
      ],
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=parameters, n_jobs=-1, cv=10, scoring=metrics, refit='mcc')\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qttmg9ayVGeL"
      },
      "outputs": [],
      "source": [
        "classifier = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zvaGtn0VGeL",
        "outputId": "d5f5313a-c232-4638-b8e9-c03351074656"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbose': 1,\n",
              " 'batch_size': 256,\n",
              " 'epochs': 5,\n",
              " 'solver': 'adam',\n",
              " 'units': 50,\n",
              " 'build_fn': <function __main__.create_lstm_model(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam')>}"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_kGV3S6VGeL"
      },
      "outputs": [],
      "source": [
        "#cv_results = DataFrame(grid.cv_results_)\n",
        "\n",
        "#cv_results[['param_units','param_dropout_rate','param_regularizer','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYpncXoMTPWa"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(grid.cv_results_)\n",
        "new_path = '/content/test.xls'\n",
        "writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/ESM23BLSTM2.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsMHQT0K8vHE",
        "outputId": "1892800a-52a2-4219-e199-cb27214862f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "178/178 [==============================] - 57s 316ms/step\n",
            "acc: 0.627689594356261\n",
            "f1: 0.7643710235517357\n",
            "mcc: -0.05678453135191831\n",
            "sn: [0.8908091123330715, 0.8995253164556962, 0.9007593610892904, 0.8921237327787886, 0.8964435146443515, 0.8843660876328753, 0.8881630519989548, 0.8896425776154449, 0.8869359916054564, 0.8885736394119165, 0.8852542806031178, 0.8936833896542761, 0.890382626680455, 0.8833849329205367, 0.8821861304459913, 0.8934942287513117, 0.8920395421436004, 0.8877947654832858, 0.8877419354838709, 0.8979803210771621, 0.8864402385273529, 0.8848153926157046, 0.8957345971563981, 0.8921825813221406, 0.8866087871612733, 0.8834291688447464, 0.8913663469017371, 0.8870886075949367, 0.8958442924776433, 0.8759278897136797, 0.8877445932028837, 0.8896825396825396, 0.893628088426528, 0.8906493506493507, 0.8885699373695198, 0.8909518828451883, 0.8936774193548387, 0.8942233632862644, 0.8881630519989548, 0.8970888661899897, 0.8904566444330426, 0.8985317252228632, 0.8857218263394036, 0.8947229551451187, 0.8880063542494043, 0.889937106918239, 0.8896120801874512, 0.8876080691642652, 0.8971340839303992, 0.8895514648690692, 0.8925684485006519, 0.8904566444330426, 0.8798975672215109, 0.8899895724713243, 0.8889465490399585, 0.8962536023054755, 0.8838794233289646, 0.8974489795918368, 0.8833986928104575, 0.8943406022845275, 0.8885187083546899, 0.8917431192660551, 0.8881939014855356, 0.8835651725914477, 0.8868861024033438, 0.8917164372890158, 0.8937160589604345, 0.8973765432098766, 0.8849673202614379, 0.9016095534787124, 0.8886827458256029, 0.8874458874458875, 0.8864836325237593, 0.8924591863176989, 0.8923438724849752, 0.8874154966198647, 0.8984068947505877, 0.8950904392764858, 0.8959462948618642, 0.8935669456066946, 0.8908045977011494, 0.8834596289521819, 0.8909657320872274, 0.8928294071964794, 0.8919761101012724, 0.8836307214895268, 0.8830892143808255, 0.8899496154866083, 0.8916102136529442, 0.8881408596582082, 0.892263759086189, 0.8968295218295218, 0.8919133192389006, 0.8849350649350649, 0.8922758977008525, 0.8865414710485133, 0.8921237327787886, 0.8877419354838709, 0.8882565959648215, 0.8929679420889348, 0.8928664072632945, 0.8853319338756231, 0.8900235663786331, 0.8867381637457494, 0.8929765886287625, 0.8870217166494312, 0.8969153704191932, 0.8878748370273793, 0.8831667947732513, 0.8874358974358975, 0.8828104744620171, 0.8889466840052016, 0.9021681649920676, 0.8858318333761892, 0.8939197930142303, 0.8934599156118144, 0.8872318158032444, 0.8867482426451445, 0.8996865203761756, 0.889732844421163, 0.8825678496868476, 0.8888016745159603, 0.8937596699329551, 0.8876783398184176, 0.8935281837160751, 0.8905433646812957, 0.8945222929936306, 0.8811881188118812, 0.8906493506493507, 0.8923156001028013, 0.8914240755310779, 0.885427394438723, 0.8889454915944982, 0.8966327329678935, 0.895681581685744, 0.8888314374353671, 0.8935552033808769, 0.893666927286943, 0.8906617839393147, 0.8892331525948877, 0.8992207792207793, 0.8894927536231884, 0.8888014686598479, 0.8885456885456885, 0.8886861313868614, 0.8982830385015609, 0.8986175115207373, 0.8917014613778705, 0.8973085968121244, 0.8814446479979063, 0.8891478891478891, 0.8946955840083617, 0.8822314049586777, 0.8895483870967742, 0.8884615384615384, 0.8830865159781761, 0.8803486529318542, 0.8954794878494905, 0.8900817995910021, 0.8873826903023984, 0.9028920137967631, 0.8894955798231929, 0.8926436184039511, 0.8906209405040271, 0.8980228928199792, 0.8895784846133954, 0.8942789348800422, 0.8906934777004383, 0.8952702702702703, 0.8899509170756911, 0.8930148013502986, 0.8888888888888888, 0.89022477783586, 0.88871834228703, 0.8888314374353671, 0.883733055265902, 0.8865847414234511, 0.898287493513233, 0.8816675297773174, 0.8863223462237217, 0.8962018730489074, 0.881914072549524, 0.8902910121040433, 0.8815384615384615, 0.8965696465696466, 0.8856996412096361, 0.8920716112531969, 0.8953217885758594, 0.8826570173171362, 0.8848939472322814, 0.8899717876378559, 0.8958825072121689, 0.8942605997931747, 0.8875585632483082, 0.8842132775744903, 0.8788192646297255, 0.8826109391124871, 0.8858681713259811, 0.895778364116095, 0.8866752910737387, 0.893145686734428, 0.8916863362182009, 0.8852459016393442, 0.8853652196516766, 0.8911269760326365, 0.8988822459059007, 0.8898064516129032, 0.878716744913928, 0.8926790868538441, 0.8900672529746508, 0.9008914525432616, 0.8950276243093923, 0.8909616395165528, 0.8820151396502218, 0.8888311688311689, 0.8823529411764706, 0.8864402385273529, 0.8903611327617563, 0.8867874967165748, 0.8898505114083399, 0.8809156378600823, 0.8937865108868827, 0.8849487785657998, 0.8918007265179034, 0.8870838881491345, 0.8932264736297828, 0.8901613742842269, 0.8969572999232933, 0.8896408120770432, 0.8892331525948877, 0.8945463944171621, 0.8863991662324127, 0.8930244664237377, 0.8942432925240948, 0.8906652913873131, 0.8836173001310615, 0.8852713178294573, 0.8842676311030742, 0.8824136152656008, 0.8958333333333334, 0.8789610389610389, 0.8949935815147625, 0.8820915032679738, 0.8832856771510268, 0.8896321070234113, 0.8943790849673202, 0.8943954333160353, 0.8897368421052632, 0.8845355474831345, 0.8974160206718347, 0.9021143304620204, 0.8906617839393147, 0.8968937614199948, 0.889751552795031, 0.8893280632411067, 0.8887736582836402, 0.8889468196037539, 0.8909281594126901, 0.886917372881356, 0.8865062761506276, 0.8921697864487214, 0.8897495481538858, 0.8924099156657296, 0.8928016571724495, 0.891315652626105, 0.8892331525948877, 0.893181228934405, 0.8875523012552301, 0.8854842897948585, 0.8920052424639581, 0.8832211289487313, 0.8902788636955955, 0.8853187042842215, 0.8852287581699346, 0.886487893777662, 0.8888307611823175, 0.8899717876378559, 0.8845265588914549, 0.8901013250194856, 0.8918425853531404, 0.88684619368203, 0.8913670952505904, 0.8880480167014614, 0.8914448177823727, 0.8815584415584415, 0.8927840327533265, 0.8902887139107611, 0.8895184135977338, 0.8951592026922082, 0.8906330416881112, 0.8911757139181888, 0.8890353189246178, 0.8897596656217346, 0.891130074993535, 0.8970472955317481, 0.8822303282959875, 0.8842215804673142, 0.8927829698857737, 0.8795907660020986, 0.8936610608020699, 0.8886880165289256, 0.8864526233359437, 0.8874435890629148, 0.8879353861686017, 0.8892626131953428, 0.8822761681023231, 0.883150756390193, 0.8914788914788915, 0.8948048591367278, 0.8875064800414723, 0.8832725377800938, 0.8879040667361835, 0.888623707239459, 0.8835651725914477, 0.8860158311345646, 0.8914994720168955, 0.8880558428128231, 0.8916432404804497, 0.8839634941329857, 0.8941881678394579, 0.8881806108897743, 0.8959430979978925, 0.8918083462132921, 0.8924703455389376, 0.8904145077720207, 0.8937728937728938, 0.8886603239907431, 0.8897800776196636, 0.8938923395445134, 0.8876906891109942, 0.8897001303780965, 0.8906617839393147, 0.8884835852006253, 0.8884555382215289, 0.8901543912933435, 0.8842628960460853, 0.8978634705575821, 0.8844961240310077, 0.8864795918367347, 0.8899895724713243, 0.8939313984168865, 0.896790757381258, 0.8976683937823834, 0.8940899581589958, 0.8917592353397055, 0.8902788636955955, 0.9030398322851153, 0.8890325918261769, 0.889546858908342, 0.8908765652951699, 0.8862806468440271, 0.88671875, 0.8892979226926111, 0.8891491022638564, 0.8813738441215324, 0.8881987577639752, 0.8948320413436692, 0.8780740357235309, 0.89118102114492, 0.8889761717727154, 0.8890918580375783, 0.8923276983094929, 0.8829563387690689, 0.8827732204286849, 0.8884308167997939, 0.8868421052631579, 0.8873019994806544, 0.8868986693961105, 0.8921721099015034, 0.8848846253564947, 0.891042430591933, 0.8874548270521425, 0.8883170355120947, 0.8930439330543933, 0.8885969521807672, 0.8908296943231441, 0.8990461049284578, 0.8918491163281456, 0.8939628482972136, 0.8880577077210794, 0.8910814966683752, 0.8891224382553863, 0.8899869960988297, 0.8839077481212749, 0.8916256157635468, 0.8849948078920041, 0.8961919666145018, 0.8853569567483064, 0.885427666314678, 0.8882840850181442, 0.8956499223200415, 0.885617509119333, 0.8818753273965427, 0.8905147635223413, 0.8957087126137842, 0.8942457231726283, 0.8859832635983264, 0.8880914407230197, 0.8862936344969199, 0.8918988648090815, 0.8879017507185786, 0.8964718001545197, 0.8931478078235757, 0.8852292880668863, 0.8922018348623854, 0.8828782852768563, 0.9014956162970603, 0.891338174273859, 0.8807929969104017, 0.8948182521268369, 0.8848996832101372, 0.8871742980015178, 0.8885706847175214, 0.8932672233820459, 0.8912986673634701, 0.8928012519561815, 0.8853734439834025, 0.8925039042165539, 0.8851107676455435, 0.8888888888888888, 0.889688866032399, 0.8960228749675071, 0.8844051028378026, 0.8880268942332558, 0.8974954815388587, 0.8873897249610794, 0.8850574712643678, 0.8902407455345587, 0.8925663251904387, 0.8909891248058001, 0.8871768085662053, 0.8820472850090932, 0.8921721099015034, 0.8854085095275385, 0.888623707239459, 0.8874481327800829, 0.8861682729877572, 0.8876839659178931, 0.8814446479979063, 0.8701836048616498, 0.8892052808697903, 0.8833202819107283, 0.8973704365585907, 0.877720207253886, 0.8795024617776626, 0.8908995541568319, 0.8918989320135452, 0.893378519290928, 0.8903126601742696, 0.8961447678992919, 0.8819843342036554, 0.8901960784313725, 0.8856995086630463, 0.8871391076115486, 0.8869772366331392, 0.8982655966865131, 0.8884254431699687, 0.8907216494845361, 0.8753260302556077, 0.8944645628556648, 0.8816894018887723, 0.8884575569358178, 0.8858541612986344, 0.8820283762480294, 0.8983094262295082, 0.8846153846153846, 0.8789759503491078, 0.8883076118231755, 0.8906576200417536, 0.8843081679979387, 0.8920676202860858, 0.8870801033591731, 0.895631702851164, 0.8901838901838902, 0.8945191313340227, 0.8857814950339781, 0.888715953307393, 0.8893816853639447, 0.8888602372356885, 0.8839793281653747, 0.892875851231011, 0.8883355176933159, 0.8953669963560645, 0.9033742331288344, 0.8851174934725848, 0.8837809917355371, 0.890979381443299, 0.8878576952822892, 0.8942582488958171, 0.8895784846133954, 0.8893617021276595, 0.8914871255911718, 0.8857442348008385, 0.8870085915126269, 0.8936946326211569, 0.8914688233759457, 0.8942084942084942, 0.886983632112237, 0.8931178310740354, 0.8954713006845708, 0.8888030888030888, 0.8976153447382064, 0.8827676240208877, 0.8925512587594082, 0.8957508577461072, 0.8939393939393939, 0.8819062581827704, 0.8926553672316384, 0.8869340232858991, 0.8878188443519001, 0.8954640250260688, 0.8873640600725013, 0.8843379701184956, 0.8904501691386937, 0.8851030110935024, 0.8912596401028278, 0.8896677050882659, 0.8785509512640084, 0.8915849251419721, 0.8843102124392117, 0.8917297156274459, 0.8876811594202898, 0.8930882733626715, 0.8986187125358353, 0.8861219195849546, 0.8821689259645464, 0.8957569408067051, 0.8940224484468807, 0.8943552563438633, 0.8970549908782903, 0.8883997928534438, 0.8929946112394149, 0.8953797132235793, 0.8848958333333333, 0.891990607878946, 0.8855943321962739, 0.8922594142259415, 0.887611082070047, 0.8926451612903226, 0.8921161825726142, 0.8927362665972403, 0.8882167280378748, 0.8885448916408669, 0.8932140978432404, 0.8867096774193548, 0.8939587050726485, 0.8903107861060329, 0.8929584730461697, 0.8953427524856097, 0.8836307214895268, 0.8859626020542534, 0.8846558066211245, 0.8964520367936926, 0.8828852119958635, 0.8954451345755694, 0.8904435058078142, 0.8846851515936771, 0.8904109589041096, 0.8881731512496779, 0.88717277486911, 0.8921052631578947, 0.8925233644859814, 0.8868650590046178, 0.8887461459403906, 0.8872062663185378, 0.8918989320135452, 0.887997930677703, 0.8930341768849465, 0.8886870783601453, 0.8832304526748971, 0.8836129032258064, 0.8928479215078751, 0.8792569659442725, 0.8845253576072822, 0.8867339022498061, 0.8844272844272845, 0.8914567644767593, 0.8878073770491803, 0.8937662337662338, 0.8927648578811369, 0.8811752470098804, 0.889745566692367, 0.8946135831381733, 0.8874868559411146, 0.8892688058916359, 0.8822618125484121, 0.8814834024896265, 0.8899608865710561, 0.8909853249475891, 0.884585391213933, 0.8890899689762151, 0.8919761101012724, 0.8891170431211499, 0.8917164372890158, 0.8864229765013055, 0.8900441902781389, 0.8797011849562082, 0.8820619630304608, 0.8886286755139214, 0.8905447070914697, 0.8808344198174707, 0.8843379701184956, 0.8997127187255158, 0.8872334960184948, 0.894172981447609, 0.8902566788894709, 0.8928663404584084, 0.890588540316308, 0.8846455663091812, 0.8875032475967783, 0.8881561593247165, 0.8883419689119171, 0.890357698289269, 0.8889177264469245, 0.8797090153286568, 0.8899106673673147, 0.8818795430944963, 0.8892038134501418, 0.8905524006195147, 0.8893495724280902, 0.8903061224489796, 0.896685655100984, 0.8892347600518806, 0.8890895021924168, 0.8900578642819569, 0.8863871635610766, 0.8877604166666667, 0.881159420289855, 0.8934699103713188, 0.889348500517063, 0.892235782913529, 0.888574369531652, 0.8815240083507306, 0.8892347600518806, 0.884460141271443, 0.8822761681023231, 0.8860858257477243, 0.9001040582726326, 0.8848468987176132, 0.8882307494205511, 0.8848127244740893, 0.8888311688311689, 0.8965696465696466, 0.8885424785658612, 0.8847769028871391, 0.8904285347703361, 0.8922155688622755, 0.8926348547717843, 0.8937007874015748, 0.888132040869793, 0.8859315589353612, 0.8854166666666666, 0.8862370723945903, 0.8866597186034393, 0.8796972860125261, 0.8854384133611691, 0.8892016376663255, 0.892243623112962, 0.8975950349107835, 0.8860561914672217, 0.8804998698255663, 0.8920041536863966, 0.8955338809034907, 0.8910737386804657, 0.8874903673259696, 0.8941961992809451, 0.8888310335850039, 0.8868766404199475, 0.8872832369942196, 0.8961478396668402, 0.8880772241064441, 0.8962828177800883, 0.8937210499227998, 0.888031914893617, 0.8889464147035983, 0.8770150806032241, 0.8941359626362221, 0.886487893777662, 0.893298969072165, 0.8890342842187909, 0.8829759752002067, 0.8965067778936392, 0.8966597077244259, 0.8927925600619995, 0.8974292391586601, 0.8981770833333333, 0.8861746361746362, 0.8831168831168831, 0.8882868937048504, 0.8915316257187663, 0.8943954333160353, 0.8963462036797097, 0.885736595523165, 0.8834403080872913, 0.8883928571428571, 0.887707468879668, 0.888974358974359, 0.906054279749478, 0.8917783031258208, 0.8962389970658843, 0.8878138075313807, 0.8846555323590815, 0.8830364058869093, 0.8920469361147327, 0.8954367666232073, 0.8888888888888888, 0.9006501950585175, 0.9011857707509882, 0.8897821576763485, 0.8771929824561403, 0.8801855191960835, 0.8895243046529764, 0.8882445967316817, 0.8949126413155191, 0.8807099973897154, 0.8905408869520636, 0.8842931937172774, 0.8818085668958223, 0.891835673426937, 0.8913439043410449, 0.8906489524782831, 0.8952356557377049, 0.8894955798231929, 0.894185437401781, 0.8873019994806544, 0.8985239852398524, 0.8934833813137922, 0.8905263157894737, 0.8935611038107752, 0.8892323544564658, 0.8921644685802949, 0.8933021806853583, 0.9012441679626749, 0.8879109500388299, 0.8917737789203085, 0.8930718954248366, 0.8879603029511621, 0.8820459290187892, 0.8889174595011571, 0.8817400364678302, 0.8931258106355383, 0.8913678618857902, 0.8825207468879668, 0.879027997886952, 0.8932450331125827, 0.8905433646812957, 0.8821513313999473, 0.8865248226950354, 0.8874706954936181, 0.8921952492821718, 0.8985507246376812, 0.8821400878780047, 0.8929224340558892, 0.8945169712793734, 0.8821223209618401, 0.8870466321243523, 0.8910658307210031, 0.878360741320804, 0.8938417933522288, 0.8971279373368146, 0.8867677824267782, 0.885435870424019, 0.8913213448006255, 0.8913721413721414, 0.8876140808344198, 0.8923836755913699, 0.8876462938881664, 0.8892060197197716, 0.8923985618900873, 0.881585811163276, 0.8876288659793814, 0.887993762993763, 0.891849935316947, 0.8910764510355408, 0.8940259740259741, 0.8878213451051675, 0.8868021610496527, 0.8961992136304063, 0.8847545219638243, 0.892987012987013, 0.8858267716535433, 0.8895784846133954, 0.8927461139896373, 0.8848277675519327, 0.8921465968586387, 0.8946400420388859, 0.8804177545691906, 0.8962655601659751, 0.8851662404092071, 0.885593220338983, 0.8933543472550565, 0.8925039042165539, 0.8896408120770432, 0.8883647798742138, 0.884191647450679, 0.8864229765013055, 0.8853868194842407, 0.885699096225412, 0.8933643170668732, 0.8875998968806393, 0.9021849593495935, 0.8850274366344395, 0.896216500262743, 0.8898064516129032, 0.8979538300104932, 0.8824593128390597, 0.8842435327933107, 0.895010395010395, 0.8881391123799637, 0.8885126334983069, 0.88572168955688, 0.8948871009602907, 0.8960835509138381, 0.8936503788868565, 0.8917737789203085, 0.8811242908715833, 0.8828549262994569, 0.8890612878200155, 0.8828104744620171, 0.8867339022498061, 0.8902627511591963, 0.8888300688194812, 0.8875554396034437, 0.8907131862493587, 0.8891759235339706, 0.8838577641340496, 0.8901269759004924, 0.8860726417559446, 0.8860662047729022, 0.8812940255674406, 0.8860036354193715, 0.8849237134729765, 0.8906331763474621, 0.8995859213250518, 0.892875851231011, 0.8795149638802889, 0.8948592095065875, 0.890509081606549, 0.8961677887105127, 0.8871377732587697, 0.8942457231726283, 0.8950760505284867, 0.889033264033264, 0.8977569118414189, 0.8956749672346003, 0.8838292367399742, 0.8836307214895268, 0.8837628865979381, 0.8850604268449472, 0.8959358011907844, 0.8807672369103162, 0.8914788914788915, 0.892110762800418, 0.8864583333333333, 0.8922996878251821, 0.885006518904824, 0.8826155462184874, 0.8952134540750324, 0.8947095435684648, 0.8954640250260688, 0.882688813911238, 0.8891765924391507, 0.8957848461339539, 0.8870099923136049, 0.8888888888888888, 0.8836601307189542, 0.8867073494295569, 0.8994282744282744, 0.8974558670820353, 0.8859857482185273, 0.9018533020099191, 0.8941299790356394, 0.8976889119709166, 0.8881647549530761, 0.888079125455492, 0.8913896885632033, 0.8894044856921887, 0.8965695125096724, 0.8879916644959625, 0.8972229431611731, 0.8828781512605042, 0.8892670157068063, 0.8937960042060988, 0.8891491022638564, 0.875747335586171, 0.88828125, 0.886870783601453, 0.8948051948051948, 0.8761585993820803, 0.8776885203420576, 0.8807026743576298, 0.8872419269454738, 0.8854842897948585, 0.891422648354496, 0.8949700286682304, 0.8976398152898922, 0.8854440357330531, 0.896047227926078, 0.8884031884803292, 0.8834244080145719, 0.894268516095263, 0.8882051282051282, 0.8851662404092071, 0.8921594165147174, 0.8865710560625815, 0.8968831168831168, 0.8858176181865152, 0.8877973112719751, 0.8878600823045267, 0.8830832902224521, 0.8853187042842215, 0.8944788441692466, 0.8888307611823175, 0.8867727628489434, 0.8937710002584647, 0.8941146234901054, 0.8909705958886287, 0.8932702418506835, 0.8927094105480868, 0.8816783945790982, 0.8940655908381051, 0.8925467474321833, 0.8881873191265457, 0.8820486290739783, 0.8909233586188857, 0.8969258589511754, 0.8842377260981912, 0.8859305664317411, 0.8946953781512605, 0.8904861474124411, 0.8958441558441559, 0.8826132222800624, 0.8911182450508294, 0.8926509186351707, 0.8936610608020699, 0.8753861997940268, 0.8847247350736624, 0.8924731182795699, 0.8868801652892562, 0.8927543813758828, 0.8824302998421883, 0.8957309184993532, 0.8938992042440318, 0.8822784810126583, 0.888373292085589, 0.885974025974026, 0.8909043793728946, 0.8918143899895725, 0.8892661269260904, 0.8950505312257061, 0.8837628865979381, 0.8885691865027465, 0.8905317769130998, 0.8813204086979303, 0.8983140147523709, 0.8882551205600208, 0.8890038809831824, 0.8839634941329857, 0.8909043793728946, 0.9006047856955035, 0.8910323253388946, 0.8891726251276814, 0.8884845334026514, 0.9002834321051275, 0.887583035258048, 0.892017566520279, 0.8914627798021864, 0.883224967490247, 0.8858937450929076, 0.8874291602266873, 0.8893805309734514, 0.889572124007174, 0.8936114732724902, 0.8825200103279112, 0.8830469351115671, 0.8880105401844532, 0.8782608695652174, 0.8888600363541937, 0.8885416666666667, 0.8949170397682381, 0.889747552807831, 0.8928107967817285, 0.8947232281427833, 0.8901013250194856, 0.8895817095349441, 0.8863049095607235, 0.8917246713070379, 0.8881987577639752, 0.8887163561076604, 0.8922402681103377, 0.8883572567783095, 0.9024517475221701, 0.8922996878251821, 0.8858765814613995, 0.8968563263185243, 0.9022360894435777, 0.8935458986886089, 0.8858024691358025, 0.8852415966386554, 0.8872395833333333]\n",
            "sp: [0.8908091123330715, 0.8995253164556962, 0.9007593610892904, 0.8921237327787886, 0.8964435146443515, 0.8843660876328753, 0.8881630519989548, 0.8896425776154449, 0.8869359916054564, 0.8885736394119165, 0.8852542806031178, 0.8936833896542761, 0.890382626680455, 0.8833849329205367, 0.8821861304459913, 0.8934942287513117, 0.8920395421436004, 0.8877947654832858, 0.8877419354838709, 0.8979803210771621, 0.8864402385273529, 0.8848153926157046, 0.8957345971563981, 0.8921825813221406, 0.8866087871612733, 0.8834291688447464, 0.8913663469017371, 0.8870886075949367, 0.8958442924776433, 0.8759278897136797, 0.8877445932028837, 0.8896825396825396, 0.893628088426528, 0.8906493506493507, 0.8885699373695198, 0.8909518828451883, 0.8936774193548387, 0.8942233632862644, 0.8881630519989548, 0.8970888661899897, 0.8904566444330426, 0.8985317252228632, 0.8857218263394036, 0.8947229551451187, 0.8880063542494043, 0.889937106918239, 0.8896120801874512, 0.8876080691642652, 0.8971340839303992, 0.8895514648690692, 0.8925684485006519, 0.8904566444330426, 0.8798975672215109, 0.8899895724713243, 0.8889465490399585, 0.8962536023054755, 0.8838794233289646, 0.8974489795918368, 0.8833986928104575, 0.8943406022845275, 0.8885187083546899, 0.8917431192660551, 0.8881939014855356, 0.8835651725914477, 0.8868861024033438, 0.8917164372890158, 0.8937160589604345, 0.8973765432098766, 0.8849673202614379, 0.9016095534787124, 0.8886827458256029, 0.8874458874458875, 0.8864836325237593, 0.8924591863176989, 0.8923438724849752, 0.8874154966198647, 0.8984068947505877, 0.8950904392764858, 0.8959462948618642, 0.8935669456066946, 0.8908045977011494, 0.8834596289521819, 0.8909657320872274, 0.8928294071964794, 0.8919761101012724, 0.8836307214895268, 0.8830892143808255, 0.8899496154866083, 0.8916102136529442, 0.8881408596582082, 0.892263759086189, 0.8968295218295218, 0.8919133192389006, 0.8849350649350649, 0.8922758977008525, 0.8865414710485133, 0.8921237327787886, 0.8877419354838709, 0.8882565959648215, 0.8929679420889348, 0.8928664072632945, 0.8853319338756231, 0.8900235663786331, 0.8867381637457494, 0.8929765886287625, 0.8870217166494312, 0.8969153704191932, 0.8878748370273793, 0.8831667947732513, 0.8874358974358975, 0.8828104744620171, 0.8889466840052016, 0.9021681649920676, 0.8858318333761892, 0.8939197930142303, 0.8934599156118144, 0.8872318158032444, 0.8867482426451445, 0.8996865203761756, 0.889732844421163, 0.8825678496868476, 0.8888016745159603, 0.8937596699329551, 0.8876783398184176, 0.8935281837160751, 0.8905433646812957, 0.8945222929936306, 0.8811881188118812, 0.8906493506493507, 0.8923156001028013, 0.8914240755310779, 0.885427394438723, 0.8889454915944982, 0.8966327329678935, 0.895681581685744, 0.8888314374353671, 0.8935552033808769, 0.893666927286943, 0.8906617839393147, 0.8892331525948877, 0.8992207792207793, 0.8894927536231884, 0.8888014686598479, 0.8885456885456885, 0.8886861313868614, 0.8982830385015609, 0.8986175115207373, 0.8917014613778705, 0.8973085968121244, 0.8814446479979063, 0.8891478891478891, 0.8946955840083617, 0.8822314049586777, 0.8895483870967742, 0.8884615384615384, 0.8830865159781761, 0.8803486529318542, 0.8954794878494905, 0.8900817995910021, 0.8873826903023984, 0.9028920137967631, 0.8894955798231929, 0.8926436184039511, 0.8906209405040271, 0.8980228928199792, 0.8895784846133954, 0.8942789348800422, 0.8906934777004383, 0.8952702702702703, 0.8899509170756911, 0.8930148013502986, 0.8888888888888888, 0.89022477783586, 0.88871834228703, 0.8888314374353671, 0.883733055265902, 0.8865847414234511, 0.898287493513233, 0.8816675297773174, 0.8863223462237217, 0.8962018730489074, 0.881914072549524, 0.8902910121040433, 0.8815384615384615, 0.8965696465696466, 0.8856996412096361, 0.8920716112531969, 0.8953217885758594, 0.8826570173171362, 0.8848939472322814, 0.8899717876378559, 0.8958825072121689, 0.8942605997931747, 0.8875585632483082, 0.8842132775744903, 0.8788192646297255, 0.8826109391124871, 0.8858681713259811, 0.895778364116095, 0.8866752910737387, 0.893145686734428, 0.8916863362182009, 0.8852459016393442, 0.8853652196516766, 0.8911269760326365, 0.8988822459059007, 0.8898064516129032, 0.878716744913928, 0.8926790868538441, 0.8900672529746508, 0.9008914525432616, 0.8950276243093923, 0.8909616395165528, 0.8820151396502218, 0.8888311688311689, 0.8823529411764706, 0.8864402385273529, 0.8903611327617563, 0.8867874967165748, 0.8898505114083399, 0.8809156378600823, 0.8937865108868827, 0.8849487785657998, 0.8918007265179034, 0.8870838881491345, 0.8932264736297828, 0.8901613742842269, 0.8969572999232933, 0.8896408120770432, 0.8892331525948877, 0.8945463944171621, 0.8863991662324127, 0.8930244664237377, 0.8942432925240948, 0.8906652913873131, 0.8836173001310615, 0.8852713178294573, 0.8842676311030742, 0.8824136152656008, 0.8958333333333334, 0.8789610389610389, 0.8949935815147625, 0.8820915032679738, 0.8832856771510268, 0.8896321070234113, 0.8943790849673202, 0.8943954333160353, 0.8897368421052632, 0.8845355474831345, 0.8974160206718347, 0.9021143304620204, 0.8906617839393147, 0.8968937614199948, 0.889751552795031, 0.8893280632411067, 0.8887736582836402, 0.8889468196037539, 0.8909281594126901, 0.886917372881356, 0.8865062761506276, 0.8921697864487214, 0.8897495481538858, 0.8924099156657296, 0.8928016571724495, 0.891315652626105, 0.8892331525948877, 0.893181228934405, 0.8875523012552301, 0.8854842897948585, 0.8920052424639581, 0.8832211289487313, 0.8902788636955955, 0.8853187042842215, 0.8852287581699346, 0.886487893777662, 0.8888307611823175, 0.8899717876378559, 0.8845265588914549, 0.8901013250194856, 0.8918425853531404, 0.88684619368203, 0.8913670952505904, 0.8880480167014614, 0.8914448177823727, 0.8815584415584415, 0.8927840327533265, 0.8902887139107611, 0.8895184135977338, 0.8951592026922082, 0.8906330416881112, 0.8911757139181888, 0.8890353189246178, 0.8897596656217346, 0.891130074993535, 0.8970472955317481, 0.8822303282959875, 0.8842215804673142, 0.8927829698857737, 0.8795907660020986, 0.8936610608020699, 0.8886880165289256, 0.8864526233359437, 0.8874435890629148, 0.8879353861686017, 0.8892626131953428, 0.8822761681023231, 0.883150756390193, 0.8914788914788915, 0.8948048591367278, 0.8875064800414723, 0.8832725377800938, 0.8879040667361835, 0.888623707239459, 0.8835651725914477, 0.8860158311345646, 0.8914994720168955, 0.8880558428128231, 0.8916432404804497, 0.8839634941329857, 0.8941881678394579, 0.8881806108897743, 0.8959430979978925, 0.8918083462132921, 0.8924703455389376, 0.8904145077720207, 0.8937728937728938, 0.8886603239907431, 0.8897800776196636, 0.8938923395445134, 0.8876906891109942, 0.8897001303780965, 0.8906617839393147, 0.8884835852006253, 0.8884555382215289, 0.8901543912933435, 0.8842628960460853, 0.8978634705575821, 0.8844961240310077, 0.8864795918367347, 0.8899895724713243, 0.8939313984168865, 0.896790757381258, 0.8976683937823834, 0.8940899581589958, 0.8917592353397055, 0.8902788636955955, 0.9030398322851153, 0.8890325918261769, 0.889546858908342, 0.8908765652951699, 0.8862806468440271, 0.88671875, 0.8892979226926111, 0.8891491022638564, 0.8813738441215324, 0.8881987577639752, 0.8948320413436692, 0.8780740357235309, 0.89118102114492, 0.8889761717727154, 0.8890918580375783, 0.8923276983094929, 0.8829563387690689, 0.8827732204286849, 0.8884308167997939, 0.8868421052631579, 0.8873019994806544, 0.8868986693961105, 0.8921721099015034, 0.8848846253564947, 0.891042430591933, 0.8874548270521425, 0.8883170355120947, 0.8930439330543933, 0.8885969521807672, 0.8908296943231441, 0.8990461049284578, 0.8918491163281456, 0.8939628482972136, 0.8880577077210794, 0.8910814966683752, 0.8891224382553863, 0.8899869960988297, 0.8839077481212749, 0.8916256157635468, 0.8849948078920041, 0.8961919666145018, 0.8853569567483064, 0.885427666314678, 0.8882840850181442, 0.8956499223200415, 0.885617509119333, 0.8818753273965427, 0.8905147635223413, 0.8957087126137842, 0.8942457231726283, 0.8859832635983264, 0.8880914407230197, 0.8862936344969199, 0.8918988648090815, 0.8879017507185786, 0.8964718001545197, 0.8931478078235757, 0.8852292880668863, 0.8922018348623854, 0.8828782852768563, 0.9014956162970603, 0.891338174273859, 0.8807929969104017, 0.8948182521268369, 0.8848996832101372, 0.8871742980015178, 0.8885706847175214, 0.8932672233820459, 0.8912986673634701, 0.8928012519561815, 0.8853734439834025, 0.8925039042165539, 0.8851107676455435, 0.8888888888888888, 0.889688866032399, 0.8960228749675071, 0.8844051028378026, 0.8880268942332558, 0.8974954815388587, 0.8873897249610794, 0.8850574712643678, 0.8902407455345587, 0.8925663251904387, 0.8909891248058001, 0.8871768085662053, 0.8820472850090932, 0.8921721099015034, 0.8854085095275385, 0.888623707239459, 0.8874481327800829, 0.8861682729877572, 0.8876839659178931, 0.8814446479979063, 0.8701836048616498, 0.8892052808697903, 0.8833202819107283, 0.8973704365585907, 0.877720207253886, 0.8795024617776626, 0.8908995541568319, 0.8918989320135452, 0.893378519290928, 0.8903126601742696, 0.8961447678992919, 0.8819843342036554, 0.8901960784313725, 0.8856995086630463, 0.8871391076115486, 0.8869772366331392, 0.8982655966865131, 0.8884254431699687, 0.8907216494845361, 0.8753260302556077, 0.8944645628556648, 0.8816894018887723, 0.8884575569358178, 0.8858541612986344, 0.8820283762480294, 0.8983094262295082, 0.8846153846153846, 0.8789759503491078, 0.8883076118231755, 0.8906576200417536, 0.8843081679979387, 0.8920676202860858, 0.8870801033591731, 0.895631702851164, 0.8901838901838902, 0.8945191313340227, 0.8857814950339781, 0.888715953307393, 0.8893816853639447, 0.8888602372356885, 0.8839793281653747, 0.892875851231011, 0.8883355176933159, 0.8953669963560645, 0.9033742331288344, 0.8851174934725848, 0.8837809917355371, 0.890979381443299, 0.8878576952822892, 0.8942582488958171, 0.8895784846133954, 0.8893617021276595, 0.8914871255911718, 0.8857442348008385, 0.8870085915126269, 0.8936946326211569, 0.8914688233759457, 0.8942084942084942, 0.886983632112237, 0.8931178310740354, 0.8954713006845708, 0.8888030888030888, 0.8976153447382064, 0.8827676240208877, 0.8925512587594082, 0.8957508577461072, 0.8939393939393939, 0.8819062581827704, 0.8926553672316384, 0.8869340232858991, 0.8878188443519001, 0.8954640250260688, 0.8873640600725013, 0.8843379701184956, 0.8904501691386937, 0.8851030110935024, 0.8912596401028278, 0.8896677050882659, 0.8785509512640084, 0.8915849251419721, 0.8843102124392117, 0.8917297156274459, 0.8876811594202898, 0.8930882733626715, 0.8986187125358353, 0.8861219195849546, 0.8821689259645464, 0.8957569408067051, 0.8940224484468807, 0.8943552563438633, 0.8970549908782903, 0.8883997928534438, 0.8929946112394149, 0.8953797132235793, 0.8848958333333333, 0.891990607878946, 0.8855943321962739, 0.8922594142259415, 0.887611082070047, 0.8926451612903226, 0.8921161825726142, 0.8927362665972403, 0.8882167280378748, 0.8885448916408669, 0.8932140978432404, 0.8867096774193548, 0.8939587050726485, 0.8903107861060329, 0.8929584730461697, 0.8953427524856097, 0.8836307214895268, 0.8859626020542534, 0.8846558066211245, 0.8964520367936926, 0.8828852119958635, 0.8954451345755694, 0.8904435058078142, 0.8846851515936771, 0.8904109589041096, 0.8881731512496779, 0.88717277486911, 0.8921052631578947, 0.8925233644859814, 0.8868650590046178, 0.8887461459403906, 0.8872062663185378, 0.8918989320135452, 0.887997930677703, 0.8930341768849465, 0.8886870783601453, 0.8832304526748971, 0.8836129032258064, 0.8928479215078751, 0.8792569659442725, 0.8845253576072822, 0.8867339022498061, 0.8844272844272845, 0.8914567644767593, 0.8878073770491803, 0.8937662337662338, 0.8927648578811369, 0.8811752470098804, 0.889745566692367, 0.8946135831381733, 0.8874868559411146, 0.8892688058916359, 0.8822618125484121, 0.8814834024896265, 0.8899608865710561, 0.8909853249475891, 0.884585391213933, 0.8890899689762151, 0.8919761101012724, 0.8891170431211499, 0.8917164372890158, 0.8864229765013055, 0.8900441902781389, 0.8797011849562082, 0.8820619630304608, 0.8886286755139214, 0.8905447070914697, 0.8808344198174707, 0.8843379701184956, 0.8997127187255158, 0.8872334960184948, 0.894172981447609, 0.8902566788894709, 0.8928663404584084, 0.890588540316308, 0.8846455663091812, 0.8875032475967783, 0.8881561593247165, 0.8883419689119171, 0.890357698289269, 0.8889177264469245, 0.8797090153286568, 0.8899106673673147, 0.8818795430944963, 0.8892038134501418, 0.8905524006195147, 0.8893495724280902, 0.8903061224489796, 0.896685655100984, 0.8892347600518806, 0.8890895021924168, 0.8900578642819569, 0.8863871635610766, 0.8877604166666667, 0.881159420289855, 0.8934699103713188, 0.889348500517063, 0.892235782913529, 0.888574369531652, 0.8815240083507306, 0.8892347600518806, 0.884460141271443, 0.8822761681023231, 0.8860858257477243, 0.9001040582726326, 0.8848468987176132, 0.8882307494205511, 0.8848127244740893, 0.8888311688311689, 0.8965696465696466, 0.8885424785658612, 0.8847769028871391, 0.8904285347703361, 0.8922155688622755, 0.8926348547717843, 0.8937007874015748, 0.888132040869793, 0.8859315589353612, 0.8854166666666666, 0.8862370723945903, 0.8866597186034393, 0.8796972860125261, 0.8854384133611691, 0.8892016376663255, 0.892243623112962, 0.8975950349107835, 0.8860561914672217, 0.8804998698255663, 0.8920041536863966, 0.8955338809034907, 0.8910737386804657, 0.8874903673259696, 0.8941961992809451, 0.8888310335850039, 0.8868766404199475, 0.8872832369942196, 0.8961478396668402, 0.8880772241064441, 0.8962828177800883, 0.8937210499227998, 0.888031914893617, 0.8889464147035983, 0.8770150806032241, 0.8941359626362221, 0.886487893777662, 0.893298969072165, 0.8890342842187909, 0.8829759752002067, 0.8965067778936392, 0.8966597077244259, 0.8927925600619995, 0.8974292391586601, 0.8981770833333333, 0.8861746361746362, 0.8831168831168831, 0.8882868937048504, 0.8915316257187663, 0.8943954333160353, 0.8963462036797097, 0.885736595523165, 0.8834403080872913, 0.8883928571428571, 0.887707468879668, 0.888974358974359, 0.906054279749478, 0.8917783031258208, 0.8962389970658843, 0.8878138075313807, 0.8846555323590815, 0.8830364058869093, 0.8920469361147327, 0.8954367666232073, 0.8888888888888888, 0.9006501950585175, 0.9011857707509882, 0.8897821576763485, 0.8771929824561403, 0.8801855191960835, 0.8895243046529764, 0.8882445967316817, 0.8949126413155191, 0.8807099973897154, 0.8905408869520636, 0.8842931937172774, 0.8818085668958223, 0.891835673426937, 0.8913439043410449, 0.8906489524782831, 0.8952356557377049, 0.8894955798231929, 0.894185437401781, 0.8873019994806544, 0.8985239852398524, 0.8934833813137922, 0.8905263157894737, 0.8935611038107752, 0.8892323544564658, 0.8921644685802949, 0.8933021806853583, 0.9012441679626749, 0.8879109500388299, 0.8917737789203085, 0.8930718954248366, 0.8879603029511621, 0.8820459290187892, 0.8889174595011571, 0.8817400364678302, 0.8931258106355383, 0.8913678618857902, 0.8825207468879668, 0.879027997886952, 0.8932450331125827, 0.8905433646812957, 0.8821513313999473, 0.8865248226950354, 0.8874706954936181, 0.8921952492821718, 0.8985507246376812, 0.8821400878780047, 0.8929224340558892, 0.8945169712793734, 0.8821223209618401, 0.8870466321243523, 0.8910658307210031, 0.878360741320804, 0.8938417933522288, 0.8971279373368146, 0.8867677824267782, 0.885435870424019, 0.8913213448006255, 0.8913721413721414, 0.8876140808344198, 0.8923836755913699, 0.8876462938881664, 0.8892060197197716, 0.8923985618900873, 0.881585811163276, 0.8876288659793814, 0.887993762993763, 0.891849935316947, 0.8910764510355408, 0.8940259740259741, 0.8878213451051675, 0.8868021610496527, 0.8961992136304063, 0.8847545219638243, 0.892987012987013, 0.8858267716535433, 0.8895784846133954, 0.8927461139896373, 0.8848277675519327, 0.8921465968586387, 0.8946400420388859, 0.8804177545691906, 0.8962655601659751, 0.8851662404092071, 0.885593220338983, 0.8933543472550565, 0.8925039042165539, 0.8896408120770432, 0.8883647798742138, 0.884191647450679, 0.8864229765013055, 0.8853868194842407, 0.885699096225412, 0.8933643170668732, 0.8875998968806393, 0.9021849593495935, 0.8850274366344395, 0.896216500262743, 0.8898064516129032, 0.8979538300104932, 0.8824593128390597, 0.8842435327933107, 0.895010395010395, 0.8881391123799637, 0.8885126334983069, 0.88572168955688, 0.8948871009602907, 0.8960835509138381, 0.8936503788868565, 0.8917737789203085, 0.8811242908715833, 0.8828549262994569, 0.8890612878200155, 0.8828104744620171, 0.8867339022498061, 0.8902627511591963, 0.8888300688194812, 0.8875554396034437, 0.8907131862493587, 0.8891759235339706, 0.8838577641340496, 0.8901269759004924, 0.8860726417559446, 0.8860662047729022, 0.8812940255674406, 0.8860036354193715, 0.8849237134729765, 0.8906331763474621, 0.8995859213250518, 0.892875851231011, 0.8795149638802889, 0.8948592095065875, 0.890509081606549, 0.8961677887105127, 0.8871377732587697, 0.8942457231726283, 0.8950760505284867, 0.889033264033264, 0.8977569118414189, 0.8956749672346003, 0.8838292367399742, 0.8836307214895268, 0.8837628865979381, 0.8850604268449472, 0.8959358011907844, 0.8807672369103162, 0.8914788914788915, 0.892110762800418, 0.8864583333333333, 0.8922996878251821, 0.885006518904824, 0.8826155462184874, 0.8952134540750324, 0.8947095435684648, 0.8954640250260688, 0.882688813911238, 0.8891765924391507, 0.8957848461339539, 0.8870099923136049, 0.8888888888888888, 0.8836601307189542, 0.8867073494295569, 0.8994282744282744, 0.8974558670820353, 0.8859857482185273, 0.9018533020099191, 0.8941299790356394, 0.8976889119709166, 0.8881647549530761, 0.888079125455492, 0.8913896885632033, 0.8894044856921887, 0.8965695125096724, 0.8879916644959625, 0.8972229431611731, 0.8828781512605042, 0.8892670157068063, 0.8937960042060988, 0.8891491022638564, 0.875747335586171, 0.88828125, 0.886870783601453, 0.8948051948051948, 0.8761585993820803, 0.8776885203420576, 0.8807026743576298, 0.8872419269454738, 0.8854842897948585, 0.891422648354496, 0.8949700286682304, 0.8976398152898922, 0.8854440357330531, 0.896047227926078, 0.8884031884803292, 0.8834244080145719, 0.894268516095263, 0.8882051282051282, 0.8851662404092071, 0.8921594165147174, 0.8865710560625815, 0.8968831168831168, 0.8858176181865152, 0.8877973112719751, 0.8878600823045267, 0.8830832902224521, 0.8853187042842215, 0.8944788441692466, 0.8888307611823175, 0.8867727628489434, 0.8937710002584647, 0.8941146234901054, 0.8909705958886287, 0.8932702418506835, 0.8927094105480868, 0.8816783945790982, 0.8940655908381051, 0.8925467474321833, 0.8881873191265457, 0.8820486290739783, 0.8909233586188857, 0.8969258589511754, 0.8842377260981912, 0.8859305664317411, 0.8946953781512605, 0.8904861474124411, 0.8958441558441559, 0.8826132222800624, 0.8911182450508294, 0.8926509186351707, 0.8936610608020699, 0.8753861997940268, 0.8847247350736624, 0.8924731182795699, 0.8868801652892562, 0.8927543813758828, 0.8824302998421883, 0.8957309184993532, 0.8938992042440318, 0.8822784810126583, 0.888373292085589, 0.885974025974026, 0.8909043793728946, 0.8918143899895725, 0.8892661269260904, 0.8950505312257061, 0.8837628865979381, 0.8885691865027465, 0.8905317769130998, 0.8813204086979303, 0.8983140147523709, 0.8882551205600208, 0.8890038809831824, 0.8839634941329857, 0.8909043793728946, 0.9006047856955035, 0.8910323253388946, 0.8891726251276814, 0.8884845334026514, 0.9002834321051275, 0.887583035258048, 0.892017566520279, 0.8914627798021864, 0.883224967490247, 0.8858937450929076, 0.8874291602266873, 0.8893805309734514, 0.889572124007174, 0.8936114732724902, 0.8825200103279112, 0.8830469351115671, 0.8880105401844532, 0.8782608695652174, 0.8888600363541937, 0.8885416666666667, 0.8949170397682381, 0.889747552807831, 0.8928107967817285, 0.8947232281427833, 0.8901013250194856, 0.8895817095349441, 0.8863049095607235, 0.8917246713070379, 0.8881987577639752, 0.8887163561076604, 0.8922402681103377, 0.8883572567783095, 0.9024517475221701, 0.8922996878251821, 0.8858765814613995, 0.8968563263185243, 0.9022360894435777, 0.8935458986886089, 0.8858024691358025, 0.8852415966386554, 0.8872395833333333]\n",
            "sd_acc: 0.0062491648543549876\n",
            "sd_f1: 0.00483836971589913\n",
            "sd_mcc: 0.012456692575796834\n",
            "sd_sn: 0.004973247863411915\n",
            "sd_sp: 0.004973247863411915\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.07      0.11      1821\n",
            "           1       0.67      0.89      0.76      3849\n",
            "\n",
            "    accuracy                           0.63      5670\n",
            "   macro avg       0.46      0.48      0.44      5670\n",
            "weighted avg       0.53      0.63      0.56      5670\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0062491648543549876, 0.012456692575796834, 0.00483836971589913)"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_training_labels = classifier.predict(X_train)\n",
        "predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "predicted_training_labels = np.reshape(predicted_training_labels,(len(predicted_training_labels),)).astype(int)\n",
        "error_rate(Y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKqfkrJb1SP-",
        "outputId": "3d2ae15a-be8c-455c-9a24-cfef717e59d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43/43 [==============================] - 14s 322ms/step\n",
            "acc: 0.7927728613569321\n",
            "f1: 0.8820814099874107\n",
            "mcc: 0.030856399446218957\n",
            "sn: [0.887668918918919, 0.9027303754266212, 0.8889837745516652, 0.9025862068965518, 0.9058823529411765, 0.8832618025751073, 0.8920741989881956, 0.9004255319148936, 0.9080756013745704, 0.906896551724138, 0.8958155422715628, 0.9059613769941226, 0.9036144578313253, 0.9080168776371308, 0.8985507246376812, 0.8915456874466268, 0.8962264150943396, 0.8981001727115717, 0.9027538726333907, 0.905254091300603, 0.909245122985581, 0.9139966273187183, 0.9093242087254063, 0.9018456375838926, 0.8956372968349017, 0.9027303754266212, 0.9046413502109705, 0.9112426035502958, 0.8928877463581834, 0.8961702127659574, 0.9017933390264731, 0.8927659574468085, 0.8982338099243061, 0.9102564102564102, 0.9138513513513513, 0.9038961038961039, 0.9059024807527801, 0.8934356351236147, 0.9148375768217735, 0.8957795004306632, 0.9016115351993215, 0.8968185726569218, 0.9180187873612298, 0.9179487179487179, 0.8949181739879414, 0.8989637305699482, 0.9110535405872193, 0.8941076003415884, 0.9012027491408935, 0.8958509737510584, 0.9042735042735043, 0.8966101694915254, 0.8998287671232876, 0.8934010152284264, 0.8980291345329906, 0.8900432900432901, 0.8994032395566922, 0.8742463393626184, 0.8942065491183879, 0.8900432900432901, 0.8984771573604061, 0.896943231441048, 0.8967576791808873, 0.900418410041841, 0.9018771331058021, 0.8933107535986452, 0.8864027538726333, 0.9001677852348994, 0.8987012987012987, 0.9073593073593074, 0.8966386554621849, 0.902127659574468, 0.9037294015611448, 0.897370653095844, 0.913527397260274, 0.8812709030100334, 0.9138225255972696, 0.9143101970865467, 0.8894645941278065, 0.9180743243243243, 0.8998287671232876, 0.8842832469775475, 0.8931955211024979, 0.9105902777777778, 0.9057724957555179, 0.896845694799659, 0.9157254561251086, 0.8813559322033898, 0.9058219178082192, 0.9085520745131245, 0.9059322033898305, 0.8817480719794345, 0.9100346020761245, 0.8907563025210085, 0.9072961373390558, 0.9086206896551724, 0.9159592529711376, 0.8905047048759623, 0.9005190311418685, 0.9018932874354562, 0.9021459227467811, 0.8979933110367893, 0.8932291666666666, 0.9067357512953368, 0.8904923599320883, 0.8945111492281304, 0.9056122448979592, 0.9097872340425532, 0.8956228956228957, 0.9042735042735043, 0.8945548833189283, 0.9031979256698358, 0.888695652173913, 0.8994082840236687, 0.8926116838487973, 0.8853721129170231, 0.8955857385398981, 0.9031705227077977, 0.8937977909940527, 0.8945147679324894, 0.8831932773109243, 0.9041095890410958, 0.8974358974358975, 0.8946925021061499, 0.897822445561139, 0.90770533446232, 0.887668918918919, 0.8966977138018628, 0.8999151823579304, 0.9032534246575342, 0.8874570446735395, 0.8973913043478261, 0.9034188034188034, 0.8863443596268024, 0.8946474086661003, 0.8963730569948186, 0.8993055555555556, 0.9117147707979627, 0.9033942558746736, 0.8944636678200693, 0.892527287993283, 0.8920308483290489, 0.8823529411764706, 0.9029535864978903, 0.8963093145869947, 0.8947368421052632, 0.8940170940170941, 0.9040622299049266, 0.8900343642611683, 0.9028960817717206, 0.909710391822828, 0.8939264328485885, 0.902376910016978, 0.9203463203463204, 0.8957627118644068, 0.9070567986230637, 0.9045571797076526, 0.8864628820960698, 0.8976784178847808, 0.9130434782608695, 0.8889845094664371, 0.8900432900432901, 0.9131175468483816, 0.8928270042194093, 0.9072512647554806, 0.9020618556701031, 0.9072961373390558, 0.8993115318416524, 0.913718723037101, 0.8844519966015293, 0.8977469670710572, 0.8931623931623932, 0.9027538726333907, 0.8897502153316107, 0.8975021533161068, 0.9029787234042553, 0.8849706129303107, 0.8987124463519314, 0.8983050847457628, 0.9030874785591767, 0.905511811023622, 0.8914728682170543, 0.8957106812447435, 0.8982608695652174, 0.8842832469775475, 0.8851063829787233, 0.9016681299385426, 0.894781864841745, 0.8939393939393939, 0.8952299829642248, 0.9005190311418685, 0.902502157031924, 0.9018612521150592, 0.8787361229718189, 0.8959931798806479, 0.903364969801553, 0.8800690250215704, 0.9026473099914603, 0.9019776440240757, 0.8987993138936535, 0.9147627416520211, 0.9052013422818792, 0.9054640069384216, 0.8824034334763948, 0.9005102040816326, 0.885589519650655, 0.8908780903665814, 0.9103448275862069, 0.9075194468452895, 0.9009556907037359, 0.9028132992327366, 0.9061685490877498, 0.8999151823579304, 0.9020100502512562, 0.9046413502109705, 0.9077834179357022, 0.9060913705583756, 0.8993231810490694, 0.9050042408821035, 0.8967851099830795, 0.9058219178082192, 0.9040274207369323, 0.898981324278438, 0.8951817413355875, 0.8865800865800866, 0.9023136246786633, 0.8952299829642248, 0.8967297762478486, 0.8985507246376812, 0.8902439024390244, 0.8908629441624365, 0.8992379339542761, 0.8913412563667232, 0.9045138888888888, 0.9075342465753424, 0.8949615713065756, 0.8964912280701754, 0.8913601368691189, 0.8925193465176269, 0.9042016806722689, 0.8972602739726028, 0.9073756432246999, 0.891961970613656, 0.904639175257732, 0.9157351676698194, 0.8982035928143712, 0.8984771573604061, 0.9069171648163963, 0.8980458793542906, 0.8911392405063291, 0.8936535162950258, 0.8943781942078365, 0.9176570458404074, 0.8985507246376812, 0.8960817717206133, 0.9086993970714901, 0.9022491349480969, 0.901541095890411, 0.9108061749571184, 0.8987124463519314, 0.9022939677145284, 0.9090909090909091, 0.8920800696257616, 0.8846480067854113, 0.9017094017094017, 0.9185946872322194, 0.8796928327645052, 0.90770533446232, 0.9121160409556314, 0.893344709897611, 0.8928877463581834, 0.9137489325362937, 0.9056924384027187, 0.9028960817717206, 0.9113043478260869, 0.8914141414141414, 0.8932203389830509, 0.9036144578313253, 0.8980623420387531, 0.8877374784110535, 0.906896551724138, 0.8959044368600683, 0.9012875536480687, 0.9002557544757033, 0.9094827586206896, 0.8854254422914911, 0.8905047048759623, 0.8760683760683761, 0.9129332206255283, 0.8966101694915254, 0.8920552677029361, 0.9049265341400173, 0.8988954970263382, 0.9017933390264731, 0.893526405451448, 0.8898305084745762, 0.9025862068965518, 0.8972125435540069, 0.8861859252823632, 0.8936170212765957, 0.9019947961838681, 0.897302001740644, 0.9037974683544304, 0.8874570446735395, 0.8997429305912596, 0.8982758620689655, 0.8955479452054794, 0.8965217391304348, 0.9167389418907199, 0.8886054421768708, 0.8889845094664371, 0.9036973344797936, 0.8871662360034454, 0.898972602739726, 0.9113384484228474, 0.8970212765957447, 0.9145516074450084, 0.896404109589041, 0.9018245004344049, 0.894005212858384, 0.8960817717206133, 0.903862660944206, 0.9001692047377327, 0.8999158957106812, 0.9079061685490878, 0.8999158957106812, 0.8950930626057529, 0.9005998286203942, 0.8911739502999143, 0.8976784178847808, 0.9074550128534704, 0.8949615713065756, 0.8875739644970414, 0.8870151770657673, 0.9072961373390558, 0.9010152284263959, 0.8917306052855924, 0.9076133447390933, 0.9001692047377327, 0.8977853492333902, 0.8957795004306632, 0.8947811447811448, 0.9122362869198313, 0.9045183290707587, 0.8956228956228957, 0.9021645021645022, 0.9013490725126475, 0.9155172413793103, 0.9080068143100511, 0.8978540772532189, 0.9036658141517476, 0.8918228279386712, 0.909245122985581, 0.9061962134251291, 0.9020618556701031, 0.8930390492359932, 0.8951406649616368, 0.8899237933954276, 0.9051580698835274, 0.9168110918544194, 0.894420600858369, 0.9142136248948697, 0.9024807527801539, 0.9060631938514091, 0.9065180102915952, 0.9017241379310345, 0.886615515771526, 0.9063573883161512, 0.893136403127715, 0.9062233589087809, 0.9201754385964912, 0.8956228956228957, 0.8850085178875639, 0.8980458793542906, 0.899913718723037, 0.888034188034188, 0.8857388316151202, 0.9004291845493563, 0.9006050129645635, 0.9022108843537415, 0.9065981148243359, 0.8854961832061069, 0.8923728813559322, 0.9099485420240138, 0.89666951323655, 0.9010152284263959, 0.8910638297872341, 0.8965217391304348, 0.8860759493670886, 0.8950042337002541, 0.9104095563139932, 0.911993097497843, 0.8973481608212147, 0.9101123595505618, 0.9067796610169492, 0.91396933560477, 0.8991452991452992, 0.8780276816608996, 0.8837412587412588, 0.9026701119724375, 0.8948261238337574, 0.8831168831168831, 0.9215017064846417, 0.9140154772141015, 0.9003436426116839, 0.902542372881356, 0.8955349620893007, 0.9029209621993127, 0.9010238907849829, 0.8983911939034717, 0.8841567291311755, 0.8980291345329906, 0.8978540772532189, 0.9196581196581196, 0.9062233589087809, 0.8953191489361703, 0.8987341772151899, 0.9054054054054054, 0.9098786828422877, 0.8905982905982905, 0.9033391915641477, 0.893760539629005, 0.9088586030664395, 0.9097162510748066, 0.8983492615117289, 0.9023972602739726, 0.8921901528013583, 0.9036458333333334, 0.8994132439228835, 0.9037162162162162, 0.8994800693240901, 0.9120409906063194, 0.908541846419327, 0.9005059021922428, 0.9011177987962167, 0.897196261682243, 0.9132302405498282, 0.905852417302799, 0.9028716216216216, 0.8848080133555927, 0.8910638297872341, 0.907075873827792, 0.9090113735783028, 0.9031986531986532, 0.8808911739502999, 0.8922413793103449, 0.8988095238095238, 0.8908145580589255, 0.8896434634974533, 0.910941475826972, 0.8954081632653061, 0.8875638841567292, 0.8945111492281304, 0.9107744107744108, 0.9057412167952014, 0.8906779661016949, 0.898981324278438, 0.9096283783783784, 0.9028374892519346, 0.9064625850340136, 0.9060631938514091, 0.8878260869565218, 0.896551724137931, 0.9036658141517476, 0.8926116838487973, 0.8814563928873835, 0.8978540772532189, 0.8719298245614036, 0.8964624676445211, 0.8945548833189283, 0.9060118543607113, 0.8964346349745331, 0.8851756640959726, 0.8912671232876712, 0.9153122326775022, 0.9042277825711821, 0.913718723037101, 0.9003378378378378, 0.8848122866894198, 0.8876306620209059, 0.8964927288280582, 0.9060344827586206, 0.9031171019376579, 0.8965224766751484, 0.9053941908713693, 0.926271186440678, 0.8996539792387543, 0.902502157031924, 0.9096283783783784, 0.9180187873612298, 0.8706677937447168, 0.9057724957555179, 0.8980291345329906, 0.8941574936494496, 0.8997451146983857, 0.9047619047619048, 0.9013722126929674, 0.909704641350211, 0.8974137931034483, 0.89748045178106, 0.9128205128205128, 0.9025862068965518, 0.9026473099914603, 0.8853893263342082, 0.8993055555555556, 0.8871527777777778, 0.8832618025751073, 0.9012027491408935, 0.8915871639202082, 0.8975444538526672, 0.9012765957446809, 0.9045183290707587, 0.9029787234042553, 0.8836023789294817, 0.8999144568006844, 0.909404659188956, 0.9042735042735043, 0.9058219178082192, 0.8981723237597912, 0.9049621530698065, 0.9115646258503401, 0.9016115351993215, 0.89419795221843, 0.8995708154506438, 0.8818493150684932, 0.9054170249355116, 0.8908629441624365, 0.9021459227467811, 0.9023372287145242, 0.8834618680377035, 0.8928877463581834, 0.9085470085470085, 0.9123404255319149, 0.9044368600682594, 0.8930075821398483, 0.897172236503856, 0.9071367153912295, 0.896551724137931, 0.8935622317596567, 0.9018771331058021, 0.8917748917748918, 0.9161016949152543, 0.9026701119724375, 0.8892645815722738, 0.8937823834196891, 0.9121909633418585, 0.8984771573604061, 0.894874022589053, 0.8733850129198967, 0.9099405267629567, 0.9053708439897699, 0.9036144578313253, 0.8934010152284264, 0.9042277825711821, 0.8904923599320883, 0.882303132938188, 0.8970212765957447, 0.8887000849617672, 0.90995670995671, 0.9128949615713066, 0.9090128755364807, 0.8994032395566922, 0.9010327022375215, 0.8946459412780656, 0.8984771573604061, 0.8758620689655172, 0.9036777583187391, 0.8976784178847808, 0.9110350727117195, 0.8928571428571429, 0.903035413153457, 0.910025706940874, 0.8974358974358975, 0.8884192730346576, 0.909556313993174, 0.8827004219409282, 0.911986588432523, 0.9024179620034543, 0.9136752136752136, 0.9056603773584906, 0.9078947368421053, 0.8863247863247863, 0.9105760963026656, 0.9078380706287683, 0.9102455546147333, 0.8914529914529915, 0.883061049011178, 0.897196261682243, 0.9141630901287554, 0.8943781942078365, 0.8924825174825175, 0.8994932432432432, 0.9128949615713066, 0.9032815198618307, 0.8962510897994769, 0.9083629893238434, 0.9006050129645635, 0.9003407155025553, 0.8939779474130619, 0.882996632996633, 0.9066780821917808, 0.9015846538782318, 0.9027538726333907, 0.8886010362694301, 0.8991228070175439, 0.8968804159445407, 0.8955857385398981, 0.8989637305699482, 0.8950042337002541, 0.9049657534246576, 0.9094827586206896, 0.9056603773584906, 0.9026933101650738, 0.8939264328485885, 0.9141370338248048, 0.8954970263381479, 0.9082412914188616, 0.9001721170395869, 0.9020442930153322, 0.893136403127715, 0.9011082693947144, 0.8970212765957447, 0.8962585034013606, 0.9028374892519346, 0.8900255754475703, 0.8950086058519794, 0.9060118543607113, 0.8968804159445407, 0.8900343642611683, 0.8980121002592912, 0.8915254237288136, 0.8945111492281304, 0.8904347826086957, 0.8897569444444444, 0.893136403127715, 0.9015979814970564, 0.9033333333333333, 0.9083904109589042, 0.8998302207130731, 0.903364969801553, 0.896969696969697, 0.8823529411764706, 0.8938356164383562, 0.9084745762711864, 0.8955479452054794, 0.8952380952380953, 0.8994845360824743, 0.8835034013605442, 0.8963466440101954, 0.8949615713065756, 0.9191238416175231, 0.9045996592844975, 0.8966977138018628, 0.9117147707979627, 0.9048865619546248, 0.8951342281879194, 0.89748045178106, 0.9007633587786259, 0.8882252559726962, 0.8983050847457628, 0.8809318377911993, 0.8929173693086003, 0.8890799656061908, 0.9058721934369602, 0.903862660944206, 0.9172995780590717, 0.896845694799659, 0.9079861111111112, 0.9004291845493563, 0.902376910016978, 0.9014443500424809, 0.8793542905692439, 0.8904923599320883, 0.9002535925612849, 0.8766066838046273, 0.8980458793542906, 0.8968723584108199, 0.9125636672325976, 0.8970331588132635, 0.9009474590869939, 0.8825042881646655, 0.8928877463581834, 0.9019947961838681, 0.8922413793103449, 0.9033898305084745, 0.9066551426101987, 0.8956228956228957, 0.898876404494382, 0.8946917808219178, 0.903035413153457, 0.892436974789916, 0.8970464135021097, 0.8980458793542906, 0.896611642050391, 0.9187339606501284, 0.9217540842648323, 0.8940677966101694, 0.9019947961838681, 0.9011082693947144, 0.9072961373390558, 0.8967576791808873, 0.9091688089117395, 0.8950511945392492, 0.9030874785591767, 0.8981481481481481, 0.9022939677145284, 0.9054054054054054, 0.9, 0.9083191850594228, 0.8992248062015504, 0.8885017421602788, 0.8981164383561644, 0.9002557544757033, 0.9000868809730669, 0.9093988145639289, 0.8962264150943396, 0.9056924384027187, 0.9075993091537133, 0.9148397976391232, 0.8955996548748921, 0.9153976311336718, 0.8900432900432901, 0.9030612244897959, 0.9051282051282051, 0.8971088435374149, 0.9100436681222708, 0.9048027444253859, 0.8911055694098088, 0.8953098827470687, 0.9048428207306712, 0.8907849829351536, 0.8956896551724138, 0.9236111111111112, 0.8914930555555556, 0.9001706484641638, 0.8921484037963762, 0.9029787234042553, 0.8986371379897785, 0.9022108843537415, 0.8994845360824743, 0.9002557544757033, 0.9108658743633277, 0.8875536480686695, 0.9030874785591767, 0.8960817717206133, 0.9054514480408858, 0.9077328646748682, 0.8899237933954276, 0.8888888888888888, 0.9007765314926661, 0.9028871391076115, 0.8915254237288136, 0.8873949579831932, 0.8997429305912596, 0.8976982097186701, 0.8845500848896435, 0.9005059021922428, 0.8967576791808873, 0.9000853970964987, 0.8961038961038961, 0.889351081530782, 0.8875638841567292, 0.9002579535683577, 0.883304940374787, 0.9067579127459366, 0.9000861326442722, 0.8991666666666667, 0.8895497026338148, 0.8993928881179531, 0.8907849829351536, 0.9011274934952298, 0.9016253207869974, 0.8996539792387543, 0.8830059777967549, 0.903747870528109, 0.902928870292887, 0.9061433447098977, 0.9010327022375215, 0.9112271540469974, 0.896611642050391, 0.8845166809238666, 0.9050847457627119, 0.9107296137339056, 0.8870967741935484, 0.8868085106382979, 0.8996598639455783, 0.9097872340425532, 0.9136752136752136, 0.8912489379779099, 0.8960352422907489, 0.8964624676445211, 0.9084628670120898, 0.8847457627118644, 0.910267471958585, 0.8955857385398981, 0.9027538726333907, 0.8943722943722944, 0.9147627416520211, 0.8948717948717949, 0.8967254408060453, 0.9165942658557776, 0.9005998286203942, 0.9113384484228474, 0.903747870528109, 0.8991379310344828, 0.8996598639455783, 0.901541095890411, 0.8918918918918919, 0.8919831223628693, 0.907439446366782, 0.8920308483290489, 0.8994032395566922, 0.8988666085440279, 0.8812392426850258, 0.8929188255613126, 0.9047619047619048, 0.9097162510748066, 0.8896492728828058, 0.9067579127459366, 0.9122957867583835, 0.8949615713065756, 0.9060118543607113, 0.8936170212765957, 0.9017241379310345, 0.8955479452054794, 0.8901098901098901, 0.9011725293132329, 0.8872881355932203, 0.9037656903765691, 0.908541846419327, 0.8935064935064935, 0.9128949615713066, 0.9030303030303031, 0.9011177987962167, 0.9042821158690176, 0.9100436681222708, 0.9037656903765691, 0.8957627118644068, 0.9037294015611448, 0.884318766066838, 0.8954970263381479, 0.9016115351993215, 0.8890799656061908, 0.9101221640488656, 0.8945578231292517, 0.8979416809605489, 0.8953386103781882, 0.890625, 0.9023136246786633, 0.8914728682170543, 0.9009393680614859, 0.8967851099830795, 0.8977367979882649, 0.9120689655172414, 0.9076655052264808, 0.902127659574468, 0.8948261238337574, 0.9158163265306123, 0.9018612521150592, 0.8989637305699482, 0.883248730964467, 0.8945518453427065, 0.916030534351145, 0.8887015177065767, 0.9089347079037801, 0.9064377682403434, 0.9023569023569024, 0.8917089678510999, 0.8916382252559727, 0.904639175257732, 0.9052901023890785, 0.8998287671232876, 0.9121447028423773, 0.9148020654044751, 0.9032534246575342, 0.8950042337002541, 0.9, 0.9080944350758853, 0.9037974683544304, 0.8928877463581834, 0.8930075821398483, 0.8899563318777293, 0.8911739502999143, 0.9080068143100511, 0.8982035928143712, 0.8883205456095482, 0.903143585386576, 0.8977176669484361, 0.8879310344827587, 0.886986301369863, 0.8933217692974849, 0.893526405451448, 0.9014321819713563, 0.9038297872340425, 0.8956089478044739, 0.9161727349703641, 0.8916595012897678, 0.8846480067854113, 0.8814691151919867, 0.8942807625649913, 0.9053254437869822, 0.8808114961961115, 0.9045571797076526, 0.8908145580589255, 0.902229845626072, 0.8927335640138409, 0.9118150684931506, 0.9181034482758621, 0.9060052219321149, 0.8955094991364422, 0.8878424657534246, 0.9042179261862917, 0.899067005937235, 0.8857388316151202, 0.9112627986348123, 0.9061707523245984, 0.9067579127459366, 0.8939655172413793, 0.9080851063829787, 0.8963730569948186, 0.8943781942078365, 0.8907056798623064, 0.90042194092827, 0.9094754653130288, 0.9026248941574937, 0.88504753673293, 0.907035175879397, 0.8951890034364262, 0.9045608108108109, 0.9025641025641026, 0.9018771331058021, 0.9036144578313253, 0.8894601542416453, 0.918825561312608, 0.9110535405872193, 0.8951890034364262, 0.8858131487889274, 0.9003466204506065, 0.8918918918918919, 0.8994032395566922, 0.9028374892519346, 0.8917748917748918, 0.9123102866779089, 0.896969696969697, 0.8988860325621251, 0.9046808510638298, 0.8978723404255319, 0.8956372968349017, 0.8982338099243061, 0.8856655290102389, 0.8970588235294118, 0.9004255319148936, 0.8976510067114094, 0.9158716392020815, 0.8982905982905983, 0.9100840336134454, 0.8999129677980853, 0.8863443596268024, 0.9013100436681223, 0.8859060402684564, 0.9002557544757033, 0.9043927648578811, 0.8947368421052632, 0.8819503849443969, 0.882201203783319, 0.9061433447098977, 0.9071986123156982, 0.8949181739879414, 0.9065656565656566, 0.9007698887938409, 0.908541846419327, 0.901213171577123, 0.8936905790838375, 0.8935622317596567, 0.8966977138018628, 0.9001751313485113, 0.8950988822012038, 0.8981880931837791, 0.9056603773584906, 0.8948717948717949, 0.9152397260273972, 0.8839966130397968, 0.8970588235294118, 0.8873835732430144, 0.8995670995670996, 0.9092465753424658, 0.8739279588336192, 0.8878424657534246, 0.9071550255536627, 0.8770281810418445, 0.8902333621434745, 0.9076271186440678, 0.9012027491408935, 0.9168808911739503, 0.8961702127659574, 0.8878504672897196, 0.877568493150685, 0.8873602751504729, 0.8939655172413793, 0.9146551724137931]\n",
            "sp: [0.887668918918919, 0.9027303754266212, 0.8889837745516652, 0.9025862068965518, 0.9058823529411765, 0.8832618025751073, 0.8920741989881956, 0.9004255319148936, 0.9080756013745704, 0.906896551724138, 0.8958155422715628, 0.9059613769941226, 0.9036144578313253, 0.9080168776371308, 0.8985507246376812, 0.8915456874466268, 0.8962264150943396, 0.8981001727115717, 0.9027538726333907, 0.905254091300603, 0.909245122985581, 0.9139966273187183, 0.9093242087254063, 0.9018456375838926, 0.8956372968349017, 0.9027303754266212, 0.9046413502109705, 0.9112426035502958, 0.8928877463581834, 0.8961702127659574, 0.9017933390264731, 0.8927659574468085, 0.8982338099243061, 0.9102564102564102, 0.9138513513513513, 0.9038961038961039, 0.9059024807527801, 0.8934356351236147, 0.9148375768217735, 0.8957795004306632, 0.9016115351993215, 0.8968185726569218, 0.9180187873612298, 0.9179487179487179, 0.8949181739879414, 0.8989637305699482, 0.9110535405872193, 0.8941076003415884, 0.9012027491408935, 0.8958509737510584, 0.9042735042735043, 0.8966101694915254, 0.8998287671232876, 0.8934010152284264, 0.8980291345329906, 0.8900432900432901, 0.8994032395566922, 0.8742463393626184, 0.8942065491183879, 0.8900432900432901, 0.8984771573604061, 0.896943231441048, 0.8967576791808873, 0.900418410041841, 0.9018771331058021, 0.8933107535986452, 0.8864027538726333, 0.9001677852348994, 0.8987012987012987, 0.9073593073593074, 0.8966386554621849, 0.902127659574468, 0.9037294015611448, 0.897370653095844, 0.913527397260274, 0.8812709030100334, 0.9138225255972696, 0.9143101970865467, 0.8894645941278065, 0.9180743243243243, 0.8998287671232876, 0.8842832469775475, 0.8931955211024979, 0.9105902777777778, 0.9057724957555179, 0.896845694799659, 0.9157254561251086, 0.8813559322033898, 0.9058219178082192, 0.9085520745131245, 0.9059322033898305, 0.8817480719794345, 0.9100346020761245, 0.8907563025210085, 0.9072961373390558, 0.9086206896551724, 0.9159592529711376, 0.8905047048759623, 0.9005190311418685, 0.9018932874354562, 0.9021459227467811, 0.8979933110367893, 0.8932291666666666, 0.9067357512953368, 0.8904923599320883, 0.8945111492281304, 0.9056122448979592, 0.9097872340425532, 0.8956228956228957, 0.9042735042735043, 0.8945548833189283, 0.9031979256698358, 0.888695652173913, 0.8994082840236687, 0.8926116838487973, 0.8853721129170231, 0.8955857385398981, 0.9031705227077977, 0.8937977909940527, 0.8945147679324894, 0.8831932773109243, 0.9041095890410958, 0.8974358974358975, 0.8946925021061499, 0.897822445561139, 0.90770533446232, 0.887668918918919, 0.8966977138018628, 0.8999151823579304, 0.9032534246575342, 0.8874570446735395, 0.8973913043478261, 0.9034188034188034, 0.8863443596268024, 0.8946474086661003, 0.8963730569948186, 0.8993055555555556, 0.9117147707979627, 0.9033942558746736, 0.8944636678200693, 0.892527287993283, 0.8920308483290489, 0.8823529411764706, 0.9029535864978903, 0.8963093145869947, 0.8947368421052632, 0.8940170940170941, 0.9040622299049266, 0.8900343642611683, 0.9028960817717206, 0.909710391822828, 0.8939264328485885, 0.902376910016978, 0.9203463203463204, 0.8957627118644068, 0.9070567986230637, 0.9045571797076526, 0.8864628820960698, 0.8976784178847808, 0.9130434782608695, 0.8889845094664371, 0.8900432900432901, 0.9131175468483816, 0.8928270042194093, 0.9072512647554806, 0.9020618556701031, 0.9072961373390558, 0.8993115318416524, 0.913718723037101, 0.8844519966015293, 0.8977469670710572, 0.8931623931623932, 0.9027538726333907, 0.8897502153316107, 0.8975021533161068, 0.9029787234042553, 0.8849706129303107, 0.8987124463519314, 0.8983050847457628, 0.9030874785591767, 0.905511811023622, 0.8914728682170543, 0.8957106812447435, 0.8982608695652174, 0.8842832469775475, 0.8851063829787233, 0.9016681299385426, 0.894781864841745, 0.8939393939393939, 0.8952299829642248, 0.9005190311418685, 0.902502157031924, 0.9018612521150592, 0.8787361229718189, 0.8959931798806479, 0.903364969801553, 0.8800690250215704, 0.9026473099914603, 0.9019776440240757, 0.8987993138936535, 0.9147627416520211, 0.9052013422818792, 0.9054640069384216, 0.8824034334763948, 0.9005102040816326, 0.885589519650655, 0.8908780903665814, 0.9103448275862069, 0.9075194468452895, 0.9009556907037359, 0.9028132992327366, 0.9061685490877498, 0.8999151823579304, 0.9020100502512562, 0.9046413502109705, 0.9077834179357022, 0.9060913705583756, 0.8993231810490694, 0.9050042408821035, 0.8967851099830795, 0.9058219178082192, 0.9040274207369323, 0.898981324278438, 0.8951817413355875, 0.8865800865800866, 0.9023136246786633, 0.8952299829642248, 0.8967297762478486, 0.8985507246376812, 0.8902439024390244, 0.8908629441624365, 0.8992379339542761, 0.8913412563667232, 0.9045138888888888, 0.9075342465753424, 0.8949615713065756, 0.8964912280701754, 0.8913601368691189, 0.8925193465176269, 0.9042016806722689, 0.8972602739726028, 0.9073756432246999, 0.891961970613656, 0.904639175257732, 0.9157351676698194, 0.8982035928143712, 0.8984771573604061, 0.9069171648163963, 0.8980458793542906, 0.8911392405063291, 0.8936535162950258, 0.8943781942078365, 0.9176570458404074, 0.8985507246376812, 0.8960817717206133, 0.9086993970714901, 0.9022491349480969, 0.901541095890411, 0.9108061749571184, 0.8987124463519314, 0.9022939677145284, 0.9090909090909091, 0.8920800696257616, 0.8846480067854113, 0.9017094017094017, 0.9185946872322194, 0.8796928327645052, 0.90770533446232, 0.9121160409556314, 0.893344709897611, 0.8928877463581834, 0.9137489325362937, 0.9056924384027187, 0.9028960817717206, 0.9113043478260869, 0.8914141414141414, 0.8932203389830509, 0.9036144578313253, 0.8980623420387531, 0.8877374784110535, 0.906896551724138, 0.8959044368600683, 0.9012875536480687, 0.9002557544757033, 0.9094827586206896, 0.8854254422914911, 0.8905047048759623, 0.8760683760683761, 0.9129332206255283, 0.8966101694915254, 0.8920552677029361, 0.9049265341400173, 0.8988954970263382, 0.9017933390264731, 0.893526405451448, 0.8898305084745762, 0.9025862068965518, 0.8972125435540069, 0.8861859252823632, 0.8936170212765957, 0.9019947961838681, 0.897302001740644, 0.9037974683544304, 0.8874570446735395, 0.8997429305912596, 0.8982758620689655, 0.8955479452054794, 0.8965217391304348, 0.9167389418907199, 0.8886054421768708, 0.8889845094664371, 0.9036973344797936, 0.8871662360034454, 0.898972602739726, 0.9113384484228474, 0.8970212765957447, 0.9145516074450084, 0.896404109589041, 0.9018245004344049, 0.894005212858384, 0.8960817717206133, 0.903862660944206, 0.9001692047377327, 0.8999158957106812, 0.9079061685490878, 0.8999158957106812, 0.8950930626057529, 0.9005998286203942, 0.8911739502999143, 0.8976784178847808, 0.9074550128534704, 0.8949615713065756, 0.8875739644970414, 0.8870151770657673, 0.9072961373390558, 0.9010152284263959, 0.8917306052855924, 0.9076133447390933, 0.9001692047377327, 0.8977853492333902, 0.8957795004306632, 0.8947811447811448, 0.9122362869198313, 0.9045183290707587, 0.8956228956228957, 0.9021645021645022, 0.9013490725126475, 0.9155172413793103, 0.9080068143100511, 0.8978540772532189, 0.9036658141517476, 0.8918228279386712, 0.909245122985581, 0.9061962134251291, 0.9020618556701031, 0.8930390492359932, 0.8951406649616368, 0.8899237933954276, 0.9051580698835274, 0.9168110918544194, 0.894420600858369, 0.9142136248948697, 0.9024807527801539, 0.9060631938514091, 0.9065180102915952, 0.9017241379310345, 0.886615515771526, 0.9063573883161512, 0.893136403127715, 0.9062233589087809, 0.9201754385964912, 0.8956228956228957, 0.8850085178875639, 0.8980458793542906, 0.899913718723037, 0.888034188034188, 0.8857388316151202, 0.9004291845493563, 0.9006050129645635, 0.9022108843537415, 0.9065981148243359, 0.8854961832061069, 0.8923728813559322, 0.9099485420240138, 0.89666951323655, 0.9010152284263959, 0.8910638297872341, 0.8965217391304348, 0.8860759493670886, 0.8950042337002541, 0.9104095563139932, 0.911993097497843, 0.8973481608212147, 0.9101123595505618, 0.9067796610169492, 0.91396933560477, 0.8991452991452992, 0.8780276816608996, 0.8837412587412588, 0.9026701119724375, 0.8948261238337574, 0.8831168831168831, 0.9215017064846417, 0.9140154772141015, 0.9003436426116839, 0.902542372881356, 0.8955349620893007, 0.9029209621993127, 0.9010238907849829, 0.8983911939034717, 0.8841567291311755, 0.8980291345329906, 0.8978540772532189, 0.9196581196581196, 0.9062233589087809, 0.8953191489361703, 0.8987341772151899, 0.9054054054054054, 0.9098786828422877, 0.8905982905982905, 0.9033391915641477, 0.893760539629005, 0.9088586030664395, 0.9097162510748066, 0.8983492615117289, 0.9023972602739726, 0.8921901528013583, 0.9036458333333334, 0.8994132439228835, 0.9037162162162162, 0.8994800693240901, 0.9120409906063194, 0.908541846419327, 0.9005059021922428, 0.9011177987962167, 0.897196261682243, 0.9132302405498282, 0.905852417302799, 0.9028716216216216, 0.8848080133555927, 0.8910638297872341, 0.907075873827792, 0.9090113735783028, 0.9031986531986532, 0.8808911739502999, 0.8922413793103449, 0.8988095238095238, 0.8908145580589255, 0.8896434634974533, 0.910941475826972, 0.8954081632653061, 0.8875638841567292, 0.8945111492281304, 0.9107744107744108, 0.9057412167952014, 0.8906779661016949, 0.898981324278438, 0.9096283783783784, 0.9028374892519346, 0.9064625850340136, 0.9060631938514091, 0.8878260869565218, 0.896551724137931, 0.9036658141517476, 0.8926116838487973, 0.8814563928873835, 0.8978540772532189, 0.8719298245614036, 0.8964624676445211, 0.8945548833189283, 0.9060118543607113, 0.8964346349745331, 0.8851756640959726, 0.8912671232876712, 0.9153122326775022, 0.9042277825711821, 0.913718723037101, 0.9003378378378378, 0.8848122866894198, 0.8876306620209059, 0.8964927288280582, 0.9060344827586206, 0.9031171019376579, 0.8965224766751484, 0.9053941908713693, 0.926271186440678, 0.8996539792387543, 0.902502157031924, 0.9096283783783784, 0.9180187873612298, 0.8706677937447168, 0.9057724957555179, 0.8980291345329906, 0.8941574936494496, 0.8997451146983857, 0.9047619047619048, 0.9013722126929674, 0.909704641350211, 0.8974137931034483, 0.89748045178106, 0.9128205128205128, 0.9025862068965518, 0.9026473099914603, 0.8853893263342082, 0.8993055555555556, 0.8871527777777778, 0.8832618025751073, 0.9012027491408935, 0.8915871639202082, 0.8975444538526672, 0.9012765957446809, 0.9045183290707587, 0.9029787234042553, 0.8836023789294817, 0.8999144568006844, 0.909404659188956, 0.9042735042735043, 0.9058219178082192, 0.8981723237597912, 0.9049621530698065, 0.9115646258503401, 0.9016115351993215, 0.89419795221843, 0.8995708154506438, 0.8818493150684932, 0.9054170249355116, 0.8908629441624365, 0.9021459227467811, 0.9023372287145242, 0.8834618680377035, 0.8928877463581834, 0.9085470085470085, 0.9123404255319149, 0.9044368600682594, 0.8930075821398483, 0.897172236503856, 0.9071367153912295, 0.896551724137931, 0.8935622317596567, 0.9018771331058021, 0.8917748917748918, 0.9161016949152543, 0.9026701119724375, 0.8892645815722738, 0.8937823834196891, 0.9121909633418585, 0.8984771573604061, 0.894874022589053, 0.8733850129198967, 0.9099405267629567, 0.9053708439897699, 0.9036144578313253, 0.8934010152284264, 0.9042277825711821, 0.8904923599320883, 0.882303132938188, 0.8970212765957447, 0.8887000849617672, 0.90995670995671, 0.9128949615713066, 0.9090128755364807, 0.8994032395566922, 0.9010327022375215, 0.8946459412780656, 0.8984771573604061, 0.8758620689655172, 0.9036777583187391, 0.8976784178847808, 0.9110350727117195, 0.8928571428571429, 0.903035413153457, 0.910025706940874, 0.8974358974358975, 0.8884192730346576, 0.909556313993174, 0.8827004219409282, 0.911986588432523, 0.9024179620034543, 0.9136752136752136, 0.9056603773584906, 0.9078947368421053, 0.8863247863247863, 0.9105760963026656, 0.9078380706287683, 0.9102455546147333, 0.8914529914529915, 0.883061049011178, 0.897196261682243, 0.9141630901287554, 0.8943781942078365, 0.8924825174825175, 0.8994932432432432, 0.9128949615713066, 0.9032815198618307, 0.8962510897994769, 0.9083629893238434, 0.9006050129645635, 0.9003407155025553, 0.8939779474130619, 0.882996632996633, 0.9066780821917808, 0.9015846538782318, 0.9027538726333907, 0.8886010362694301, 0.8991228070175439, 0.8968804159445407, 0.8955857385398981, 0.8989637305699482, 0.8950042337002541, 0.9049657534246576, 0.9094827586206896, 0.9056603773584906, 0.9026933101650738, 0.8939264328485885, 0.9141370338248048, 0.8954970263381479, 0.9082412914188616, 0.9001721170395869, 0.9020442930153322, 0.893136403127715, 0.9011082693947144, 0.8970212765957447, 0.8962585034013606, 0.9028374892519346, 0.8900255754475703, 0.8950086058519794, 0.9060118543607113, 0.8968804159445407, 0.8900343642611683, 0.8980121002592912, 0.8915254237288136, 0.8945111492281304, 0.8904347826086957, 0.8897569444444444, 0.893136403127715, 0.9015979814970564, 0.9033333333333333, 0.9083904109589042, 0.8998302207130731, 0.903364969801553, 0.896969696969697, 0.8823529411764706, 0.8938356164383562, 0.9084745762711864, 0.8955479452054794, 0.8952380952380953, 0.8994845360824743, 0.8835034013605442, 0.8963466440101954, 0.8949615713065756, 0.9191238416175231, 0.9045996592844975, 0.8966977138018628, 0.9117147707979627, 0.9048865619546248, 0.8951342281879194, 0.89748045178106, 0.9007633587786259, 0.8882252559726962, 0.8983050847457628, 0.8809318377911993, 0.8929173693086003, 0.8890799656061908, 0.9058721934369602, 0.903862660944206, 0.9172995780590717, 0.896845694799659, 0.9079861111111112, 0.9004291845493563, 0.902376910016978, 0.9014443500424809, 0.8793542905692439, 0.8904923599320883, 0.9002535925612849, 0.8766066838046273, 0.8980458793542906, 0.8968723584108199, 0.9125636672325976, 0.8970331588132635, 0.9009474590869939, 0.8825042881646655, 0.8928877463581834, 0.9019947961838681, 0.8922413793103449, 0.9033898305084745, 0.9066551426101987, 0.8956228956228957, 0.898876404494382, 0.8946917808219178, 0.903035413153457, 0.892436974789916, 0.8970464135021097, 0.8980458793542906, 0.896611642050391, 0.9187339606501284, 0.9217540842648323, 0.8940677966101694, 0.9019947961838681, 0.9011082693947144, 0.9072961373390558, 0.8967576791808873, 0.9091688089117395, 0.8950511945392492, 0.9030874785591767, 0.8981481481481481, 0.9022939677145284, 0.9054054054054054, 0.9, 0.9083191850594228, 0.8992248062015504, 0.8885017421602788, 0.8981164383561644, 0.9002557544757033, 0.9000868809730669, 0.9093988145639289, 0.8962264150943396, 0.9056924384027187, 0.9075993091537133, 0.9148397976391232, 0.8955996548748921, 0.9153976311336718, 0.8900432900432901, 0.9030612244897959, 0.9051282051282051, 0.8971088435374149, 0.9100436681222708, 0.9048027444253859, 0.8911055694098088, 0.8953098827470687, 0.9048428207306712, 0.8907849829351536, 0.8956896551724138, 0.9236111111111112, 0.8914930555555556, 0.9001706484641638, 0.8921484037963762, 0.9029787234042553, 0.8986371379897785, 0.9022108843537415, 0.8994845360824743, 0.9002557544757033, 0.9108658743633277, 0.8875536480686695, 0.9030874785591767, 0.8960817717206133, 0.9054514480408858, 0.9077328646748682, 0.8899237933954276, 0.8888888888888888, 0.9007765314926661, 0.9028871391076115, 0.8915254237288136, 0.8873949579831932, 0.8997429305912596, 0.8976982097186701, 0.8845500848896435, 0.9005059021922428, 0.8967576791808873, 0.9000853970964987, 0.8961038961038961, 0.889351081530782, 0.8875638841567292, 0.9002579535683577, 0.883304940374787, 0.9067579127459366, 0.9000861326442722, 0.8991666666666667, 0.8895497026338148, 0.8993928881179531, 0.8907849829351536, 0.9011274934952298, 0.9016253207869974, 0.8996539792387543, 0.8830059777967549, 0.903747870528109, 0.902928870292887, 0.9061433447098977, 0.9010327022375215, 0.9112271540469974, 0.896611642050391, 0.8845166809238666, 0.9050847457627119, 0.9107296137339056, 0.8870967741935484, 0.8868085106382979, 0.8996598639455783, 0.9097872340425532, 0.9136752136752136, 0.8912489379779099, 0.8960352422907489, 0.8964624676445211, 0.9084628670120898, 0.8847457627118644, 0.910267471958585, 0.8955857385398981, 0.9027538726333907, 0.8943722943722944, 0.9147627416520211, 0.8948717948717949, 0.8967254408060453, 0.9165942658557776, 0.9005998286203942, 0.9113384484228474, 0.903747870528109, 0.8991379310344828, 0.8996598639455783, 0.901541095890411, 0.8918918918918919, 0.8919831223628693, 0.907439446366782, 0.8920308483290489, 0.8994032395566922, 0.8988666085440279, 0.8812392426850258, 0.8929188255613126, 0.9047619047619048, 0.9097162510748066, 0.8896492728828058, 0.9067579127459366, 0.9122957867583835, 0.8949615713065756, 0.9060118543607113, 0.8936170212765957, 0.9017241379310345, 0.8955479452054794, 0.8901098901098901, 0.9011725293132329, 0.8872881355932203, 0.9037656903765691, 0.908541846419327, 0.8935064935064935, 0.9128949615713066, 0.9030303030303031, 0.9011177987962167, 0.9042821158690176, 0.9100436681222708, 0.9037656903765691, 0.8957627118644068, 0.9037294015611448, 0.884318766066838, 0.8954970263381479, 0.9016115351993215, 0.8890799656061908, 0.9101221640488656, 0.8945578231292517, 0.8979416809605489, 0.8953386103781882, 0.890625, 0.9023136246786633, 0.8914728682170543, 0.9009393680614859, 0.8967851099830795, 0.8977367979882649, 0.9120689655172414, 0.9076655052264808, 0.902127659574468, 0.8948261238337574, 0.9158163265306123, 0.9018612521150592, 0.8989637305699482, 0.883248730964467, 0.8945518453427065, 0.916030534351145, 0.8887015177065767, 0.9089347079037801, 0.9064377682403434, 0.9023569023569024, 0.8917089678510999, 0.8916382252559727, 0.904639175257732, 0.9052901023890785, 0.8998287671232876, 0.9121447028423773, 0.9148020654044751, 0.9032534246575342, 0.8950042337002541, 0.9, 0.9080944350758853, 0.9037974683544304, 0.8928877463581834, 0.8930075821398483, 0.8899563318777293, 0.8911739502999143, 0.9080068143100511, 0.8982035928143712, 0.8883205456095482, 0.903143585386576, 0.8977176669484361, 0.8879310344827587, 0.886986301369863, 0.8933217692974849, 0.893526405451448, 0.9014321819713563, 0.9038297872340425, 0.8956089478044739, 0.9161727349703641, 0.8916595012897678, 0.8846480067854113, 0.8814691151919867, 0.8942807625649913, 0.9053254437869822, 0.8808114961961115, 0.9045571797076526, 0.8908145580589255, 0.902229845626072, 0.8927335640138409, 0.9118150684931506, 0.9181034482758621, 0.9060052219321149, 0.8955094991364422, 0.8878424657534246, 0.9042179261862917, 0.899067005937235, 0.8857388316151202, 0.9112627986348123, 0.9061707523245984, 0.9067579127459366, 0.8939655172413793, 0.9080851063829787, 0.8963730569948186, 0.8943781942078365, 0.8907056798623064, 0.90042194092827, 0.9094754653130288, 0.9026248941574937, 0.88504753673293, 0.907035175879397, 0.8951890034364262, 0.9045608108108109, 0.9025641025641026, 0.9018771331058021, 0.9036144578313253, 0.8894601542416453, 0.918825561312608, 0.9110535405872193, 0.8951890034364262, 0.8858131487889274, 0.9003466204506065, 0.8918918918918919, 0.8994032395566922, 0.9028374892519346, 0.8917748917748918, 0.9123102866779089, 0.896969696969697, 0.8988860325621251, 0.9046808510638298, 0.8978723404255319, 0.8956372968349017, 0.8982338099243061, 0.8856655290102389, 0.8970588235294118, 0.9004255319148936, 0.8976510067114094, 0.9158716392020815, 0.8982905982905983, 0.9100840336134454, 0.8999129677980853, 0.8863443596268024, 0.9013100436681223, 0.8859060402684564, 0.9002557544757033, 0.9043927648578811, 0.8947368421052632, 0.8819503849443969, 0.882201203783319, 0.9061433447098977, 0.9071986123156982, 0.8949181739879414, 0.9065656565656566, 0.9007698887938409, 0.908541846419327, 0.901213171577123, 0.8936905790838375, 0.8935622317596567, 0.8966977138018628, 0.9001751313485113, 0.8950988822012038, 0.8981880931837791, 0.9056603773584906, 0.8948717948717949, 0.9152397260273972, 0.8839966130397968, 0.8970588235294118, 0.8873835732430144, 0.8995670995670996, 0.9092465753424658, 0.8739279588336192, 0.8878424657534246, 0.9071550255536627, 0.8770281810418445, 0.8902333621434745, 0.9076271186440678, 0.9012027491408935, 0.9168808911739503, 0.8961702127659574, 0.8878504672897196, 0.877568493150685, 0.8873602751504729, 0.8939655172413793, 0.9146551724137931]\n",
            "sd_acc: 0.010622963617078833\n",
            "sd_f1: 0.006730872183436696\n",
            "sd_mcc: 0.029662912284688325\n",
            "sd_sn: 0.008708337939712499\n",
            "sd_sp: 0.008708337939712499\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      0.13      0.15       187\n",
            "           1       0.87      0.90      0.88      1169\n",
            "\n",
            "    accuracy                           0.79      1356\n",
            "   macro avg       0.52      0.51      0.51      1356\n",
            "weighted avg       0.77      0.79      0.78      1356\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.010622963617078833, 0.029662912284688325, 0.006730872183436696)"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_lstm = classifier.predict(X_test)\n",
        "predicted_lstm = np.where(predicted_lstm > 0.5, 1, 0)\n",
        "predicted_lstm = np.reshape(predicted_lstm,(len(predicted_lstm),)).astype(int)\n",
        "error_rate(Y_test, predicted_lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gghPVbbuLbqN"
      },
      "source": [
        "### BiLSTM with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-ZqdqeELYEp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNN, Bidirectional, Input, Embedding, LSTM, Dropout, Dense, InputLayer\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.regularizers import l2\n",
        "from sklearn.metrics import make_scorer\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc2u5VPF9ZN_"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z0kkcZp9ZN_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAHT7mSNVGrU"
      },
      "outputs": [],
      "source": [
        "X_train, X_test= train_dataset, test_dataset\n",
        "y_train, y_test = training_labels, testing_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD_Jcu4ST67v"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2z79_qvLZCo"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train[1,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUwEv4vzSISY",
        "outputId": "8b6974cb-0744-42b3-abbc-a816c991e607"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2560, 1)"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Sn7HB60VGrV"
      },
      "outputs": [],
      "source": [
        "Y_train = np.reshape(y_train,(len(y_train),1)).astype(int)\n",
        "Y_test = np.reshape(y_test,(len(y_test),1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JN7ZQUqrWfW8"
      },
      "outputs": [],
      "source": [
        "num_words = 22\n",
        "num_classes = 1\n",
        "n_cv = 3\n",
        "num_hiddens = 1280\n",
        "num_steps = 10\n",
        "num_layers = 1\n",
        "max_length = 2560"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8Q4lB7lDArN"
      },
      "outputs": [],
      "source": [
        "def create_blstm_model1(dropout_rate=0.0, units=50, learning_rate_init=0.001, regularizer=0.0, solver='adam'):\n",
        "    x_input = Input(input_shape)\n",
        "    #emb = Embedding(21, units, input_length=max_length)(x_input)\n",
        "    bi_rnn = Bidirectional(LSTM(units, activity_regularizer=l2(dropout_rate),return_sequences=True))(x_input) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x = Dropout(dropout_rate)(bi_rnn)\n",
        "    bi_rnn2 = Bidirectional(LSTM(units, activity_regularizer=l2(dropout_rate)))(x) #kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
        "    x2 = Dropout(dropout_rate)(bi_rnn2)\n",
        "    x_output = Dense(1, activation='sigmoid')(x2)\n",
        "\n",
        "    model = Model(inputs=x_input, outputs=x_output)\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_init),#solver,#\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "        )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWc9zaH0Oxmh"
      },
      "outputs": [],
      "source": [
        "blstm1 = create_blstm_model1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eOvO9GBOyQo",
        "outputId": "52b12925-b46a-4bb9-d0e4-e2fbe1116fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 2560, 1)]         0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 2560, 100)        20800     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 2560, 100)         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 100)              60400     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,301\n",
            "Trainable params: 81,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "blstm1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp0OAX3B_Q7p"
      },
      "outputs": [],
      "source": [
        "# Early Stopping\n",
        "#es = EarlyStopping(monitor='val_loss', patience=150, verbose=1)\n",
        "\n",
        "#history = blstm1.fit(train_pad, y_train,\n",
        "#                        validation_data=(val_pad, y_val),\n",
        "#                        callbacks=[es],\n",
        "#                        epochs=3, batch_size=256, verbose=1\n",
        "#                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF5onWhjNYEl"
      },
      "outputs": [],
      "source": [
        "#predicted_training_labels = blstm1.predict(train_pad)\n",
        "#predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "#predicted_training_labels = np.reshape(predicted_training_labels,(len(predicted_training_labels),)).astype(int)\n",
        "#error_rate(y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7qRQrGxNg9C"
      },
      "outputs": [],
      "source": [
        "#predicted_testing_labels = blstm1.predict(val_pad)\n",
        "#predicted_testing_labels = np.where(predicted_testing_labels > 0.5, 1, 0)\n",
        "#predicted_testing_labels = np.reshape(predicted_testing_labels,(len(predicted_testing_labels),)).astype(int)\n",
        "#error_rate(y_val, predicted_testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMK08riVVajL",
        "outputId": "746672e6-cb70-4bc1-b0ce-86ca464f2e4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-120-2f1cd1c262b7>:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_blstm_model1, verbose=1, batch_size=256, epochs=3)\n"
          ]
        }
      ],
      "source": [
        "start = time()\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_blstm_model1, verbose=1, batch_size=256, epochs=3)\n",
        "# define parameters and values for grid search\n",
        "\n",
        "parameters = {\n",
        "    'units':[50,],\n",
        "    #'learning_rate_init': [0.001, 0.01],\n",
        "    #'epochs': [2,3,5,10],\n",
        "    'solver':['adam'],\n",
        "    #'dropout_rate':[0.0,0.05, 0.1],\n",
        "    #'regularizer':[0.0,0.05, 0.1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4SgWBn54OyM"
      },
      "outputs": [],
      "source": [
        "metrics = {'accuracy':make_scorer(accuracy_score,greater_is_better=True),'f1':make_scorer(f1_score,greater_is_better=True),'mcc':make_scorer(matthews_corrcoef,greater_is_better=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "y5gZrhg7XrYk",
        "outputId": "5ed861e9-23da-4dee-d0ea-949dcde9baa6"
      },
      "outputs": [
        {
          "ename": "TerminatedWorkerError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-a8f5c1bd1715>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mcc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0;31m# worker traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1732\u001b[0m         \u001b[0;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1734\u001b[0;31m             \u001b[0merror_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m# be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
          ]
        }
      ],
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=parameters, n_jobs=-1, cv=10, scoring=metrics, refit='mcc')\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s34hMuo0Z2w2"
      },
      "outputs": [],
      "source": [
        "classifier = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xmAALc4Z-hd"
      },
      "outputs": [],
      "source": [
        "params = classifier.get_params()\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmF350wmb3Bf"
      },
      "outputs": [],
      "source": [
        "#cv_results = DataFrame(grid.cv_results_)\n",
        "\n",
        "#cv_results[['param_units','param_activation','param_dropout_rate','param_regularizer','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnu0uvNzb3C0"
      },
      "outputs": [],
      "source": [
        "df =pd.DataFrame(grid.cv_results_)\n",
        "new_path = '/content/test.xls'\n",
        "writer = pd.ExcelWriter(new_path, engine='xlsxwriter')\n",
        "df.to_excel('/content/drive/MyDrive/Halophilic/ESM23BBLSTM2.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toJ9ceVVcEVU"
      },
      "outputs": [],
      "source": [
        "predicted_training_labels = classifier.predict(X_train)\n",
        "predicted_training_labels = np.where(predicted_training_labels > 0.5, 1, 0)\n",
        "predicted_training_labels = np.reshape(predicted_training_labels,(len(predicted_training_labels),)).astype(int)\n",
        "error_rate(Y_train, predicted_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRn-66gpcEWu"
      },
      "outputs": [],
      "source": [
        "predicted_blstm = classifier.predict(X_test)\n",
        "predicted_blstm = np.where(predicted_blstm > 0.5, 1, 0)\n",
        "predicted_blstm = np.reshape(predicted_blstm,(len(predicted_blstm),)).astype(int)\n",
        "error_rate(Y_test, predicted_blstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtyKU7eecPix"
      },
      "outputs": [],
      "source": [
        "classes = np.unique(Y_test)\n",
        "\n",
        "confusion_matrix_data = confusion_matrix(Y_test, predicted_blstm, labels=classes)\n",
        "conf_matrix(confusion_matrix_data)\n",
        "confusion_matrix_data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "8eEXVSpeI8Un",
        "UC6sZ0D_kgZj",
        "WWrjbaEbPL8J",
        "as02wxoCAjGs",
        "-tgM9DaT4iGC",
        "08-efAVMAMpe"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}